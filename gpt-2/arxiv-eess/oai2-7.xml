<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T07:01:19Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|6001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1905.01993</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.01993</id><created>2019-04-26</created><authors><author><keyname>Ranwa</keyname><forenames>Al Mallah</forenames></author><author><keyname>Bilal</keyname><forenames>Farooq</forenames></author><author><keyname>Alejandro</keyname><forenames>Quintero</forenames></author></authors><title>Cooperative Evaluation of the Cause of Urban Traffic Congestion via
  Connected Vehicles</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We developed a distributed data mining system to elaborate a decision
concerning the cause of urban traffic congestion via emerging connected vehicle
(CV) technology. We observe this complex phenomena through the interactions
between vehicles exchanging messages via Vehicle to Vehicle (V2V)
communication. Results are based on real-time simulation generated scenarios
extended from the real-world traffic Travel and Activity PAtterns Simulation
(TAPAS) Cologne scenario. We evaluate a Voting Procedure (VP) useful for
obtaining deeper insights using cooperation between vehicles, Belief Functions
(BF) aim at improving representation of information and a Data Association
Technique (DAT) aiming at data mining and extracting the association rules from
the messages exchanged. Methods are tested and compared using a microscopic
urban mobility simulator, SUMO and a network simulator, ns-2, for the
simulation of communication between CVs. Compared to the Back-Propagation
algorithm (BP) extensively used in the past literature, our performance
evaluation shows that the proposed methods enhance the estimation of the cause
of congestion by 48\% for the proposed VP, 58\% for the BF, 71\% for the DAT
and 70\% for \textbeta-DAT. The methods also enhance detection time from 7.09\%
to 10.3\%, and \textbeta-DAT outperforms BP by approximately 1.25\% less false
alarms triggered by the network, which can be significant in the context of
real-time decision making. We show that a market penetration rate between 63\%
and 75\% is enough to ensure satisfactory performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02001</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02001</id><created>2019-05-06</created><updated>2019-05-16</updated><authors><author><keyname>Zhang</keyname><forenames>Xinfeng</forenames></author><author><keyname>Kwong</keyname><forenames>Sam</forenames></author><author><keyname>Kuo</keyname><forenames>C. -C. Jay</forenames></author></authors><title>Compressed Image Quality Assessment Based on Saak Features</title><categories>eess.IV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed image quality assessment plays an important role in image
services, especially in image compression applications, which can be utilized
as a guidance to optimize image processing algorithms. In this paper, we
propose an objective image quality assessment algorithm to measure the quality
of compressed images. The proposed method utilizes a data-driven transform,
Saak (Subspace approximation with augmented kernels), to decompose images into
hierarchical structural feature space. We measure the distortions of Saak
features and accumulate these distortions according to the feature importance
to human visual system. Compared with the state-of-the-art image quality
assessment methods on widely utilized datasets, the proposed method correlates
better with the subjective results. In addition, the proposed methods achieves
more robust results on different datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02061</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02061</id><created>2019-05-06</created><updated>2019-10-19</updated><authors><author><keyname>Shi</keyname><forenames>Xin</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author></authors><title>Estimation of high-dimensional factor models and its application in
  power data analysis</title><categories>stat.AP econ.EM eess.SP</categories><comments>10 pages, submitted to IEEE Trans. Big Data</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In dealing with high-dimensional data, factor models are often used for
reducing dimensions and extracting relevant information. The spectrum of
covariance matrices from power data exhibits two aspects: 1) bulk, which arises
from random noise or fluctuations and 2) spikes, which represents factors
caused by anomaly events. In this paper, we propose a new approach to the
estimation of high-dimensional factor models, minimizing the distance between
the empirical spectral density (ESD) of covariance matrices of the residuals of
power data that are obtained by subtracting principal components and the
limiting spectral density (LSD) from a multiplicative covariance structure
model. The free probability theory (FPT) is used to derive the spectral density
of the multiplicative covariance model, which efficiently solves the
computational difficulties. The proposed approach connects the estimation of
the number of factors to the LSD of covariance matrices of the residuals, which
provides estimators of the number of factors and the correlation structure
information in the residuals. Considering a lot of measurement noise is
contained in the power data and the correlation structure is complex for the
residuals, the approach prefers approaching the ESD of covariance matrices of
the residuals through a multiplicative covariance model, which avoids making
crude assumptions or simplifications on the complex structure of the data.
Theoretical studies show the proposed approach is robust against noise and
sensitive to the presence of weak factors. The synthetic data from IEEE 118-bus
power system is used to validate the effectiveness of the approach.
Furthermore, the application to the analysis of the real-world online
monitoring data in a power grid shows that the estimators in the approach can
be used to indicate the system behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02135</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02135</id><created>2019-04-04</created><authors><author><keyname>Feng</keyname><forenames>Junxi</forenames></author><author><keyname>He</keyname><forenames>Xiaohai</forenames></author><author><keyname>Teng</keyname><forenames>Qizhi</forenames></author><author><keyname>Ren</keyname><forenames>Chao</forenames></author><author><keyname>Chen</keyname><forenames>Honggang</forenames></author><author><keyname>Li</keyname><forenames>Yang</forenames></author></authors><title>Accurate and Fast reconstruction of Porous Media from Extremely Limited
  Information Using Conditional Generative Adversarial Network</title><categories>eess.IV cs.CE cs.CV physics.data-an</categories><journal-ref>Phys. Rev. E 100, 033308 (2019)</journal-ref><doi>10.1103/PhysRevE.100.033308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Porous media are ubiquitous in both nature and engineering applications, thus
their modelling and understanding is of vital importance. In contrast to direct
acquisition of three-dimensional (3D) images of such medium, obtaining its
sub-region (s) like two-dimensional (2D) images or several small areas could be
much feasible. Therefore, reconstructing whole images from the limited
information is a primary technique in such cases. Specially, in practice the
given data cannot generally be determined by users and may be incomplete or
partially informed, thus making existing reconstruction methods inaccurate or
even ineffective. To overcome this shortcoming, in this study we proposed a
deep learning-based framework for reconstructing full image from its much
smaller sub-area(s). Particularly, conditional generative adversarial network
(CGAN) is utilized to learn the mapping between input (partial image) and
output (full image). To preserve the reconstruction accuracy, two simple but
effective objective functions are proposed and then coupled with the other two
functions to jointly constrain the training procedure. Due to the inherent
essence of this ill-posed problem, a Gaussian noise is introduced for producing
reconstruction diversity, thus allowing for providing multiple candidate
outputs. Extensively tested on a variety of porous materials and demonstrated
by both visual inspection and quantitative comparison, the method is shown to
be accurate, stable yet fast ($\sim0.08s$ for a $128 \times 128$ image
reconstruction). We highlight that the proposed approach can be readily
extended, such as incorporating any user-define conditional data and an
arbitrary number of object functions into reconstruction, and being coupled
with other reconstruction methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02178</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02178</id><created>2019-05-06</created><authors><author><keyname>Buyukates</keyname><forenames>Baturalp</forenames></author><author><keyname>Soysal</keyname><forenames>Alkan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Age of Information Scaling in Large Networks with Hierarchical
  Cooperation</title><categories>cs.IT cs.NI eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given $n$ randomly located source-destination (S-D) pairs on a fixed area
network that want to communicate with each other, we study the age of
information with a particular focus on its scaling as the network size $n$
grows. We propose a three-phase transmission scheme that utilizes
\textit{hierarchical cooperation} between users along with \textit{mega update
packets} and show that an average age scaling of $O(n^{\alpha(h)}\log n)$
per-user is achievable where $h$ denotes the number of hierarchy levels and
$\alpha(h) = \frac{1}{3\cdot2^h+1}$ which tends to $0$ as $h$ increases such
that asymptotically average age scaling of the proposed scheme is $O(\log n)$.
To the best of our knowledge, this is the best average age scaling result in a
status update system with multiple S-D pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02196</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02196</id><created>2019-05-04</created><authors><author><keyname>Hu</keyname><forenames>Wenjie</forenames></author><author><keyname>Patel</keyname><forenames>Jay Harshadbhai</forenames></author><author><keyname>Robert</keyname><forenames>Zoe-Alanah</forenames></author><author><keyname>Novosad</keyname><forenames>Paul</forenames></author><author><keyname>Asher</keyname><forenames>Samuel</forenames></author><author><keyname>Tang</keyname><forenames>Zhongyi</forenames></author><author><keyname>Burke</keyname><forenames>Marshall</forenames></author><author><keyname>Lobell</keyname><forenames>David</forenames></author><author><keyname>Ermon</keyname><forenames>Stefano</forenames></author></authors><title>Mapping Missing Population in Rural India: A Deep Learning Approach with
  Satellite Imagery</title><categories>cs.CV eess.IV</categories><comments>7 pages</comments><acm-class>I.2.10; I.2.6; J.2; J.4</acm-class><journal-ref>AAAI/ACM Conference on AI, Ethics, and Society (AIES '19), January
  27-28, 2019, Honolulu, HI, USA</journal-ref><doi>10.1145/3306618.3314263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millions of people worldwide are absent from their country's census.
Accurate, current, and granular population metrics are critical to improving
government allocation of resources, to measuring disease control, to responding
to natural disasters, and to studying any aspect of human life in these
communities. Satellite imagery can provide sufficient information to build a
population map without the cost and time of a government census. We present two
Convolutional Neural Network (CNN) architectures which efficiently and
effectively combine satellite imagery inputs from multiple sources to
accurately predict the population density of a region. In this paper, we use
satellite imagery from rural villages in India and population labels from the
2011 SECC census. Our best model achieves better performance than previous
papers as well as LandScan, a community standard for global population
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02197</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02197</id><created>2019-05-04</created><authors><author><keyname>Khajeh-Hosseini</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Talebpour</keyname><forenames>Alireza</forenames></author></authors><title>Back to the Future: Predicting Traffic Shockwave Formation and
  Propagation Using a Convolutional Encoder-Decoder Network</title><categories>cs.LG cs.CV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes a deep learning methodology to predict the propagation of
traffic shockwaves. The input to the deep neural network is time-space diagram
of the study segment, and the output of the network is the predicted (future)
propagation of the shockwave on the study segment in the form of time-space
diagram. The main feature of the proposed methodology is the ability to extract
the features embedded in the time-space diagram to predict the propagation of
traffic shockwaves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02200</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02200</id><created>2019-05-06</created><updated>2019-05-18</updated><authors><author><keyname>Kang</keyname><forenames>Yuhao</forenames></author><author><keyname>Gao</keyname><forenames>Song</forenames></author><author><keyname>Roth</keyname><forenames>Robert E.</forenames></author></authors><title>Transferring Multiscale Map Styles Using Generative Adversarial Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>12 pages, 17 figure</comments><acm-class>I.2.1; I.4.9</acm-class><journal-ref>International Journal of Cartography, 2019</journal-ref><doi>10.1080/23729333.2019.1615729</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The advancement of the Artificial Intelligence (AI) technologies makes it
possible to learn stylistic design criteria from existing maps or other visual
art and transfer these styles to make new digital maps. In this paper, we
propose a novel framework using AI for map style transfer applicable across
multiple map scales. Specifically, we identify and transfer the stylistic
elements from a target group of visual examples, including Google Maps,
OpenStreetMap, and artistic paintings, to unstylized GIS vector data through
two generative adversarial network (GAN) models. We then train a binary
classifier based on a deep convolutional neural network to evaluate whether the
transfer styled map images preserve the original map design characteristics.
Our experiment results show that GANs have a great potential for multiscale map
style transferring, but many challenges remain requiring future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02201</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02201</id><created>2019-05-06</created><authors><author><keyname>Trinca</keyname><forenames>D</forenames></author><author><keyname>Madureira</keyname><forenames>R</forenames></author></authors><title>IRXCT: Iterative Reconstruction and visualization application for X-ray
  Computed Tomography</title><categories>eess.IV</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report describes the IRXCT Windows application for reconstruction and
visualization of tomography tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02248</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02248</id><created>2019-05-06</created><updated>2019-05-15</updated><authors><author><keyname>Chen</keyname><forenames>Xiaoliang</forenames></author><author><keyname>Li</keyname><forenames>Baojia</forenames></author><author><keyname>Proietti</keyname><forenames>Roberto</forenames></author><author><keyname>Lu</keyname><forenames>Hongbo</forenames></author><author><keyname>Zhu</keyname><forenames>Zuqing</forenames></author><author><keyname>Yoo</keyname><forenames>S. J. Ben</forenames></author></authors><title>DeepRMSA: A Deep Reinforcement Learning Framework for Routing,
  Modulation and Spectrum Assignment in Elastic Optical Networks</title><categories>cs.NI cs.LG eess.SP</categories><doi>10.1109/JLT.2019.2923615</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes DeepRMSA, a deep reinforcement learning framework for
routing, modulation and spectrum assignment (RMSA) in elastic optical networks
(EONs). DeepRMSA learns the correct online RMSA policies by parameterizing the
policies with deep neural networks (DNNs) that can sense complex EON states.
The DNNs are trained with experiences of dynamic lightpath provisioning. We
first modify the asynchronous advantage actor-critic algorithm and present an
episode-based training mechanism for DeepRMSA, namely, DeepRMSA-EP. DeepRMSA-EP
divides the dynamic provisioning process into multiple episodes (each
containing the servicing of a fixed number of lightpath requests) and performs
training by the end of each episode. The optimization target of DeepRMSA-EP at
each step of servicing a request is to maximize the cumulative reward within
the rest of the episode. Thus, we obviate the need for estimating the rewards
related to unknown future states. To overcome the instability issue in the
training of DeepRMSA-EP due to the oscillations of cumulative rewards, we
further propose a window-based flexible training mechanism, i.e., DeepRMSA-FLX.
DeepRMSA-FLX attempts to smooth out the oscillations by defining the
optimization scope at each step as a sliding window, and ensuring that the
cumulative rewards always include rewards from a fixed number of requests.
Evaluations with the two sample topologies show that DeepRMSA-FLX can
effectively stabilize the training while achieving blocking probability
reductions of more than 20.3% and 14.3%, when compared with the baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02250</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02250</id><created>2019-05-06</created><authors><author><keyname>D'Oro</keyname><forenames>Salvatore</forenames></author><author><keyname>Restuccia</keyname><forenames>Francesco</forenames></author><author><keyname>Melodia</keyname><forenames>Tommaso</forenames></author></authors><title>Hiding Data in Plain Sight: Undetectable Wireless Communications Through
  Pseudo-Noise Asymmetric Shift Keying</title><categories>cs.CR cs.NI eess.SP</categories><journal-ref>IEEE International Conference on Computer Communications
  (INFOCOM'19) 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Undetectable wireless transmissions are fundamental to avoid eavesdroppers.
To address this issue, wireless steganography hides covert information inside
primary information by slightly modifying the transmitted waveform such that
primary information will still be decodable, while covert information will be
seen as noise by agnostic receivers. Since the addition of covert information
inevitably decreases the SNR of the primary transmission, key challenges in
wireless steganography are: i) to assess the impact of the covert channel on
the primary channel as a function of different channel conditions; and ii) to
make sure that the covert channel is undetectable. Existing approaches are
protocol-specific, also we notice that existing wireless technologies rely on
phase-keying modulations that in most cases do not use the channel up to its
Shannon capacity. Therefore, the residual capacity can be leveraged to
implement a wireless system based on a pseudo-noise asymmetric shift keying
(PN-ASK) modulation, where covert symbols are mapped by shifting the amplitude
of primary symbols. This way, covert information will be undetectable, since a
receiver expecting phase-modulated symbols will see their shift in amplitude as
an effect of channel/path loss degradation. We first investigate the SER of
PN-ASK as a function of the channel; then, we find the optimal PN-ASK
parameters that optimize primary and covert throughput under different channel
condition. We evaluate the throughput performance and undetectability of PN-ASK
through extensive simulations and on an experimental testbed based on USRP N210
software-defined radios. We show that PN-ASK improves the throughput by more
than 8x with respect to prior art. Finally, we demonstrate through experiments
that PN-ASK is able to transmit covert data on top of IEEE 802.11g frames,
which are correctly decoded by an off-the-shelf laptop WiFi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02259</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02259</id><created>2019-05-06</created><updated>2019-06-13</updated><authors><author><keyname>Albright</keyname><forenames>Michael</forenames></author><author><keyname>McCloskey</keyname><forenames>Scott</forenames></author></authors><title>Source Generator Attribution via Inversion</title><categories>cs.CV cs.LG eess.IV</categories><comments>Updated with new experiments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With advances in Generative Adversarial Networks (GANs) leading to
dramatically-improved synthetic images and video, there is an increased need
for algorithms which extend traditional forensics to this new category of
imagery. While GANs have been shown to be helpful in a number of computer
vision applications, there are other problematic uses such as `deep fakes'
which necessitate such forensics. Source camera attribution algorithms using
various cues have addressed this need for imagery captured by a camera, but
there are fewer options for synthetic imagery. We address the problem of
attributing a synthetic image to a specific generator in a white box setting,
by inverting the process of generation. This enables us to simultaneously
determine whether the generator produced the image and recover an input which
produces a close match to the synthetic image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02283</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02283</id><created>2019-05-06</created><authors><author><keyname>Olatunji</keyname><forenames>Tobi</forenames></author><author><keyname>Yao</keyname><forenames>Li</forenames></author><author><keyname>Covington</keyname><forenames>Ben</forenames></author><author><keyname>Rhodes</keyname><forenames>Alexander</forenames></author><author><keyname>Upton</keyname><forenames>Anthony</forenames></author></authors><title>Caveats in Generating Medical Imaging Labels from Radiology Reports</title><categories>cs.CL cs.CV eess.IV</categories><comments>Accepted workshop contribution for Medical Imaging with Deep Learning
  (MIDL), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acquiring high-quality annotations in medical imaging is usually a costly
process. Automatic label extraction with natural language processing (NLP) has
emerged as a promising workaround to bypass the need of expert annotation.
Despite the convenience, the limitation of such an approximation has not been
carefully examined and is not well understood. With a challenging set of 1,000
chest X-ray studies and their corresponding radiology reports, we show that
there exists a surprisingly large discrepancy between what radiologists
visually perceive and what they clinically report. Furthermore, with inherently
flawed report as ground truth, the state-of-the-art medical NLP fails to
produce high-fidelity labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02285</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02285</id><created>2019-05-06</created><updated>2020-02-13</updated><authors><author><keyname>Salscheider</keyname><forenames>Niels Ole</forenames></author></authors><title>Simultaneous Object Detection and Semantic Segmentation</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both object detection in and semantic segmentation of camera images are
important tasks for automated vehicles. Object detection is necessary so that
the planning and behavior modules can reason about other road users. Semantic
segmentation provides for example free space information and information about
static and dynamic parts of the environment. There has been a lot of research
to solve both tasks using Convolutional Neural Networks. These approaches give
good results but are computationally demanding. In practice, a compromise has
to be found between detection performance, detection quality and the number of
tasks. Otherwise it is not possible to meet the real-time requirements of
automated vehicles. In this work, we propose a neural network architecture to
solve both tasks simultaneously. This architecture was designed to run with
around 10 Hz on 1 MP images on current hardware. Our approach achieves a mean
IoU of 61.2% for the semantic segmentation task on the challenging Cityscapes
benchmark. It also achieves an average precision of 69.3% for cars and 67.7% on
the moderate difficulty level of the KITTI benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02312</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02312</id><created>2019-05-06</created><authors><author><keyname>Esmaili</keyname><forenames>Amirhossein</forenames></author><author><keyname>Kachuee</keyname><forenames>Mohammad</forenames></author><author><keyname>Shabany</keyname><forenames>Mahdi</forenames></author></authors><title>Non-invasive Blood Pressure Estimation Using Phonocardiogram</title><categories>eess.SP</categories><comments>The collected data set can be accessed using the following url link:
  http://www.kaggle.com/mkachuee/noninvasivebp</comments><journal-ref>2017 IEEE International Symposium on Circuits and Systems (ISCAS),
  pp. 1-4. IEEE, 2017</journal-ref><doi>10.1109/ISCAS.2017.8050240</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach based on pulse transit time (PTT) for
the estimation of blood pressure (BP). In order to achieve this goal, a data
acquisition hardware is designed for high-resolution sampling of
phonocardiogram (PCG) and photoplethysmogram (PPG). These two signals can
derive PTT values. Meanwhile, a force-sensing resistor (FSR) is placed under
the cuff of the BP reference device to mark the moments of measurements
accurately via recording instantaneous cuff pressure. For deriving the PTT-BP
models, a calibration procedure including a supervised physical exercise is
conducted for each individual. The proposed method is evaluated on 24 subjects.
The final results prove that using PCG for PTT measurement alongside the
proposed models, the BP can be estimated reliably. Since the use of PCG
requires a minimal low-cost hardware, the proposed method enables ubiquitous BP
estimation in portable healthcare devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02314</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02314</id><created>2019-05-06</created><authors><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>Overview and Comparison of Nonlinear Interference Modelling Approaches
  in Ultra-Wideband Optical Transmission Systems</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The recent advances in modelling nonlinear interference of systems operating
beyond the C-band are discussed. Estimation accuracy as well as computational
complexity of current approaches are compared and addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02324</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02324</id><created>2019-05-06</created><updated>2019-05-13</updated><authors><author><keyname>Kavousi-Fard</keyname><forenames>Abdollah</forenames></author><author><keyname>Wang</keyname><forenames>Boyu</forenames></author><author><keyname>Avatefipour</keyname><forenames>Omid</forenames></author><author><keyname>Dabbaghjamanesh</keyname><forenames>Morteza</forenames></author><author><keyname>Sahba</keyname><forenames>Ramin</forenames></author><author><keyname>Sahba</keyname><forenames>Amin</forenames></author></authors><title>Superconducting Fault Current Limiter Allocation in Reconfigurable Smart
  Grids</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superconducting fault current limiters (SFCLs) are new high-precision and
fast-response devices which help to reduce the fault current within the
breaking capacity of the protective relays. Nevertheless, the reconfigurable
structure of the distribution network can affect their performance negatively
by changing the supplying path of the electrical loads and thus keeping SFCL in
a useless point which cannot limit the high fault currents. This paper proposes
an aggregated approach to solve the optimal placement of SFCLs considering the
reconfiguration of feeders through the pre-located tie and sectionalizing
switches. While SFCL placement problem aims to minimize the number of SFCLs and
limit the high short circuit currents in the first seconds of the fault, the
reconfiguration strategy is used to minimize the total grid costs incorporating
the cost of power losses and customer interruptions. According to the high
non-linearity and complexity of the proposed problem, social spider algorithm
(SSA) with a two-phase modification method is developed to solve the proposed
problem. The feasibility and performance of the proposed method are examined on
an IEEE test system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02337</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02337</id><created>2019-05-06</created><authors><author><keyname>Ali</keyname><forenames>Konpal Shaukat</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Jahangir</forenames></author></authors><title>On Clustering and Channel Disparity in Non-Orthogonal Multiple Access
  (NOMA)</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) allows multiple users to share a
time-frequency resource block by using different power levels. An important
challenge associated with NOMA is the selection of users that share a resource
block. This is referred to as clustering, which generally exploits the channel
disparity (i.e. distinctness) among the users. We discuss clustering and the
related resource allocation challenges (e.g. power allocation) associated with
NOMA and highlight open problems that require further investigation. We review
the related literature on exploiting channel disparity for clustering and
resource allocation. There have been several misconceptions regarding NOMA
clustering including: 1) clustering users with low channel disparity is
detrimental, 2) similar power allocation is disastrous for NOMA. We clarify
such misunderstandings with numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02373</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02373</id><created>2019-05-07</created><authors><author><keyname>Qin</keyname><forenames>Shuzhen</forenames></author><author><keyname>Liu</keyname><forenames>Qiang</forenames></author><author><keyname>Yu</keyname><forenames>Bo</forenames></author><author><keyname>Liu</keyname><forenames>Shaoshan</forenames></author></authors><title>PI-BA Bundle Adjustment Acceleration on Embedded FPGAs with
  Co-observation Optimization</title><categories>eess.IV cs.RO</categories><comments>in Proceedings of IEEE FCCM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bundle adjustment (BA) is a fundamental optimization technique used in many
crucial applications, including 3D scene reconstruction, robotic localization,
camera calibration, autonomous driving, space exploration, street view map
generation etc. Essentially, BA is a joint non-linear optimization problem, and
one which can consume a significant amount of time and power, especially for
large optimization problems. Previous approaches of optimizing BA performance
heavily rely on parallel processing or distributed computing, which trade
higher power consumption for higher performance. In this paper we propose
{\pi}-BA, the first hardware-software co-designed BA engine on an embedded
FPGA-SoC that exploits custom hardware for higher performance and power
efficiency. Specifically, based on our key observation that not all points
appear on all images in a BA problem, we designed and implemented a
Co-Observation Optimization technique to accelerate BA operations with
optimized usage of memory and computation resources. Experimental results
confirm that {\pi}-BA outperforms the existing software implementations in
terms of performance and power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02378</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02378</id><created>2019-05-07</created><authors><author><keyname>Ouyang</keyname><forenames>Jiahong</forenames></author><author><keyname>Mathai</keyname><forenames>Tejas Sudharshan</forenames></author><author><keyname>Lathrop</keyname><forenames>Kira</forenames></author><author><keyname>Galeotti</keyname><forenames>John</forenames></author></authors><title>Accurate Tissue Interface Segmentation via Adversarial Pre-Segmentation
  of Anterior Segment OCT Images</title><categories>eess.IV cs.CV</categories><comments>First two authors contributed equally. Biomedical Optics Express
  journal submission. 27 pages, 15 figures. Submitted to the journal on May 6th
  2019 at 11:38pm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical Coherence Tomography (OCT) is an imaging modality that has been
widely adopted for visualizing corneal, retinal and limbal tissue structure
with micron resolution. It can be used to diagnose pathological conditions of
the eye, and for developing pre-operative surgical plans. In contrast to the
posterior retina, imaging the anterior tissue structures, such as the limbus
and cornea, results in B-scans that exhibit increased speckle noise patterns
and imaging artifacts. These artifacts, such as shadowing and specularity, pose
a challenge during the analysis of the acquired volumes as they substantially
obfuscate the location of tissue interfaces. To deal with the artifacts and
speckle noise patterns and accurately segment the shallowest tissue interface,
we propose a cascaded neural network framework, which comprises of a
conditional Generative Adversarial Network (cGAN) and a Tissue Interface
Segmentation Network (TISN). The cGAN pre-segments OCT B-scans by removing
undesired specular artifacts and speckle noise patterns just above the
shallowest tissue interface, and the TISN combines the original OCT image with
the pre-segmentation to segment the shallowest interface. We show the
applicability of the cascaded framework to corneal datasets, demonstrate that
it precisely segments the shallowest corneal interface, and also show its
generalization capacity to limbal datasets. We also propose a hybrid framework,
wherein the cGAN pre-segmentation is passed to a traditional image
analysis-based segmentation algorithm, and describe the improved segmentation
performance. To the best of our knowledge, this is the first approach to remove
severe specular artifacts and speckle noise patterns (prior to the shallowest
interface) that affects the interpretation of anterior segment OCT datasets,
thereby resulting in the accurate segmentation of the shallowest tissue
interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02395</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02395</id><created>2019-05-07</created><authors><author><keyname>Partani</keyname><forenames>Sanket</forenames></author><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>A Controller for Network-Assisted CACC based Platooning</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Platooning involves a set of vehicles moving in a cooperative fashion at
equal inter-vehicular distances. Taking advantage of wireless communication
technology, this paper aims to show the impact of network protocols on a
platoon using a controller, based on the Cooperative Adaptive Cruise Control
(CACC) principles. The network protocols used in this work are DSRC (Dedicated
Short Range Communication) and LTE-V2V sidelink (Mode 4). The main focus of
this work is to showcase the ability of the controller to maintain platoon
stability despite having uncertainties in both, the platoon and the message
delivery rates over the network protocols. The controller interacts with all
vehicles using messages transmitted over the network protocols. The controller
is designed to be responsible for micro-managing every vehicle in the platoon
and to ensure that the platoon does not break under any circumstances. SUMO
(Simulation of Urban MObility) is used as the simulation platform. Results
indicate, that the controller manages to achieve platoon stability in all
scenarios, unless a set number of consecutive messages are not transmitted, in
which case it leads to collisions. This work also presents certain bottlenecks
pertaining to wireless communication with vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02411</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02411</id><created>2019-05-07</created><authors><author><keyname>Tataraidze</keyname><forenames>Alexander</forenames></author><author><keyname>Olesyuk</keyname><forenames>Roman</forenames></author><author><keyname>Pikhletsky</keyname><forenames>Mikhail</forenames></author></authors><title>Can We Monitor Breathing During Sleep via Wi-Fi on Smartphone?</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decade there has been high interest in home sleep monitoring
among research community and society. Smartphone-based sleep monitoring seems
to be especially attractive. However, smartphone should be able to register
physiological processes for that, such as breathing or heartbeats. In this
study, we tried to detect breathing based on the analysis of channel state
information (CSI) of Wi-Fi connection between a smartphone and an access point.
We collected data of 5 subjects with different body mass index (17-33) in base
sleep postures: prone, supine, and side. The obtained CSI-based respiratory
signal was compared with ground truth from a contact belt sensor. The mean
correlation coefficient between the signals of 0.85 was achieved. The mean
absolute difference between respiratory rates (breaths per epoch) is 0.39. The
results show that it is possible to use smartphones without additional sensors
for registering breathing based on CSI and potentially for sleep monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02488</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02488</id><created>2019-05-07</created><authors><author><keyname>Wang</keyname><forenames>Qi</forenames></author><author><keyname>He</keyname><forenames>Xiange</forenames></author><author><keyname>Li</keyname><forenames>Xuelong</forenames></author></authors><title>Locality and Structure Regularized Low Rank Representation for
  Hyperspectral Image Classification</title><categories>cs.CV eess.IV</categories><comments>14 pages, 7 figures, TGRS2019</comments><journal-ref>IEEE Transactions on Geoscience and Remote Sensing ( Volume: 57 ,
  Issue: 2 , Feb. 2019 )</journal-ref><doi>10.1109/TGRS.2018.2862899</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral image (HSI) classification, which aims to assign an accurate
label for hyperspectral pixels, has drawn great interest in recent years.
Although low rank representation (LRR) has been used to classify HSI, its
ability to segment each class from the whole HSI data has not been exploited
fully yet. LRR has a good capacity to capture the underlying lowdimensional
subspaces embedded in original data. However, there are still two drawbacks for
LRR. First, LRR does not consider the local geometric structure within data,
which makes the local correlation among neighboring data easily ignored.
Second, the representation obtained by solving LRR is not discriminative enough
to separate different data. In this paper, a novel locality and structure
regularized low rank representation (LSLRR) model is proposed for HSI
classification. To overcome the above limitations, we present locality
constraint criterion (LCC) and structure preserving strategy (SPS) to improve
the classical LRR. Specifically, we introduce a new distance metric, which
combines both spatial and spectral features, to explore the local similarity of
pixels. Thus, the global and local structures of HSI data can be exploited
sufficiently. Besides, we propose a structure constraint to make the
representation have a near block-diagonal structure. This helps to determine
the final classification labels directly. Extensive experiments have been
conducted on three popular HSI datasets. And the experimental results
demonstrate that the proposed LSLRR outperforms other state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02525</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02525</id><created>2019-04-30</created><authors><author><keyname>Keskin</keyname><forenames>Gokce</forenames></author><author><keyname>Lee</keyname><forenames>Tyler</forenames></author><author><keyname>Stephenson</keyname><forenames>Cory</forenames></author><author><keyname>Elibol</keyname><forenames>Oguz H.</forenames></author></authors><title>Many-to-Many Voice Conversion with Out-of-Dataset Speaker Support</title><categories>eess.AS cs.CL cs.SD</categories><comments>Submitted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Cycle-GAN based many-to-many voice conversion method that can
convert between speakers that are not in the training set. This property is
enabled through speaker embeddings generated by a neural network that is
jointly trained with the Cycle-GAN. In contrast to prior work in this domain,
our method enables conversion between an out-of-dataset speaker and a target
speaker in either direction and does not require re-training. Out-of-dataset
speaker conversion quality is evaluated using an independently trained speaker
identification model, and shows good style conversion characteristics for
previously unheard speakers. Subjective tests on human listeners show style
conversion quality for in-dataset speakers is comparable to the
state-of-the-art baseline model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02533</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02533</id><created>2019-05-07</created><authors><author><keyname>da Silva</keyname><forenames>Bruno Fontana</forenames></author><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Uch&#xf4;a-Filho</keyname><forenames>Bartolomeu F.</forenames></author><author><keyname>Ruyet</keyname><forenames>Didier Le</forenames></author></authors><title>A Multistage Method for SCMA Codebook Design Based on MDS Codes</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Wireless Communication Letters</comments><doi>10.1109/LWC.2019.2925801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse Code Multiple Access (SCMA) has been recently proposed for the future
generation of wireless communication standards. SCMA system design involves
specifying several parameters. In order to simplify the procedure, most works
consider a multistage design approach. Two main stages are usually emphasized
in these methods: sparse signatures design (equivalently, resource allocation)
and codebook design. In this paper, we present a novel SCMA codebook design
method. The proposed method considers SCMA codebooks structured with an
underlying vector space obtained from classical block codes. In particular,
when using maximum distance separable (MDS) codes, our proposed design provides
maximum signal-space diversity with a relatively small alphabet. The use of
small alphabets also helps to maintain desired properties in the codebooks,
such as low peak-to-average power ratio and low-complexity detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02538</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02538</id><created>2019-05-07</created><authors><author><keyname>Qian</keyname><forenames>Guocheng</forenames></author><author><keyname>Gu</keyname><forenames>Jinjin</forenames></author><author><keyname>Ren</keyname><forenames>Jimmy S.</forenames></author><author><keyname>Dong</keyname><forenames>Chao</forenames></author><author><keyname>Zhao</keyname><forenames>Furong</forenames></author><author><keyname>Lin</keyname><forenames>Juan</forenames></author></authors><title>Trinity of Pixel Enhancement: a Joint Solution for Demosaicking,
  Denoising and Super-Resolution</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demosaicing, denoising and super-resolution (SR) are of practical importance
in digital image processing and have been studied independently in the passed
decades. Despite the recent improvement of learning-based image processing
methods in image quality, there lacks enough analysis into their interactions
and characteristics under a realistic setting of the mixture problem of
demosaicing, denoising and SR. In existing solutions, these tasks are simply
combined to obtain a high-resolution image from a low-resolution raw mosaic
image, resulting in a performance drop of the final image quality. In this
paper, we first rethink the mixture problem from a holistic perspective and
then propose the Trinity Enhancement Network (TENet), a specially designed
learning-based method for the mixture problem, which adopts a novel image
processing pipeline order and a joint learning strategy. In order to obtain the
correct color sampling for training, we also contribute a new dataset namely
PixelShift200, which consists of high-quality full color sampled real-world
images using the advanced pixel shift technique. Experiments demonstrate that
our TENet is superior to existing solutions in both quantitative and
qualitative perspective. Our experiments also show the necessity of the
proposed PixelShift200 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02541</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02541</id><created>2019-05-03</created><authors><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>He</keyname><forenames>Hengtao</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Deep Learning Based on Orthogonal Approximate Message Passing for
  CP-Free OFDM</title><categories>eess.SP cs.LG</categories><comments>5 pages, 4 figures, updated manuscript, International Conference on
  Acoustics, Speech and Signal Processing (ICASSP 2019). arXiv admin note:
  substantial text overlap with arXiv:1903.04766</comments><doi>10.1109/ICASSP.2019.8682639</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation and signal detection are very challenging for an
orthogonal frequency division multiplexing (OFDM) system without cyclic prefix
(CP). In this article, deep learning based on orthogonal approximate message
passing (DL-OAMP) is used to address these problems. The DL-OAMP receiver
includes a channel estimation neural network (CE-Net) and a signal detection
neural network based on OAMP, called OAMP-Net. The CE-Net is initialized by the
least square channel estimation algorithm and refined by minimum mean-squared
error (MMSE) neural network. The OAMP-Net is established by unfolding the
iterative OAMP algorithm and adding some trainable parameters to improve the
detection performance. The DL-OAMP receiver is with low complexity and can
estimate time-varying channels with only a single training. Simulation results
demonstrate that the bit-error rate (BER) of the proposed scheme is lower than
those of competitive algorithms for high-order modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02544</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02544</id><created>2019-05-07</created><authors><author><keyname>Elloumi</keyname><forenames>Yaroub</forenames><affiliation>LIGM</affiliation></author><author><keyname>Akil</keyname><forenames>Mohamed</forenames><affiliation>LIGM</affiliation></author><author><keyname>Boudegga</keyname><forenames>Henda</forenames></author></authors><title>Ocular Diseases Diagnosis in Fundus Images using a Deep Learning:
  Approaches, tools and Performance evaluation</title><categories>eess.IV cs.CV cs.LG cs.NE</categories><proxy>ccsd</proxy><journal-ref>SPIE Real-Time Image Processing and Deep Learning, Apr 2019,
  Baltimore, Maryland, United States</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ocular pathology detection from fundus images presents an important challenge
on health care. In fact, each pathology has different severity stages that may
be deduced by verifying the existence of specific lesions. Each lesion is
characterized by morphological features. Moreover, several lesions of different
pathologies have similar features. We note that patient may be affected
simultaneously by several pathologies. Consequently, the ocular pathology
detection presents a multi-class classification with a complex resolution
principle. Several detection methods of ocular pathologies from fundus images
have been proposed. The methods based on deep learning are distinguished by
higher performance detection, due to their capability to configure the network
with respect to the detection objective. This work proposes a survey of ocular
pathology detection methods based on deep learning. First, we study the
existing methods either for lesion segmentation or pathology classification.
Afterwards, we extract the principle steps of processing and we analyze the
proposed neural network structures. Subsequently, we identify the hardware and
software environment required to employ the deep learning architecture.
Thereafter, we investigate about the experimentation principles involved to
evaluate the methods and the databases used either for training and testing
phases. The detection performance ratios and execution times are also reported
and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02545</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02545</id><created>2019-05-03</created><updated>2019-07-07</updated><authors><author><keyname>Yoshioka</keyname><forenames>Takuya</forenames></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>Dimitriadis</keyname><forenames>Dimitrios</forenames></author><author><keyname>Hinthorn</keyname><forenames>William</forenames></author><author><keyname>Huang</keyname><forenames>Xuedong</forenames></author><author><keyname>Stolcke</keyname><forenames>Andreas</forenames></author><author><keyname>Zeng</keyname><forenames>Michael</forenames></author></authors><title>Meeting Transcription Using Virtual Microphone Arrays</title><categories>eess.AS cs.CL cs.SD</categories><report-no>MSR-TR-2019-11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a system that generates speaker-annotated transcripts of meetings
by using a virtual microphone array, a set of spatially distributed
asynchronous recording devices such as laptops and mobile phones. The system is
composed of continuous audio stream alignment, blind beamforming, speech
recognition, speaker diarization using prior speaker information, and system
combination. When utilizing seven input audio streams, our system achieves a
word error rate (WER) of 22.3% and comes within 3% of the close-talking
microphone WER on the non-overlapping speech segments. The speaker-attributed
WER (SAWER) is 26.7%. The relative gains in SAWER over the single-device system
are 14.8%, 20.3%, and 22.4% for three, five, and seven microphones,
respectively. The presented system achieves a 13.6% diarization error rate when
10% of the speech duration contains more than one speaker. The contribution of
each component to the overall performance is also investigated, and we validate
the system with experiments on the NIST RT-07 conference meeting test set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02567</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02567</id><created>2019-05-05</created><updated>2019-05-24</updated><authors><author><keyname>Wu</keyname><forenames>Weiwen</forenames></author><author><keyname>Yu</keyname><forenames>Haijun</forenames></author><author><keyname>Chen</keyname><forenames>Peijun</forenames></author><author><keyname>Luo</keyname><forenames>Fulin</forenames></author><author><keyname>Liu</keyname><forenames>Fenglin</forenames></author><author><keyname>Wang</keyname><forenames>Qian</forenames></author><author><keyname>Zhu</keyname><forenames>Yining</forenames></author><author><keyname>Zhang</keyname><forenames>Yanbo</forenames></author><author><keyname>Feng</keyname><forenames>Jian</forenames></author><author><keyname>Yu</keyname><forenames>Hengyong</forenames></author></authors><title>DLIMD: Dictionary Learning based Image-domain Material Decomposition for
  spectral CT</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The potential huge advantage of spectral computed tomography (CT) is its
capability to provide accuracy material identification and quantitative tissue
information. This can benefit clinical applications, such as brain angiography,
early tumor recognition, etc. To achieve more accurate material components with
higher material image quality, we develop a dictionary learning based
image-domain material decomposition (DLIMD) for spectral CT in this paper.
First, we reconstruct spectral CT image from projections and calculate material
coefficients matrix by selecting uniform regions of basis materials from image
reconstruction results. Second, we employ the direct inversion (DI) method to
obtain initial material decomposition results, and a set of image patches are
extracted from the mode-1 unfolding of normalized material image tensor to
train a united dictionary by the K-SVD technique. Third, the trained dictionary
is employed to explore the similarities from decomposed material images by
constructing the DLIMD model. Fourth, more constraints (i.e., volume
conservation and the bounds of each pixel within material maps) are further
integrated into the model to improve the accuracy of material decomposition.
Finally, both physical phantom and preclinical experiments are employed to
evaluate the performance of the proposed DLIMD in material decomposition
accuracy, material image edge preservation and feature recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02590</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02590</id><created>2019-05-07</created><authors><author><keyname>Gessert</keyname><forenames>Nils</forenames></author><author><keyname>Schlaefer</keyname><forenames>Alexander</forenames></author></authors><title>Efficient Neural Architecture Search on Low-Dimensional Data for OCT
  Image Segmentation</title><categories>eess.IV cs.CV</categories><comments>Accepted at MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/Syg3FDjntN</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typically, deep learning architectures are handcrafted for their respective
learning problem. As an alternative, neural architecture search (NAS) has been
proposed where the architecture's structure is learned in an additional
optimization step. For the medical imaging domain, this approach is very
promising as there are diverse problems and imaging modalities that require
architecture design. However, NAS is very time-consuming and medical learning
problems often involve high-dimensional data with high computational
requirements. We propose an efficient approach for NAS in the context of
medical, image-based deep learning problems by searching for architectures on
low-dimensional data which are subsequently transferred to high-dimensional
data. For OCT-based layer segmentation, we demonstrate that a search on 1D data
reduces search time by 87.5% compared to a search on 2D data while the final 2D
models achieve similar performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02616</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02616</id><created>2019-05-07</created><updated>2019-06-16</updated><authors><author><keyname>Mishra</keyname><forenames>Sakshi</forenames></author><author><keyname>Palanisamy</keyname><forenames>Praveen</forenames></author></authors><title>An Integrated Multi-Time-Scale Modeling for Solar Irradiance Forecasting
  Using Deep Learning</title><categories>cs.LG eess.SP stat.ML</categories><comments>19 pages, 12 figures, 3 tables, under review for journal submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For short-term solar irradiance forecasting, the traditional point
forecasting methods are rendered less useful due to the non-stationary
characteristic of solar power. The amount of operating reserves required to
maintain reliable operation of the electric grid rises due to the variability
of solar energy. The higher the uncertainty in the generation, the greater the
operating-reserve requirements, which translates to an increased cost of
operation. In this research work, we propose a unified architecture for
multi-time-scale predictions for intra-day solar irradiance forecasting using
recurrent neural networks (RNN) and long-short-term memory networks (LSTMs).
This paper also lays out a framework for extending this modeling approach to
intra-hour forecasting horizons thus, making it a multi-time-horizon
forecasting approach, capable of predicting intra-hour as well as intra-day
solar irradiance. We develop an end-to-end pipeline to effectuate the proposed
architecture. The performance of the prediction model is tested and validated
by the methodical implementation. The robustness of the approach is
demonstrated with case studies conducted for geographically scattered sites
across the United States. The predictions demonstrate that our proposed unified
architecture-based approach is effective for multi-time-scale solar forecasts
and achieves a lower root-mean-square prediction error when benchmarked against
the best-performing methods documented in the literature that use separate
models for each time-scale during the day. Our proposed method results in a
71.5% reduction in the mean RMSE averaged across all the test sites compared to
the ML-based best-performing method reported in the literature. Additionally,
the proposed method enables multi-time-horizon forecasts with real-time inputs,
which have a significant potential for practical industry applications in the
evolving grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02639</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02639</id><created>2019-05-07</created><authors><author><keyname>Karhila</keyname><forenames>Reima</forenames></author><author><keyname>Smolander</keyname><forenames>Anna-Riikka</forenames></author><author><keyname>Ylinen</keyname><forenames>Sari</forenames></author><author><keyname>Kurimo</keyname><forenames>Mikko</forenames></author></authors><title>Transparent pronunciation scoring using articulatorily weighted phoneme
  edit distance</title><categories>eess.AS cs.SD</categories><comments>Submitted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For researching effects of gamification in foreign language learning for
children in the &quot;Say It Again, Kid!&quot; project we developed a feedback paradigm
that can drive gameplay in pronunciation learning games. We describe our
scoring system based on the difference between a reference phone sequence and
the output of a multilingual CTC phoneme recogniser. We present a white-box
scoring model of mapped weighted Levenshtein edit distance between reference
and error with error weights for articulatory differences computed from a
training set of scored utterances. The system can produce a human-readable list
of each detected mispronunciation's contribution to the utterance score. We
compare our scoring method to established black box methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02688</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02688</id><created>2019-05-07</created><authors><author><keyname>Xie</keyname><forenames>Jian</forenames></author><author><keyname>Ma</keyname><forenames>Zixiao</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyu</forenames></author><author><keyname>Bu</keyname><forenames>Fankun</forenames></author></authors><title>Data-Driven Based Method for Power System Time-Varying Composite Load
  Modeling</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast and accurate load parameters identification has great impact on the
power systems operation and stability analysis. This paper proposes a novel
transfer reinforcement learning based method to identify composite ZIP and
induction motor (IM) load models. An imitation learning process is firstly
introduced to improve the exploitation and exploration process. The transfer
learning process is then employed to overcome the challenge of time consuming
optimization when dealing with new tasks. An Associative memory is designed to
realize demension reduction and knowledge learning and transfer between
different optimization tasks. Agents can exploit the optimal knowledge from
source tasks to accelerate search rate and improve solution accuracy. The
greedy rule is adopted to balance global search and local search. Convergency
analysis shows that the proposed method can converge to the global optimal
solution with probability 1. The performance of the proposed ITQ appraoch have
been validated on 68-bus system. Simulation results in multi-test cases verify
that the proposed method has superior convergence rate and stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02703</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02703</id><created>2019-05-07</created><updated>2019-11-21</updated><authors><author><keyname>Zhang</keyname><forenames>Shan</forenames></author><author><keyname>Geng</keyname><forenames>Baocheng</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>Fusion of Deep Neural Networks for Activity Recognition: A Regular Vine
  Copula Based Approach</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose regular vine copula based fusion of multiple deep
neural network classifiers for the problem of multi-sensor based human activity
recognition. We take the cross-modal dependence into account by employing
regular vine copulas that are extremely flexible and powerful graphical models
to characterize complex dependence among multiple modalities. Multiple deep
neural networks are used to extract high-level features from multi-sensing
modalities, with each deep neural network processing the data collected from a
single sensor. The extracted high-level features are then combined using a
regular vine copula model. Numerical experiments are conducted to demonstrate
the effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02704</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02704</id><created>2019-05-07</created><authors><author><keyname>Sharmin</keyname><forenames>Saima</forenames></author><author><keyname>Panda</keyname><forenames>Priyadarshini</forenames></author><author><keyname>Sarwar</keyname><forenames>Syed Shakib</forenames></author><author><keyname>Lee</keyname><forenames>Chankyu</forenames></author><author><keyname>Ponghiran</keyname><forenames>Wachirawit</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>A Comprehensive Analysis on Adversarial Robustness of Spiking Neural
  Networks</title><categories>cs.NE cs.LG eess.SP</categories><comments>Accepted in IJCNN2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this era of machine learning models, their functionality is being
threatened by adversarial attacks. In the face of this struggle for making
artificial neural networks robust, finding a model, resilient to these attacks,
is very important. In this work, we present, for the first time, a
comprehensive analysis of the behavior of more bio-plausible networks, namely
Spiking Neural Network (SNN) under state-of-the-art adversarial tests. We
perform a comparative study of the accuracy degradation between conventional
VGG-9 Artificial Neural Network (ANN) and equivalent spiking network with
CIFAR-10 dataset in both whitebox and blackbox setting for different types of
single-step and multi-step FGSM (Fast Gradient Sign Method) attacks. We
demonstrate that SNNs tend to show more resiliency compared to ANN under
black-box attack scenario. Additionally, we find that SNN robustness is largely
dependent on the corresponding training mechanism. We observe that SNNs trained
by spike-based backpropagation are more adversarially robust than the ones
obtained by ANN-to-SNN conversion rules in several whitebox and blackbox
scenarios. Finally, we also propose a simple, yet, effective framework for
crafting adversarial attacks from SNNs. Our results suggest that attacks
crafted from SNNs following our proposed method are much stronger than those
crafted from ANNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02717</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02717</id><created>2019-05-07</created><authors><author><keyname>Sinha</keyname><forenames>Priyanka</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Impact of 3D Antenna Radiation Patterns on TDOA-Based Wireless
  Localization of UAVs</title><categories>eess.SP</categories><comments>Antenna effects, cellular positioning, Cramer-Rao lower bound (CRLB),
  drone-localization, TDOA based localization, unauthorized drone detection</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next big commercial applications of drones require to fly the drone beyond
the visual line of sight (BVLOS). This inevitable ability to fly BVLOS will
also necessitate the ability to keep track of the drone's location, in order to
ensure successful completion of the intended service. In this context, we
explore the fundamental limits of 3D localization of drones in conjunction with
the effects of the 3D antenna radiation patterns. Although the localization of
drone/unmanned aerial vehicle (UAV) is a well-studied topic in the literature,
its relationship to the antenna effects remains mostly unexplored. In this
paper, we investigate the impact of antenna radiation pattern on the accuracy
of time-difference-of-arrival (TDOA)-based localization of the UAV.
Specifically, we consider a scenario where a fixed number of radio-frequency
(RF) sensors, placed at some known locations on the ground, collect the TDOA
measurements from the signals transmitted from the UAV and estimate the
location of the UAV from these observations. In order to study the impact of
the antenna effects on the fundamental limits of the TDOA-based positioning
scheme, we develop a simple analytical model to approximate the total antenna
gains experienced by an air-to-ground (A2G) link, for various orientations of
the antennas. We then derive the Cramer-Rao lower bound for the TDOA based
localization scheme, for all three combinations of the transmit and the receive
antenna orientations: vertical-vertical (VV), horizontal-horizontal (HH), and
vertical-horizontal (VH).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02749</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02749</id><created>2019-05-07</created><authors><author><keyname>Rout</keyname><forenames>Litu</forenames></author><author><keyname>Bhateja</keyname><forenames>Yatharath</forenames></author><author><keyname>Garg</keyname><forenames>Ankur</forenames></author><author><keyname>Mishra</keyname><forenames>Indranil</forenames></author><author><keyname>Moorthi</keyname><forenames>S Manthira</forenames></author><author><keyname>Dhar</keyname><forenames>Debjyoti</forenames></author></authors><title>DeepSWIR: A Deep Learning Based Approach for the Synthesis of Short-Wave
  InfraRed Band using Multi-Sensor Concurrent Datasets</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Network (CNN) is achieving remarkable progress in
various computer vision tasks. In the past few years, the remote sensing
community has observed Deep Neural Network (DNN) finally taking off in several
challenging fields. In this study, we propose a DNN to generate a predefined
High Resolution (HR) synthetic spectral band using an ensemble of concurrent
Low Resolution (LR) bands and existing HR bands. Of particular interest, the
proposed network, namely DeepSWIR, synthesizes Short-Wave InfraRed (SWIR) band
at 5m Ground Sampling Distance (GSD) using Green (G), Red (R) and Near InfraRed
(NIR) bands at both 24m and 5m GSD, and SWIR band at 24m GSD. To our knowledge,
the highest spatial resolution of commercially deliverable SWIR band is at 7.5m
GSD. Also, we propose a Gaussian feathering based image stitching approach in
light of processing large satellite imagery. To experimentally validate the
synthesized HR SWIR band, we critically analyse the qualitative and
quantitative results produced by DeepSWIR using state-of-the-art evaluation
metrics. Further, we convert the synthesized DN values to Top Of Atmosphere
(TOA) reflectance and compare with the corresponding band of Sentinel-2B.
Finally, we show one real world application of the synthesized band by using it
to map wetland resources over our region of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02797</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02797</id><created>2019-05-07</created><authors><author><keyname>Peifer</keyname><forenames>Maria</forenames></author><author><keyname>Chamon</keyname><forenames>Luiz. F. O.</forenames></author><author><keyname>Paternain</keyname><forenames>Santiago</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author></authors><title>Sparse multiresolution representations with adaptive kernels</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reproducing kernel Hilbert spaces (RKHSs) are key elements of many
non-parametric tools successfully used in signal processing, statistics, and
machine learning. In this work, we aim to address three issues of the classical
RKHS based techniques. First, they require the RKHS to be known a priori, which
is unrealistic in many applications. Furthermore, the choice of RKHS affects
the shape and smoothness of the solution, thus impacting its performance.
Second, RKHSs are ill-equipped to deal with heterogeneous degrees of
smoothness, i.e., with functions that are smooth in some parts of their domain
but vary rapidly in others. Finally, the computational complexity of evaluating
the solution of these methods grows with the number of data points, rendering
these techniques infeasible for many applications. Though kernel learning,
local kernel adaptation, and sparsity have been used to address these issues,
many of these approaches are computationally intensive or forgo optimality
guarantees. We tackle these problems by leveraging a novel integral
representation of functions in RKHSs that allows for arbitrary centers and
different kernels at each center. To address the complexity issues, we then
write the function estimation problem as a sparse functional program that
explicitly minimizes the support of the representation leading to low
complexity solutions. Despite their non-convexity and infinite dimensionality,
we show these problems can be solved exactly and efficiently by leveraging
duality, and we illustrate this new approach in simulated and real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02823</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02823</id><created>2019-05-07</created><authors><author><keyname>Bottos</keyname><forenames>Stephen</forenames></author><author><keyname>Balasingam</keyname><forenames>Balakumar</forenames></author></authors><title>Tracking the Progression of Reading Through Eye-gaze Measurements</title><categories>cs.HC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of tracking the progression of reading
through eye-gaze measurements. Such an algorithm is novel and will ultimately
help to develop a method of analyzing eye-gaze data which had been collected
during reading activity in order to uncover crucial information regarding the
individual's interest level and quality of experience while reading a passage
of text or book. Additionally, such an approach will serve as a &quot;visual
signature&quot; - a method of verifying if an individual has indeed given adequate
attention to critical text-based information. Further, an accurate
&quot;reading-progression-tracker&quot; has potential applications in educational
institutions, e-readers and parenting solutions. Tracking the progression of
reading remains a challenging problem due to the fact that eye-gaze movements
are highly noisy and the eye-gaze is easily distracted in a limited space, like
an e-book. In a prior work, we proposed an approach to analyze eye-gaze
fixation points collected while reading a page of text in order to classify
each measurement to a line of text; this approach did not consider tracking the
progression of reading along the line of text. In this paper, we extend the
capabilities of the previous algorithm in order to accurately track the
progression of reading along each line. the proposed approach employs least
squares batch estimation in order to estimate three states of the horizontal
saccade: position, velocity and acceleration. First, the proposed approach is
objectively evaluated on a simulated eye-gaze dataset. Then, the proposed
algorithm is demonstrated on real data collected by a Gazepoint eye-tracker
while the subject is reading several pages from an electronic book.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02872</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02872</id><created>2019-05-07</created><updated>2019-07-30</updated><authors><author><keyname>Zhang</keyname><forenames>Zhuo</forenames></author><author><keyname>Fu</keyname><forenames>Guangyuan</forenames></author><author><keyname>Di</keyname><forenames>Fuqiang</forenames></author><author><keyname>Li</keyname><forenames>Changlong</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author></authors><title>Generative Reversible Data Hiding by Image to Image Translation via GANs</title><categories>eess.IV cs.CR cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional reversible data hiding technique is based on cover image
modification which inevitably leaves some traces of rewriting that can be more
easily analyzed and attacked by the warder. Inspired by the cover synthesis
steganography based generative adversarial networks, in this paper, a novel
generative reversible data hiding scheme (GRDH) by image translation is
proposed. First, an image generator is used to obtain a realistic image, which
is used as an input to the image-to-image translation model with CycleGAN.
After image translation, a stego image with different semantic information will
be obtained. The secret message and the original input image can be recovered
separately by a well-trained message extractor and the inverse transform of the
image translation. Experimental results have verified the effectiveness of the
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02899</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02899</id><created>2019-05-07</created><authors><author><keyname>Kinoshita</keyname><forenames>Yuma</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Convolutional Neural Networks Considering Local and Global features for
  Image Enhancement</title><categories>eess.IV cs.CV cs.MM</categories><comments>To appear in Proc. ICIP2019. arXiv admin note: text overlap with
  arXiv:1901.05686</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel convolutional neural network (CNN)
architecture considering both local and global features for image enhancement.
Most conventional image enhancement methods, including Retinex-based methods,
cannot restore lost pixel values caused by clipping and quantizing. CNN-based
methods have recently been proposed to solve the problem, but they still have a
limited performance due to network architectures not handling global features.
To handle both local and global features, the proposed architecture consists of
three networks: a local encoder, a global encoder, and a decoder. In addition,
high dynamic range (HDR) images are used for generating training data for our
networks. The use of HDR images makes it possible to train CNNs with
better-quality images than images directly captured with cameras. Experimental
results show that the proposed method can produce higher-quality images than
conventional image enhancement methods including CNN-based methods, in terms of
various objective quality metrics: TMQI, entropy, NIQE, and BRISQUE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02914</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02914</id><created>2019-05-08</created><authors><author><keyname>Pham</keyname><forenames>Dung Tien</forenames></author><author><keyname>Van Nguyen</keyname><forenames>Thai</forenames></author><author><keyname>Le</keyname><forenames>Hai Xuan</forenames></author><author><keyname>Nguyen</keyname><forenames>Linh</forenames></author><author><keyname>Thai</keyname><forenames>Nguyen Huu</forenames></author><author><keyname>Phan</keyname><forenames>Tuan Anh</forenames></author><author><keyname>Pham</keyname><forenames>Hai Tuan</forenames></author><author><keyname>Duong</keyname><forenames>Anh Hoai</forenames></author></authors><title>Adaptive neural network based dynamic surface control for uncertain dual
  arm robots</title><categories>cs.RO cs.AI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper discusses an adaptive strategy to effectively control nonlinear
manipulation motions of a dual arm robot (DAR) under system uncertainties
including parameter variations, actuator nonlinearities and external
disturbances. It is proposed that the control scheme is first derived from the
dynamic surface control (DSC) method, which allows the robot's end-effectors to
robustly track the desired trajectories. Moreover, since exactly determining
the DAR system's dynamics is impractical due to the system uncertainties, the
uncertain system parameters are then proposed to be adaptively estimated by the
use of the radial basis function network (RBFN). The adaptation mechanism is
derived from the Lyapunov theory, which theoretically guarantees stability of
the closed-loop control system. The effectiveness of the proposed RBFN-DSC
approach is demonstrated by implementing the algorithm in a synthetic
environment with realistic parameters, where the obtained results are highly
promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02921</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02921</id><created>2019-05-08</created><authors><author><keyname>Parthasarathy</keyname><forenames>Srinivas</forenames></author><author><keyname>Busso</keyname><forenames>Carlos</forenames></author></authors><title>Semi-Supervised Speech Emotion Recognition with Ladder Networks</title><categories>eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech emotion recognition (SER) systems find applications in various fields
such as healthcare, education, and security and defense. A major drawback of
these systems is their lack of generalization across different conditions. This
problem can be solved by training models on large amounts of labeled data from
the target domain, which is expensive and time-consuming. Another approach is
to increase the generalization of the models. An effective way to achieve this
goal is by regularizing the models through multitask learning (MTL), where
auxiliary tasks are learned along with the primary task. These methods often
require the use of labeled data which is computationally expensive to collect
for emotion recognition (gender, speaker identity, age or other emotional
descriptors). This study proposes the use of ladder networks for emotion
recognition, which utilizes an unsupervised auxiliary task. The primary task is
a regression problem to predict emotional attributes. The auxiliary task is the
reconstruction of intermediate feature representations using a denoising
autoencoder. This auxiliary task does not require labels so it is possible to
train the framework in a semi-supervised fashion with abundant unlabeled data
from the target domain. This study shows that the proposed approach creates a
powerful framework for SER, achieving superior performance than fully
supervised single-task learning (STL) and MTL baselines. The approach is
implemented with several acoustic features, showing that ladder networks
generalize significantly better in cross-corpus settings. Compared to the STL
baselines, the proposed approach achieves relative gains in concordance
correlation coefficient (CCC) between 3.0% and 3.5% for within corpus
evaluations, and between 16.1% and 74.1% for cross corpus evaluations,
highlighting the power of the architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02937</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02937</id><created>2019-05-08</created><authors><author><keyname>Hussein</keyname><forenames>Sarah</forenames></author><author><keyname>Sahyoun</keyname><forenames>Walaa</forenames></author><author><keyname>Ziade</keyname><forenames>Youmni</forenames></author><author><keyname>Shubair</keyname><forenames>Raed M.</forenames></author></authors><title>Nano-Antenna Directivity for Electromagnetic Propagation in WBANs</title><categories>eess.SP</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-vivo sensing, diagnosis and treatment of diseases is having a great
attention lately. With advanced computational systems, the processing of the
biological data as well as the prediction of diagnosis is becoming more
promising. However, the implementation of these systems inside the human body
has a major challenge; modeling the communication channel. To overcome this
problem, researchers are investigating the main factors that define the
characteristics of the communication channel between nano-devices. In this
work, we summarize the elements that contribute to the path loss encountered by
an EM wave traveling in water, skin or epidermis. Then, the impact of
nano-antenna directivity on the EM propagating wave is studied along with the
frequency and the communication distance. The simulation results show that the
nano-antenna directivity seems to have minor contributions 5 to 7 dB on the
total path loss inside the human body with respect to the distance 2 to 30 dB
and frequency 10 to 15 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02944</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02944</id><created>2019-05-08</created><authors><author><keyname>Altmann</keyname><forenames>Yoann</forenames></author><author><keyname>McLaughlin</keyname><forenames>Stephen</forenames></author><author><keyname>Davies</keyname><forenames>Michael E.</forenames></author></authors><title>Fast online 3D reconstruction of dynamic scenes from individual
  single-photon detection events</title><categories>eess.IV stat.AP stat.CO</categories><doi>10.1109/TIP.2019.2952008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an algorithm for online 3D reconstruction of
dynamic scenes using individual times of arrival (ToA) of photons recorded by
single-photon detector arrays. One of the main challenges in 3D imaging using
single-photon Lidar is the integration time required to build ToA histograms
and reconstruct reliable 3D profiles in the presence of non-negligible ambient
illumination. This long integration time also prevents the analysis of rapid
dynamic scenes using existing techniques. We propose a new method which does
not rely on the construction of ToA histograms but allows, for the first time,
individual detection events to be processed online, in a parallel manner in
different pixels, while accounting for the intrinsic spatiotemporal structure
of dynamic scenes. Adopting a Bayesian approach, a Bayesian model is
constructed to capture the dynamics of the 3D profile and an approximate
inference scheme based on assumed density filtering is proposed, yielding a
fast and robust reconstruction algorithm able to process efficiently thousands
to millions of frames, as usually recorded using single-photon detectors. The
performance of the proposed method, able to process hundreds of frames per
second, is assessed using a series of experiments conducted with static and
dynamic 3D scenes and the results obtained pave the way to a new family of
real-time 3D reconstruction solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02954</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.02954</id><created>2019-05-08</created><updated>2019-12-19</updated><authors><author><keyname>Amirshahi</keyname><forenames>Alireza</forenames></author><author><keyname>Hashemi</keyname><forenames>Matin</forenames></author></authors><title>Ultra Low-Power and Real-time ECG Classification Based on STDP and
  R-STDP Neural Networks for Wearable Devices</title><categories>eess.SP cs.LG cs.NE</categories><comments>Published in IEEE Transactions on Biomedical Circuits and Systems
  (TBioCAS), 2019</comments><doi>10.1109/TBCAS.2019.2948920</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel ECG classification algorithm for real-time
cardiac monitoring on ultra low-power wearable devices. The proposed solution
is based on spiking neural networks which are the third generation of neural
networks. In specific, we employ spike-timing dependent plasticity (STDP), and
reward-modulated STDP (R-STDP), in which the model weights are trained
according to the timings of spike signals, and reward or punishment signals.
Experiments show that the proposed solution is suitable for real-time
operation, achieves comparable accuracy with respect to previous methods, and
more importantly, its energy consumption is significantly smaller than previous
neural network based solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03025</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03025</id><created>2019-05-08</created><updated>2019-05-19</updated><authors><author><keyname>Iida</keyname><forenames>Kenta</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>An Image Identification Scheme of Encrypted JPEG Images for
  Privacy-Preserving Photo Sharing Services</title><categories>eess.IV</categories><comments>This paper will be presented at IEEE International conference on
  Image Processing 2019</comments><doi>10.1587/transinf.2019MUP0006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an image identification scheme for double-compressed encrypted
JPEG images that aims to identify encrypted JPEG images that are generated from
an original JPEG image. To store images without any visual sensitive
information on photo sharing services, encrypted JPEG images are generated by
using a block-scrambling-based encryption method that has been proposed for
Encryption-then-Compression systems with JPEG compression. In addition, feature
vectors robust against JPEG compression are extracted from encrypted JPEG
images. The use of the image encryption and feature vectors allows us to
identify encrypted images recompressed multiple times. Moreover, the proposed
scheme is designed to identify images re-encrypted with different keys. The
results of a simulation show that the identification performance of the scheme
is high even when images are recompressed and re-encrypted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03026</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03026</id><created>2019-05-08</created><authors><author><keyname>Baltruschat</keyname><forenames>Ivo Matteo</forenames></author><author><keyname>Szwargulski</keyname><forenames>Patryk</forenames></author><author><keyname>Griese</keyname><forenames>Florian</forenames></author><author><keyname>Grosser</keyname><forenames>Mirco</forenames></author><author><keyname>Werner</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Knopp</keyname><forenames>Tobias</forenames></author></authors><title>3d-SMRnet: Achieving a new quality of MPI system matrix recovery by deep
  learning</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic particle imaging (MPI) data is commonly reconstructed using a system
matrix acquired in a time-consuming calibration measurement. The calibration
approach has the important advantage over model-based reconstruction that it
takes the complex particle physics as well as system imperfections into
account. This benefit comes for the cost that the system matrix needs to be
re-calibrated whenever the scan parameters, particle types or even the particle
environment (e.g. viscosity or temperature) changes. One route for reducing the
calibration time is the sampling of the system matrix at a subset of the
spatial positions of the intended field-of-view and employing system matrix
recovery. Recent approaches used compressed sensing (CS) and achieved
subsampling factors up to 28 that still allowed reconstructing MPI images of
sufficient quality. In this work, we propose a novel framework with a 3d-System
Matrix Recovery Network and demonstrate it to recover a 3d system matrix with a
subsampling factor of 64 in less than one minute and to outperform CS in terms
of system matrix quality, reconstructed image quality, and processing time. The
advantage of our method is demonstrated by reconstructing open access MPI
datasets. The model is further shown to be capable of inferring system matrices
for different particle types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03032</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03032</id><created>2019-05-08</created><authors><author><keyname>Xu</keyname><forenames>Pengfei</forenames></author><author><keyname>Jia</keyname><forenames>Yinjie</forenames></author><author><keyname>Wang</keyname><forenames>Zhijian</forenames></author></authors><title>Blind separation of rotor vibration signals in high-noise environments</title><categories>eess.SP</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the operation of the engine rotor, the vibration signal measured by
the sensor is the mixed signal of each vibration source, and contains strong
noise at the same time. In this paper, a new separation method for mixed
vibration signals in strong noise environment(SNR=-5) is proposed. Firstly, the
time-delay auto-correlation de-noising method is used to de-noise the mixed
signals, and then the common blind separation algorithm (MSNR algorithm is used
here) is used to separate the mixed vibration signals, which improves the
separation performance. The simulation results verify the validity of the
method. The proposed method provides a new idea for health monitoring and fault
diagnosis of engine rotor vibration signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03036</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03036</id><created>2019-05-08</created><updated>2019-08-19</updated><authors><author><keyname>Burwinkel</keyname><forenames>Hendrik</forenames></author><author><keyname>Kazi</keyname><forenames>Anees</forenames></author><author><keyname>Vivar</keyname><forenames>Gerome</forenames></author><author><keyname>Albarqouni</keyname><forenames>Shadi</forenames></author><author><keyname>Zahnd</keyname><forenames>Guillaume</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Ahmadi</keyname><forenames>Seyed-Ahmad</forenames></author></authors><title>Adaptive Image-Feature Learning for Disease Classification Using
  Inductive Graph Networks</title><categories>cs.LG eess.IV stat.ML</categories><comments>9 pages, 2 figures</comments><msc-class>68T99</msc-class><doi>10.1007/978-3-030-32226-7_71</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Geometric Deep Learning (GDL) has been introduced as a novel and
versatile framework for computer-aided disease classification. GDL uses patient
meta-information such as age and gender to model patient cohort relations in a
graph structure. Concepts from graph signal processing are leveraged to learn
the optimal mapping of multi-modal features, e.g. from images to disease
classes. Related studies so far have considered image features that are
extracted in a pre-processing step. We hypothesize that such an approach
prevents the network from optimizing feature representations towards achieving
the best performance in the graph network. We propose a new network
architecture that exploits an inductive end-to-end learning approach for
disease classification, where filters from both the CNN and the graph are
trained jointly. We validate this architecture against state-of-the-art
inductive graph networks and demonstrate significantly improved classification
scores on a modified MNIST toy dataset, as well as comparable classification
results with higher stability on a chest X-ray image dataset. Additionally, we
explain how the structural information of the graph affects both the image
filters and the feature learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03064</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03064</id><created>2019-05-08</created><authors><author><keyname>De Bast</keyname><forenames>Sibren</forenames></author><author><keyname>Vingradov</keyname><forenames>Evgenii</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author></authors><title>Cellular Coverage-Aware Path Planning for UAVs</title><categories>eess.SP</categories><comments>5 pages, 8 figures, SPAWC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Up until now, path planning for unmanned aerial vehicles (UAVs) has mainly
been focused on the optimisation towards energy efficiency. However, to operate
UAVs safely, wireless coverage is of utmost importance. Currently, deployed
cellular networks often exhibit an inadequate performance for aerial users due
to high amounts of intercell interference. Furthermore, taking the never-ending
trend of densification into account, the level of interference experienced by
UAVs will only increase in the future. For the purpose of UAV trajectory
planning, wireless coverage should be taken into account to mitigate
interference and to lower the risk of dangerous connectivity outages. In this
paper, several path planning strategies are proposed and evaluated to optimise
wireless coverage for UAVs. A simulator using a real-life 3D map is used to
evaluate the proposed algorithms for both 4G and 5G scenarios. We show that the
proposed Coverage-Aware A* algorithm, which alters the UAV's flying altitude,
is able to improve the mean SINR by 3-4dB and lower the cellular outage
probability by a factor of 10. Furthermore, the outages that still occur have a
60% shorter length, hence posing a lower risk to induce harmful accidents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03072</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03072</id><created>2019-05-08</created><updated>2019-07-25</updated><authors><author><keyname>L&#xfc;scher</keyname><forenames>Christoph</forenames></author><author><keyname>Beck</keyname><forenames>Eugen</forenames></author><author><keyname>Irie</keyname><forenames>Kazuki</forenames></author><author><keyname>Kitza</keyname><forenames>Markus</forenames></author><author><keyname>Michel</keyname><forenames>Wilfried</forenames></author><author><keyname>Zeyer</keyname><forenames>Albert</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Ralf</forenames></author><author><keyname>Ney</keyname><forenames>Hermann</forenames></author></authors><title>RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w/o Data
  Augmentation</title><categories>cs.CL cs.SD eess.AS</categories><comments>Proceedings of INTERSPEECH 2019</comments><doi>10.21437/Interspeech.2019-1780</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present state-of-the-art automatic speech recognition (ASR) systems
employing a standard hybrid DNN/HMM architecture compared to an attention-based
encoder-decoder design for the LibriSpeech task. Detailed descriptions of the
system development, including model design, pretraining schemes, training
schedules, and optimization approaches are provided for both system
architectures. Both hybrid DNN/HMM and attention-based systems employ
bi-directional LSTMs for acoustic modeling/encoding. For language modeling, we
employ both LSTM and Transformer based architectures. All our systems are built
using RWTHs open-source toolkits RASR and RETURNN. To the best knowledge of the
authors, the results obtained when training on the full LibriSpeech training
set, are the best published currently, both for the hybrid DNN/HMM and the
attention-based systems. Our single hybrid system even outperforms previous
results obtained from combining eight single systems. Our comparison shows that
on the LibriSpeech 960h task, the hybrid DNN/HMM system outperforms the
attention-based system by 15% relative on the clean and 40% relative on the
other test sets in terms of word error rate. Moreover, experiments on a reduced
100h-subset of the LibriSpeech training corpus even show a more pronounced
margin between the hybrid DNN/HMM and attention-based architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03083</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03083</id><created>2019-05-03</created><authors><author><keyname>Yousefi</keyname><forenames>Nooshin</forenames></author><author><keyname>Hasankhani</keyname><forenames>Farhad</forenames></author><author><keyname>Kiani</keyname><forenames>Mahsa</forenames></author></authors><title>Appointment scheduling model in healthcare using clustering algorithms</title><categories>eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study we provided a scheduling procedure which is combination of
machine learning and mathematical programming. Outpatients who request for
appointment in healthcare facilities have different priorities. Determining the
priority of outpatients and allocating the capacity based on the priority
classes are important concepts that have to be considered in scheduling of
outpatients. Two stages are defined for scheduling an incoming patient. In the
first stage, We applied and compared different clustering methods such as
k-mean clustering and agglomerative hierarchical clustering methods to classify
outpatients into priority classes and suggested the best pattern to cluster the
outpatients. In the second stage, we modeled the scheduling problem as a Markov
Decision Process (MDP) problem that tries to decrease waiting time of higher
priority outpatients. Due to the curse of dimensionality, we used uid
approximation method to estimate the optimal solution of the MDP. We applied
our methodology on a dataset of Shaheed Rajaei Medical and Research Center in
Iran, and we represented that how our models works in prioritizing and
scheduling of outpatients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03087</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03087</id><created>2019-05-08</created><authors><author><keyname>Upadhya</keyname><forenames>Abhijeet</forenames></author><author><keyname>Dwivedi</keyname><forenames>Vivek K.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Interference-Limited Mixed MUD-RF/FSO Two-Way Cooperative Networks over
  Double Generalized Gamma Turbulence Channels</title><categories>eess.SP</categories><comments>05 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this letter, the performance of multiuser-radio frequency/free space
optics (RF/FSO) two-way relay network in the presence of interference is
investigated. The FSO link accounts for pointing errors and both types of
detection techniques, i.e. intensity modulation/direct detection as well as
coherent demodulation, which is modeled as double generalized gamma (D-GG)
turbulence channel. On the other hand, the multiple users on the RF link are
assumed to undergo Nakagami-m fading. Multiple co-channel interferers (CCIs)
which corrupt the signal at relay node are modeled using Nakagami-m
distribution. Specifically, the exact closed-form expressions for the outage
probability (OP) of the overall system is derived. Moreover, the closed form
expression for the achievable sum-rate (ASR) of the considered system is
presented. In order to simplify the results,the asymptotic approximations of
the OP and ASR are derived in terms of elementary functions. The results
presented in the paper are validated by Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03106</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03106</id><created>2019-05-06</created><updated>2019-09-10</updated><authors><author><keyname>Ehrenborg</keyname><forenames>Casimir</forenames></author><author><keyname>Gustafsson</keyname><forenames>Mats</forenames></author><author><keyname>Capek</keyname><forenames>Miloslav</forenames></author></authors><title>Analysis of Capacity Bounds on MIMO Antennas</title><categories>eess.SP</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal spectral efficiency of MIMO antennas in an ideal line-of-sight
channel is investigated when bandwidth requirements are placed on the antenna.
By posing the problem as a convex optimization problem restricted by the input
port Q-factor a semi-analytical expression is formed for its solution. It is
shown that this solution is solely dependent on energy modes of the antenna.
These modes are compared to the characteristic modes and the ability to induce
them through sub-regions of a plate is investigated. The position of these
regions is also investigated when they are raised above the ground plane. Their
performance is illustrated through spectral efficiency over $Q$, a quantity
that is connected to the true capacity. It is demonstrated that the spatial
diversity of the controlled regions correlates with the number of significant
energy modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03107</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03107</id><created>2019-05-08</created><updated>2019-11-23</updated><authors><author><keyname>Elbir</keyname><forenames>Ahmet M.</forenames></author><author><keyname>Mishra</keyname><forenames>Kumar Vijay</forenames></author></authors><title>Joint Antenna Selection and Hybrid Beamformer Design using Unquantized
  and Quantized Deep Learning Networks</title><categories>eess.SP</categories><comments>10 pages, 7 figures, 2 tables, to appear in IEEE Transactions on
  Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In millimeter-wave communications, multiple-input-multiple-output (MIMO)
systems use large antenna arrays to achieve high gain and spectral efficiency.
These massive MIMO systems employ hybrid beamformers to reduce power
consumption associated with fully digital beamforming in large arrays. Further
savings in cost and power are possible through the use of subarrays. Unlike
prior works that resort to large latency methods such as optimization and
greedy search for subarray selection, we propose a deep-learning-based approach
in order to overcome the complexity issue without causing significant
performance loss. We formulate antenna selection and hybrid beamformer design
as a classification/prediction problem for convolutional neural networks
(CNNs). For antenna selection, the CNN accepts the channel matrix as input and
outputs a subarray with optimal spectral efficiency. The resultant subarray
channel matrix is then again fed to a CNN to obtain analog and baseband
beamformers. We train the CNNs with several noisy channel matrices that have
different channel statistics in order to achieve a robust performance at the
network output. Numerical experiments show that our CNN framework provides an
order better spectral efficiency and is 10 times faster than the conventional
techniques. Further investigations with quantized-CNNs show that the proposed
network, saved in no more than 5 bits, is also suited for digital mobile
devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03109</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03109</id><created>2019-05-04</created><updated>2020-02-17</updated><authors><author><keyname>Vajdi</keyname><forenames>Amir</forenames></author><author><keyname>Zaghian</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Farahmand</keyname><forenames>Saman</forenames></author><author><keyname>Rastegar</keyname><forenames>Elham</forenames></author><author><keyname>Maroofi</keyname><forenames>Kian</forenames></author><author><keyname>Jia</keyname><forenames>Shaohua</forenames></author><author><keyname>Pomplun</keyname><forenames>Marc</forenames></author><author><keyname>Haspel</keyname><forenames>Nurit</forenames></author><author><keyname>Bayat</keyname><forenames>Akram</forenames></author></authors><title>Human Gait Database for Normal Walk Collected by Smart Phone
  Accelerometer</title><categories>eess.SP cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The goal of this study is to introduce a comprehensive gait database of 93
human subjects who walked between two endpoints during two different sessions
and record their gait data using two smartphones, one was attached to the right
thigh and another one on the left side of the waist. This data is collected
with the intention to be utilized by a deep learning-based method which
requires enough time points. The metadata including age, gender, smoking, daily
exercise time, height, and weight of an individual is recorded. this data set
is publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03160</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03160</id><created>2019-05-08</created><updated>2020-01-28</updated><authors><author><keyname>Sanchez</keyname><forenames>Jesus Rodriguez</forenames></author><author><keyname>Rusek</keyname><forenames>Fredrik</forenames></author><author><keyname>Edfors</keyname><forenames>Ove</forenames></author><author><keyname>Sarajlic</keyname><forenames>Muris</forenames></author><author><keyname>Liu</keyname><forenames>Liang</forenames></author></authors><title>Decentralized Massive MIMO Processing Exploring Daisy-chain Architecture
  and Recursive Algorithms</title><categories>eess.SP</categories><comments>Manuscript accepted for publication in IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2020.2964496</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms for Massive MIMO uplink detection and downlink precoding typically
rely on a centralized approach, by which baseband data from all antenna modules
are routed to a central node in order to be processed. In the case of Massive
MIMO, where hundreds or thousands of antennas are expected in the base-station,
said routing becomes a bottleneck since interconnection throughput is limited.
This paper presents a fully decentralized architecture and an algorithm for
Massive MIMO uplink detection and downlink precoding based on the Stochastic
Gradient Descent (SGD) method, which does not require a central node for these
tasks. Through a recursive approach and very low complexity operations, the
proposed algorithm provides a good trade-off between performance,
interconnection throughput and latency. Further, our proposed solution achieves
significantly lower interconnection data-rate than other architectures,
enabling future scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03172</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03172</id><created>2019-05-08</created><authors><author><keyname>Huang</keyname><forenames>Renke</forenames></author><author><keyname>Fan</keyname><forenames>Rui</forenames></author><author><keyname>Yin</keyname><forenames>Tianzhixi</forenames></author><author><keyname>Wang</keyname><forenames>Shaobu</forenames></author><author><keyname>Tan</keyname><forenames>Zhenyu</forenames></author></authors><title>Parameters Calibration for Power Grid Stability Models using Deep
  Learning Methods</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel parameter calibration approach for power system
stability models using automatic data generation and advanced deep learning
technology. A PMU-measurement-based event playback approach is used to identify
potential inaccurate parameters and automatically generate extensive simulation
data, which are used for training a convolutional neural network (CNN). The
accurate parameters will be predicted by the well-trained CNN model and
validated by original PMU measurements. The accuracy and effectiveness of the
proposed deep learning approach have been validated through extensive
simulation and field data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03175</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03175</id><created>2019-05-08</created><authors><author><keyname>Lu</keyname><forenames>Siyuan</forenames></author><author><keyname>Lu</keyname><forenames>Jinming</forenames></author><author><keyname>Lin</keyname><forenames>Jun</forenames></author><author><keyname>Wang</keyname><forenames>Zhongfeng</forenames></author></authors><title>A Hardware-Oriented and Memory-Efficient Method for CTC Decoding</title><categories>eess.SP cs.LG</categories><comments>13 pages, 11 figures</comments><journal-ref>IEEE Access, vol. 7, pp. 120681-120694, 2019</journal-ref><doi>10.1109/ACCESS.2019.2937680</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Connectionist Temporal Classification (CTC) has achieved great success in
sequence to sequence analysis tasks such as automatic speech recognition (ASR)
and scene text recognition (STR). These applications can use the CTC objective
function to train the recurrent neural networks (RNNs), and decode the outputs
of RNNs during inference. While hardware architectures for RNNs have been
studied, hardware-based CTCdecoders are desired for high-speed CTC-based
inference systems. This paper, for the first time, provides a low-complexity
and memory-efficient approach to build a CTC-decoder based on the beam search
decoding. Firstly, we improve the beam search decoding algorithm to save the
storage space. Secondly, we compress a dictionary (reduced from 26.02MB to
1.12MB) and use it as the language model. Meanwhile searching this dictionary
is trivial. Finally, a fixed-point CTC-decoder for an English ASR and an STR
task using the proposed method is implemented with C++ language. It is shown
that the proposed method has little precision loss compared with its
floating-point counterpart. Our experiments demonstrate the compression ratio
of the storage required by the proposed beam search decoding algorithm are
29.49 (ASR) and 17.95 (STR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03176</identifier>
 <datestamp>2020-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03176</id><created>2019-05-08</created><updated>2020-01-22</updated><authors><author><keyname>Lan</keyname><forenames>Ti-Yen</forenames></author><author><keyname>Bendory</keyname><forenames>Tamir</forenames></author><author><keyname>Boumal</keyname><forenames>Nicolas</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author></authors><title>Multi-target Detection with an Arbitrary Spacing Distribution</title><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the structure reconstruction problem in single-particle
cryo-electron microscopy, we consider the multi-target detection model, where
multiple copies of a target signal occur at unknown locations in a long
measurement, further corrupted by additive Gaussian noise. At low noise levels,
one can easily detect the signal occurrences and estimate the signal by
averaging. However, in the presence of high noise, which is the focus of this
paper, detection is impossible. Here, we propose two
approaches---autocorrelation analysis and an approximate expectation
maximization algorithm---to reconstruct the signal without the need to detect
signal occurrences in the measurement. In particular, our methods apply to an
arbitrary spacing distribution of signal occurrences. We demonstrate
reconstructions with synthetic data and empirically show that the sample
complexity of both methods scales as 1/SNR^3 in the low SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03183</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03183</id><created>2019-05-08</created><updated>2019-12-16</updated><authors><author><keyname>Alexandru</keyname><forenames>Roxana</forenames></author><author><keyname>Dragotti</keyname><forenames>Pier Luigi</forenames></author></authors><title>Reconstructing Classes of Non-bandlimited Signals from Time Encoded
  Information</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate time encoding as an alternative method to classical sampling,
and address the problem of reconstructing classes of non-bandlimited signals
from time-based samples. We consider a sampling mechanism based on first
filtering the input, before obtaining the timing information using a time
encoding machine. Within this framework, we show that sampling by timing is
equivalent to a non-uniform sampling problem, where the reconstruction of the
input depends on the characteristics of the filter and on its non-uniform
shifts. The classes of filters we focus on are exponential and polynomial
splines, and we show that their fundamental properties are locally preserved in
the context of non-uniform sampling. Leveraging these properties, we then
derive sufficient conditions and propose novel algorithms for perfect
reconstruction of classes of non-bandlimited signals such as: streams of
Diracs, sequences of pulses and piecewise constant signals. Next, we extend
these methods to operate with arbitrary filters, and also present simulation
results on synthetic noisy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03209</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03209</id><created>2019-05-08</created><authors><author><keyname>Ali</keyname><forenames>Sharib</forenames></author><author><keyname>Zhou</keyname><forenames>Felix</forenames></author><author><keyname>Daul</keyname><forenames>Christian</forenames></author><author><keyname>Braden</keyname><forenames>Barbara</forenames></author><author><keyname>Bailey</keyname><forenames>Adam</forenames></author><author><keyname>Realdon</keyname><forenames>Stefano</forenames></author><author><keyname>East</keyname><forenames>James</forenames></author><author><keyname>Wagni&#xe8;res</keyname><forenames>Georges</forenames></author><author><keyname>Loschenov</keyname><forenames>Victor</forenames></author><author><keyname>Grisan</keyname><forenames>Enrico</forenames></author><author><keyname>Blondel</keyname><forenames>Walter</forenames></author><author><keyname>Rittscher</keyname><forenames>Jens</forenames></author></authors><title>Endoscopy artifact detection (EAD 2019) challenge dataset</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><comments>12 pages, EAD2019 dataset description</comments><doi>10.17632/C7FJBXCGJ9.1</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Endoscopic artifacts are a core challenge in facilitating the diagnosis and
treatment of diseases in hollow organs. Precise detection of specific artifacts
like pixel saturations, motion blur, specular reflections, bubbles and debris
is essential for high-quality frame restoration and is crucial for realizing
reliable computer-assisted tools for improved patient care. At present most
videos in endoscopy are currently not analyzed due to the abundant presence of
multi-class artifacts in video frames. Through the endoscopic artifact
detection (EAD 2019) challenge, we address this key bottleneck problem by
solving the accurate identification and localization of endoscopic frame
artifacts to enable further key quantitative analysis of unusable video frames
such as mosaicking and 3D reconstruction which is crucial for delivering
improved patient care. This paper summarizes the challenge tasks and describes
the dataset and evaluation criteria established in the EAD 2019 challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03229</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03229</id><created>2019-04-08</created><updated>2019-06-03</updated><authors><author><keyname>Li</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Hu</forenames></author><author><keyname>Shuai</keyname><forenames>Wenquan</forenames></author><author><keyname>Zhang</keyname><forenames>Honghao</forenames></author><author><keyname>Peng</keyname><forenames>Yong</forenames></author></authors><title>Image-based reconstruction for the impact problems by using DPNNs</title><categories>cs.OH cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the improvement of the pattern recognition and feature extraction of
Deep Neural Networks (DPNNs), image-based design and optimization have been
widely used in multidisciplinary researches. Recently, a Reconstructive Neural
Network (ReConNN) has been proposed to obtain an image-based model from an
analysis-based model [1, 2], and a steady-state heat transfer of a heat sink
has been successfully reconstructed. Commonly, this method is suitable to
handle stable-state problems. However, it has difficulties handling nonlinear
transient impact problems, due to the bottlenecks of the Deep Neural Network
(DPNN). For example, nonlinear transient problems make it difficult for the
Generative Adversarial Network (GAN) to generate various reasonable images.
Therefore, in this study, an improved ReConNN method is proposed to address the
mentioned weaknesses. Time-dependent ordered images can be generated.
Furthermore, the improved method is successfully applied in impact simulation
case and engineering experiment. Through the experiments, comparisons and
analyses, the improved method is demonstrated to outperform the former one in
terms of its accuracy, efficiency and costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03238</identifier>
 <datestamp>2019-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03238</id><created>2019-05-08</created><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Banawan</keyname><forenames>Karim</forenames></author><author><keyname>Seddik</keyname><forenames>Karim G.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On Timely Channel Coding with Hybrid ARQ</title><categories>cs.IT cs.NI eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A status updating communication system is examined, in which a transmitter
communicates with a receiver over a noisy channel. The goal is to realize
timely delivery of fresh data over time, which is assessed by an
age-of-information (AoI) metric. Channel coding is used to combat the channel
errors, and feedback is sent to acknowledge updates' reception. In case
decoding is unsuccessful, a hybrid ARQ protocol is employed, in which
incremental redundancy (IR) bits are transmitted to enhance the decoding
ability. This continues for some amount of time in case decoding remains
unsuccessful, after which a new (fresh) status update is transmitted instead.
In case decoding is successful, the transmitter has the option to idly wait for
a certain amount of time before sending a new update. A general problem is
formulated that optimizes the codeword and IR lengths for each update, and the
waiting times, such that the long term average AoI is minimized. Stationary
deterministic policies are investigated, in which the codeword and IR lengths
are fixed for each update, and the waiting time is a deterministic function of
the AoI. The optimal waiting policy is then derived, and is shown to have a
threshold structure, in which the transmitter sends a new update only if the
AoI grows above a certain threshold that is a function of the codeword and IR
lengths. Choosing the codeword and IR lengths is discussed in the context of
binary symmetric channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03247</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03247</id><created>2019-05-07</created><authors><author><keyname>Cao</keyname><forenames>Yanjun</forenames></author><author><keyname>St-Onge</keyname><forenames>David</forenames></author><author><keyname>Zell</keyname><forenames>Andreas</forenames></author><author><keyname>Beltrame</keyname><forenames>Giovanni</forenames></author></authors><title>Collaborative Localization and Tracking with Minimal Infrastructure</title><categories>eess.SP cs.RO</categories><comments>This paper is submitted to IROS2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization and tracking are two very active areas of research for robotics,
automation, and the Internet-of-Things. Accurate tracking for a large number of
devices usually requires deployment of substantial infrastructure (infrared
tracking systems, cameras, wireless antennas, etc.), which is not ideal for
inaccessible or protected environments. This paper stems from the challenge
posed such environments: cover a large number of units spread over a large
number of small rooms, with minimal required localization infrastructure. The
idea is to accurately track the position of handheld devices or mobile robots,
without interfering with its architecture. Using Ultra-Wide Band (UWB) devices,
we leveraged our expertise in distributed and collaborative robotic systems to
develop an novel solution requiring a minimal number of fixed anchors. We
discuss a strategy to share the UWB network together with an Extended Kalman
filter derivation to collaboratively locate and track UWB-equipped devices, and
show results from our experimental campaign tracking visitors in the Chambord
castle in France.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03277</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03277</id><created>2019-05-08</created><authors><author><keyname>Wronski</keyname><forenames>Bartlomiej</forenames></author><author><keyname>Garcia-Dorado</keyname><forenames>Ignacio</forenames></author><author><keyname>Ernst</keyname><forenames>Manfred</forenames></author><author><keyname>Kelly</keyname><forenames>Damien</forenames></author><author><keyname>Krainin</keyname><forenames>Michael</forenames></author><author><keyname>Liang</keyname><forenames>Chia-Kai</forenames></author><author><keyname>Levoy</keyname><forenames>Marc</forenames></author><author><keyname>Milanfar</keyname><forenames>Peyman</forenames></author></authors><title>Handheld Multi-Frame Super-Resolution</title><categories>cs.CV eess.IV</categories><comments>24 pages, accepted to Siggraph 2019 Technical Papers program</comments><doi>10.1145/3306346.3323024</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Compared to DSLR cameras, smartphone cameras have smaller sensors, which
limits their spatial resolution; smaller apertures, which limits their light
gathering ability; and smaller pixels, which reduces their signal-to noise
ratio. The use of color filter arrays (CFAs) requires demosaicing, which
further degrades resolution. In this paper, we supplant the use of traditional
demosaicing in single-frame and burst photography pipelines with a multiframe
super-resolution algorithm that creates a complete RGB image directly from a
burst of CFA raw images. We harness natural hand tremor, typical in handheld
photography, to acquire a burst of raw frames with small offsets. These frames
are then aligned and merged to form a single image with red, green, and blue
values at every pixel site. This approach, which includes no explicit
demosaicing step, serves to both increase image resolution and boost signal to
noise ratio. Our algorithm is robust to challenging scene conditions: local
motion, occlusion, or scene changes. It runs at 100 milliseconds per
12-megapixel RAW input burst frame on mass-produced mobile phones.
Specifically, the algorithm is the basis of the Super-Res Zoom feature, as well
as the default merge method in Night Sight mode (whether zooming or not) on
Google's flagship phone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03278</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03278</id><created>2019-05-08</created><authors><author><keyname>Levin</keyname><forenames>David N.</forenames></author></authors><title>On the representation of speech and music</title><categories>cs.SD eess.AS stat.ME</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most automatic speech recognition (ASR) systems, the audio signal is
processed to produce a time series of sensor measurements (e.g., filterbank
outputs). This time series encodes semantic information in a speaker-dependent
way. An earlier paper showed how to use the sequence of sensor measurements to
derive an &quot;inner&quot; time series that is unaffected by any previous invertible
transformation of the sensor measurements. The current paper considers two or
more speakers, who mimic one another in the following sense: when they say the
same words, they produce sensor states that are invertibly mapped onto one
another. It follows that the inner time series of their utterances must be the
same when they say the same words. In other words, the inner time series
encodes their speech in a manner that is speaker-independent. Consequently, the
ASR training process can be simplified by collecting and labelling the inner
time series of the utterances of just one speaker, instead of training on the
sensor time series of the utterances of a large variety of speakers. A similar
argument suggests that the inner time series of music is
instrument-independent. This is demonstrated in experiments on monophonic
electronic music.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03287</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03287</id><created>2019-05-08</created><authors><author><keyname>Tyagi</keyname><forenames>Siddharth</forenames></author><author><keyname>Mayergoyz</keyname><forenames>Isaak</forenames></author></authors><title>Optimal Time-Domain Pulse Width Modulation for Three-Phase Inverters</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel optimal time-domain technique for pulse-width modulation (PWM) in
three-phase inverters is presented. This technique is based on the time-domain
per phase analysis of three-phase inverters. The role of symmetries on the
structure of three-phase PWM inverter voltages and their harmonic contents are
discussed. Numerical results highlighting improvements in the harmonic
performance of three-phase inverters are presented
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03330</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03330</id><created>2019-05-08</created><updated>2019-08-02</updated><authors><author><keyname>Kavalerov</keyname><forenames>Ilya</forenames></author><author><keyname>Wisdom</keyname><forenames>Scott</forenames></author><author><keyname>Erdogan</keyname><forenames>Hakan</forenames></author><author><keyname>Patton</keyname><forenames>Brian</forenames></author><author><keyname>Wilson</keyname><forenames>Kevin</forenames></author><author><keyname>Roux</keyname><forenames>Jonathan Le</forenames></author><author><keyname>Hershey</keyname><forenames>John R.</forenames></author></authors><title>Universal Sound Separation</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, accepted to WASPAA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent deep learning approaches have achieved impressive performance on
speech enhancement and separation tasks. However, these approaches have not
been investigated for separating mixtures of arbitrary sounds of different
types, a task we refer to as universal sound separation, and it is unknown how
performance on speech tasks carries over to non-speech tasks. To study this
question, we develop a dataset of mixtures containing arbitrary sounds, and use
it to investigate the space of mask-based separation architectures, varying
both the overall network architecture and the framewise analysis-synthesis
basis for signal transformations. These network architectures include
convolutional long short-term memory networks and time-dilated convolution
stacks inspired by the recent success of time-domain enhancement networks like
ConvTasNet. For the latter architecture, we also propose novel modifications
that further improve separation performance. In terms of the framewise
analysis-synthesis basis, we explore both a short-time Fourier transform (STFT)
and a learnable basis, as used in ConvTasNet. For both of these bases, we also
examine the effect of window size. In particular, for STFTs, we find that
longer windows (25-50 ms) work best for speech/non-speech separation, while
shorter windows (2.5 ms) work best for arbitrary sounds. For learnable bases,
shorter windows (2.5 ms) work best on all tasks. Surprisingly, for universal
sound separation, STFTs outperform learnable bases. Our best methods produce an
improvement in scale-invariant signal-to-distortion ratio of over 13 dB for
speech/non-speech separation and close to 10 dB for universal sound separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03356</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03356</id><created>2019-05-08</created><updated>2019-10-29</updated><authors><author><keyname>Chen</keyname><forenames>Yicheng</forenames></author><author><keyname>Jakary</keyname><forenames>Angela</forenames></author><author><keyname>Avadiappan</keyname><forenames>Sivakami</forenames></author><author><keyname>Hess</keyname><forenames>Christopher P.</forenames></author><author><keyname>Lupo</keyname><forenames>Janine M.</forenames></author></authors><title>QSMGAN: Improved Quantitative Susceptibility Mapping using 3D Generative
  Adversarial Networks with Increased Receptive Field</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative susceptibility mapping (QSM) is a powerful MRI technique that
has shown great potential in quantifying tissue susceptibility in numerous
neurological disorders. However, the intrinsic ill-posed dipole inversion
problem greatly affects the accuracy of the susceptibility map. We propose
QSMGAN: a 3D deep convolutional neural network approach based on a 3D U-Net
architecture with increased receptive field of the input phase compared to the
output and further refined the network using the WGAN with gradient penalty
training strategy. Our method generates accurate QSM maps from single
orientation phase maps efficiently and performs significantly better than
traditional non-learning-based dipole inversion algorithms. The generalization
capability was verified by applying the algorithm to an unseen pathology--brain
tumor patients with radiation-induced cerebral microbleeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03371</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03371</id><created>2019-05-08</created><authors><author><keyname>Jiang</keyname><forenames>Shaowei</forenames></author><author><keyname>Bian</keyname><forenames>Zichao</forenames></author><author><keyname>Huang</keyname><forenames>Xizhi</forenames></author><author><keyname>Song</keyname><forenames>Pengming</forenames></author><author><keyname>Zhang</keyname><forenames>He</forenames></author><author><keyname>Zhang</keyname><forenames>Yongbing</forenames></author><author><keyname>Zheng</keyname><forenames>Guoan</forenames></author></authors><title>Rapid and robust whole slide imaging based on LED-array illumination and
  color-multiplexed single-shot autofocusing</title><categories>eess.IV physics.ins-det</categories><journal-ref>Quantitative Imaging in Medicine and Surgery, 9(5), 823-831,
  (2019)</journal-ref><doi>10.21037/qims.2019.05.04</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: The use of whole slide imaging (WSI) for digital pathology has
recently been cleared for primary diagnosis in the US. A conventional WSI
system scans the tissue slide to different positions and acquires the digital
images. In a typical implementation, a focus map is created prior to the
scanning process, leading to significant overhead time and a necessity for high
positional accuracy of the mechanical system. The resulting cost of WSI system
is often prohibitive for frozen section procedure during surgery.
  Methods: We report a novel WSI scheme based on a programmable LED array for
sample illumination. In between two regular brightfield image acquisitions, we
acquire one additional image by turning on a red and a green LED for color
multiplexed illumination. We then identify the translational shift of the red-
and green-channel images by maximizing the image mutual information or
cross-correlation. The resulting translational shift is used for dynamic focus
correction in the scanning process. Since we track the differential focus
during adjacent acquisitions, there is no positional repeatability requirement
in our scheme.
  Results: We demonstrate a prototype WSI platform with a mean focusing error
of ~0.3 microns. Different from previous implementations, this prototype
platform requires no focus map surveying, no secondary camera or additional
optics, and allows for continuous sample motion in the focus tracking process.
  Conclusions: A programmable LED array can be used for color-multiplexed
single-shot autofocusing in WSI. The reported scheme may enable the development
of cost-effective WSI platforms without positional repeatability requirement.
It may also provide a turnkey solution for other high-content microscopy
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03440</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03440</id><created>2019-05-09</created><authors><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Xu</keyname><forenames>Xiaoli</forenames></author></authors><title>Path Design for Cellular-Connected UAV with Reinforcement Learning</title><categories>cs.NI cs.LG eess.SP</categories><comments>submitted for conference publications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the path design problem for cellular-connected unmanned
aerial vehicle (UAV), which aims to minimize its mission completion time while
maintaining good connectivity with the cellular network. We first argue that
the conventional path design approach via formulating and solving optimization
problems faces several practical challenges, and then propose a new
reinforcement learning-based UAV path design algorithm by applying
\emph{temporal-difference} method to directly learn the \emph{state-value
function} of the corresponding Markov Decision Process. The proposed algorithm
is further extended by using linear function approximation with tile coding to
deal with large state space. The proposed algorithms only require the raw
measured or simulation-generated signal strength as the input and are suitable
for both online and offline implementations. Numerical results show that the
proposed path designs can successfully avoid the coverage holes of cellular
networks even in the complex urban environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03443</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03443</id><created>2019-05-09</created><authors><author><keyname>Srinivasan</keyname><forenames>Muralikrishnan</forenames></author><author><keyname>Subhash</keyname><forenames>Athira</forenames></author><author><keyname>Kalyani</keyname><forenames>Sheetal</forenames></author></authors><title>Joint power and resource allocation of D2D communication with
  low-resolution ADC</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the joint power control and resource allocation for a
device-to-device (D2D) underlay cellular system with a multi-antenna BS
employing ADCs with different resolutions. We propose a four-step algorithm
that optimizes the ADC resolution profile at the base station (BS) to reduce
the energy consumption and perform joint power control and resource allocation
of D2D communication users (DUEs) and cellular users (CUEs) to improve the D2D
reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03445</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03445</id><created>2019-05-09</created><authors><author><keyname>Cao</keyname><forenames>Haichao</forenames></author><author><keyname>Liu</keyname><forenames>Hong</forenames></author><author><keyname>Song</keyname><forenames>Enmin</forenames></author><author><keyname>Ma</keyname><forenames>Guangzhi</forenames></author><author><keyname>Xu</keyname><forenames>Xiangyang</forenames></author><author><keyname>Jin</keyname><forenames>Renchao</forenames></author><author><keyname>Liu</keyname><forenames>Tengying</forenames></author><author><keyname>Hung</keyname><forenames>Chih-Cheng</forenames></author></authors><title>Two-Stage Convolutional Neural Network Architecture for Lung Nodule
  Detection</title><categories>cs.CV eess.IV</categories><comments>29 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early detection of lung cancer is an effective way to improve the survival
rate of patients. It is a critical step to have accurate detection of lung
nodules in computed tomography (CT) images for the diagnosis of lung cancer.
However, due to the heterogeneity of the lung nodules and the complexity of the
surrounding environment, robust nodule detection has been a challenging task.
In this study, we propose a two-stage convolutional neural network (TSCNN)
architecture for lung nodule detection. The CNN architecture in the first stage
is based on the improved UNet segmentation network to establish an initial
detection of lung nodules. Simultaneously, in order to obtain a high recall
rate without introducing excessive false positive nodules, we propose a novel
sampling strategy, and use the offline hard mining idea for training and
prediction according to the proposed cascaded prediction method. The CNN
architecture in the second stage is based on the proposed dual pooling
structure, which is built into three 3D CNN classification networks for false
positive reduction. Since the network training requires a significant amount of
training data, we adopt a data augmentation method based on random mask.
Furthermore, we have improved the generalization ability of the false positive
reduction model by means of ensemble learning. The proposed method has been
experimentally verified on the LUNA dataset. Experimental results show that the
proposed TSCNN architecture can obtain competitive detection performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03471</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03471</id><created>2019-05-09</created><updated>2019-06-03</updated><authors><author><keyname>Sinha</keyname><forenames>Priyanka</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Turgut</keyname><forenames>Esma</forenames></author><author><keyname>Gursoy</keyname><forenames>M. Cenk</forenames></author></authors><title>RSS-Based Detection of Drones in the Presence of RF Interferers</title><categories>eess.SP</categories><comments>8 pages, Aggregate interference amplitude, LOS/NLOS, nearest
  neighbor, PPP, stochastic geometry, drone detection, UTM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drones will have extensive use cases across various commercial, government,
and military sectors, ranging from delivery of consumer goods to search and
rescue operations. To maintain the safety and security of people and
infrastructure, it becomes critically important to quickly and accurately
detect non-cooperating drones. In this paper we formulate a received signal
strength (RSS) based detector, leveraging the existing wireless infrastructures
that might already be serving other devices. Thus the detector can detect the
presence of a drone signal buried in radio frequency (RF) interference and
thermal noise, in a mixed line-of-sight (LOS) and non-LOS (NLOS) environment.
We develop analytical expressions for the probability of false alarm and the
probability of detection of a drone, which quantify the impact of aggregate
interference and air-to-ground (A2G) propagation characteristics on the
detection performance of individual sensors. We also provide analytical
expressions for the average network probability of detection, which capture the
impact of sensor density on a network's detection coverage. Finally, we find
the critical sensor density that maximizes the average network probability of
detection for a given requirement of the probability of false alarm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03500</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03500</id><created>2019-05-09</created><updated>2019-09-25</updated><authors><author><keyname>Menne</keyname><forenames>Tobias</forenames></author><author><keyname>Sklyar</keyname><forenames>Ilya</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Ralf</forenames></author><author><keyname>Ney</keyname><forenames>Hermann</forenames></author></authors><title>Analysis of Deep Clustering as Preprocessing for Automatic Speech
  Recognition of Sparsely Overlapping Speech</title><categories>cs.SD cs.CL eess.AS</categories><journal-ref>Proceedings of INTERSPEECH 2019</journal-ref><doi>10.21437/Interspeech.2019-1728</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Significant performance degradation of automatic speech recognition (ASR)
systems is observed when the audio signal contains cross-talk. One of the
recently proposed approaches to solve the problem of multi-speaker ASR is the
deep clustering (DPCL) approach. Combining DPCL with a state-of-the-art hybrid
acoustic model, we obtain a word error rate (WER) of 16.5 % on the commonly
used wsj0-2mix dataset, which is the best performance reported thus far to the
best of our knowledge. The wsj0-2mix dataset contains simulated cross-talk
where the speech of multiple speakers overlaps for almost the entire utterance.
In a more realistic ASR scenario the audio signal contains significant portions
of single-speaker speech and only part of the signal contains speech of
multiple competing speakers. This paper investigates obstacles of applying DPCL
as a preprocessing method for ASR in such a scenario of sparsely overlapping
speech. To this end we present a data simulation approach, closely related to
the wsj0-2mix dataset, generating sparsely overlapping speech datasets of
arbitrary overlap ratio. The analysis of applying DPCL to sparsely overlapping
speech is an important interim step between the fully overlapping datasets like
wsj0-2mix and more realistic ASR datasets, such as CHiME-5 or AMI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03519</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03519</id><created>2019-05-09</created><authors><author><keyname>Li</keyname><forenames>Liying</forenames></author><author><keyname>Yang</keyname><forenames>Chungang</forenames></author><author><keyname>Mkiramweni</keyname><forenames>Mbazingwa E.</forenames></author><author><keyname>Pang</keyname><forenames>Lei</forenames></author></authors><title>Intelligent Scheduling and Power Control for Multimedia Transmission in
  5G CoMP Systems: A Dynamic Bargaining Game</title><categories>cs.NI eess.SP</categories><comments>11 pages, 14 figures, This paper is accepted for publication in the
  IEEE Journal on Selected Areas in Communications (JSAC) Special Issue on
  &quot;Multimedia Economics for Future Networks: Theory Methods , and Application&quot;
  on 21 April 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent terminals support a large number of multimedia, such as picture,
audio, video, and so on. The coexistence of various multimedia makes it
necessary to provide service for different requests. In this work, we consider
interference-aware coordinated multi-point (CoMP) to mitigate inter-cell
interference and improve total throughput in the fifth-generation (5G) mobile
networks. To select the scheduled edge users, cluster the cooperative base
stations (BSs), and determine the transmitting power, a novel dynamic
bargaining approach is proposed. Based on affinity propagation, we first select
the users to be scheduled and the cooperative BSs serving them respectively.
Then, based on the Nash bargaining solution (NBS), we develop a power control
scheme considering the transmission delay, which guarantees a generalized
proportional fairness among users. Simulation results demonstrate the
superiority of the user-centric scheduling and power control methods in 5G CoMP
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03554</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03554</id><created>2019-05-09</created><authors><author><keyname>Kiranyaz</keyname><forenames>Serkan</forenames></author><author><keyname>Avci</keyname><forenames>Onur</forenames></author><author><keyname>Abdeljaber</keyname><forenames>Osama</forenames></author><author><keyname>Ince</keyname><forenames>Turker</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author><author><keyname>Inman</keyname><forenames>Daniel J.</forenames></author></authors><title>1D Convolutional Neural Networks and Applications: A Survey</title><categories>eess.SP cs.AI</categories><comments>20 pages, 17 figures, MSSP (Elsevier) submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last decade, Convolutional Neural Networks (CNNs) have become the
de facto standard for various Computer Vision and Machine Learning operations.
CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating
convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and
millions of parameters have the ability to learn complex objects and patterns
providing that they can be trained on a massive size visual database with
ground-truth labels. With a proper training, this unique ability makes them the
primary tool for various engineering applications for 2D signals such as images
and video frames. Yet, this may not be a viable option in numerous applications
over 1D signals especially when the training data is scarce or
application-specific. To address this issue, 1D CNNs have recently been
proposed and immediately achieved the state-of-the-art performance levels in
several applications such as personalized biomedical data classification and
early diagnosis, structural health monitoring, anomaly detection and
identification in power electronics and motor-fault detection. Another major
advantage is that a real-time and low-cost hardware implementation is feasible
due to the simple and compact configuration of 1D CNNs that perform only 1D
convolutions (scalar multiplications and additions). This paper presents a
comprehensive review of the general architecture and principals of 1D CNNs
along with their major engineering applications, especially focused on the
recent progress in this field. Their state-of-the-art performance is
highlighted concluding with their unique properties. The benchmark datasets and
the principal 1D CNN software used in those applications are also publically
shared in a dedicated website.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03567</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03567</id><created>2019-05-09</created><authors><author><keyname>Romero-Jerez</keyname><forenames>Juan M.</forenames></author><author><keyname>Lopez-Martinez</keyname><forenames>F. Javier</forenames></author><author><keyname>Pe&#xf1;a-Martin</keyname><forenames>Juan P.</forenames></author><author><keyname>Abdi</keyname><forenames>Ali</forenames></author></authors><title>Stochastic Fading Channel Models with Multiple Dominant Specular
  Components for 5G and Beyond</title><categories>cs.IT eess.SP math.IT</categories><comments>This work has been submitted to the IEEE for publication. Copyright
  may be transferred without notice, after which this version may no longer be
  accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a comprehensive statistical characterization of the multipath
wireless channel built as a superposition of a number of scattered waves with
random phases. We consider an arbitrary number $N$ of specular (dominant)
components plus other diffusely propagating waves. Our approach covers the
cases on which the specular components have constant amplitudes, as well as
when these components experience random fluctuations. These propagation
scenarios are found in different use cases of 5G networks, as well as in the
context of large intelligent surface based communications. We show that this
class of fading models can be expressed in terms of a continuous mixture of an
underlying Rician (or Rician shadowed) fading model, averaged over the phase
distributions of the specular waves. It is shown that the fluctuations of the
specular components have a detrimental impact on performance, and the best
performance is obtained when there is only one specular component.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03632</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03632</id><created>2019-05-09</created><updated>2019-12-11</updated><authors><author><keyname>Malek</keyname><forenames>Jiri</forenames></author><author><keyname>Koldovsky</keyname><forenames>Zbynek</forenames></author><author><keyname>Bohac</keyname><forenames>Marek</forenames></author></authors><title>Block-Online Multi-Channel Speech Enhancement Using DNN-Supported
  Relative Transfer Function Estimates</title><categories>cs.SD cs.SY eess.AS</categories><comments>10 pages, 8 figures, 4 tables. Modified version of the article
  accepted for publication in IET Signal Processing journal. Original results
  unchanged, additional experiments presented, refined discussion and
  conclusions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work addresses the problem of block-online processing for multi-channel
speech enhancement. Such processing is vital in scenarios with moving speakers
and/or when very short utterances are processed, e.g., in voice assistant
scenarios. We consider several variants of a system that performs beamforming
supported by DNN-based voice activity detection (VAD) followed by
post-filtering. The speaker is targeted through estimating relative transfer
functions between microphones. Each block of the input signals is processed
independently in order to make the method applicable in highly dynamic
environments. Owing to the short length of the processed block, the statistics
required by the beamformer are estimated less precisely. The influence of this
inaccuracy is studied and compared to the processing regime when recordings are
treated as one block (batch processing). The experimental evaluation of the
proposed method is performed on large datasets of CHiME-4 and on another
dataset featuring moving target speaker. The experiments are evaluated in terms
of objective and perceptual criteria (such as signal-to-interference ratio
(SIR) or perceptual evaluation of speech quality (PESQ), respectively).
Moreover, word error rate (WER) achieved by a baseline automatic speech
recognition system is evaluated, for which the enhancement method serves as a
front-end solution. The results indicate that the proposed method is robust
with respect to short length of the processed block. Significant improvements
in terms of the criteria and WER are observed even for the block length of 250
ms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03637</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03637</id><created>2019-05-09</created><authors><author><keyname>Caracalla</keyname><forenames>Hugo</forenames></author><author><keyname>Roebel</keyname><forenames>Axel</forenames></author></authors><title>Sound texture synthesis using convolutional neural networks</title><categories>cs.SD eess.AS</categories><comments>submitted to Digital Audio Conference (DAFx 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following article introduces a new parametric synthesis algorithm for
sound textures inspired by existing methods used for visual textures. Using a
2D Convolutional Neural Network (CNN), a sound signal is modified until the
temporal cross-correlations of the feature maps of its log-spectrogram resemble
those of a target texture. We show that the resulting synthesized sound signal
is both different from the original and of high quality, while being able to
reproduce singular events appearing in the original. This process is performed
in the time domain, discarding the harmful phase recovery step which usually
concludes synthesis performed in the time-frequency domain. It is also
straightforward and flexible, as it does not require any fine tuning between
several losses when synthesizing diverse sound textures. A way of extending the
synthesis in order to produce a sound of any length is also presented, after
which synthesized spectrograms and sound signals are showcased. We also discuss
on the choice of CNN, on border effects in our synthesized signals and on
possible ways of modifying the algorithm in order to improve its current long
computation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03639</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03639</id><created>2019-05-09</created><authors><author><keyname>Roth</keyname><forenames>Karsten</forenames></author><author><keyname>Konopczy&#x144;ski</keyname><forenames>Tomasz</forenames></author><author><keyname>Hesser</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Liver Lesion Segmentation with slice-wise 2D Tiramisu and Tversky loss
  function</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present, lesion segmentation is still performed manually (or
semi-automatically) by medical experts. To facilitate this process, we
contribute a fully-automatic lesion segmentation pipeline. This work proposes a
method as a part of the LiTS (Liver Tumor Segmentation Challenge) competition
for ISBI 17 and MICCAI 17 comparing methods for automatics egmentation of liver
lesions in CT scans. By utilizing cascaded, densely connected 2D U-Nets and a
Tversky-coefficient based loss function, our framework achieves very good shape
extractions with high detection sensitivity, with competitive scores at time of
publication. In addition, adjusting hyperparameters in our Tversky-loss allows
to tune the network towards higher sensitivity or robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03689</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03689</id><created>2019-05-09</created><updated>2019-06-20</updated><authors><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Pei</keyname><forenames>Yiyang</forenames></author><author><keyname>Guo</keyname><forenames>Huayan</forenames></author></authors><title>Intelligent Reflecting Surface: A Programmable Wireless Environment for
  Physical Layer Security</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an intelligent reflecting surface (IRS) to
provide a programmable wireless environment for physical layer security. By
adjusting the reflecting coefficients, the IRS can change the attenuation and
scattering of the incident electromagnetic wave so that it can propagate in a
desired way toward the intended receiver. Specifically, we consider a downlink
multiple-input single-output (MISO) broadcast system where the base station
(BS) transmits independent data streams to multiple legitimate receivers and
keeps them secret from multiple eavesdroppers. By jointly optimizing the
beamformers at the BS and reflecting coefficients at the IRS, we formulate a
minimum-secrecy-rate maximization problem under various practical constraints
on the reflecting coefficients. The constraints capture the scenarios of both
continuous and discrete reflecting coefficients of the reflecting elements. Due
to the non-convexity of the formulated problem, we propose an efficient
algorithm based on the alternating optimization and the path-following
algorithm to solve it in an iterative manner. Besides, we show that the
proposed algorithm can converge to a local (global) optimum. Furthermore, we
develop two suboptimal algorithms with some forms of closed-form solutions to
reduce the computational complexity. Finally, the simulation results validate
the advantages of the introduced IRS and the effectiveness of the proposed
algorithms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03691</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03691</id><created>2019-04-17</created><authors><author><keyname>Yan</keyname><forenames>Wei</forenames></author><author><keyname>shao</keyname><forenames>Yiting</forenames></author><author><keyname>Liu</keyname><forenames>Shan</forenames></author><author><keyname>Li</keyname><forenames>Thomas H</forenames></author><author><keyname>Li</keyname><forenames>Zhu</forenames></author><author><keyname>Li</keyname><forenames>Ge</forenames></author></authors><title>Deep AutoEncoder-based Lossy Geometry Compression for Point Clouds</title><categories>cs.CV cs.MM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Point cloud is a fundamental 3D representation which is widely used in real
world applications such as autonomous driving. As a newly-developed media
format which is characterized by complexity and irregularity, point cloud
creates a need for compression algorithms which are more flexible than existing
codecs. Recently, autoencoders(AEs) have shown their effectiveness in many
visual analysis tasks as well as image compression, which inspires us to employ
it in point cloud compression. In this paper, we propose a general
autoencoder-based architecture for lossy geometry point cloud compression. To
the best of our knowledge, it is the first autoencoder-based geometry
compression codec that directly takes point clouds as input rather than voxel
grids or collections of images. Compared with handcrafted codecs, this approach
adapts much more quickly to previously unseen media contents and media formats,
meanwhile achieving competitive performance. Our architecture consists of a
pointnet-based encoder, a uniform quantizer, an entropy estimation block and a
nonlinear synthesis transformation module. In lossy geometry compression of
point cloud, results show that the proposed method outperforms the test model
for categories 1 and 3 (TMC13) published by MPEG-3DG group on the 125th
meeting, and on average a 73.15\% BD-rate gain is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03699</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03699</id><created>2019-04-30</created><authors><author><keyname>AlShehri</keyname><forenames>Helala</forenames></author><author><keyname>Hussain</keyname><forenames>Muhammad</forenames></author><author><keyname>AboAlSamh</keyname><forenames>Hatim</forenames></author><author><keyname>Emad-ul-Haq</keyname><forenames>Qazi</forenames></author><author><keyname>Azmi</keyname><forenames>Aqil M.</forenames></author></authors><title>Alignment-Free Cross-Sensor Fingerprint Matching based on the
  Co-Occurrence of Ridge Orientations and Gabor-HoG Descriptor</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing automatic fingerprint verification methods are designed to work
under the assumption that the same sensor is installed for enrollment and
authentication (regular matching). There is a remarkable decrease in efficiency
when one type of contact-based sensor is employed for enrolment and another
type of contact-based sensor is used for authentication (cross-matching or
fingerprint sensor interoperability problem,). The ridge orientation patterns
in a fingerprint are invariant to sensor type. Based on this observation, we
propose a robust fingerprint descriptor called the co-occurrence of ridge
orientations (Co-Ror), which encodes the spatial distribution of ridge
orientations. Employing this descriptor, we introduce an efficient automatic
fingerprint verification method for cross-matching problem. Further, to enhance
the robustness of the method, we incorporate scale based ridge orientation
information through Gabor-HoG descriptor. The two descriptors are fused with
canonical correlation analysis (CCA), and the matching score between two
fingerprints is calculated using city-block distance. The proposed method is
alignment-free and can handle the matching process without the need for a
registration step. The intensive experiments on two benchmark databases
(FingerPass and MOLF) show the effectiveness of the method and reveal its
significant enhancement over the state-of-the-art methods such as VeriFinger (a
commercial SDK), minutia cylinder-code (MCC), MCC with scale, and the
thin-plate spline (TPS) model. The proposed research will help security
agencies, service providers and law-enforcement departments to overcome the
interoperability problem of contact sensors of different technology and
interaction types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03702</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03702</id><created>2019-04-30</created><updated>2019-05-17</updated><authors><author><keyname>Garbin</keyname><forenames>Stephan J.</forenames></author><author><keyname>Shen</keyname><forenames>Yiru</forenames></author><author><keyname>Schuetz</keyname><forenames>Immo</forenames></author><author><keyname>Cavin</keyname><forenames>Robert</forenames></author><author><keyname>Hughes</keyname><forenames>Gregory</forenames></author><author><keyname>Talathi</keyname><forenames>Sachin S.</forenames></author></authors><title>OpenEDS: Open Eye Dataset</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>11 pages; 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a large scale data set, OpenEDS: Open Eye Dataset, of eye-images
captured using a virtual-reality (VR) head mounted display mounted with two
synchronized eyefacing cameras at a frame rate of 200 Hz under controlled
illumination. This dataset is compiled from video capture of the eye-region
collected from 152 individual participants and is divided into four subsets:
(i) 12,759 images with pixel-level annotations for key eye-regions: iris, pupil
and sclera (ii) 252,690 unlabelled eye-images, (iii) 91,200 frames from
randomly selected video sequence of 1.5 seconds in duration and (iv) 143 pairs
of left and right point cloud data compiled from corneal topography of eye
regions collected from a subset, 143 out of 152, participants in the study. A
baseline experiment has been evaluated on OpenEDS for the task of semantic
segmentation of pupil, iris, sclera and background, with the mean
intersectionover-union (mIoU) of 98.3 %. We anticipate that OpenEDS will create
opportunities to researchers in the eye tracking community and the broader
machine learning and computer vision community to advance the state of
eye-tracking for VR applications. The dataset is available for download upon
request at https://research.fb.com/programs/openeds-challenge
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03761</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03761</id><created>2019-05-09</created><updated>2019-08-14</updated><authors><author><keyname>Alrabeiah</keyname><forenames>Muhammad</forenames></author><author><keyname>Alkhateeb</keyname><forenames>Ahmed</forenames></author></authors><title>Deep Learning for TDD and FDD Massive MIMO: Mapping Channels in Space
  and Frequency</title><categories>cs.IT eess.SP math.IT</categories><comments>An extended version of an (invited) Asilomar paper; the dataset and
  code files are available online at
  http://deepmimo.net/DeepMIMO_applications.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can we map the channels at one set of antennas and one frequency band to the
channels at another set of antennas---possibly at a different location and a
different frequency band? If this channel-to-channel mapping is possible, we
can expect dramatic gains for massive MIMO systems. For example, in FDD massive
MIMO, the uplink channels can be mapped to the downlink channels or the
downlink channels at one subset of antennas can be mapped to the downlink
channels at all the other antennas. This can significantly reduce (or even
eliminate) the downlink training/feedback overhead. In the context of
cell-free/distributed massive MIMO systems, this channel mapping can be
leveraged to reduce the fronthaul signaling overhead as only the channels at a
subset of the distributed terminals need to be fed to the central unit which
can map them to the channels at all the other terminals. This mapping can also
find interesting applications in mmWave beam prediction, MIMO radar, and
massive MIMO based positioning.
  In this paper, we introduce the new concept of channel mapping in space and
frequency, where the channels at one set of antennas and one frequency band are
mapped to the channels at another set of antennas and frequency band. First, we
prove that this channel-to-channel mapping function exists under the condition
that the mapping from the candidate user positions to the channels at the first
set of antennas is bijective; a condition that can be achieved with high
probability in several practical MIMO communication scenarios. Then, we note
that the channel-to-channel mapping function, even if it exists, is typically
unknown and very hard to characterize analytically as it heavily depends on the
various elements of the surrounding environment. With this motivation, we
propose to leverage the powerful learning capabilities of deep neural networks
....
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03808</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03808</id><created>2019-05-09</created><authors><author><keyname>Zhou</keyname><forenames>Mingda</forenames><affiliation>Eugene</affiliation></author><author><keyname>Feng</keyname><forenames>Zhe</forenames><affiliation>Eugene</affiliation></author><author><keyname>Huang</keyname><forenames>Xinming</forenames><affiliation>Eugene</affiliation></author><author><keyname>Youjian</keyname><affiliation>Eugene</affiliation></author><author><keyname>Liu</keyname></author></authors><title>Maximum A Posteriori Probability (MAP) Joint Fine Frequency Offset and
  Channel Estimation for MIMO Systems with Channels of Arbitrary Correlation</title><categories>eess.SP cs.IT math.IT</categories><comments>Part of the results is being submitted to Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel and frequency offset estimation is a classic topic with a large body
of prior work using mainly maximum likelihood (ML) approach together with
Cram\'er-Rao Lower bounds (CRLB) analysis. We provide the maximum a posteriori
(MAP) estimation solution which is particularly useful for for tracking where
previous estimation can be used as prior knowledge. Unlike the ML cases, the
corresponding Bayesian Cram\'er-Rao Lower bound (BCRLB) shows clear relation
with parameters and a low complexity algorithm achieves the BCRLB in almost all
SNR range. We allow the time invariant channel within a packet to have
arbitrary correlation and mean. The estimation is based on pilot/training
signals. An unexpected result is that the joint MAP estimation is equivalent to
an individual MAP estimation of the frequency offset first, again different
from the ML results. We provide insight on the pilot/training signal design
based on the BCRLB. Unlike past algorithms that trade performance and/or
complexity for the accommodation of time varying channels, the MAP solution
provides a different route for dealing with time variation. Within a short
enough (segment of) packet where the channel and CFO are approximately time
invariant, the low complexity algorithm can be employed. Similar to belief
propagation, the estimation of the previous (segment of) packet can serve as
the prior knowledge for the next (segment of) packet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03809</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03809</id><created>2019-05-09</created><authors><author><keyname>Nguyen</keyname><forenames>H. D.</forenames></author><author><keyname>Tran</keyname><forenames>K. P.</forenames></author><author><keyname>Zeng</keyname><forenames>X.</forenames></author><author><keyname>Koehl</keyname><forenames>L.</forenames></author><author><keyname>Tartare</keyname><forenames>G.</forenames></author></authors><title>Wearable Sensor Data Based Human Activity Recognition using Machine
  Learning: A new approach</title><categories>cs.LG cs.HC eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent years have witnessed the rapid development of human activity
recognition (HAR) based on wearable sensor data. One can find many practical
applications in this area, especially in the field of health care. Many machine
learning algorithms such as Decision Trees, Support Vector Machine, Naive
Bayes, K-Nearest Neighbor, and Multilayer Perceptron are successfully used in
HAR. Although these methods are fast and easy for implementation, they still
have some limitations due to poor performance in a number of situations. In
this paper, we propose a novel method based on the ensemble learning to boost
the performance of these machine learning methods for HAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03828</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03828</id><created>2019-05-09</created><updated>2019-08-15</updated><authors><author><keyname>Neekhara</keyname><forenames>Paarth</forenames></author><author><keyname>Hussain</keyname><forenames>Shehzeen</forenames></author><author><keyname>Pandey</keyname><forenames>Prakhar</forenames></author><author><keyname>Dubnov</keyname><forenames>Shlomo</forenames></author><author><keyname>McAuley</keyname><forenames>Julian</forenames></author><author><keyname>Koushanfar</keyname><forenames>Farinaz</forenames></author></authors><title>Universal Adversarial Perturbations for Speech Recognition Systems</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Published as a conference paper at INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we demonstrate the existence of universal adversarial audio
perturbations that cause mis-transcription of audio signals by automatic speech
recognition (ASR) systems. We propose an algorithm to find a single
quasi-imperceptible perturbation, which when added to any arbitrary speech
signal, will most likely fool the victim speech recognition model. Our
experiments demonstrate the application of our proposed technique by crafting
audio-agnostic universal perturbations for the state-of-the-art ASR system --
Mozilla DeepSpeech. Additionally, we show that such perturbations generalize to
a significant extent across models that are not available during training, by
performing a transferability test on a WaveNet based ASR system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03847</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03847</id><created>2019-05-09</created><authors><author><keyname>Elvander</keyname><forenames>Filip</forenames></author><author><keyname>Haasler</keyname><forenames>Isabel</forenames></author><author><keyname>Jakobsson</keyname><forenames>Andreas</forenames></author><author><keyname>Karlsson</keyname><forenames>Johan</forenames></author></authors><title>Multi-Marginal Optimal Mass Transport with Partial Information</title><categories>eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During recent decades, there has been a substantial development in optimal
mass transport theory and methods. In this work, we consider multi-marginal
problems wherein only partial information of each marginal is available, which
is a setup common in many inverse problems in, e.g., imaging and spectral
estimation. By considering an entropy regularized approximation of the original
transport problem, we propose an algorithm corresponding to a block-coordinate
ascent of the dual problem, where Newton's algorithm is used to solve the
sub-problems. In order to make this computationally tractable for large-scale
settings, we utilize the tensor structure that arises in practical problems,
allowing for computing projections of the multi-marginal transport plan using
only matrix-vector operations of relatively small matrices. As illustrating
examples, we apply the resulting method to tracking and barycenter problems in
spatial spectral estimation. In particular, we show that the optimal mass
transport framework allows for fusing information from different time steps, as
well as from different sensor arrays, also when the sensor arrays are not
jointly calibrated. Furthermore, we show that by incorporating knowledge of
underlying dynamics in tracking scenarios, one may arrive at accurate spectral
estimates, as well as faithful reconstructions of spectra corresponding to
unobserved time points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03854</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03854</id><created>2019-05-04</created><authors><author><keyname>Islam</keyname><forenames>Bashima</forenames></author><author><keyname>Luo</keyname><forenames>Yubo</forenames></author><author><keyname>Nirjon</keyname><forenames>Shahriar</forenames></author></authors><title>Zygarde: Time-Sensitive On-Device Deep Intelligence on
  Intermittently-Powered Systems</title><categories>cs.DC cs.LG eess.SP</categories><comments>Under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a time-, energy-, and accuracy-aware scheduling
algorithm for intermittently powered systems that execute compressed deep
learning tasks that are suitable for MCUs and are powered solely by harvested
energy. The sporadic nature of harvested energy, resource constraints of the
embedded platform, and the computational demand of deep neural networks (even
though compressed) pose a unique and challenging real-time scheduling problem
for which no solutions have been proposed in the literature. We empirically
study the problem and model the energy harvesting pattern as well as the
trade-off between the accuracy and execution of a deep neural network. We
develop an imprecise computing-based scheduling algorithm that improves the
schedulability of deep learning tasks on intermittently powered systems. We
also utilize the dependency of the computational need of data samples for deep
learning models and propose early termination of deep neural networks. We
further propose a semi-supervised machine learning model that exploits the deep
features and contributes in determining the imprecise partition of a task. We
implement our proposed algorithms on two different datasets and real-life
scenarios and show that it increases the accuracy by 9.45% - 3.19%, decreases
the execution time by 14\% and successfully schedules 33%-12% more tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03864</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03864</id><created>2019-05-09</created><authors><author><keyname>Ocal</keyname><forenames>Orhan</forenames></author><author><keyname>Elibol</keyname><forenames>Oguz H.</forenames></author><author><keyname>Keskin</keyname><forenames>Gokce</forenames></author><author><keyname>Stephenson</keyname><forenames>Cory</forenames></author><author><keyname>Thomas</keyname><forenames>Anil</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Adversarially Trained Autoencoders for Parallel-Data-Free Voice
  Conversion</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for converting the voices between a set of speakers. Our
method is based on training multiple autoencoder paths, where there is a single
speaker-independent encoder and multiple speaker-dependent decoders. The
autoencoders are trained with an addition of an adversarial loss which is
provided by an auxiliary classifier in order to guide the output of the encoder
to be speaker independent. The training of the model is unsupervised in the
sense that it does not require collecting the same utterances from the speakers
nor does it require time aligning over phonemes. Due to the use of a single
encoder, our method can generalize to converting the voice of out-of-training
speakers to speakers in the training dataset. We present subjective tests
corroborating the performance of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03889</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03889</id><created>2019-05-09</created><authors><author><keyname>Ehlers</keyname><forenames>Simon F. G.</forenames></author></authors><title>Traffic Queue Length and Pressure Estimation for Road Networks with
  Geometric Deep Learning Algorithms</title><categories>cs.LG eess.SP</categories><comments>Project thesis as part of a masters program at University</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to urbanization and the increase of individual mobility, in most
metropolitan areas around the world congestion and inefficient traffic
management occur. Highly necessary intelligent traffic control systems, which
are able to reduce congestion, rely on measurements of traffic situations in
urban road networks and freeways. Unfortunately, the instrumentation for
accurate traffic measurement is expensive and not widely implemented. This
thesis addresses this problem, where relatively inexpensive and easy to install
loop-detectors are used by a geometric deep learning algorithm, which uses
loop-detector data in a spatial context of a road network, to estimate queue
length in front of signalized intersections, which can be then used for
following traffic control tasks. Therefore, in the first part of this work a
conventional estimation method for queue length (which does not use machine
learning techniques) based on second-by-second loop-detector data is
implemented, which uses detected shockwaves in queues to estimate the length
and point of time for the maximum queue. The method is later used as reference
but also as additional input information for the geometric deep learning
approach. In the second part the geometric deep learning algorithm is
developed, which uses spatial correlations in the road network but also
temporal correlations in detector data time sequences by new attention
mechanisms, to overcome the limitations of conventional methods like excess
traffic demand, lane changing and stop-and-go traffic. Therefore, it is
necessary to abstract the topology of the road network in a graph. Both
approaches are compared regarding their performance, reliability as well as
limitations and validated by usage of the traffic simulation software SUMO
(Simulation of Urban MObility). Finally, the results are discussed in the
conclusions and further investigations are suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03890</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03890</id><created>2019-05-09</created><updated>2019-11-07</updated><authors><author><keyname>Zheng</keyname><forenames>Chaobing</forenames></author><author><keyname>Li</keyname><forenames>Zhengguo</forenames></author><author><keyname>Yang</keyname><forenames>Yi</forenames></author><author><keyname>Wu</keyname><forenames>Shiqian</forenames></author></authors><title>Exposure Interpolation Via Fusing Conventional and Deep Learning Methods</title><categories>eess.IV cs.CV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning based methods have penetrated many image processing problems
and become dominant solutions to these problems. A natural question raised here
is &quot;Is there any space for conventional methods on these problems?&quot; In this
paper, exposure interpolation is taken as an example to answer this question
and the answer is &quot;Yes&quot;. A framework on fusing conventional and deep learning
method is introduced to generate an medium exposure image for two
large-exposureratio images. Experimental results indicate that the quality of
the medium exposure image is increased significantly through using the deep
learning method to refine the interpolated image via the conventional method.
The conventional method can be adopted to improve the convergence speed of the
deep learning method and to reduce the number of samples which is required by
the deep learning method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03901</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03901</id><created>2019-05-09</created><authors><author><keyname>Bhandari</keyname><forenames>Ayush</forenames></author><author><keyname>Krahmer</keyname><forenames>Felix</forenames></author><author><keyname>Raskar</keyname><forenames>Ramesh</forenames></author></authors><title>On Unlimited Sampling and Reconstruction</title><categories>cs.IT eess.SP math.IT</categories><comments>22 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shannon's sampling theorem is one of the cornerstone topics that is well
understood and explored, both mathematically and algorithmically. That said,
practical realization of this theorem still suffers from a severe bottleneck
due to the fundamental assumption that the samples can span an arbitrary range
of amplitudes. In practice, the theorem is realized using so-called
analog-to-digital converters (ADCs) which clip or saturate whenever the signal
amplitude exceeds the maximum recordable ADC voltage thus leading to a
significant information loss. In this paper, we develop an alternative paradigm
for sensing and recovery, called the Unlimited Sampling Framework. It is based
on the observation that when a signal is mapped to an appropriate bounded
interval via a modulo operation before entering the ADC, the saturation problem
no longer exists, but one rather encounters a different type of information
loss due to the modulo operation. Such an alternative setup can be implemented,
for example, via so-called folding or self-reset ADCs, as they have been
proposed in various contexts in the circuit design literature. The key task
that we need to accomplish in order to cope with this new type of information
loss is to recover a bandlimited signal from its modulo samples. In this paper
we derive conditions when this is possible and present an empirically stable
recovery algorithm with guaranteed perfect recovery. The sampling density
required for recovery is independent of the maximum recordable ADC voltage and
depends on the signal bandwidth only. Numerical experiments validate our
approach and indeed show that it is possible to perfectly recover functions
that take values that are orders of magnitude higher than the ADC's threshold.
Applications of the unlimited sampling paradigm can be found in a number of
fields such as signal processing, communication and imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03903</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03903</id><created>2019-05-09</created><authors><author><keyname>Rodriguez-Fernandez</keyname><forenames>Javier</forenames></author><author><keyname>Gonzalez-Prelcic</keyname><forenames>Nuria</forenames></author><author><keyname>Shimizu</keyname><forenames>Takayuki</forenames></author></authors><title>Channel Tracking and Hybrid Precoding for Wideband Hybrid Millimeter
  Wave MIMO Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major source of difficulty when operating with large arrays at mmWave
frequencies is to estimate the wideband channel, since the use of hybrid
architectures acts as a compression stage for the received signal. Moreover,
the channel has to be tracked and the antenna arrays regularly reconfigured to
obtain appropriate beamforming gains when a mobile setting is considered. In
this paper, we focus on the problem of channel tracking for frequency-selective
mmWave channels, and propose two novel channel tracking algorithms that
leverage prior statistical information on the angles-of-arrival and
angles-of-departure. Exploiting this prior information, we also propose a
precoding and combining design method to increase the received SNR during
channel tracking, such that near-optimum data rates can be obtained with
low-overhead. In our numerical results, we analyze the performance of our
proposed algorithms for different system parameters. Simulation results show
that, using channel realizations extracted from the 5G New Radio channel model,
our proposed channel tracking framework is able to achieve near-optimum data
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03916</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03916</id><created>2019-05-09</created><updated>2019-06-24</updated><authors><author><keyname>Hu</keyname><forenames>Rui</forenames></author><author><keyname>Tong</keyname><forenames>Jun</forenames></author><author><keyname>Xi</keyname><forenames>Jiangtao</forenames></author><author><keyname>Guo</keyname><forenames>Qinghua</forenames></author><author><keyname>Yu</keyname><forenames>Yanguang</forenames></author></authors><title>Channel Covariance Matrix Estimation via Dimension Reduction for Hybrid
  MIMO MmWave Communication Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid massive MIMO structures with lower hardware complexity and power
consumption have been considered as a potential candidate for millimeter wave
(mmWave) communications. Channel covariance information can be used for
designing transmitter precoders, receiver combiners, channel estimators, etc.
However, hybrid structures allow only a lower-dimensional signal to be
observed, which adds difficulties for channel covariance matrix estimation. In
this paper, we formulate the channel covariance estimation as a structured
low-rank matrix sensing problem via Kronecker product expansion and use a
low-complexity algorithm to solve this problem. Numerical results with uniform
linear arrays (ULA) and uniform squared planar arrays (USPA) are provided to
demonstrate the effectiveness of our proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03918</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03918</id><created>2019-05-09</created><authors><author><keyname>Viteri-Mera</keyname><forenames>Carlos A.</forenames></author><author><keyname>Teixeira</keyname><forenames>Fernando L.</forenames></author></authors><title>Beamforming Algorithm for Multiuser Wideband Millimeter-Wave Systems
  with Hybrid and Subarray Architectures</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a beamforming algorithm for multiuser wideband millimeter wave
(mmWave) communication systems where one access point uses hybrid
analog/digital beamforming while multiple user stations have phased-arrays with
a single RF chain. The algorithm operates in a more general mode than others
available in literature and has lower computational complexity and training
overhead. Throughout the paper, we describe: i) the construction of novel
beamformer sets (codebooks) with wide sector beams and narrow beams based on
the orthogonality property of beamformer vectors, ii) a beamforming algorithm
that uses training transmissions over the codebooks to select the beamformers
that maximize the received sumpower along the bandwidth, and iii) a numerical
validation of the algorithm in standard indoor scenarios for mmWave WLANs using
channels obtained with both statistical and raytracing models. Our algorithm is
designed to serve multiple users in a wideband OFDM system and does not require
channel matrix knowledge or a particular channel structure. Moreover, we
incorporate antenna-specific aspects in the analysis, such as antenna coupling,
element radiation pattern, and beam squint. Although there are no other
solutions for the general system studied in this paper, we characterize the
algorithm's achievable rate and show that it attains more than 70 percent of
the spectral efficiency (between 1.5 and 3 dB SNR loss) with respect to ideal
fully-digital beamforming in the analyzed scenarios. We also show that our
algorithm has similar sum-rate performance as other solutions in the literature
for some special cases, while providing significantly lower computational
complexity (with a linear dependence on the number of antennas) and shorter
training overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03930</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03930</id><created>2019-05-10</created><authors><author><keyname>Lee</keyname><forenames>Hyeongtaek</forenames></author><author><keyname>Kim</keyname><forenames>Sucheol</forenames></author><author><keyname>Choi</keyname><forenames>Junil</forenames></author></authors><title>Efficient Channel AoD/AoA Estimation Using Widebeams for Millimeter Wave
  MIMO Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 6 figures, accepted by IEEE SPAWC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using millimeter-wave (mmWave) bands is expected to provide high data rates
through large licensed and unlicensed spectrum. Due to large path loss and
sparse scattering propagation properties, proper beam alignment is important in
mmWave systems. Small carrier wavelengths at mmWave bands let wireless
communication systems use large antenna arrays to provide sufficient
beamforming gain with highly directional beams. Hence, high resolution channel
angle-of-departure (AoD) and angle-of-arrival (AoA) estimation is crucial for
beam alignment to get the advantages of large beamforming gain. Using large
antenna arrays, however, can lead to high system complexity and channel
estimation overhead. This paper proposes a channel AoD/AoA estimation technique
using widebeams to lower estimation overhead and auxiliary-beam-pair (ABP) to
get high resolution channel AoD/AoA estimates considering hybrid transceiver
structures. To fully use the hybrid transceiver structures, the linear
combination of discrete Fourier transform (DFT) vectors is considered to
construct widebeams. Numerical results show that the proposed estimator can get
high resolution channel AoD/AoA estimates with lower overhead compared to
previous estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03935</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03935</id><created>2019-05-10</created><authors><author><keyname>Mohan</keyname><forenames>K. Aditya</forenames></author><author><keyname>Panas</keyname><forenames>Robert M.</forenames></author><author><keyname>Cuadra</keyname><forenames>Jefferson A.</forenames></author></authors><title>SABER: A Systems Approach to Blur Estimation and Reduction in X-ray
  Imaging</title><categories>eess.IV cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blur in X-ray radiographs not only reduces the sharpness of image edges but
also reduces the overall contrast. The effective blur in a radiograph is the
combined effect of blur from multiple sources such as the detector panel, X-ray
source spot, and system motion. In this paper, we use a systems approach to
model the point spread function (PSF) of the effective radiographic blur as the
convolution of multiple PSFs, where each PSF models one of the various sources
of blur. Then, we present a numerical optimization algorithm for estimating
each PSF from multiple radiographs acquired at different X-ray source to object
(SOD) and object to detector distances (ODD). Finally, we computationally
reduce blur in radiographs using deblurring algorithms that use the estimated
PSFs from the previous step. Our approach to estimate and reduce blur is called
SABER, which is an acronym for systems approach to blur estimation and
reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03939</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03939</id><created>2019-05-10</created><authors><author><keyname>Abrar</keyname><forenames>Alemayehu Solomon</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>Baset</keyname><forenames>Aniqua</forenames></author><author><keyname>Kasera</keyname><forenames>Sneha Kumar</forenames></author></authors><title>Quantifying an Interference-Assisted Signal Strength Breathing
  Surveillance Attack</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A malicious attacker could, by taking control of internet-of-things devices,
use them to capture received signal strength (RSS) measurements and perform
surveillance on a person's vital signs, activities, audio in their environment,
and other RF sensing capabilities. This paper considers an attacker who looks
for periodic changes in the RSS in order to surveil a person's breathing rate.
The challenge to the attacker is that a person's breathing causes a low
amplitude change in RSS, and RSS is typically quantized with a significantly
larger step size. This paper contributes a lower bound on an attacker's
breathing monitoring performance as a function of the RSS step size and
sampling frequency so that a designer can understand their relationship. Our
bound considers the little-known and counter-intuitive fact that an adversary
can improve their sinusoidal parameter estimates by making some devices
transmit to add interference power into the RSS measurements. We demonstrate
this capability experimentally. As we show, for typical transceivers, the RSS
surveillance attack can monitor RSS with remarkable accuracy. New mitigation
strategies will be required to prevent RSS surveillance attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03949</identifier>
 <datestamp>2019-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03949</id><created>2019-05-10</created><updated>2019-12-23</updated><authors><author><keyname>Ma</keyname><forenames>Dong</forenames></author><author><keyname>Lan</keyname><forenames>Guohao</forenames></author><author><keyname>Hassan</keyname><forenames>Mahbub</forenames></author><author><keyname>Hu</keyname><forenames>Wen</forenames></author><author><keyname>Das</keyname><forenames>Sajal K.</forenames></author></authors><title>Sensing, Computing, and Communication for Energy Harvesting IoTs: A
  Survey</title><categories>eess.SP cs.NI</categories><comments>Accpeted for publication in IEEE Communications Surveys and Tutorials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing number of deployments of Internet of Things (IoT)
infrastructure for a wide variety of applications, the battery maintenance has
become a major limitation for the sustainability of such infrastructure. To
overcome this problem, energy harvesting offers a viable alternative to
autonomously power IoT devices, resulting in a number of battery-less energy
harvesting IoTs (or EH-IoTs) appearing in the market in recent years. Standards
activities are also underway, which involve wireless protocol design suitable
for EH-IoTs as well as testing procedures for various energy harvesting
methods. Despite the early commercial and standards activities, IoT sensing,
computing and communications under unpredictable power supply still face
significant research challenges. This paper systematically surveys recent
advances in EH-IoTs from several perspectives. First, it reviews the recent
commercial developments for EH-IoT in terms of both products and services,
followed by initial standards activities in this space. Then it surveys methods
that enable the use of energy harvesting hardware as a proxy for conventional
sensors to detect contexts in energy efficient manner. Next it reviews the
advancements in efficient checkpointing and timekeeping for intermittently
powered IoT devices. We also survey recent research in novel wireless
communication techniques for EH-IoTs, such as the applications of reinforcement
learning to optimize power allocations on-the-fly under unpredictable energy
productions, and packet-less IoT communications and backscatter communication
techniques for energy impoverished environments. The paper is concluded with a
discussion of future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03951</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03951</id><created>2019-05-10</created><authors><author><keyname>Cheng</keyname><forenames>Zhengxue</forenames></author><author><keyname>Akyazi</keyname><forenames>Pinar</forenames></author><author><keyname>Sun</keyname><forenames>Heming</forenames></author><author><keyname>Katto</keyname><forenames>Jiro</forenames></author><author><keyname>Ebrahimi</keyname><forenames>Touradj</forenames></author></authors><title>Perceptual Quality Study on Deep Learning based Image Compression</title><categories>eess.IV</categories><comments>Accepted as a conference contribution to IEEE International
  Conference on Image Processing (ICIP) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently deep learning based image compression has made rapid advances with
promising results based on objective quality metrics. However, a rigorous
subjective quality evaluation on such compression schemes have rarely been
reported. This paper aims at perceptual quality studies on learned compression.
First, we build a general learned compression approach, and optimize the model.
In total six compression algorithms are considered for this study. Then, we
perform subjective quality tests in a controlled environment using
high-resolution images. Results demonstrate learned compression optimized by
MS-SSIM yields competitive results that approach the efficiency of
state-of-the-art compression. The results obtained can provide a useful
benchmark for future developments in learned image compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03988</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.03988</id><created>2019-05-10</created><authors><author><keyname>Romero</keyname><forenames>Daniel</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Non-cooperative Aerial Base Station Placement via Stochastic
  Optimization</title><categories>eess.SP math.OC</categories><comments>Submitted to Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous unmanned aerial vehicles (UAVs) with on-board base station
equipment can potentially provide connectivity in areas where the terrestrial
infrastructure is overloaded, damaged, or absent. Use cases comprise emergency
response, wildfire suppression, surveillance, and cellular communications in
crowded events to name a few. A central problem to enable this technology is to
place such aerial base stations (AirBSs) in locations that approximately
optimize the relevant communication metrics. To alleviate the limitations of
existing algorithms, which require intensive and reliable communications among
AirBSs or between the AirBSs and a central controller, this paper leverages
stochastic optimization and machine learning techniques to put forth an
adaptive and decentralized algorithm for AirBS placement without inter-AirBS
cooperation or communication. The approach relies on a smart design of the
network utility function and on a stochastic gradient ascent iteration that can
be evaluated with information available in practical scenarios. To complement
the theoretical convergence properties, a simulation study corroborates the
effectiveness of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04007</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04007</id><created>2019-05-10</created><authors><author><keyname>Benkhelifa</keyname><forenames>Fatma</forenames></author><author><keyname>Qin</keyname><forenames>Zhijin</forenames></author><author><keyname>McCann</keyname><forenames>Julie</forenames></author></authors><title>Minimum Throughput Maximization in LoRa Networks Powered by Ambient
  Energy Harvesting</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the uplink transmissions in low-power wide-area
networks (LPWAN) where the users are self-powered by the energy harvested from
the ambient environment. Demonstrating their potential in supporting diverse
Internet-of-Things (IoT) applications, we focus on long range (LoRa) networks
where the LoRa users are using the harvested energy to transmit data to a
gateway via different spreading codes. Precisely, we study the throughput
fairness optimization problem for LoRa users by jointly optimizing the
spreading factor (SF) assignment, energy harvesting (EH) time duration, and the
transmit power of LoRa users. First, through examination of the various
permutations of collisions among users, we derive a general expression of the
packet collision time between LoRa users, which depends on the SFs and EH
duration requirements. Then, after reviewing prior SF allocation work, we
develop two types of algorithms that either assure fair SF assignment indeed
purposefully 'unfair' allocation schemes for the LoRa users. Our results
unearth three new findings. Firstly, we demonstrate that, to maximize the
minimum rate, the unfair SF allocation algorithm outperforms the other
approaches. Secondly, considering the derived expression of packet collision
between simultaneous users, we are now able to improve the performance of the
minimum rate of LoRa users and show that it is protected from inter-SF
interference which occurs between users with different SFs. That is, imperfect
SF orthogonality has no impact on minimum rate performance. Finally, we have
observed that co-SF interference is the main limitation in the throughput
performance, and not the energy scarcity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04041</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04041</id><created>2019-05-10</created><authors><author><keyname>Zhang</keyname><forenames>Qianqian</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Intelligent User Association for Symbiotic Radio Networks using Deep
  Reinforcement Learning</title><categories>eess.SP cs.IT math.IT</categories><comments>12 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we are interested in symbiotic radio networks, in which an
Internet-of-Things (IoT) network parasitizes in a primary network to achieve
spectrum-, energy-, and infrastructure-efficient communications. Specifically,
the BS serves multiple cellular users using time division multiple access
(TDMA) and each IoT device is associated with one cellular user for information
transmission. We focus on the user association problem, whose objective is to
link each IoT device to an appropriate cellular user by maximizing the sum rate
of all IoT devices. However, the difficulty in obtaining the full real-time
channel information makes it difficult to design an optimal policy for this
problem. To overcome this issue, we propose two deep reinforcement learning
(DRL) algorithms, both use the historical information to infer the current
information in order to make appropriate decisions. One algorithm, centralized
DRL, makes decisions for all IoT devices at one time with global information.
The other algorithm, distributed DRL, makes a decision only for one IoT device
at one time using local information. Finally, simulation results show that the
two DRL algorithms achieve comparable performance as the optimal user
association policy which requires perfect real-time information, and the
distributed DRL algorithm has the advantage of scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04050</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04050</id><created>2019-05-10</created><authors><author><keyname>G&#xf6;&#xdf;ling</keyname><forenames>Nico</forenames></author><author><keyname>Hadad</keyname><forenames>Elior</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author><author><keyname>Doclo</keyname><forenames>Simon</forenames></author></authors><title>Binaural LCMV Beamforming with Partial Noise Estimation</title><categories>eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Besides suppressing all undesired signal components, another important task
of binaural noise reduction algorithms is the preservation of the spatial
impression of the acoustical scene, which can be achieved by preserving the
binaural cues of all signal components. While the well-known binaural minimum
variance distortionless response (BMVDR) beamformer at least can preserve the
binaural cues of a single desired source, several extensions have been proposed
to additionally preserve the binaural cues of interfering sources and diffuse
noise. The binaural linearly-constrained minimum variance (BLCMV) beamformer
uses additional constraints to preserve the binaural cues of interfering
sources and enables a direct scaling using an interference scaling parameter.
The BMVDR with partial noise estimation (BMVDR-N) is aimed at preserving a
scaled version of the diffuse noise to partially preserve its interaural
coherence and hence its perceived diffuseness. In this paper, we propose to
combine both extensions of the BMVDR, leading to the BLCMV with partial noise
estimation (BLCMV-N). It is shown that the BLCMV-N can be seen as a mixture of
the noisy input signal and the output of a BLCMV that uses an adjusted
interference scaling parameter. A theoretical analysis and comparison between
the BMVDR, its extensions and the proposed BLCMV-N in terms of noise reduction
and binaural cue preservation performance is provided. Experimental results and
results of a subjective listening test show that the BLCMV-N is able to to
preserve the spatial impression of an interfering source, i.e. like the BLCMV,
and yields a trade-off between noise reduction and binaural cue preservation of
diffuse noise, i.e. like the BMVDR-N.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04095</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04095</id><created>2019-05-10</created><authors><author><keyname>Jaming</keyname><forenames>Philippe</forenames><affiliation>IMB</affiliation></author><author><keyname>Kellay</keyname><forenames>Karim</forenames><affiliation>IMB</affiliation></author><author><keyname>Perez</keyname><forenames>Rolando</forenames><suffix>Iii</suffix><affiliation>IMB</affiliation></author></authors><title>Phase retrieval for wide-band signals</title><categories>math.CA eess.SP math.CV</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study investigates the phase retrieval problem for wide-band signals. We
solve the following problem: given f $\in$ L 2 (R) with Fourier transform in L
2 (R, e^{2c|x|} dx), we find all functions g $\in$ L 2 (R) with Fourier
transform in L 2 (R, e^{2c|x| dx}), such that |f (x)| = |g(x)| for all x $\in$
R. To do so, we first translate the problem to functions in the Hardy spaces on
the disc via a conformal bijection, and take advantage of the inner-outer
factorization. We also consider the same problem with additional constraints
involving some transforms of f and g, and determine if these constraints force
uniqueness of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04105</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04105</id><created>2019-05-10</created><authors><author><keyname>Lee</keyname><forenames>Dongwook</forenames></author><author><keyname>Moon</keyname><forenames>Won-Jin</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Which Contrast Does Matter? Towards a Deep Understanding of MR Contrast
  using Collaborative GAN</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>32 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thanks to the recent success of generative adversarial network (GAN) for
image synthesis, there are many exciting GAN approaches that successfully
synthesize MR image contrast from other images with different contrasts. These
approaches are potentially important for image imputation problems, where
complete set of data is often difficult to obtain and image synthesis is one of
the key solutions for handling the missing data problem. Unfortunately, the
lack of the scalability of the existing GAN-based image translation approaches
poses a fundamental challenge to understand the nature of the MR contrast
imputation problem: which contrast does matter? Here, we present a systematic
approach using Collaborative Generative Adversarial Networks (CollaGAN), which
enable the learning of the joint image manifold of multiple MR contrasts to
investigate which contrasts are essential. Our experimental results showed that
the exogenous contrast from contrast agents is not replaceable, but other
endogenous contrast such as T1, T2, etc can be synthesized from other contrast.
These findings may give important guidance to the acquisition protocol design
for MR in real clinical environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04116</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04116</id><created>2019-05-10</created><authors><author><keyname>Kirwin</keyname><forenames>William D.</forenames></author><author><keyname>Mour&#xe3;o</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Nunes</keyname><forenames>Jo&#xe3;o P.</forenames></author><author><keyname>Thiemann</keyname><forenames>Thomas</forenames></author></authors><title>Holomorphic fractional Fourier transforms</title><categories>math-ph eess.SP math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fractional Fourier Transform (FrFT) has widespread applications in areas
like signal analysis, Fourier optics, diffraction theory, etc. The Holomorphic
Fractional Fourier Transform (HFrFT) proposed in the present paper may be used
in the same wide range of applications with improved properties. The HFrFT of
signals spans a one-parameter family of (essentially) holomorphic functions,
where the parameter takes values in the bounded interval $t\in (0,\pi/2)$. At
the boundary values of the parameter, one obtains the original signal at $t=0$
and its Fourier transform at the other end of the interval $t=\pi/2$. If the
initial signal is $L^2 $, then, for an appropriate choice of inner product that
will be detailed below, the transform is unitary for all values of the
parameter in the interval. This transform provides a heat kernel smoothening of
the signals while preserving unitarity for $L^2$-signals and continuously
interpolating between the original signal and its Fourier transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04122</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04122</id><created>2019-05-09</created><updated>2019-06-11</updated><authors><author><keyname>Chaudhry</keyname><forenames>Ritwick</forenames></author><author><keyname>Ghosh</keyname><forenames>Arunabh</forenames></author><author><keyname>Rajwade</keyname><forenames>Ajit</forenames></author></authors><title>Noise- and Outlier-Resistant Tomographic Reconstruction under Unknown
  Viewing Parameters</title><categories>eess.IV</categories><comments>5 pages with the last page for References. arXiv admin note:
  substantial text overlap with arXiv:1811.04876</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an algorithm for effectively reconstructing an
object from a set of its tomographic projections without any knowledge of the
viewing directions or any prior structural information, in the presence of
pathological amounts of noise, unknown shifts in the projections, and outliers.
We introduce a novel statistically motivated pipeline of first processing the
projections, then obtaining an initial estimate for the orientations and the
shifts, and eventually performing a refinement procedure to obtain the final
reconstruction. Even in the presence of high noise variance (up to $50\%$ of
the average value of the (noiseless) projections) and presence of outliers, we
are able to reconstruct the object successfully. We also provide interesting
empirical comparisons of our method with popular sparsity-based optimization
procedures that have been used earlier for image reconstruction tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04129</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04129</id><created>2019-05-09</created><authors><author><keyname>Kobayashi</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Two-layer Near-lossless HDR Coding with Backward Compatibility to JPEG</title><categories>eess.IV cs.CV</categories><comments>To appear in IEEE International Conference on Image Processing 2019,
  Taipei, Taiwan</comments><doi>10.1587/transfun.E102.A.1842</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient two-layer near-lossless coding method using an
extended histogram packing technique with backward compatibility to the legacy
JPEG standard. The JPEG XT, which is the international standard to compress HDR
images, adopts a two-layer coding method for backward compatibility to the
legacy JPEG standard. However, there are two problems with this two-layer
coding method. One is that it does not exhibit better near-lossless performance
than other methods for HDR image compression with single-layer structure. The
other problem is that the determining the appropriate values of the coding
parameters may be required for each input image to achieve good compression
performance of near-lossless compression with the two-layer coding method of
the JPEG XT. To solve these problems, we focus on a histogram-packing technique
that takes into account the histogram sparseness of HDR images. We used
zero-skip quantization, which is an extension of the histogram-packing
technique proposed for lossless coding, for implementing the proposed
near-lossless coding method. The experimental results indicate that the
proposed method exhibits not only a better near-lossless compression
performance than that of the two-layer coding method of the JPEG XT, but also
there are no issue regarding the combination of parameter values without losing
backward compatibility to the JPEG standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04144</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04144</id><created>2019-05-09</created><updated>2019-05-13</updated><authors><author><keyname>Peng</keyname><forenames>Junzheng</forenames></author><author><keyname>Yao</keyname><forenames>Manhong</forenames></author><author><keyname>Cai</keyname><forenames>Zixin</forenames></author><author><keyname>Qiu</keyname><forenames>Xue</forenames></author><author><keyname>Zhang</keyname><forenames>Zibang</forenames></author><author><keyname>Li</keyname><forenames>Shiping</forenames></author><author><keyname>Zhong</keyname><forenames>Jingang</forenames></author></authors><title>Optical synthetic sampling imaging: concept and an example of microscopy</title><categories>eess.IV physics.optics</categories><doi>10.1063/1.5115448</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital two-dimensional (2D) spatial sampling devices (such as charge-coupled
device) have been widely used in various imaging systems, especially in
computational imaging systems. However, the undersampling of digital sampling
devices is a problem that limits the resolution of the acquired images. In this
study, we present a synthetic sampling imaging (SSI) concept to solve the
undersampling problem. It combines the structured illumination system and
conventional 2D image detection system to simultaneously sample the specimen
from the illumination and the detection sides. Then, we synthesize the
illumination sampling rate and the detection sampling rate to reconstruct a
high sampling rate image. The concept of the proposed SSI is demonstrated by an
example of microscopy. Experimental results confirm that the proposed method
can double the sampling resolution of the microscope. The synthetic sampling
scheme, where the sampling task is shared by the illumination and detection
sides, provides insight for resolving the undersampling problem of the digital
imaging system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04149</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04149</id><created>2019-05-10</created><updated>2019-10-26</updated><authors><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Yao</keyname><forenames>Lina</forenames></author><author><keyname>Wang</keyname><forenames>Xianzhi</forenames></author><author><keyname>Monaghan</keyname><forenames>Jessica</forenames></author><author><keyname>Mcalpine</keyname><forenames>David</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author></authors><title>A Survey on Deep Learning based Brain Computer Interface: Recent
  Advances and New Frontiers</title><categories>cs.HC cs.LG eess.SP q-bio.NC</categories><comments>summarized more than 230 papers most published in the last five years</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain-Computer Interface (BCI) bridges the human's neural world and the outer
physical world by decoding individuals' brain signals into commands
recognizable by computer devices. Deep learning has lifted the performance of
brain-computer interface systems significantly in recent years. In this
article, we systematically investigate brain signal types for BCI and related
deep learning concepts for brain signal analysis. We then present a
comprehensive survey of deep learning techniques used for BCI, by summarizing
over 230 contributions most published in the past five years. Finally, we
discuss the applied areas, opening challenges, and future directions for deep
learning-based BCI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04166</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04166</id><created>2019-05-10</created><authors><author><keyname>Palossi</keyname><forenames>Daniele</forenames></author><author><keyname>Conti</keyname><forenames>Francesco</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>An Open Source and Open Hardware Deep Learning-powered Visual Navigation
  Engine for Autonomous Nano-UAVs</title><categories>cs.RO cs.LG eess.SP</categories><comments>Accepted for publication in Proceeding of International Conference on
  Distributed Computing in Sensor Systems (DCOSS 2019). arXiv admin note: text
  overlap with arXiv:1805.01831</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter
and sub-10 Watts of total power budget, have so far been considered incapable
of running sophisticated visual-based autonomous navigation software without
external aid from base-stations, ad-hoc local positioning infrastructure, and
powerful external computation servers. In this work, we present what is, to the
best of our knowledge, the first 27g nano-UAV system able to run aboard an
end-to-end, closed-loop visual pipeline for autonomous navigation based on a
state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie
2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination
of an ultra-low power computing device (the GAP8 system-on-chip) with a novel
methodology for the deployment of deep convolutional neural networks (CNNs). We
enable onboard real-time execution of a state-of-the-art deep CNN at up to
18Hz. Field experiments demonstrate that the system's high responsiveness
prevents collisions with unexpected dynamic obstacles up to a flight speed of
1.5m/s. In addition, we also demonstrate the capability of our visual
navigation engine of fully autonomous indoor navigation on a 113m previously
unseen path. To share our key findings with the embedded and robotics
communities and foster further developments in autonomous nano-UAVs, we
publicly release all our code, datasets, and trained networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04176</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04176</id><created>2019-05-10</created><updated>2019-05-15</updated><authors><author><keyname>Muckley</keyname><forenames>Matthew J.</forenames></author><author><keyname>Ades-Aron</keyname><forenames>Benjamin</forenames></author><author><keyname>Papaioannou</keyname><forenames>Antonios</forenames></author><author><keyname>Lemberskiy</keyname><forenames>Gregory</forenames></author><author><keyname>Solomon</keyname><forenames>Eddy</forenames></author><author><keyname>Lui</keyname><forenames>Yvonne W.</forenames></author><author><keyname>Sodickson</keyname><forenames>Daniel K.</forenames></author><author><keyname>Fieremans</keyname><forenames>Els</forenames></author><author><keyname>Novikov</keyname><forenames>Dmitry S.</forenames></author><author><keyname>Knoll</keyname><forenames>Florian</forenames></author></authors><title>Training a Neural Network for Gibbs and Noise Removal in Diffusion MRI</title><categories>eess.IV</categories><comments>Pre-print prior to submission to Magnetic Resonance in Medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop and evaluate a neural network-based method for Gibbs artifact and
noise removal. A convolutional neural network (CNN) was designed for artifact
removal in diffusion-weighted imaging data. Two implementations were
considered: one for magnitude images and one for complex images. Both models
were based on the same encoder-decoder structure and were trained by simulating
MRI acquisitions on synthetic non-MRI images. Both machine learning methods
were able to mitigate artifacts in diffusion-weighted images and diffusion
parameter maps. The CNN for complex images was also able to reduce artifacts in
partial Fourier acquisitions. The proposed CNNs extend the ability of artifact
correction in diffusion MRI. The machine learning method described here can be
applied on each imaging slice independently, allowing it to be used flexibly in
clinical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04181</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04181</id><created>2019-05-10</created><authors><author><keyname>Murad</keyname><forenames>Abdulmajid</forenames></author><author><keyname>Kraemer</keyname><forenames>Frank Alexander</forenames></author><author><keyname>Bach</keyname><forenames>Kerstin</forenames></author><author><keyname>Taylor</keyname><forenames>Gavin</forenames></author></authors><title>Autonomous Management of Energy-Harvesting IoT Nodes Using Deep
  Reinforcement Learning</title><categories>cs.LG cs.AI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement learning (RL) is capable of managing wireless,
energy-harvesting IoT nodes by solving the problem of autonomous management in
non-stationary, resource-constrained settings. We show that the
state-of-the-art policy-gradient approaches to RL are appropriate for the IoT
domain and that they outperform previous approaches. Due to the ability to
model continuous observation and action spaces, as well as improved function
approximation capability, the new approaches are able to solve harder problems,
permitting reward functions that are better aligned with the actual application
goals. We show such a reward function and use policy-gradient approaches to
learn capable policies, leading to behavior more appropriate for IoT nodes with
less manual design effort, increasing the level of autonomy in IoT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04197</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04197</id><created>2019-05-10</created><authors><author><keyname>Jun</keyname><forenames>Tae Joon</forenames></author><author><keyname>Kweon</keyname><forenames>Jihoon</forenames></author><author><keyname>Kim</keyname><forenames>Young-Hak</forenames></author><author><keyname>Kim</keyname><forenames>Daeyoung</forenames></author></authors><title>T-Net: Encoder-Decoder in Encoder-Decoder architecture for the main
  vessel segmentation in coronary angiography</title><categories>eess.IV cs.CV</categories><comments>42 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we proposed T-Net containing a small encoder-decoder inside
the encoder-decoder structure (EDiED). T-Net overcomes the limitation that
U-Net can only have a single set of the concatenate layer between encoder and
decoder block. To be more precise, the U-Net symmetrically forms the
concatenate layers, so the low-level feature of the encoder is connected to the
latter part of the decoder, and the high-level feature is connected to the
beginning of the decoder. T-Net arranges the pooling and up-sampling
appropriately during the encoder process, and likewise during the decoding
process so that feature-maps of various sizes are obtained in a single block.
As a result, all features from the low-level to the high-level extracted from
the encoder are delivered from the beginning of the decoder to predict a more
accurate mask. We evaluated T-Net for the problem of segmenting three main
vessels in coronary angiography images. The experiment consisted of a
comparison of U-Net and T-Nets under the same conditions, and an optimized
T-Net for the main vessel segmentation. As a result, T-Net recorded a Dice
Similarity Coefficient score (DSC) of 0.815, 0.095 higher than that of U-Net,
and the optimized T-Net recorded a DSC of 0.890 which was 0.170 higher than
that of U-Net. In addition, we visualized the weight activation of the
convolutional layer of T-Net and U-Net to show that T-Net actually predicts the
mask from earlier decoders. Therefore, we expect that T-Net can be effectively
applied to other similar medical image segmentation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04200</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04200</id><created>2019-05-10</created><authors><author><keyname>Yang</keyname><forenames>Yang</forenames></author><author><keyname>Chen</keyname><forenames>Mingzhe</forenames></author><author><keyname>Guo</keyname><forenames>Caili</forenames></author><author><keyname>Feng</keyname><forenames>Chunyan</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author></authors><title>Power Efficient Visible Light Communication (VLC) with Unmanned Aerial
  Vehicles (UAVs)</title><categories>eess.SP cs.IT math.IT</categories><comments>4 pages, 4 figures. Accepted for publication in IEEE Communications
  Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel approach that combines visible light communication (VLC) with
unmanned aerial vehicles (UAVs) to simultaneously provide flexible
communication and illumination is proposed. To minimize the power consumption,
the locations of UAVs and the cell associations are optimized under
illumination and communication constraints. An efficient sub-optimal solution
that divides the original problem into two sub-problems is proposed. The first
sub-problem is modeled as a classical smallest enclosing disk problem to obtain
the optimal locations of UAVs, given the cell association. Then, assuming fixed
UAV locations, the second sub-problem is modeled as a min-size clustering
problem to obtain the optimized cell association. In addition, the obtained UAV
locations and cell associations are iteratively optimized multiple times to
reduce the power consumption. Numerical results show that the proposed approach
can reduce the total transmit power consumption by at least 53.8% compared to
two baseline algorithms with fixed UAV locations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04224</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04224</id><created>2019-05-10</created><authors><author><keyname>Alam</keyname><forenames>Minhaj</forenames></author><author><keyname>Le</keyname><forenames>David</forenames></author><author><keyname>Lim</keyname><forenames>Jennifer I.</forenames></author><author><keyname>Chan</keyname><forenames>R. V. P.</forenames></author><author><keyname>Yao</keyname><forenames>Xincheng</forenames></author></authors><title>Supervised machine learning based multi-task artificial intelligence
  classification of retinopathies</title><categories>q-bio.QM eess.IV q-bio.TO</categories><comments>Supplemental material attached at the end</comments><journal-ref>https://www.mdpi.com/2077-0383/8/6/872</journal-ref><doi>10.3390/jcm8060872</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Artificial intelligence (AI) classification holds promise as a novel and
affordable screening tool for clinical management of ocular diseases. Rural and
underserved areas, which suffer from lack of access to experienced
ophthalmologists may particularly benefit from this technology. Quantitative
optical coherence tomography angiography (OCTA) imaging provides excellent
capability to identify subtle vascular distortions, which are useful for
classifying retinovascular diseases. However, application of AI for
differentiation and classification of multiple eye diseases is not yet
established. In this study, we demonstrate supervised machine learning based
multi-task OCTA classification. We sought 1) to differentiate normal from
diseased ocular conditions, 2) to differentiate different ocular disease
conditions from each other, and 3) to stage the severity of each ocular
condition. Quantitative OCTA features, including blood vessel tortuosity (BVT),
blood vascular caliber (BVC), vessel perimeter index (VPI), blood vessel
density (BVD), foveal avascular zone (FAZ) area (FAZ-A), and FAZ contour
irregularity (FAZ-CI) were fully automatically extracted from the OCTA images.
A stepwise backward elimination approach was employed to identify sensitive
OCTA features and optimal-feature-combinations for the multi-task
classification. For proof-of-concept demonstration, diabetic retinopathy (DR)
and sickle cell retinopathy (SCR) were used to validate the supervised machine
leaning classifier. The presented AI classification methodology is applicable
and can be readily extended to other ocular diseases, holding promise to enable
a mass-screening platform for clinical deployment and telemedicine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04230</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04230</id><created>2019-05-10</created><authors><author><keyname>Elibol</keyname><forenames>Oguz H.</forenames></author><author><keyname>Keskin</keyname><forenames>Gokce</forenames></author><author><keyname>Thomas</keyname><forenames>Anil</forenames></author></authors><title>Semi-supervised and Population Based Training for Voice Commands
  Recognition</title><categories>eess.AS cs.AI cs.LG</categories><journal-ref>ICASSP 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a rapid design methodology that combines automated hyper-parameter
tuning with semi-supervised training to build highly accurate and robust models
for voice commands classification. Proposed approach allows quick evaluation of
network architectures to fit performance and power constraints of available
hardware, while ensuring good hyper-parameter choices for each network in
real-world scenarios. Leveraging the vast amount of unlabeled data with a
student/teacher based semi-supervised method, classification accuracy is
improved from 84% to 94% in the validation set. For model optimization, we
explore the hyper-parameter space through population based training and obtain
an optimized model in the same time frame as it takes to train a single model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04243</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04243</id><created>2019-05-10</created><updated>2020-02-02</updated><authors><author><keyname>Wang</keyname><forenames>Zhengwei</forenames></author><author><keyname>She</keyname><forenames>Qi</forenames></author><author><keyname>Smeaton</keyname><forenames>Alan F.</forenames></author><author><keyname>Ward</keyname><forenames>Tomas E.</forenames></author><author><keyname>Healy</keyname><forenames>Graham</forenames></author></authors><title>Synthetic-Neuroscore: Using A Neuro-AI Interface for Evaluating
  Generative Adversarial Networks</title><categories>cs.CV cs.LG eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial networks (GANs) are increasingly attracting attention
in the computer vision, natural language processing, speech synthesis and
similar domains. Arguably the most striking results have been in the area of
image synthesis. However, evaluating the performance of GANs is still an open
and challenging problem. Existing evaluation metrics primarily measure the
dissimilarity between real and generated images using automated statistical
methods. They often require large sample sizes for evaluation and do not
directly reflect human perception of image quality. In this work, we describe
an evaluation metric we call Neuroscore, for evaluating the performance of
GANs, that more directly reflects psychoperceptual image quality through the
utilization of brain signals. Our results show that Neuroscore has superior
performance to the current evaluation metrics in that: (1) It is more
consistent with human judgment; (2) The evaluation process needs much smaller
numbers of samples; and (3) It is able to rank the quality of images on a per
GAN basis. A convolutional neural network (CNN) based neuro-AI interface is
proposed to predict Neuroscore from GAN-generated images directly without the
need for neural responses. Importantly, we show that including neural responses
during the training phase of the network can significantly improve the
prediction capability of the proposed model. Materials related to this work are
provided at https://github.com/villawang/Neuro-AI-Interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04247</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04247</id><created>2019-05-10</created><authors><author><keyname>Yousefikamal</keyname><forenames>Parvin</forenames></author></authors><title>Breast Tumor Classification and Segmentation using Convolutional Neural
  Networks</title><categories>cs.CV eess.IV</categories><comments>12 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Breast cancer is considered as the most fatal type of cancer among women
worldwide and it is crucially important to be diagnosed at its early stages. In
the current study, we aim to represent a fast and efficient framework which
consists of two main parts:1- image classification, and 2- tumor region
segmentation. At the initial stage, the images are classified into the two
categories of normal and abnormal. Since the Deep Neural Networks have
performed successfully in machine vision task, we would employ the
convolutional neural networks for the classification of images. In the second
stage, the suggested framework is to diagnose and segment the tumor in the
mammography images. First, the mammography images are pre-processed by removing
noise and artifacts, and then, segment the image using the level-set algorithm
based on the spatial fuzzy c-means clustering. The proper initialization and
optimal configuration have strong effects on the performance of the level-set
segmentation. Thus, in our suggested framework, we have improved the level-set
algorithm by utilizing the spatial fuzzy c-means clustering which ultimately
results in a more precise segmentation. In order to evaluate the proposed
approach, we conducted experiments using the Mammographic Image Analysis (MIAS)
dataset. The tests have shown that the convolutional neural networks could
achieve high accuracy in classification of images. Moreover, the improved
level-set segmentation method, along with the fuzzy c-means clustering, could
perfectly do the segmentation on the tumor area. The suggested method has
classified the images with the accuracy of 78% and the AUC of 69%, which, as
compared to the previous methods, is 2% more accurate and 6% better AUC; and
has been able to extract the tumor area in a more precise way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04252</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04252</id><created>2019-05-10</created><updated>2019-11-21</updated><authors><author><keyname>Seitl</keyname><forenames>F.</forenames></author><author><keyname>Petrich</keyname><forenames>L.</forenames></author><author><keyname>Stan&#x11b;k</keyname><forenames>J.</forenames></author><author><keyname>Krill</keyname><forenames>C. E.</forenames><suffix>III</suffix></author><author><keyname>Schmidt</keyname><forenames>V.</forenames></author><author><keyname>Bene&#x161;</keyname><forenames>V.</forenames></author></authors><title>Exploration of Gibbs-Laguerre tessellations for three-dimensional
  stochastic modeling</title><categories>eess.IV stat.CO</categories><msc-class>60D55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random tessellations are well suited for probabilistic modeling of
three-dimensional (3D) grain microstructures of polycrystalline materials. The
present paper is focused on so-called Gibbs-Laguerre tessellations, in which
the generators of the Laguerre tessellation form a Gibbs point process. The
goal is to construct an energy function of the Gibbs point process such that
the resulting tessellation matches some desired geometrical properties. Since
the model is analytically intractable, our main tool of analysis is stochastic
simulation based on Markov chain Monte Carlo. Such simulations enable us to
investigate the properties of the models, and, in the next step, to apply the
knowledge gained to the statistical reconstruction of the 3D microstructure of
an aluminum alloy extracted from 3D tomographic image data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04284</identifier>
 <datestamp>2019-05-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04284</id><created>2019-05-10</created><authors><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author><author><keyname>Rahnavard</keyname><forenames>Nazanin</forenames></author></authors><title>Primary User Localization and Online Radio Cartography via Structured
  Tensor Decomposition</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to the 2019 IEEE Global Communications Conference
  (GLOBECOM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Source localization and radio cartography using multi-way representation of
spectrum is the subject of study in this paper. A joint matrix factorization
and tensor decomposition problem is proposed and solved using an iterative
algorithm. The multi-way measured spectrum is organized in a tensor and it is
modeled by multiplication of a propagation tensor and a channel gain matrix.
The tensor indicates the propagating power from each location and each
frequency over time and the channel matrix links the propagating tensor to the
sensed spectrum. We utilize sparsity and other intrinsic characteristics of
spectrum to identify the solution of the proposed problem. Moreover, The online
implementation of the proposed framework results in online radio cartography
which is a powerful tool for efficient spectrum awareness and utilization. The
simulation results show that our algorithm is a promising technique for dynamic
primary user localization and online radio cartography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04302</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04302</id><created>2019-05-10</created><authors><author><keyname>Nnolim</keyname><forenames>U. A.</forenames></author></authors><title>Analysis of Probabilistic multi-scale fractional order fusion-based
  de-hazing algorithm</title><categories>eess.IV cs.CV</categories><comments>22 pages, 8 figures, journal preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, a de-hazing algorithm based on probability and multi-scale
fractional order-based fusion is proposed. The proposed scheme improves on a
previously implemented multiscale fraction order-based fusion by augmenting its
local contrast and edge sharpening features. It also brightens de-hazed images,
while avoiding sky region over-enhancement. The results of the proposed
algorithm are analyzed and compared with existing methods from the literature
and indicate better performance in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04307</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04307</id><created>2019-05-10</created><authors><author><keyname>Civitarese</keyname><forenames>Daniel</forenames></author><author><keyname>Szwarcman</keyname><forenames>Daniela</forenames></author><author><keyname>Brazil</keyname><forenames>Emilio Vital</forenames></author><author><keyname>Zadrozny</keyname><forenames>Bianca</forenames></author></authors><title>Semantic Segmentation of Seismic Images</title><categories>eess.IV cs.LG</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Almost all work to understand Earth's subsurface on a large scale relies on
the interpretation of seismic surveys by experts who segment the survey
(usually a cube) into layers; a process that is very time demanding. In this
paper, we present a new deep neural network architecture specially designed to
semantically segment seismic images with a minimal amount of training data. To
achieve this, we make use of a transposed residual unit that replaces the
traditional dilated convolution for the decode block. Also, instead of using a
predefined shape for up-scaling, our network learns all the steps to upscale
the features from the encoder. We train our neural network using the Penobscot
3D dataset; a real seismic dataset acquired offshore Nova Scotia, Canada. We
compare our approach with two well-known deep neural network topologies: Fully
Convolutional Network and U-Net. In our experiments, we show that our approach
can achieve more than 99 percent of the mean intersection over union (mIOU)
metric, outperforming the existing topologies. Moreover, our qualitative
results show that the obtained model can produce masks very close to human
interpretation with very little discontinuity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04326</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04326</id><created>2019-05-10</created><authors><author><keyname>Fall</keyname><forenames>Everett</forenames></author><author><keyname>Chang</keyname><forenames>Kai-wei</forenames></author><author><keyname>Chen</keyname><forenames>Liang-Gee</forenames></author></authors><title>Dynamically Expanded CNN Array for Video Coding</title><categories>eess.IV cs.LG</categories><comments>3 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video coding is a critical step in all popular methods of streaming video.
Marked progress has been made in video quality, compression, and computational
efficiency. Recently, there has been an interest in finding ways to apply
techniques form the fast-progressing field of machine learning to further
improve video coding.
  We present a method that uses convolutional neural networks to help refine
the output of various standard coding methods. The novelty of our approach is
to train multiple different sets of network parameters, with each set
corresponding to a specific, short segment of video. The array of network
parameter sets expands dynamically to match a video of any length. We show that
our method can improve the quality and compression efficiency of standard video
codecs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04348</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04348</id><created>2019-05-10</created><authors><author><keyname>Revay</keyname><forenames>Shauna</forenames></author><author><keyname>Teschke</keyname><forenames>Matthew</forenames></author></authors><title>Multiclass Language Identification using Deep Learning on Spectral
  Images of Audio Signals</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first step in any voice recognition software is to determine what
language a speaker is using, and ideally this process would be automated. The
technique described in this paper, language identification for audio
spectrograms (LIFAS), uses spectrograms generated from audio signals as inputs
to a convolutional neural network (CNN) to be used for language identification.
LIFAS requires minimal pre-processing on the audio signals as the spectrograms
are generated during each batch as they are input to the network during
training.
  LIFAS utilizes deep learning tools that are shown to be successful on image
processing tasks and applies it to audio signal classification. LIFAS performs
binary language classification with an accuracy of 97\%, and multi-class
classification with six languages at an accuracy of 89\% on 3.75 second audio
clips.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04362</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04362</id><created>2019-05-10</created><authors><author><keyname>Jog</keyname><forenames>Varun</forenames></author><author><keyname>La</keyname><forenames>Richard J.</forenames></author><author><keyname>Martins</keyname><forenames>Nuno C.</forenames></author></authors><title>Channels, Learning, Queueing and Remote Estimation Systems With A
  Utilization-Dependent Component</title><categories>math.OC cs.IT eess.SP math.IT stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we survey the main models, techniques, concepts, and results
centered on the design and performance evaluation of engineered systems that
rely on a utilization-dependent component (UDC) whose operation may depend on
its usage history or assigned workload. More specifically, we report on
research themes concentrating on the characterization of the capacity of
channels and the design with performance guarantees of learning algorithms,
queueing and remote estimation systems. Causes for the dependency of a UDC on
past utilization include the use of replenishable energy sources to power the
transmission of information among the sub-components of a networked system, the
influence of the dynamics of optimization iterates on the convergence of
learning mechanisms and the assistance of a human operator for servicing a
queue. Our analysis unveils the similarity of the UDC models typically adopted
in each of the research themes, and it reveals the differences in the
objectives and technical approaches employed. We also identify new challenges
and future research directions inspired by the cross-pollination among the
central concepts, techniques and problem formulations of the research themes
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04384</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04384</id><created>2019-05-10</created><authors><author><keyname>Ali</keyname><forenames>Sharib</forenames></author><author><keyname>Rittscher</keyname><forenames>Jens</forenames></author></authors><title>Efficient video indexing for monitoring disease activity and progression
  in the upper gastrointestinal tract</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted at IEEE International Symposium on Biomedical Imaging
  (ISBI), 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Endoscopy is a routine imaging technique used for both diagnosis and
minimally invasive surgical treatment. While the endoscopy video contains a
wealth of information, tools to capture this information for the purpose of
clinical reporting are rather poor. In date, endoscopists do not have any
access to tools that enable them to browse the video data in an efficient and
user friendly manner. Fast and reliable video retrieval methods could for
example, allow them to review data from previous exams and therefore improve
their ability to monitor disease progression. Deep learning provides new
avenues of compressing and indexing video in an extremely efficient manner. In
this study, we propose to use an autoencoder for efficient video compression
and fast retrieval of video images. To boost the accuracy of video image
retrieval and to address data variability like multi-modality and view-point
changes, we propose the integration of a Siamese network. We demonstrate that
our approach is competitive in retrieving images from 3 large scale videos of 3
different patients obtained against the query samples of their previous
diagnosis. Quantitative validation shows that the combined approach yield an
overall improvement of 5% and 8% over classical and variational autoencoders,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04385</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04385</id><created>2019-05-10</created><authors><author><keyname>Ali</keyname><forenames>Sharib</forenames></author><author><keyname>Alham</keyname><forenames>Nasullah Khalid</forenames></author><author><keyname>Verrill</keyname><forenames>Clare</forenames></author><author><keyname>Rittscher</keyname><forenames>Jens</forenames></author></authors><title>Ink removal from histopathology whole slide images by combining
  classification, detection and image generation models</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted paper at IEEE International Symposium on Biomedical Imaging
  (ISBI) 2019, Venice, Italy</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Histopathology slides are routinely marked by pathologists using permanent
ink markers that should not be removed as they form part of the medical record.
Often tumour regions are marked up for the purpose of highlighting features or
other downstream processing such an gene sequencing. Once digitised there is no
established method for removing this information from the whole slide images
limiting its usability in research and study. Removal of marker ink from these
high-resolution whole slide images is non-trivial and complex problem as they
contaminate different regions and in an inconsistent manner. We propose an
efficient pipeline using convolution neural networks that results in ink-free
images without compromising information and image resolution. Our pipeline
includes a sequential classical convolution neural network for accurate
classification of contaminated image tiles, a fast region detector and a domain
adaptive cycle consistent adversarial generative model for restoration of
foreground pixels. Both quantitative and qualitative results on four different
whole slide images show that our approach yields visually coherent ink-free
whole slide images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04392</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04392</id><created>2019-05-10</created><authors><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author><author><keyname>Alkhouri</keyname><forenames>Ismail</forenames></author><author><keyname>Rahnavard</keyname><forenames>Nazanin</forenames></author></authors><title>Large-Scale Spectrum Occupancy Learning via Tensor Decomposition and
  LSTM Networks</title><categories>eess.SP cs.CV cs.LG cs.NE</categories><comments>Submitted to the 2019 IEEE Global Communications Conference
  (GLOBECOM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new paradigm for large-scale spectrum occupancy learning based on long
short-term memory (LSTM) recurrent neural networks is proposed. Studies have
shown that spectrum usage is a highly correlated time series. Moreover, there
is a correlation for occupancy of spectrum between different frequency
channels. Therefore, revealing all these correlations using learning and
prediction of one-dimensional time series is not a trivial task. In this paper,
we introduce a new framework for representing the spectrum measurements in a
tensor format. Next, a time-series prediction method based on CANDECOMP/PARFAC
(CP) tensor decomposition and LSTM recurrent neural networks is proposed. The
proposed method is computationally efficient and is able to capture different
types of correlation within the measured spectrum. Moreover, it is robust
against noise and missing entries of sensed spectrum. The superiority of the
proposed method is evaluated over a large-scale synthetic dataset in terms of
prediction accuracy and computational efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04395</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04395</id><created>2019-05-10</created><authors><author><keyname>Boljanovic</keyname><forenames>Veljko</forenames></author><author><keyname>Yaghoubi</keyname><forenames>Forough</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>User Association in Dense mmWave Networks based on Rate Requirements</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE GLOBECOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commonly considered user association frameworks in millimeter-wave
communications are based on the sum rate maximization, and they essentially
neglect user specific rate and service requirements. Furthermore, new features
of millimeter-wave communications including spatial multiplexing, connectivity
to multiple coordinated base stations and dense base station deployment are not
considered. In this work, we propose a two-step optimization framework for
single-shot user association in dense millimeter-wave networks which takes into
account users' rate requirements, multi-connectivity, and hybrid transceiver
architecture for spatial multiplexing. The proposed framework considers
multiple RF chains at each base station and assigns them to different users
that also have multiple RF chains for connectivity with more than one base
station. In the first step, the objective of the user association is to
maximize the number of users with satisfied rate requirements while minimizing
network underutilization. In the second step, remaining RF chains are assigned
to users, whose rate requirement has not been met, such that network sum rate
is maximized. This is a novel problem formulation for user associate in
millimeter-wave networks. We propose low complexity sub-optimal user
association algorithms based on this formulation, numerically evaluate the
optimal and sub-optimal solutions, and compare them to the conventional
association approaches in terms of the number of associated users and network
sum rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04418</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04418</id><created>2019-05-10</created><updated>2019-12-01</updated><authors><author><keyname>Bianco</keyname><forenames>Michael J.</forenames></author><author><keyname>Gerstoft</keyname><forenames>Peter</forenames></author><author><keyname>Traer</keyname><forenames>James</forenames></author><author><keyname>Ozanich</keyname><forenames>Emma</forenames></author><author><keyname>Roch</keyname><forenames>Marie A.</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author><author><keyname>Deledalle</keyname><forenames>Charles-Alban</forenames></author></authors><title>Machine learning in acoustics: theory and applications</title><categories>eess.SP cs.LG cs.SD eess.AS physics.app-ph</categories><comments>Published with free access in Journal of the Acoustical Society of
  America, 27 Nov. 2019</comments><journal-ref>Journal of the Acoustical Society of America, 146(5)
  pp.3590--3628, 2019</journal-ref><doi>10.1121/1.5133944</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic data provide scientific and engineering insights in fields ranging
from biology and communications to ocean and Earth science. We survey the
recent advances and transformative potential of machine learning (ML),
including deep learning, in the field of acoustics. ML is a broad family of
techniques, which are often based in statistics, for automatically detecting
and utilizing patterns in data. Relative to conventional acoustics and signal
processing, ML is data-driven. Given sufficient training data, ML can discover
complex relationships between features and desired labels or actions, or
between features themselves. With large volumes of training data, ML can
discover models describing complex acoustic phenomena such as human speech and
reverberation. ML in acoustics is rapidly developing with compelling results
and significant future promise. We first introduce ML, then highlight ML
developments in four acoustics research areas: source localization in speech
processing, source localization in ocean acoustics, bioacoustics, and
environmental sounds in everyday scenes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04425</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04425</id><created>2019-05-10</created><authors><author><keyname>Xu</keyname><forenames>Yajing</forenames></author><author><keyname>Yang</keyname><forenames>Haitao</forenames></author><author><keyname>Cheng</keyname><forenames>Mingfei</forenames></author><author><keyname>Li</keyname><forenames>Si</forenames></author></authors><title>Cyclone intensity estimate with context-aware cyclegan</title><categories>cs.CV eess.IV</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning approaches to cyclone intensity estimationhave recently shown
promising results. However, sufferingfrom the extreme scarcity of cyclone data
on specific in-tensity, most existing deep learning methods fail to
achievesatisfactory performance on cyclone intensity estimation,especially on
classes with few instances. To avoid the degra-dation of recognition
performance caused by scarce samples,we propose a context-aware CycleGAN which
learns the la-tent evolution features from adjacent cyclone intensity
andsynthesizes CNN features of classes lacking samples fromunpaired source
classes. Specifically, our approach synthe-sizes features conditioned on the
learned evolution features,while the extra information is not required.
Experimentalresults of several evaluation methods show the effectivenessof our
approach, even can predicting unseen classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04441</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04441</id><created>2019-05-10</created><updated>2019-12-22</updated><authors><author><keyname>Tanaka</keyname><forenames>Yuichi</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Generalized Sampling on Graphs With Subspace and Smoothness Priors</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for generalized sampling of graph signals that
parallels sampling in shift-invariant (SI) subspaces. This framework allows for
arbitrary input signals, which are not constrained to be bandlimited.
Furthermore, the sampling and reconstruction filters may be different. We
present design methods of the correction filter that compensate for these
differences and lead to closed form expressions in the graph frequency domain.
In this study, we consider two priors on graph signals: The first is a subspace
prior, where the signal is assumed to lie in a periodic graph spectrum (PGS)
subspace. The PGS subspace is proposed as a counterpart of the SI subspace used
in standard sampling theory. The second is a smoothness prior that imposes a
smoothness requirement on the graph signal. We suggest the use of recovery
techniques for when the recovery filter can be optimized and under a setting in
which a predefined filter must be used. Sampling is performed in the graph
frequency domain, which is a counterpart of &quot;sampling by modulation&quot; used in SI
subspaces. We compare our approach with existing sampling techniques on graph
signal processing. The effectiveness of the proposed generalized sampling
approach is validated numerically through several experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04442</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04442</id><created>2019-05-11</created><authors><author><keyname>Wang</keyname><forenames>Zihan</forenames></author><author><keyname>Li</keyname><forenames>Yaoguang</forenames></author><author><keyname>Cui</keyname><forenames>Wei</forenames></author></authors><title>ECG Identification under Exercise and Rest Situations via Various
  Learning Methods</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the advancement of information security, human recognition as its core
technology, has absorbed an increasing amount of attention in the past few
years. A myriad of biometric features including fingerprint, face, iris, have
been applied to security systems, which are occasionally considered vulnerable
to forgery and spoofing attacks. Due to the difficulty of being fabricated,
electrocardiogram (ECG) has attracted much attention. Though many works have
shown the excellent human identification provided by ECG, most current ECG
human identification (ECGID) researches only focus on rest situation. In this
manuscript, we overcome the oversimplification of previous researches and
evaluate the performance under both exercise and rest situations, especially
the influence of exercise on ECGID. By applying various existing learning
methods to our ECG dataset, we find that current methods which can well support
the identification of individuals under rests, do not suffice to present
satisfying ECGID performance under exercise situations, therefore exposing the
deficiency of existing ECG identification methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04449</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04449</id><created>2019-05-11</created><updated>2019-09-14</updated><authors><author><keyname>Xu</keyname><forenames>Wen-Hao</forenames></author><author><keyname>Zhao</keyname><forenames>Xi-Le</forenames></author><author><keyname>Jiang</keyname><forenames>Tai-Xiang</forenames></author><author><keyname>Wang</keyname><forenames>Yao</forenames></author><author><keyname>Ng</keyname><forenames>Michael</forenames></author></authors><title>Deep Plug-and-play Prior for Low-rank Tensor Completion</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-dimensional images, such as color images and multi-spectral images, are
highly correlated and contain abundant spatial and spectral information.
However, real-world multi-dimensional images are usually corrupted by missing
entries. By integrating deterministic low-rankness prior with the data-driven
deep prior, we suggest a novel regularized tensor completion model for
multi-dimensional image completion. In the objective function, we adopt the
newly emerged tensor nuclear norm (TNN) to characterize the global low-rankness
prior of the multi-dimensional images. We also formulate an implicit
regularizer to plug in the denoising neural network (termed as deep denoiser),
which is convinced to express the deep image prior learned from a large number
of natural images. The resulting model can be efficiently solved by the
alternating directional method of multipliers algorithm under the plug-and-play
(PnP) framework. Experimental results on color images, videos, and
multi-spectral images demonstrate that the proposed method can recover both the
global structure and fine details very well and achieve superior performance
over competing methods in terms of quality metrics and visual effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04500</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04500</id><created>2019-05-11</created><updated>2020-02-07</updated><authors><author><keyname>Jyothi</keyname><forenames>R.</forenames></author><author><keyname>Babu</keyname><forenames>P.</forenames></author></authors><title>SOLVIT:A Reference-Free Source Localization Technique using Majorization
  Minimization</title><categories>eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of localizing the source using range and
range-difference measurements. Both the problems are non-convex and non-smooth
and are challenging to solve. In this paper, we develop an iterative algorithm
- Source Localization Via an Iterative technique (SOLVIT) to localize the
source using all the distinct range-difference measurements, i.e., without
choosing a reference sensor. SOLVIT is based on the Majorization Minimization
approach - in which a novel upper bound is formulated and minimized to get a
closed-form solution at every iteration. We also solve the source localization
problem based on range measurements and rederive the Standard Fixed Point
algorithm using the Majorization Minimization approach. By doing so, we show a
less intricate way to prove the convergence of the Standard Fixed Point
algorithm. Numerical simulations and experiments in an anechoic chamber confirm
that SOLVIT performs better than existing reference-based and reference-free
methods in terms of source positioning accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04529</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04529</id><created>2019-05-11</created><authors><author><keyname>Jyothi</keyname><forenames>R.</forenames></author><author><keyname>Babu</keyname><forenames>P.</forenames></author><author><keyname>Bahl</keyname><forenames>R.</forenames></author></authors><title>Novel Algorithms based on Majorization Minimization for Nonnegative
  Matrix Factorization</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix decomposition is ubiquitous and has applications in various fields
like speech processing, data mining and image processing to name a few. Under
matrix decomposition, nonnegative matrix factorization is used to decompose a
nonnegative matrix into a product of two nonnegative matrices which gives some
meaningful interpretation of the data. Thus, nonnegative matrix factorization
has an edge over the other decomposition techniques. In this paper, we propose
two novel iterative algorithms based on Majorization Minimization (MM)-in which
we formulate a novel upper bound and minimize it to get a closed form solution
at every iteration. Since the algorithms are based on MM, it is ensured that
the proposed methods will be monotonic. The proposed algorithms differ in the
updating approach of the two nonnegative matrices. The first
algorithm-Iterative Nonnegative Matrix Factorization (INOM) sequentially
updates the two nonnegative matrices while the second algorithm-Parallel
Iterative Nonnegative Matrix Factorization (PARINOM) parallely updates them. We
also prove that the proposed algorithms converge to the stationary point of the
problem. Simulations were conducted to compare the proposed methods with the
existing ones and was found that the proposed algorithms performs better than
the existing ones in terms of computational speed and convergence.
  KeyWords: Nonnegative matrix factorization, Majorization Minimization, Big
Data, Parallel, Multiplicative Update
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04554</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04554</id><created>2019-05-11</created><authors><author><keyname>Sarkar</keyname><forenames>Achintya kr.</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Tang</keyname><forenames>Hao</forenames></author><author><keyname>Shon</keyname><forenames>Suwon</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Time-Contrastive Learning Based Deep Bottleneck Features for
  Text-Dependent Speaker Verification</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><comments>Copyright (c) 2019 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</comments><journal-ref>IEEE/ACM Transactions on Audio, Speech, and Language Processing,
  2019</journal-ref><doi>10.1109/TASLP.2019.2915322</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are a number of studies about extraction of bottleneck (BN) features
from deep neural networks (DNNs)trained to discriminate speakers, pass-phrases
and triphone states for improving the performance of text-dependent speaker
verification (TD-SV). However, a moderate success has been achieved. A recent
study [1] presented a time contrastive learning (TCL) concept to explore the
non-stationarity of brain signals for classification of brain states. Speech
signals have similar non-stationarity property, and TCL further has the
advantage of having no need for labeled data. We therefore present a TCL based
BN feature extraction method. The method uniformly partitions each speech
utterance in a training dataset into a predefined number of multi-frame
segments. Each segment in an utterance corresponds to one class, and class
labels are shared across utterances. DNNs are then trained to discriminate all
speech frames among the classes to exploit the temporal structure of speech. In
addition, we propose a segment-based unsupervised clustering algorithm to
re-assign class labels to the segments. TD-SV experiments were conducted on the
RedDots challenge database. The TCL-DNNs were trained using speech data of
fixed pass-phrases that were excluded from the TD-SV evaluation set, so the
learned features can be considered phrase-independent. We compare the
performance of the proposed TCL bottleneck (BN) feature with those of
short-time cepstral features and BN features extracted from DNNs discriminating
speakers, pass-phrases, speaker+pass-phrase, as well as monophones whose labels
and boundaries are generated by three different automatic speech recognition
(ASR) systems. Experimental results show that the proposed TCL-BN outperforms
cepstral features and speaker+pass-phrase discriminant BN features, and its
performance is on par with those of ASR derived BN features. Moreover,....
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04572</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04572</id><created>2019-05-11</created><authors><author><keyname>Chaudhari</keyname><forenames>Shailesh</forenames></author></authors><title>Interference Mitigation and Resource Allocation in Underlay Cognitive
  Radio Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>Ph.D. Dissertation, UCLA 2018</comments><doi>10.13140/RG.2.2.26407.60326</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to ever increasing usage of wireless devices and data hungry
applications, it has become necessary to improve the spectral efficiency of
existing wireless networks. One way of improving spectral efficiency is to
share the spectrum amongst different coexisting networks and serve multiple
devices simultaneously. Spectrum sharing mechanisms for coexistence of a
licensed network, such as LTE, with an unlicensed network, such as Wi-Fi, are
being considered in the recent literature and standardizations. In order to
enable the coexistence between licensed and unlicensed users, it is necessary
to include interference mitigation techniques to protect the licensed primary
users (PUs) from harmful interference. Typical interference mitigation
mechanisms are based on spectrum sensing and cognitive radio (CR), wherein
unlicensed secondary users (SUs) observe the spectrum and utilize it when
licensed PUs are inactive. Thus, the SUs utilize empty time-slots in the shared
spectrum to avoid the interference. The spectral efficiency can be further
improved if the SUs are allowed to transmit concurrently with PUs by exploiting
the spatial dimension provided by multiple antenna techniques. The underlay CR
paradigm allows such coexistence where SUs transmit its signal in the same
time-slots as PUs by exploiting the spatial and frequency resources in the
network. In order to exploit the spatial dimension, SUs can utilize the
location coordinates of PUs to steer its signal away from PUs to mitigate the
interference. The SU transmitter can also employ multiple antenna techniques to
serve a large number of devices. Further, the SUs can utilize frequency bands
occupied by PUs by dynamically selecting the frequency band that provides the
highest rate. In this work, we develop techniques for PU location estimation,
spatial resource allocation and frequency band selection for SUs in underlay CR
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04585</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04585</id><created>2019-05-11</created><authors><author><keyname>Jagtap</keyname><forenames>Pushpak</forenames></author><author><keyname>Soudjani</keyname><forenames>Sadegh</forenames></author><author><keyname>Zamani</keyname><forenames>Majid</forenames></author></authors><title>Formal Synthesis of Stochastic Systems via Control Barrier Certificates</title><categories>eess.SY cs.SY math.OC</categories><comments>20 pages, 11 figures. arXiv admin note: text overlap with
  arXiv:1807.00064</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study formal synthesis of control policies for discrete-time stochastic
control systems against complex temporal properties. Our goal is to synthesize
a control policy for the system together with a lower bound on the probability
that the system satisfies a complex temporal property. The desired properties
of the system are expressed as a fragment of linear temporal logic (LTL),
called safe-LTL over finite traces. We propose leveraging \emph{control barrier
certificates} which alleviate the issue of the curse of dimensionality
associated with discretization-based approaches existing in the literature. We
show how control barrier certificates can be used for synthesizing policies
while guaranteeing lower bounds on the probability of satisfaction for the
given property. Our approach decomposes negation of the specification into
sequential reachabilities and then finds control barrier certificates for
computing upper-bounds on the reachability probabilities. Control policies
associated with these barrier certificates are then combined as a hybrid
control policy for the concrete system that guarantees a lower bound on the
probability of satisfaction of the property. We distinguish uncountable and
finite input sets in the computation of barrier certificates. For the former,
control barrier certificates can be computed using sum-of-square optimization.
For the latter, we develop a computational method based on counter-example
guided inductive synthesis. We demonstrate the effectiveness of the proposed
approach on a room temperature control and lane keeping of a vehicle modeled as
a four-dimensional single-track kinematic model. We compare our results with
the discretization-based methods in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04589</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04589</id><created>2019-05-11</created><authors><author><keyname>Liu</keyname><forenames>Gi-Ren</forenames></author><author><keyname>Lo</keyname><forenames>Yu-Lun</forenames></author><author><keyname>Sheu</keyname><forenames>Yuan-Chung</forenames></author><author><keyname>Wu</keyname><forenames>Hau-Tieng</forenames></author></authors><title>Explore intrinsic geometry of sleep dynamics and predict sleep stage by
  unsupervised learning techniques</title><categories>eess.SP</categories><comments>41 pages, 21 figures. arXiv admin note: text overlap with
  arXiv:1803.01710</comments><msc-class>42A, 60J</msc-class><acm-class>I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel unsupervised approach for sleep dynamics exploration and
automatic annotation by combining modern harmonic analysis tools. Specifically,
we apply diffusion-based algorithms, diffusion map (DM) and alternating
diffusion (AD) algorithms, to reconstruct the intrinsic geometry of sleep
dynamics by reorganizing the spectral information of an electroencephalogram
(EEG) extracted from a nonlinear-type time frequency analysis tool, the
synchrosqueezing transform (SST). The visualization is achieved by the
nonlinear dimension reduction properties of DM and AD. Moreover, the
reconstructed nonlinear geometric structure of the sleep dynamics allows us to
achieve the automatic annotation purpose. The hidden Markov model is trained to
predict the sleep stage. The prediction performance is validated on a publicly
available benchmark database, Physionet Sleep-EDF [extended] SC* and ST*, with
the leave-one-subject-out cross validation. The overall accuracy and macro F1
achieve 82:57% and 76% in Sleep-EDF SC* and 77.01% and 71:53% in Sleep-EDF ST*,
which is compatible with the state-of-the-art results by supervised
learning-based algorithms. The results suggest the potential of the proposed
algorithm for clinical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04596</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04596</id><created>2019-05-11</created><authors><author><keyname>Mokatren</keyname><forenames>Lubna Shibly</forenames></author><author><keyname>Cetin</keyname><forenames>Ahmet Enis</forenames></author><author><keyname>Ansari</keyname><forenames>Rashid</forenames></author></authors><title>Deep Layered LMS Predictor</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we present a new approach to design a Least Mean Squares (LMS)
predictor. This approach exploits the concept of deep neural networks and their
supremacy in terms of performance and accuracy. The new LMS predictor is
implemented as a deep neural network using multiple non linear LMS filters. The
network consists of multiple layers with nonlinear activation functions, where
each neuron in the hidden layers corresponds to a certain FIR filter output
which goes through nonlinearity. The output of the last layer is the
prediction. We hypothesize that this approach will outperform the traditional
adaptive filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04599</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04599</id><created>2019-05-11</created><authors><author><keyname>Perfecto</keyname><forenames>Cristina</forenames></author><author><keyname>Elbamby</keyname><forenames>Mohammed S.</forenames></author><author><keyname>Park</keyname><forenames>Jihong</forenames></author><author><keyname>Del Ser</keyname><forenames>Javier</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author></authors><title>Mobile XR over 5G: A way forward with mmWaves and Edge</title><categories>eess.SP</categories><journal-ref>IEEE MMTC Communications - Frontiers vol.~14, no.~2, pp. 29--34,
  March 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This e-letter summarizes our most recent work and contributed approaches to
increase the capacity, cut down on the latency and provide higher reliability
in several extended reality (XR) scenarios. To that end, several technologies
from emerging 5G communications systems are weaved together towards enabling a
fully immersive XR experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04621</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04621</id><created>2019-05-11</created><authors><author><keyname>Zhong</keyname><forenames>Zilong</forenames></author><author><keyname>Li</keyname><forenames>Jonathan</forenames></author><author><keyname>Clausi</keyname><forenames>David A.</forenames></author><author><keyname>Wong</keyname><forenames>Alexander</forenames></author></authors><title>Generative Adversarial Networks and Conditional Random Fields for
  Hyperspectral Image Classification</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted by IEEE T-CYB</comments><doi>10.1109/TCYB.2019.2915094</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the hyperspectral image (HSI) classification task
with a generative adversarial network and conditional random field (GAN-CRF)
-based framework, which integrates a semi-supervised deep learning and a
probabilistic graphical model, and make three contributions. First, we design
four types of convolutional and transposed convolutional layers that consider
the characteristics of HSIs to help with extracting discriminative features
from limited numbers of labeled HSI samples. Second, we construct
semi-supervised GANs to alleviate the shortage of training samples by adding
labels to them and implicitly reconstructing real HSI data distribution through
adversarial training. Third, we build dense conditional random fields (CRFs) on
top of the random variables that are initialized to the softmax predictions of
the trained GANs and are conditioned on HSIs to refine classification maps.
This semi-supervised framework leverages the merits of discriminative and
generative models through a game-theoretical approach. Moreover, even though we
used very small numbers of labeled training HSI samples from the two most
challenging and extensively studied datasets, the experimental results
demonstrated that spectral-spatial GAN-CRF (SS-GAN-CRF) models achieved
top-ranking accuracy for semi-supervised HSI classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04627</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04627</id><created>2019-05-11</created><authors><author><keyname>Bernstein</keyname><forenames>Brett</forenames></author><author><keyname>Liu</keyname><forenames>Sheng</forenames></author><author><keyname>Papadaniil</keyname><forenames>Chrysa</forenames></author><author><keyname>Fernandez-Granda</keyname><forenames>Carlos</forenames></author></authors><title>Sparse Recovery Beyond Compressed Sensing: Separable Nonlinear Inverse
  Problems</title><categories>eess.SP cs.IT math.IT math.NA math.OC</categories><comments>40 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting information from nonlinear measurements is a fundamental challenge
in data analysis. In this work, we consider separable inverse problems, where
the data are modeled as a linear combination of functions that depend
nonlinearly on certain parameters of interest. These parameters may represent
neuronal activity in a human brain, frequencies of electromagnetic waves,
fluorescent probes in a cell, or magnetic relaxation times of biological
tissues. Separable nonlinear inverse problems can be reformulated as
underdetermined sparse-recovery problems, and solved using convex programming.
This approach has had empirical success in a variety of domains, from
geophysics to medical imaging, but lacks a theoretical justification. In
particular, compressed-sensing theory does not apply, because the measurement
operators are deterministic and violate incoherence conditions such as the
restricted-isometry property. Our main contribution is a theory for sparse
recovery adapted to deterministic settings. We show that convex programming
succeeds in recovering the parameters of interest, as long as their values are
sufficiently distinct with respect to the correlation structure of the
measurement operator. The theoretical results are illustrated through numerical
experiments for two applications: heat-source localization and estimation of
brain activity from electroencephalography data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04628</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04628</id><created>2019-05-11</created><updated>2019-11-20</updated><authors><author><keyname>Skoglund</keyname><forenames>Jan</forenames></author><author><keyname>Valin</keyname><forenames>Jean-Marc</forenames></author></authors><title>Improving Opus Low Bit Rate Quality with Neural Speech Synthesis</title><categories>eess.AS cs.SD</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The voice mode of the Opus audio coder can compress wideband speech at bit
rates ranging from 6 kb/s to 40 kb/s. However, Opus is at its core a waveform
matching coder, and as the rate drops below 10 kb/s, quality degrades quickly.
As the rate reduces even further, parametric coders tend to perform better than
waveform coders. In this paper we propose a backward-compatible way of
improving low bit rate Opus quality by re-synthesizing speech from the decoded
parameters. We compare two different neural generative models, WaveNet and
LPCNet. WaveNet is a powerful, high-complexity, and high-latency architecture
that is not feasible for a practical system, yet provides a best known
achievable quality with generative models. LPCNet is a low-complexity,
low-latency RNN-based generative model, and practically implementable on mobile
phones. We apply these systems with parameters from Opus coded at 6 kb/s as
conditioning features for the generative models. Listening tests show that for
the same 6 kb/s Opus bit stream, synthesized speech using LPCNet clearly
outperforms the output of the standard Opus decoder. This opens up ways to
improve the quality of existing speech and audio waveform coders without
breaking compatibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04709</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04709</id><created>2019-05-12</created><updated>2019-05-14</updated><authors><author><keyname>Min</keyname><forenames>Gang</forenames></author><author><keyname>Zhang</keyname><forenames>Changqing</forenames></author><author><keyname>Zhang</keyname><forenames>Xiongwei</forenames></author><author><keyname>Tan</keyname><forenames>Wei</forenames></author></authors><title>Deep Vocoder: Low Bit Rate Compression of Speech with Deep Autoencoder</title><categories>cs.MM cs.IT cs.SD eess.AS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the success of deep neural networks (DNNs) in speech processing,
this paper presents Deep Vocoder, a direct end-to-end low bit rate speech
compression method with deep autoencoder (DAE). In Deep Vocoder, DAE is used
for extracting the latent representing features (LRFs) of speech, which are
then efficiently quantized by an analysis-by-synthesis vector quantization (AbS
VQ) method. AbS VQ aims to minimize the perceptual spectral reconstruction
distortion rather than the distortion of LRFs vector itself. Also, a suboptimal
codebook searching technique is proposed to further reduce the computational
complexity. Experimental results demonstrate that Deep Vocoder yields
substantial improvements in terms of frequency-weighted segmental SNR, STOI and
PESQ score when compared to the output of the conventional SQ- or VQ-based
codec. The yielded PESQ score over the TIMIT corpus is 3.34 and 3.08 for speech
coding at 2400 bit/s and 1200 bit/s, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04711</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04711</id><created>2019-05-12</created><updated>2019-10-28</updated><authors><author><keyname>Ma</keyname><forenames>Boyuan</forenames></author><author><keyname>Wei</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Liu</keyname><forenames>Chuni</forenames></author><author><keyname>Ban</keyname><forenames>Xiaojuan</forenames></author><author><keyname>Huang</keyname><forenames>Haiyou</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Xue</keyname><forenames>Weihua</forenames></author><author><keyname>Wu</keyname><forenames>Stephen</forenames></author><author><keyname>Gao</keyname><forenames>Mingfei</forenames></author><author><keyname>Shen</keyname><forenames>Qing</forenames></author><author><keyname>Abuassba</keyname><forenames>Adnan Omer</forenames></author><author><keyname>Shen</keyname><forenames>Haokai</forenames></author><author><keyname>Su</keyname><forenames>Yanjing</forenames></author></authors><title>Data augmentation in microscopic images for material data mining</title><categories>cond-mat.mtrl-sci cs.CV eess.IV</categories><comments>17 pages, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent progress in material data mining has been driven by high-capacity
models trained on large datasets. However, collecting experimental data (real
data) has been extremely costly since the amount of human effort and expertise
required. Here, we develop a novel transfer learning strategy to address small
or insufficient data problem. This strategy realizes the fusion of real and
simulated data, and the augmentation of training data in data mining procedure.
For a specific task of image segmentation, this strategy can generate synthetic
images by fusing physical mechanism of simulated images and &quot;image style&quot; of
real images. The result shows that the model trained with the acquired
synthetic images and 35% of the real images outperforms the model trained on
all real images. As the time required to generate synthetic data is almost
negligible, this strategy is able to reduce the time cost of real data
preparation by roughly 65%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04732</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04732</id><created>2019-05-12</created><updated>2019-07-12</updated><authors><author><keyname>Sarieddeen</keyname><forenames>Hadi</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>Terahertz-Band Ultra-Massive Spatial Modulation MIMO</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prospect of ultra-massive multiple-input multiple-output (UM-MIMO)
technology to combat the distance problem at the Terahertz (THz)-band is
considered. It is well-known that the very large available bandwidths at THz
frequencies come at the cost of severe propagation losses and power
limitations, which result in very short communication distances. Recently,
graphene-based plasmonic nano-antenna arrays that can accommodate hundreds of
antenna elements in a few millimeters have been proposed. While such arrays
enable efficient beamforming that can increase the communication range, they
fail to provide sufficient spatial degrees of freedom for spatial multiplexing.
In this paper, we examine spatial modulation (SM) techniques that can leverage
the properties of densely packed configurable arrays of subarrays of
nano-antennas, to increase capacity and spectral efficiency, while maintaining
acceptable beamforming performance. Depending on the communication distance and
the frequency of operation, a specific SM configuration that ensures good
channel conditions is recommended. We analyze the performance of the proposed
schemes theoretically and numerically in terms of symbol and bit error rates,
where significant gains are observed compared to conventional SM. We
demonstrate that SM at very high frequencies is a feasible paradigm, and we
motivate several extensions that can make THz-band SM a future research trend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04738</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04738</id><created>2019-05-12</created><authors><author><keyname>Tran</keyname><forenames>Ha-Vu</forenames></author><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author><author><keyname>Diamantoulakis</keyname><forenames>Panagiotis D.</forenames></author><author><keyname>Abou-Rjeily</keyname><forenames>Chadi</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>Ultra-small Cell Networks with Collaborative RF and Lightwave Power
  Transfer</title><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a hybrid radio frequency (RF)/visible light
communication (VLC) ultra-small cell network consisting of multiple optical
angle-diversity transmitters, one multi-antenna RF access point (AP), and
multiple terminal devices. In the network, the optical transmitters play the
primary role and are responsible for delivering information and power over the
visible light, while the RF AP acts as a complementary power transfer system.
Thus, we propose a novel collaborative RF and lightwave resource allocation
scheme for hybrid RF/VLC ultra-small cell networks. The proposed scheme aims to
maximize the communication quality-of-service provided by the VLC under a
constraint of total RF and light energy harvesting performance, while keeping
illumination constant and ensuring health safety. This scheme leads to the
formulation of two optimization problems that correspond to the resource
allocation at the optical transmitters and the RF AP. Both problems are
optimally solved by appropriate algorithms. Moreover, we propose a closed-form
suboptimal solution with high accuracy to tackle the optical transmitters'
resource allocation problem, as well as an efficient semi-decentralized method.
Finally, simulation results illustrate the achievable performance of the
investigated system and the effectiveness of the proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04787</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04787</id><created>2019-05-12</created><updated>2019-08-06</updated><authors><author><keyname>Der Sarkissian</keyname><forenames>Henri</forenames></author><author><keyname>Lucka</keyname><forenames>Felix</forenames></author><author><keyname>van Eijnatten</keyname><forenames>Maureen</forenames></author><author><keyname>Colacicco</keyname><forenames>Giulia</forenames></author><author><keyname>Coban</keyname><forenames>Sophia Bethany</forenames></author><author><keyname>Batenburg</keyname><forenames>Kees Joost</forenames></author></authors><title>A Cone-Beam X-Ray CT Data Collection designed for Machine Learning</title><categories>eess.IV cs.LG cs.NA math.NA stat.ML</categories><comments>The reconstruction codes and links to the data are available at
  https://github.com/cicwi/WalnutReconstructionCodes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike previous works, this open data collection consists of X-ray cone-beam
(CB) computed tomography (CT) datasets specifically designed for machine
learning applications and high cone-angle artefact reduction. Forty-two walnuts
were scanned with a laboratory X-ray set-up to provide not only data from a
single object but from a class of objects with natural variability. For each
walnut, CB projections on three different source orbits were acquired to
provide CB data with different cone angles as well as being able to compute
artefact-free, high-quality ground truth images from the combined data that can
be used for supervised learning. We provide the complete image reconstruction
pipeline: raw projection data, a description of the scanning geometry,
pre-processing and reconstruction scripts using open software, and the
reconstructed volumes. Due to this, the dataset can not only be used for high
cone-angle artefact reduction but also for algorithm development and evaluation
for other tasks, such as image reconstruction from limited or sparse-angle
(low-dose) scanning, super resolution, or segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04788</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04788</id><created>2019-05-12</created><authors><author><keyname>Yousefvand</keyname><forenames>Mohammad</forenames></author><author><keyname>Hamidouche</keyname><forenames>Kenza</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan B.</forenames></author></authors><title>Learning-based Resource Optimization in Ultra Reliable Low Latency
  HetNets</title><categories>cs.NI cs.LG eess.SP</categories><comments>Submitted to IEEE Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problems of user offloading and resource optimization are
jointly addressed to support ultra-reliable and low latency communications
(URLLC) in HetNets. In particular, a multi-tier network with a single macro
base station (MBS) and multiple overlaid small cell base stations (SBSs) is
considered that includes users with different latency and reliability
constraints. Modeling the latency and reliability constraints of users with
probabilistic guarantees, the joint problem of user offloading and resource
allocation (JUR) in a URLLC setting is formulated as an optimization problem to
minimize the cost of serving users for the MBS. In the considered scheme, SBSs
bid to serve URLLC users under their coverage at a given price, and the MBS
decides whether to serve each user locally or to offload it to one of the
overlaid SBSs. Since the JUR optimization is NP-hard, we propose a low
complexity learning-based heuristic method (LHM) which includes a support
vector machine-based user association model and a convex resource optimization
(CRO) algorithm. To further reduce the delay, we propose an alternating
direction method of multipliers (ADMM)-based solution to the CRO problem.
Simulation results show that using LHM, the MBS significantly decreases the
spectrum access delay for users (by $\sim$ 93\%) as compared to JUR, while also
reducing its bandwidth and power costs in serving users (by $\sim$ 33\%) as
compared to directly serving users without offloading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04791</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04791</id><created>2019-05-12</created><updated>2019-07-11</updated><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Zheng</keyname><forenames>Tong</forenames></author><author><keyname>Zhang</keyname><forenames>Shengping</forenames></author><author><keyname>Wang</keyname><forenames>Meng</forenames></author></authors><title>DeepIlluminance: Contextual Illuminance Estimation via Deep Neural
  Networks</title><categories>cs.CV cs.AI eess.IV</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational color constancy refers to the estimation of the scene
illumination and makes the perceived color relatively stable under varying
illumination. In the past few years, deep Convolutional Neural Networks (CNNs)
have delivered superior performance in illuminant estimation. Several
representative methods formulate it as a multi-label prediction problem by
learning the local appearance of image patches using CNNs. However, these
approaches inevitably make incorrect estimations for the ambiguous patches
affected by their neighborhood contexts. Inaccurate local estimates are likely
to bring in degraded performance when combining into a global prediction. To
address the above issues, we propose a contextual deep network for patch-based
illuminant estimation equipped with refinement. First, the contextual net with
a center-surround architecture extracts local contextual features from image
patches, and generates initial illuminant estimates and the corresponding color
corrected patches. The patches are sampled based on the observation that pixels
with large color differences describe the illumination well. Then, the
refinement net integrates the input patches with the corrected patches in
conjunction with the use of intermediate features to improve the performance.
To train such a network with numerous parameters, we propose a stage-wise
training strategy, in which the features and the predicted illuminant from
previous stages are provided to the next learning stage with more finer
estimates recovered. Experiments show that our approach obtains competitive
performance on two illuminant estimation benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04794</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04794</id><created>2019-05-12</created><authors><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Ezuma</keyname><forenames>Martins</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Coverage Enhancement for NLOS mmWave Links Using Passive Reflectors</title><categories>eess.SP physics.app-ph</categories><comments>The manuscript is submitted to IEEE Transactions on Antennas and
  Propagation. arXiv admin note: text overlap with arXiv:1808.06223</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future 5G networks are expected to use millimeter wave (mmWave) frequency
bands to take advantage of large unused spectrum. However, due to the high path
loss at mmWave frequencies, coverage of mmWave signals can get severely
reduced, especially for non-line-of-sight (NLOS) scenarios as mmWave signals
are severely attenuated when going through obstructions. In this work, we study
the use of passive metallic reflectors of different shapes/sizes to improve 28
GHz mmWave signal coverage for both indoor and outdoor NLOS scenarios. We
quantify the gains that can be achieved in the link quality with metallic
reflectors using measurements, analytical expressions, and ray tracing
simulations. In particular, we provide an analytical model for the end-to-end
received power in an NLOS scenario using reflectors of different shapes and
sizes. For a given size of the flat metallic sheet reflector approaching to the
size of incident plane waves, we show that the reflected received power for the
NLOS link is same as line-of-sight (LOS)free space received power of the same
link distance. Extensive results are provided to study impact of environmental
features and reflector characteristics on NLOS link quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04803</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04803</id><created>2019-05-12</created><authors><author><keyname>Ghimire</keyname><forenames>Sandesh</forenames></author><author><keyname>Dhamala</keyname><forenames>Jwala</forenames></author><author><keyname>Gyawali</keyname><forenames>Prashnna Kumar</forenames></author><author><keyname>Sapp</keyname><forenames>John L</forenames></author><author><keyname>Horacek</keyname><forenames>B. Milan</forenames></author><author><keyname>Wang</keyname><forenames>Linwei</forenames></author></authors><title>Generative Modeling and Inverse Imaging of Cardiac Transmembrane
  Potential</title><categories>eess.IV cs.LG eess.SP stat.ML</categories><journal-ref>In International Conference on Medical Image Computing and
  Computer-Assisted Intervention, pp. 508-516. Springer, Cham, 2018</journal-ref><doi>10.1007/978-3-030-00934-2_57</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noninvasive reconstruction of cardiac transmembrane potential (TMP) from
surface electrocardiograms (ECG) involves an ill-posed inverse problem.
Model-constrained regularization is powerful for incorporating rich
physiological knowledge about spatiotemporal TMP dynamics. These models are
controlled by high-dimensional physical parameters which, if fixed, can
introduce model errors and reduce the accuracy of TMP reconstruction.
Simultaneous adaptation of these parameters during TMP reconstruction, however,
is difficult due to their high dimensionality. We introduce a novel
model-constrained inference framework that replaces conventional physiological
models with a deep generative model trained to generate TMP sequences from
low-dimensional generative factors. Using a variational auto-encoder (VAE) with
long short-term memory (LSTM) networks, we train the VAE decoder to learn the
conditional likelihood of TMP, while the encoder learns the prior distribution
of generative factors. These two components allow us to develop an efficient
algorithm to simultaneously infer the generative factors and TMP signals from
ECG data. Synthetic and real-data experiments demonstrate that the presented
method significantly improve the accuracy of TMP reconstruction compared with
methods constrained by conventional physiological models or without
physiological constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04813</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04813</id><created>2019-05-12</created><authors><author><keyname>Ghimire</keyname><forenames>Sandesh</forenames></author><author><keyname>Sapp</keyname><forenames>John L</forenames></author><author><keyname>Horacek</keyname><forenames>Milan</forenames></author><author><keyname>Wang</keyname><forenames>Linwei</forenames></author></authors><title>A Variational Approach to Sparse Model Error Estimation in Cardiac
  Electrophysiological Imaging</title><categories>eess.IV</categories><journal-ref>In International Conference on Medical Image Computing and
  Computer-Assisted Intervention, pp. 745-753. Springer, Cham, 2017</journal-ref><doi>10.1007/978-3-319-66185-8_84</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noninvasive reconstruction of cardiac electrical activity from surface
electrocardiograms (ECG) involves solving an ill-posed inverse problem. Cardiac
electrophysiological (EP) models have been used as important a priori knowledge
to constrain this inverse problem. However, the reconstruction suffer from
inaccuracy and uncertainty of the prior model itself which could be mitigated
by estimating a priori model error. Unfortunately, due to the need to handle an
additional large number of unknowns in a problem that already suffers from
ill-posedness, model error estimation remains an unresolved challenge. In this
paper, we address this issue by modeling and estimating the a priori model
error in a low dimensional space using a novel sparse prior based on the
variational approximation of L0 norm. This prior is used in a posterior
regularized Bayesian formulation to quantify the error in a priori EP model
during the reconstruction of transmural action potential from ECG data. Through
synthetic and real-data experiments, we demonstrate the ability of the
presented method to timely capture a priori model error and thus to improve
reconstruction accuracy compared to approaches without model error correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04815</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04815</id><created>2019-05-12</created><authors><author><keyname>Saragadam</keyname><forenames>Vishwanath</forenames></author><author><keyname>Sankaranarayanan</keyname><forenames>Aswin C.</forenames></author></authors><title>Programmable Spectrometry -- Per-pixel Classification of Materials using
  Learned Spectral Filters</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many materials have distinct spectral profiles. This facilitates estimation
of the material composition of a scene at each pixel by first acquiring its
hyperspectral image, and subsequently filtering it using a bank of spectral
profiles. This process is inherently wasteful since only a set of linear
projections of the acquired measurements contribute to the classification task.
We propose a novel programmable camera that is capable of producing images of a
scene with an arbitrary spectral filter. We use this camera to optically
implement the spectral filtering of the scene's hyperspectral image with the
bank of spectral profiles needed to perform per-pixel material classification.
This provides gains both in terms of acquisition speed --- since only the
relevant measurements are acquired --- and in signal-to-noise ratio --- since
we invariably avoid narrowband filters that are light inefficient. Given
training data, we use a range of classical and modern techniques including SVMs
and neural networks to identify the bank of spectral profiles that facilitate
material classification. We verify the method in simulations on standard
datasets as well as real data using a lab prototype of the camera.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04837</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04837</id><created>2019-05-12</created><authors><author><keyname>Xu</keyname><forenames>Ling</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Xia</keyname><forenames>Guiyang</forenames></author><author><keyname>Zhang</keyname><forenames>Yijin</forenames></author><author><keyname>Zhuang</keyname><forenames>Zhihong</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author></authors><title>Secure Hybrid Digital and Analog Precoder for mmWave Systems with
  low-resolution DACs and finite-quantized phase shifters</title><categories>cs.IT eess.SP math.IT</categories><comments>11 pages,7figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Millimeter wave (mmWave) communication has been regarded as one of the most
promising technologies for the future generation wireless networks because of
its advantages of providing a ultra-wide new spectrum and ultra-high data
transmission rate. To reduce the power consumption and circuit cost for mmWave
systems, hybrid digital and analog (HDA) architecture is preferred in such a
scenario. In this paper, an artificial-noise (AN) aided secure HDA beamforming
scheme is proposed for mmWave MISO system with low resolution digital-to-analog
converters (DACs) and finite-quantized phase shifters on RF. The additive
quantization noise model for AN aided HDA system is established to make an
analysis of the secrecy performance of such systems. With the partial channel
knowledge of eavesdropper available, an approximate expression of secrecy rate
(SR) is derived. Then using this approximation formula, we propose a two-layer
alternately iterative structure (TLAIS) for optimizing digital precoder (DP) of
confidential message (CM), digital AN projection matrix (DANPM) and analog
precoder (AP). The inner-layer iteration loop is to design the DP of CMs and
DANPM alternatively given a fixed matrix of AP. The outer-layer iteration loop
is in between digital baseband part and analog part, where the former refers to
DP and DANPM, and the latter is AP. Then for a given digital part, we propose a
gradient ascent algorithm to find the vector of AP vector. Given a matrix of
AP, we make use of general power iteration (GPI) method to compute DP and
DANPM. This process is repeated until the terminal condition is reached.
Simulation results show that the proposed TLAIS can achieve a better SR
performance compared to existing methods, especially in the high
signal-to-noise ratio region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04872</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04872</id><created>2019-05-13</created><authors><author><keyname>Li</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>Ryan Wen</forenames></author><author><keyname>Liu</keyname><forenames>Zhao</forenames></author><author><keyname>Liu</keyname><forenames>Jingxian</forenames></author></authors><title>Similarity Grouping-Guided Neural Network Modeling for Maritime Time
  Series Prediction</title><categories>cs.CE cs.LG eess.SP</categories><comments>12 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Reliable and accurate prediction of time series plays a crucial role in
maritime industry, such as economic investment, transportation planning, port
planning and design, etc. The dynamic growth of maritime time series has the
predominantly complex, nonlinear and non-stationary properties. To guarantee
high-quality prediction performance, we propose to first adopt the empirical
mode decomposition (EMD) and ensemble EMD (EEMD) methods to decompose the
original time series into high- and low-frequency components. The low-frequency
components can be easily predicted directly through traditional neural network
(NN) methods. It is more difficult to predict high-frequency components due to
their properties of weak mathematical regularity. To take advantage of the
inherent self-similarities within high-frequency components, these components
will be divided into several continuous small (overlapping) segments. The
grouped segments with high similarities are then selected to form more proper
training datasets for traditional NN methods. This regrouping strategy can
assist in enhancing the prediction accuracy of high-frequency components. The
final prediction result is obtained by integrating the predicted high- and
low-frequency components. Our proposed three-step prediction frameworks benefit
from the time series decomposition and similar segments grouping. Experiments
on both port cargo throughput and vessel traffic flow have illustrated its
superior performance in terms of prediction accuracy and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04874</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04874</id><created>2019-05-13</created><authors><author><keyname>Fu</keyname><forenames>Szu-Wei</forenames></author><author><keyname>Liao</keyname><forenames>Chien-Feng</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author><author><keyname>Lin</keyname><forenames>Shou-De</forenames></author></authors><title>MetricGAN: Generative Adversarial Networks based Black-box Metric Scores
  Optimization for Speech Enhancement</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted by Thirty-sixth International Conference on Machine Learning
  (ICML) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial loss in a conditional generative adversarial network (GAN) is not
designed to directly optimize evaluation metrics of a target task, and thus,
may not always guide the generator in a GAN to generate data with improved
metric scores. To overcome this issue, we propose a novel MetricGAN approach
with an aim to optimize the generator with respect to one or multiple
evaluation metrics. Moreover, based on MetricGAN, the metric scores of the
generated data can also be arbitrarily specified by users. We tested the
proposed MetricGAN on a speech enhancement task, which is particularly suitable
to verify the proposed approach because there are multiple metrics measuring
different aspects of speech signals. Moreover, these metrics are generally
complex and could not be fully optimized by Lp or conventional adversarial
losses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04876</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04876</id><created>2019-05-13</created><authors><author><keyname>Ali</keyname><forenames>Ahmed K.</forenames></author><author><keyname>Er&#xe7;elebi</keyname><forenames>Ergun</forenames></author></authors><title>An M-QAM Signal Modulation Recognition Algorithm in AWGN Channel</title><categories>eess.SP</categories><comments>18 pages</comments><doi>10.1155/2019/6752694</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the distinct features from input data, before the classification,
is a part of complexity to the methods of Automatic Modulation Classification
(AMC) which deals with modulation classification was a pattern recognition
problem. Although the algorithms that focus on MultiLevel Quadrature Amplitude
Modulation (M-QAM) which underneath different channel scenarios was well
detailed. A search of the literature revealed indicates that few studies were
done on the classification of high order M-QAM modulation schemes like128-QAM,
256-QAM, 512-QAM and1024-QAM. This work is focusing on the investigation of the
powerful capability of the natural logarithmic properties and the possibility
of extracting Higher-Order Cumulant's (HOC) features from input data received
raw. The HOC signals were extracted under Additive White Gaussian Noise (AWGN)
channel with four effective parameters which were defined to distinguished the
types of modulation from the set; 4-QAM~1024-QAM. This approach makes the
recognizer more intelligent and improves the success rate of classification.
From simulation results, which was achieved under statistical models for noisy
channels, manifest that recognized algorithm executes was recognizing in M-QAM,
furthermore, most results were promising and showed that the logarithmic
classifier works well over both AWGN and different fading channels, as well as
it can achieve a reliable recognition rate even at a lower signal-to-noise
ratio (less than zero), it can be considered as an Integrated Automatic
Modulation Classification (AMC) system in order to identify high order of M-QAM
signals that applied a unique logarithmic classifier, to represents higher
versatility, hence it has a superior performance via all previous works in
automatic modulation identification system
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04893</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04893</id><created>2019-05-13</created><updated>2019-05-14</updated><authors><author><keyname>Yamazaki</keyname><forenames>Etsushi</forenames></author><author><keyname>Farsad</keyname><forenames>Nariman</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Low Noise Non-Linear Equalization Using Neural Networks and Belief
  Propagation</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinearities can be introduced into communication systems by the physical
components such as the power amplifier, or during signal propagation through a
nonlinear channel. These nonlinearities can be compensated by a nonlinear
equalizer at the receiver side. The nonlinear equalizer also operates on the
additive noise, which can lead to noise enhancement. In this work we evaluate
this trade-off between distortion reduction and noise-enhancement via nonlinear
equalization techniques. We first, evaluate the trade-off between nonlinearity
compensation and noise enhancement for the Volterra equalizer, and propose a
method to determine the training SNR that optimizes this performance trade-off.
We then propose a new approach for nonlinear equalization that alternates
between neural networks (NNs) for nonlinearity compensation, and belief
propagation (BP) for noise removal. This new approach achieves a 0.6 dB gain
compared to the Volterra equalizer with the optimal training SNR, and a 1.7 dB
gain compared to a system with no nonlinearity compensation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04921</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04921</id><created>2019-05-13</created><authors><author><keyname>Zhao</keyname><forenames>Tianxiao</forenames></author><author><keyname>Luo</keyname><forenames>Chunbo</forenames></author><author><keyname>Min</keyname><forenames>Geyong</forenames></author><author><keyname>Zhou</keyname><forenames>Jianming</forenames></author><author><keyname>Guo</keyname><forenames>Dechun</forenames></author><author><keyname>Miao</keyname><forenames>Wang</forenames></author><author><keyname>Mi</keyname><forenames>Yang</forenames></author></authors><title>A DoA Estimation Based Robust Beam Forming Method for UAV-BS
  Communication</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High data rate communication with Unmanned Aerial Vehicles (UAV) is of
growing demand among industrial and commercial applications since the last
decade. In this paper, we investigate enhancing beam forming performance based
on signal Direction of Arrival (DoA) estimation to support UAV-cellular network
communication. We first study UAV fast moving scenario where we found that
drone's mobility cause degradation of beam forming algorithm performance. Then,
we propose a DoA estimation algorithm and a steering vector adaptive receiving
beam forming method. The DoA estimation algorithm is of high precision with low
computational complexity. Also it enables a beam former to timely adjust
steering vector value in calculating beam forming weight. Simulation results
show higher SINR performance and more stability of proposed method than
traditional method based on Multiple Signal Classification (MUSIC) DoA
estimation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04931</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04931</id><created>2019-05-13</created><authors><author><keyname>Flordelis</keyname><forenames>Jose</forenames></author><author><keyname>Li</keyname><forenames>Xuhong</forenames></author><author><keyname>Edfors</keyname><forenames>Ove</forenames></author><author><keyname>Tufvesson</keyname><forenames>Fredrik</forenames></author></authors><title>Massive MIMO Extensions to the COST 2100 Channel Model: Modeling and
  Validation</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Transactions of Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To enable realistic studies of massive multiple-input multiple-output
systems, the COST 2100 channel model is extended based on measurements. First,
the concept of a base station-side visibility region (BS-VR) is proposed to
model the appearance and disappearance of clusters when using a
physically-large array. We find that BS-VR lifetimes are exponentially
distributed, and that the number of BS-VRs is Poisson distributed with
intensity proportional to the sum of the array length and the mean lifetime.
Simulations suggest that under certain conditions longer lifetimes can help
decorrelating closely-located users. Second, the concept of a multipath
component visibility region (MPC-VR) is proposed to model birth-death processes
of individual MPCs at the mobile station side. We find that both MPC lifetimes
and MPC-VR radii are lognormally distributed. Simulations suggest that unless
MPC-VRs are applied the channel condition number is overestimated. Key
statistical properties of the proposed extensions, e.g., autocorrelation
functions, maximum likelihood estimators, and Cramer-Rao bounds, are derived
and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04954</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04954</id><created>2019-05-13</created><authors><author><keyname>Fontanesi</keyname><forenames>Gianluca</forenames></author><author><keyname>Ahmadi</keyname><forenames>Hamed</forenames></author><author><keyname>Zhu</keyname><forenames>Anding</forenames></author></authors><title>Over the Sea UAV Based Communication</title><categories>eess.SP</categories><comments>5 pages, 2 tables, 3 pictures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned Aerial Vehicle (UAV) aided wireless networks have been recently
envisioned as a solution to provide a reliable, low latency cellular link for
search and rescue operations over the sea. We propose three different network
architectures, based on the technology deployed on the UAV: a flying relay, a
flying Base Station (BS) and a flying Remote Radio Head (RRH). We describe the
challenges and highlight the benefits of the proposed architectures from the
perspective of search and rescue operations over the sea. We compare the
performance in term of data rate and latency, analyzing different solutions to
provide a Backhaul (BH)/Fronthaul (FH) link for long coverage over the sea.
Results show that a system architecture is not outperforming over the others. A
cost function is thus indicated as a tool to find a suboptimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04963</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04963</id><created>2019-05-13</created><authors><author><keyname>Lundberg</keyname><forenames>Lars</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Mazur</keyname><forenames>Mikael</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Mirani</keyname><forenames>Ali</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Foo</keyname><forenames>Benjamin</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Schr&#xf6;der</keyname><forenames>Jochen</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Torres-Company</keyname><forenames>Victor</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Karlsson</keyname><forenames>Magnus</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Andrekson</keyname><forenames>Peter A.</forenames><affiliation>Photonics Laboratory, Department of Microtechnology and Nanoscience, Chalmers University of Technology, Gothenburg, Sweden</affiliation></author></authors><title>Phase-coherent lightwave communications with frequency combs</title><categories>eess.SP physics.optics</categories><comments>17 pages, 9 figures</comments><doi>10.1038/s41467-019-14010-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fiber-optical networks are a crucial telecommunication infrastructure in
society. Wavelength division multiplexing allows for transmitting parallel data
streams over the fiber bandwidth, and coherent detection enables the use of
sophisticated modulation formats and electronic compensation of signal
impairments. In the future, optical frequency combs may replace multiple lasers
used for the different wavelength channels. We demonstrate two novel signal
processing schemes that take advantage of the broadband phase coherence of
optical frequency combs. This approach allows for a more efficient estimation
and compensation of optical phase noise in coherent communication systems,
which can significantly simplify the signal processing or increase the
transmission performance. With further advances in space division multiplexing
and chip-scale frequency comb sources, these findings pave the way for compact
energy-efficient optical transceivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04983</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04983</id><created>2019-05-03</created><authors><author><keyname>Zhao</keyname><forenames>Yajun</forenames></author><author><keyname>Yu</keyname><forenames>Guanghui</forenames></author><author><keyname>Xu</keyname><forenames>Hanqing</forenames></author></authors><title>6G Mobile Communication Network: Vision, Challenges and Key Technologies</title><categories>eess.SP</categories><comments>28 pages, 6 figures, SCIENTIA SINICA Informationis</comments><journal-ref>SCIENTIA SINICA Informationis, Volume 49, Issue 8: 963-987(2019)</journal-ref><doi>10.1360/N112019-00033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the open of the scale-up commercial deployment of 5G network, more and
more researchers and related organizations began to consider the next
generation of mobile communication system. This article will explore the 6G
concept for 2030s. Firstly, this article summarizes the future 6G vision with
four keywords: &quot;Intelligent Connectivity&quot;, &quot;Deep Connectivity&quot;, &quot;Holographic
Connectivity&quot; and &quot;Ubiquitous Connectivity&quot;, and these four keywords together
constitute the 6G overall vision of &quot;Wherever you think, everything follows
your heart &quot;. Then, the technical requirements and challenges to realize the 6G
vision are analyzed, including peak throughput, higher energy efficiency,
connection every where and anytime, new theories and technologies,
self-aggregating communications fabric, and some non-technical challenges. Then
the potential key technologies of 6G are classified and presented:
communication technologies on new spectrum, including terahertz communication
and visible light communication; fundamental technologies, including sparse
theory (compressed sensing), new channel coding technology, large-scale antenna
and flexible spectrum usage; special technical features, including
Space-Air-Ground-Sea integrated communication and wireless tactile network. By
exploring the 6G vision, requirements and challenges, as well as potential key
technologies, this article attempts to outline the overall framework of 6G, and
to provide directional guidance for the subsequent 6G research.
  Keywords 6G, vision, terahertz, VLC, compressed sensing, free duplex,
wireless tactile network
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04996</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04996</id><created>2019-05-08</created><authors><author><keyname>Pilz</keyname><forenames>Matthias</forenames></author><author><keyname>Al-Fagih</keyname><forenames>Luluwah</forenames></author></authors><title>Selfish Energy Sharing in Prosumer Communities: A Demand-Side Management
  Concept</title><categories>eess.SP cs.SY physics.soc-ph</categories><comments>6 pages, 5 figures, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Global warming is endangering the earth's ecosystem. It is imperative for us
to limit green house gas emissions in order to combat rising global average
temperatures. One way to move forward is the integration of renewable energy
resources on all levels of the power system, i.e. from large-scale energy
producers to individual households. The future smart grid provides the
technology for this. In this paper, a novel demand-side management concept is
proposed. It is implemented by a utility company which focuses on renewable
energy. Through a specific billing mechanism, prosumers are encouraged to
balance load and supply. A game-theoretic approach models households as
self-determined rational energy users that want to reduce their individual
electricity costs. To achieve this, they selfishly share energy with their
neighbours and also schedule their energy storage systems. The scheme is
designed such that monetary transactions between households are not necessary.
Thus, it provides an alternative approach to energy trading schemes from the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04999</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.04999</id><created>2019-05-07</created><authors><author><keyname>Bonnin</keyname><forenames>Michele</forenames></author><author><keyname>Corinto</keyname><forenames>Fernando</forenames></author><author><keyname>Gilli</keyname><forenames>Marco</forenames></author></authors><title>Phase space decomposition for phase noise and synchronization analysis
  of planar nonlinear oscillators</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Circuits and Systems II: Express Briefs
  (Volume: 59, Issue: 10, Oct. 2012 )</journal-ref><doi>10.1109/TCSII.2012.2213363</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synchronization phenomena, frequency shift and phase noise are often limiting
key factors in the performances of oscillators. The perturbation projection
method allows to characterize how the oscillator's output is modified by these
disturbances. In this brief we discuss the appropriate decomposition of
perturbations for synchronization and phase noise analysis of planar nonlinear
oscillators. We derive analytical formulas for the vectors spanning the
directions along which the perturbations have to be projected. We also discuss
the implications of this decomposition in control theory and to what extent a
simple orthogonal projection is correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05002</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05002</id><created>2019-05-06</created><authors><author><keyname>Nguyen</keyname><forenames>Duc-Phuc</forenames></author><author><keyname>Le</keyname><forenames>Dinh-Dung</forenames></author><author><keyname>Tran</keyname><forenames>Thi-Hong</forenames></author><author><keyname>Nakada</keyname><forenames>Takashi</forenames></author><author><keyname>Nakashima</keyname><forenames>Yasuhiko</forenames></author></authors><title>A Compact Low-Latency Systematic Successive Cancellation Polar Decoder
  for Visible Light Communication Systems</title><categories>eess.SP</categories><comments>IEICE Technical Report, Vol.117, Issue 44, pp.3-7</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel polarization and Polar code are widely considered as major
breakthroughs in coding theory because they have shown promising features for
future wireless standards. The main drawbacks of Polar code are high-latency in
decoding hardware, and unimpressive error-correction performance in case
limited code-length is implemented. These two disadvantages limit
implementation of Polar code in low-throughput wireless communication systems.
In this paper, we propose a low-complexity low-latency hardware architecture
for the soft-decision compact (16,11) Systematic Successive Cancellation Polar
Decoder (S-SCD). Experimental results has shown that the latency of the
proposed S-SCD improves 3.75 times and 2.75 times compared with conventional
and 2b-SC architectures. Besides, it has also shown a better BER/FER
performance compared with RS(15,11) code, which is applied widely in current
VLC-based systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05008</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05008</id><created>2019-05-10</created><authors><author><keyname>Ayyer</keyname><forenames>Kartik</forenames></author><author><keyname>Morgan</keyname><forenames>Andrew J.</forenames></author><author><keyname>Aquila</keyname><forenames>Andrew A.</forenames></author><author><keyname>DeMirci</keyname><forenames>Hasan</forenames></author><author><keyname>Hogue</keyname><forenames>Brenda G.</forenames></author><author><keyname>Kirian</keyname><forenames>Richard A.</forenames></author><author><keyname>Xavier</keyname><forenames>P. Lourdu</forenames></author><author><keyname>Yoon</keyname><forenames>Chun Hong</forenames></author><author><keyname>Chapman</keyname><forenames>Henry N.</forenames></author><author><keyname>Barty</keyname><forenames>Anton</forenames></author></authors><title>The low-signal limit of X-ray single particle imaging</title><categories>eess.IV physics.optics</categories><comments>11 pages, 7 figures</comments><doi>10.1364/OE.27.037816</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An outstanding question in X-ray single particle imaging experiments has been
the feasibility of imaging sub 10-nm-sized biomolecules under realistic
experimental conditions where very few photons are expected to be measured in a
single snapshot and instrument background may be significant relative to
particle scattering. While analyses of simulated data have shown that the
determination of an average image should be feasible using Bayesian algorithms
such as the EMC algorithm for near-perfect diffraction patterns, this has yet
to be demonstrated using experimental data containing realistic non-isotropic
instrument background, sample variability and other experimental factors. In
this work, we show that the orientation and phase retrieval steps work at
photon counts diluted to the signal levels one expects from smaller molecules
or with weaker pulses using data from experimental measurements of 60-nm PR772
viruses. Even when the signal is reduced to a fraction as little as 1/256, the
virus electron density determined using ab initio phasing is of almost the same
quality as the high-signal data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05011</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05011</id><created>2019-05-09</created><authors><author><keyname>Manasi</keyname><forenames>Susmita Dey</forenames></author><author><keyname>Snigdha</keyname><forenames>Farhana Sharmin</forenames></author><author><keyname>Sapatnekar</keyname><forenames>Sachin S.</forenames></author></authors><title>NeuPart: Using Analytical Models to Drive Energy-Efficient Partitioning
  of CNN Computations on Cloud-Connected Mobile Clients</title><categories>cs.DC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data processing on convolutional neural networks (CNNs) places a heavy burden
on energy-constrained mobile platforms. This work optimizes energy on a mobile
client by partitioning CNN computations between in situ processing on the
client and offloaded computations in the cloud. A new analytical CNN energy
model is formulated, capturing all major components of the in situ computation,
for ASIC-based deep learning accelerators. The model is benchmarked against
measured silicon data. The analytical framework is used to determine the energy
optimal partition point between the client and the cloud at runtime. On
standard CNN topologies, partitioned computation is demonstrated to provide
significant energy savings on the client over fully cloud-based or fully in
situ computation. For example, at 60 Mbps bit rate and 0.5 W transmission
power, the optimal partition for AlexNet [SqueezeNet] saves up to 47.4% [70.0%]
energy over fully cloud-based computation, and 31.3% [31.3%] energy over fully
in situ computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05019</identifier>
 <datestamp>2019-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05019</id><created>2019-05-13</created><updated>2019-12-19</updated><authors><author><keyname>Caputo</keyname><forenames>S.</forenames></author><author><keyname>Mucchi</keyname><forenames>L.</forenames></author><author><keyname>Cataliotti</keyname><forenames>F. S.</forenames></author><author><keyname>Catani</keyname><forenames>J.</forenames></author></authors><title>Measurement-based VLC channel characterization for I2V communications in
  a real urban scenario</title><categories>eess.SP</categories><report-no>2019arXiv190505019C</report-no><journal-ref>2019arXiv190505019C</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC) is nowadays envisaged as a promising
technology to enable new classes of services in intelligent transportation
systems ranging e.g. from assisted driving to autonomous vehicles. The
assessment of the performance of VLC for automotive applications requires as a
basic step a model of the propagation of the VLC signal in a real scenario. In
this paper a measurement campaign has been carried out by using a real
traffic-light as source and a photoreceiver positioned at different distances,
heights and azimuth angles along the road. The acquired data allowed us to come
up with different propagation models. The models have been compared in terms of
complexity and accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05025</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05025</id><created>2019-05-13</created><updated>2019-10-16</updated><authors><author><keyname>Quinn</keyname><forenames>Se&#xe1;n</forenames></author><author><keyname>Murphy</keyname><forenames>Noel</forenames></author><author><keyname>Smeaton</keyname><forenames>Alan F.</forenames></author></authors><title>Tracking Human Behavioural Consistency by Analysing Periodicity of
  Household Water Consumption</title><categories>eess.SP cs.CY</categories><comments>2019 2nd International Conference on Sensors, Signal and Image
  Processing</comments><doi>10.1145/3365245.3365246</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People are living longer than ever due to advances in healthcare, and this
has prompted many healthcare providers to look towards remote patient care as a
means to meet the needs of the future. It is now a priority to enable people to
reside in their own homes rather than in overburdened facilities whenever
possible. The increasing maturity of IoT technologies and the falling costs of
connected sensors has made the deployment of remote healthcare at scale an
increasingly attractive prospect. In this work we demonstrate that we can
measure the consistency and regularity of the behaviour of a household using
sensor readings generated from interaction with the home environment. We show
that we can track changes in this behaviour regularity longitudinally and
detect changes that may be related to significant life events or trends that
may be medically significant. We achieve this using periodicity analysis on
water usage readings sampled from the main household water meter every 15
minutes for over 8 months. We utilise an IoT Application Enablement Platform in
conjunction with low cost LoRa-enabled sensors and a Low Power Wide Area
Network in order to validate a data collection methodology that could be
deployed at large scale in future. We envision the statistical methods
described here being applied to data streams from the homes of elderly and
at-risk groups, both as a means of early illness detection and for monitoring
the well-being of those with known illnesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05064</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05064</id><created>2019-05-13</created><updated>2019-05-14</updated><authors><author><keyname>Furqan</keyname><forenames>Haji M.</forenames></author><author><keyname>Hamamreh</keyname><forenames>Jehad. M.</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author></authors><title>Physical Layer Security for NOMA: Requirements, Merits, Challenges, and
  Recommendations</title><categories>eess.SP</categories><comments>Submitted to : IEEE communication magazine</comments><report-no>COMMAG-19-00287</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-Orthogonal Multiple Access (NOMA) has been recognized as one of the most
significant enabling technologies for future wireless systems due to its
eminent spectral efficiency, ability to provide an additional degree of freedom
for Ultra Reliable Low Latency Communications (URLLC) and grant free random
access. Meanwhile, Physical Layer Security (PLS) has got much attention for
future wireless communication systems due to its capability to provide security
without relying on traditional cryptography based algorithms. In this article,
security design requirements for NOMA and solutions provided by PLS to fulfill
these requirements are discussed. The merits and challenges arising from
employing PLS to NOMA are identified. Finally, future recommendations and
prospective solutions are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05075</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05075</id><created>2019-05-13</created><authors><author><keyname>Furqan</keyname><forenames>Haji M.</forenames></author><author><keyname>Solaija</keyname><forenames>Muhammad Sohaib J.</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author></authors><title>Intelligent Physical Layer Security Approach for V2X Communication</title><categories>eess.SP</categories><comments>Submitted to IEEE Communication magazine</comments><report-no>COMMAG-19-00169</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent transportation systems (ITS) with advanced sensing and computing
technologies are expected to support a whole new set of services including
pedestrian and vehicular safety, internet access for vehicles, and eventually,
driverless cars. Wireless communication is a major driving factor behind ITS,
enabling reliable communication between vehicles, infrastructure, pedestrians
and network, generally referred to as vehicle to everything (V2X)
communication. However, the broadcast nature of wireless communication renders
it prone to jamming, eavesdropping and spoofing attacks which can adversely
affect ITS. Keeping in view this issue, we suggest the use of an intelligent
security framework for V2X communication security, referred to as intelligent
V2X security (IV2XS), to provide a reliable and robust solution capable of
adapting to different conditions, scenarios and user requirements. We also
identify the conditions that impact the security and describe the open
challenges in achieving a realistic IV2XS system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05092</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05092</id><created>2019-05-13</created><updated>2019-09-10</updated><authors><author><keyname>Ehret</keyname><forenames>Thibaud</forenames></author><author><keyname>Davy</keyname><forenames>Axel</forenames></author><author><keyname>Arias</keyname><forenames>Pablo</forenames></author><author><keyname>Facciolo</keyname><forenames>Gabriele</forenames></author></authors><title>Joint Demosaicking and Denoising by Fine-Tuning of Bursts of Raw Images</title><categories>cs.CV eess.IV</categories><comments>ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demosaicking and denoising are the first steps of any camera image processing
pipeline and are key for obtaining high quality RGB images. A promising current
research trend aims at solving these two problems jointly using convolutional
neural networks. Due to the unavailability of ground truth data these networks
cannot be currently trained using real RAW images. Instead, they resort to
simulated data. In this paper we present a method to learn demosaicking
directly from mosaicked images, without requiring ground truth RGB data. We
apply this to learn joint demosaicking and denoising only from RAW images, thus
enabling the use of real data. In addition we show that for this application
fine-tuning a network to a specific burst improves the quality of restoration
for both demosaicking and denoising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05113</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05113</id><created>2019-05-13</created><updated>2019-09-19</updated><authors><author><keyname>Sun</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Jiaming</forenames></author><author><keyname>Kamilov</keyname><forenames>Ulugbek S.</forenames></author></authors><title>Block Coordinate Regularization by Denoising</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating a vector from its noisy measurements
using a prior specified only through a denoising function. Recent work on
plug-and-play priors (PnP) and regularization-by-denoising (RED) has shown the
state-of-the-art performance of estimators under such priors in a range of
imaging tasks. In this work, we develop a new block coordinate RED algorithm
that decomposes a large-scale estimation problem into a sequence of updates
over a small subset of the unknown variables. We theoretically analyze the
convergence of the algorithm and discuss its relationship to the traditional
proximal optimization. Our analysis complements and extends recent theoretical
results for RED-based estimation methods. We numerically validate our method
using several denoiser priors, including those based on convolutional neural
network (CNN) denoisers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05163</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05163</id><created>2019-05-13</created><updated>2019-06-04</updated><authors><author><keyname>Han</keyname><forenames>Xintian</forenames></author><author><keyname>Hu</keyname><forenames>Yuxuan</forenames></author><author><keyname>Foschini</keyname><forenames>Luca</forenames></author><author><keyname>Chinitz</keyname><forenames>Larry</forenames></author><author><keyname>Jankelson</keyname><forenames>Lior</forenames></author><author><keyname>Ranganath</keyname><forenames>Rajesh</forenames></author></authors><title>Adversarial Examples for Electrocardiograms</title><categories>eess.SP cs.CR cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the electrocardiogram (ECG) has seen a large diffusion in
both medical and commercial applications, fueled by the rise of single-lead
versions. Single-lead ECG can be embedded in medical devices and wearable
products such as the injectable Medtronic Linq monitor, the iRhythm Ziopatch
wearable monitor, and the Apple Watch Series 4. Recently, deep neural networks
have been used to automatically analyze ECG tracings, outperforming even
physicians specialized in cardiac electrophysiology in detecting certain rhythm
irregularities. However, deep learning classifiers have been shown to be
brittle to adversarial examples, which are examples created to look
incontrovertibly belonging to a certain class to a human eye but contain subtle
features that fool the classifier into misclassifying them into the wrong
class. Very recently, adversarial examples have also been created for
medical-related tasks. Yet, traditional attack methods to create adversarial
examples, such as projected gradient descent (PGD) do not extend directly to
ECG signals, as they generate examples that introduce square wave artifacts
that are not physiologically plausible. Here, we developed a method to
construct smoothed adversarial examples for single-lead ECG. First, we
implemented a neural network model achieving state-of-the-art performance on
the data from the 2017 PhysioNet/Computing-in-Cardiology Challenge for
arrhythmia detection from single lead ECG classification. For this model, we
utilized a new technique to generate smoothed examples to produce signals that
are 1) indistinguishable to cardiologists from the original examples and 2)
incorrectly classified by the neural network. Finally, we show that adversarial
examples are not unique and provide a general technique to collate and perturb
known adversarial examples to create new ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05169</identifier>
 <datestamp>2019-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05169</id><created>2019-05-13</created><authors><author><keyname>Zhang</keyname><forenames>Xuaner Cecilia</forenames></author><author><keyname>Chen</keyname><forenames>Qifeng</forenames></author><author><keyname>Ng</keyname><forenames>Ren</forenames></author><author><keyname>Koltun</keyname><forenames>Vladlen</forenames></author></authors><title>Zoom To Learn, Learn To Zoom</title><categories>cs.CV eess.IV</categories><comments>CVPR 2019,
  https://ceciliavision.github.io/project-pages/project-zoom.html (paper,
  video, supp, code, dataset)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows that when applying machine learning to digital zoom for
photography, it is beneficial to use real, RAW sensor data for training.
Existing learning-based super-resolution methods do not use real sensor data,
instead operating on RGB images. In practice, these approaches result in loss
of detail and accuracy in their digitally zoomed output when zooming in on
distant image regions. We also show that synthesizing sensor data by resampling
high-resolution RGB images is an oversimplified approximation of real sensor
data and noise, resulting in worse image quality. The key barrier to using real
sensor data for training is that ground truth high-resolution imagery is
missing. We show how to obtain the ground-truth data with optically zoomed
images and contribute a dataset, SR-RAW, for real-world computational zoom. We
use SR-RAW to train a deep network with a novel contextual bilateral loss
(CoBi) that delivers critical robustness to mild misalignment in input-output
image pairs. The trained network achieves state-of-the-art performance in 4X
and 8X computational zoom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05227</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05227</id><created>2019-05-13</created><authors><author><keyname>Bereyhi</keyname><forenames>Ali</forenames></author><author><keyname>Asaad</keyname><forenames>Saba</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Ralf R.</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author></authors><title>RLS Precoding for Massive MIMO Systems with Nonlinear Front-End</title><categories>eess.SP cs.IT math.IT</categories><comments>To be presented in the 20th IEEE International Workshop on Signal
  Processing Advances in Wireless Communications (SPAWC) 2019 in Cannes,
  France. 6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To keep massive MIMO systems cost-efficient, power amplifiers with rather
small output dynamic ranges are employed. They may distort the transmit signal
and degrade the performance. This paper proposes a distortion aware precoding
scheme for realistic scenarios in which RF chains have nonlinear
characteristics. The proposed scheme utilizes the method of regularized
least-squares (RLS) to jointly compensate the channel impacts and the
distortion imposed by the RF chains.
  To construct the designed transmit waveform with low computational
complexity, an iterative algorithm based on approximate message passing is
developed. This algorithm is shown to track the achievable average signal
distortion of the proposed scheme tightly, even for practical system
dimensions. The results demonstrate considerable enhancement compared to the
state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05228</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05228</id><created>2019-05-13</created><authors><author><keyname>Fang</keyname><forenames>Cheng-Yi</forenames></author><author><keyname>Lin</keyname><forenames>Hung-Hsi</forenames></author><author><keyname>Alouini</keyname><forenames>Mehdi</forenames></author><author><keyname>Fainman</keyname><forenames>Yeshaiahu</forenames></author><author><keyname>Amili</keyname><forenames>Abdelkrim El</forenames></author></authors><title>Reconfigurable On-chip Photoconductive Switches</title><categories>eess.SP physics.app-ph</categories><comments>15 pages,3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microwave photonics uses light to carry and process microwave signals over a
photonic link. However, light can instead be used as a stimulus to microwave
devices that directly control microwave signals. Such optically controlled
amplitude and phase-shift switches are investigated for use in reconfigurable
microwave systems, but they suffer from large footprint, high optical power
level required for switching, lack of scalability and complex integration
requirements, restricting their implementation in practical microwave systems.
Here, we report Monolithic Optically Reconfigurable Integrated Microwave
Switches (MORIMSs) built on a CMOS compatible silicon photonic chip that
addresses all of the stringent requirements. Our scalable micrometer-scale
switches provide higher switching efficiency and require optical power orders
of magnitude lower than the state-of-the-art. Also, it opens a new research
direction on silicon photonic platforms integrating microwave circuitry. This
work has important implications in reconfigurable microwave and millimeter wave
devices for future communication networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05281</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05281</id><created>2019-05-13</created><updated>2019-07-14</updated><authors><author><keyname>Al-Aboosi</keyname><forenames>Yasin Yousif</forenames></author><author><keyname>Abdulnabi</keyname><forenames>Hussein A.</forenames></author></authors><title>Modeling Of A Shallow Water Acoustic Communication Channel</title><categories>eess.SP</categories><comments>Research needs to be redrafted and the section of results not
  complete need more simulation to complete</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In these last years, many studies have focalized on the design of reliable
underwater acoustic communication systems. However, the ocean acoustic
communication channel exhibits strong amplitude and phase fluctuations and the
phenomena of diffraction, refraction and reflection. Due to the complexity of
the environment, the motions of transducers, sea surface, etc., the underwater
acoustic signals exhibit random temporal and spatial frequency fluctuations in
both amplitude and phase. Therefore, it is very important to model a so complex
channel. Acoustic propagation is characterized by three major factors:
attenuation that increases with signal frequency, time-varying multipath
propagation, and low speed of sound (1500 m/s). The background noise, although
often characterized as Gaussian, is not white, but has a decaying power
spectral density. The channel capacity depends on the distance and may be
extremely limited. In this paper, we propose a new multipath channel model for
shallow underwater acoustic communications. In particular, our model takes into
account the effects due to spreading loss, scattering and reflections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05307</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05307</id><created>2019-05-13</created><authors><author><keyname>Roy</keyname><forenames>Harshit</forenames></author><author><keyname>Sharad</keyname><forenames>Mrigank</forenames></author></authors><title>Current Mode Neuron for the Memristor based synapse</title><categories>cs.ET eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to many limitations of Von Neumann architecture such as speed, memory
bandwidth, efficiency of global interconnects and increase in the application
of artificial neural network, researchers have been pushed to look into
alternative architectures such as Neuromorphic computing system. Memristors
(memristive crossbar memory RCM) are used as synapses due to its high packing
density and energy efficiency and CMOS blocks as neurons. The increase in the
terminal resistance of the RCM can degrade its energy efficiency and bandwidth.
A more energy efficient current mode neuron has been proposed in this paper
which can operate at lower voltages as compared to conventional voltage mode
neuron circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05315</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05315</id><created>2019-05-13</created><authors><author><keyname>Gong</keyname><forenames>Tierui</forenames></author><author><keyname>Shlezinger</keyname><forenames>Nir</forenames></author><author><keyname>Ioushua</keyname><forenames>Shahar Stein</forenames></author><author><keyname>Namer</keyname><forenames>Moshe</forenames></author><author><keyname>Yang</keyname><forenames>Zhijia</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>RF Chain Reduction for MIMO Systems: A Hardware Prototype</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RF chain circuits play a major role in digital receiver architectures,
allowing passband communication signals to be processed in baseband. When
operating at high frequencies, these circuits tend to be costly. This increased
cost imposes a major limitation on future multiple-input multiple-output (MIMO)
communication technologies. A common approach to mitigate the increased cost is
to utilize hybrid architectures, in which the received signal is combined in
analog into a lower dimension, thus reducing the number of RF chains. In this
work we present a hardware prototype implementing analog combining for RF chain
reduction. The prototype consists of a specially designed configurable
combining board as well as a dedicated experimental setup. Our hardware
prototype allows to evaluate the effect of analog combining in MIMO systems
using actual communication signals. The experimental study, which focuses on
channel estimation accuracy in MIMO channels, demonstrates that using the
proposed prototype, the achievable channel estimation performance is within a
small gap in a statistical sense from that obtained using a costly receiver in
which each antenna is connected to a dedicated RF chain. Furthermore, in the
considered scenarios, this gap becomes negligible when the reduction rate,
i.e., the ratio of the number of RF chains to the number of antennas, is above
$62.5\%$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05316</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05316</id><created>2019-05-13</created><authors><author><keyname>Elbamby</keyname><forenames>Mohammed S.</forenames></author><author><keyname>Perfecto</keyname><forenames>Cristina</forenames></author><author><keyname>Liu</keyname><forenames>Chen-Feng</forenames></author><author><keyname>Park</keyname><forenames>Jihong</forenames></author><author><keyname>Samarakoon</keyname><forenames>Sumudu</forenames></author><author><keyname>Chen</keyname><forenames>Xianfu</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author></authors><title>Wireless Edge Computing with Latency and Reliability Guarantees</title><categories>cs.NI eess.SP</categories><comments>20 pages, 13 figures. Accepted for publication in Proceedings of the
  IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Edge computing is an emerging concept based on distributing computing,
storage, and control services closer to end network nodes. Edge computing lies
at the heart of the fifth generation (5G) wireless systems and beyond. While
current state-of-the-art networks communicate, compute, and process data in a
centralized manner (at the cloud), for latency and compute-centric
applications, both radio access and computational resources must be brought
closer to the edge, harnessing the availability of computing and
storage-enabled small cell base stations in proximity to the end devices.
Furthermore, the network infrastructure must enable a distributed edge
decision-making service that learns to adapt to the network dynamics with
minimal latency and optimize network deployment and operation accordingly. This
article will provide a fresh look to the concept of edge computing by first
discussing the applications that the network edge must provide, with a special
emphasis on the ensuing challenges in enabling ultra-reliable and low-latency
edge computing services for mission-critical applications such as virtual
reality (VR), vehicle-to-everything (V2X), edge artificial intelligence (AI),
and so forth. Furthermore, several case studies where the edge is key are
explored followed by insights and prospect for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05319</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05319</id><created>2019-05-13</created><authors><author><keyname>Shao</keyname><forenames>Z.</forenames></author><author><keyname>Landau</keyname><forenames>L.</forenames></author><author><keyname>de Lamare</keyname><forenames>R.</forenames></author></authors><title>Study of Channel Estimation with Oversampling for 1-bit Large-Scale MIMO
  Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>7 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an oversampling based low-resolution aware least
squares channel estimator for large-scale multiple-antenna systems with 1-bit
analog-to-digital converters on each receive antenna. To mitigate the
information loss caused by the coarse quantization, oversampling is applied at
the receiver, where the sampling rate is faster than the Nyquist rate. We also
characterize analytical performances, in terms of the deterministic
Cram\'er-Rao bounds, on estimating the channel parameters. Based on the
correlation of the filtered noise, both the Fisher information for white noise
and a lower bound of Fisher information for colored noise are provided.
Numerical results are provided to illustrate the mean square error performances
of the proposed channel estimator and the corresponding Cram\'er-Rao bound as a
function of the signal-to-noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05373</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05373</id><created>2019-05-13</created><authors><author><keyname>Ward</keyname><forenames>Chris M.</forenames></author><author><keyname>Harguess</keyname><forenames>Josh</forenames></author><author><keyname>Crabb</keyname><forenames>Brendan</forenames></author><author><keyname>Parameswaran</keyname><forenames>Shibin</forenames></author></authors><title>Image quality assessment for determining efficacy and limitations of
  Super-Resolution Convolutional Neural Network (SRCNN)</title><categories>cs.CV eess.IV</categories><journal-ref>Proceedings Volume 10396, Applications of Digital Image Processing
  XL; 1039605 (2017)</journal-ref><doi>10.1117/12.2275157</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Traditional metrics for evaluating the efficacy of image processing
techniques do not lend themselves to understanding the capabilities and
limitations of modern image processing methods - particularly those enabled by
deep learning. When applying image processing in engineering solutions, a
scientist or engineer has a need to justify their design decisions with clear
metrics. By applying blind/referenceless image spatial quality (BRISQUE),
Structural SIMilarity (SSIM) index scores, and Peak signal-to-noise ratio
(PSNR) to images before and after image processing, we can quantify quality
improvements in a meaningful way and determine the lowest recoverable image
quality for a given method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05401</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05401</id><created>2019-05-14</created><updated>2019-06-27</updated><authors><author><keyname>Chataignon</keyname><forenames>Joseph</forenames></author><author><keyname>Rini</keyname><forenames>Stefano</forenames></author></authors><title>Comparison-limited Vector Quantization</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variation of the classic vector quantization problem is considered, in
which the analog-to-digital (A2D) conversion is not constrained by the
cardinality of the output but rather by the number of comparators available for
quantization. More specifically, we consider the scenario in which a vector
quantizer of dimension d is comprised of k comparators, each receiving a linear
combination of the inputs and producing zero/one when this signal is
above/below a threshold. Given a distribution of the inputs and a distortion
criterion, the value of the linear combinations and thresholds are to be
configured so as to minimize the distortion between the quantizer input and its
reconstruction. This vector quantizer architecture naturally arises in many A2D
conversion scenarios in which the quantizer's cost and energy consumption are
severely restricted. For this novel vector quantizer architecture, we propose
an algorithm to determine the optimal configuration and provide the first
performance evaluation for the case of uniform and Gaussian sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05406</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05406</id><created>2019-05-14</created><authors><author><keyname>Ryu</keyname><forenames>Ernest K.</forenames></author><author><keyname>Liu</keyname><forenames>Jialin</forenames></author><author><keyname>Wang</keyname><forenames>Sicheng</forenames></author><author><keyname>Chen</keyname><forenames>Xiaohan</forenames></author><author><keyname>Wang</keyname><forenames>Zhangyang</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>Plug-and-Play Methods Provably Converge with Properly Trained Denoisers</title><categories>cs.CV eess.IV</categories><comments>Published in the International Conference on Machine Learning, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plug-and-play (PnP) is a non-convex framework that integrates modern
denoising priors, such as BM3D or deep learning-based denoisers, into ADMM or
other proximal algorithms. An advantage of PnP is that one can use pre-trained
denoisers when there is not sufficient data for end-to-end training. Although
PnP has been recently studied extensively with great empirical success,
theoretical analysis addressing even the most basic question of convergence has
been insufficient. In this paper, we theoretically establish convergence of
PnP-FBS and PnP-ADMM, without using diminishing stepsizes, under a certain
Lipschitz condition on the denoisers. We then propose real spectral
normalization, a technique for training deep learning-based denoisers to
satisfy the proposed Lipschitz condition. Finally, we present experimental
results validating the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05449</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05449</id><created>2019-05-14</created><updated>2019-08-19</updated><authors><author><keyname>Wang</keyname><forenames>Xuanxuan</forenames></author><author><keyname>Feng</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Yunfei</forenames></author><author><keyname>Ge</keyname><forenames>Ning</forenames></author></authors><title>UAV Swarm-Enabled Aerial CoMP: A Physical Layer Security Perspective</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike aerial base station enabled by a single unmanned aerial vehicle (UAV),
aerial coordinated multiple points (CoMP) can be enabled by a UAV swarm. In
this case, the management of multiple UAVs is important. This paper considers
the power allocation strategy for a UAV swarm-enabled aerial network to enhance
the physical layer security of the downlink transmission, where an eavesdropper
moves following the trajectory of the swarm for better eavesdropping. Unlike
existing works, we use only the large-scale channel state information (CSI) and
maximize the secrecy throughput in a whole-trajectory-oriented manner. The
overall transmission energy constraint on each UAV and the total transmission
duration for all the legitimate users are considered. The non-convexity of the
formulated problem is solved by using max-min optimization with iteration. Both
the transmission power of desired signals and artificial noise (AN) are derived
iteratively. Simulation results are presented to validate the effectiveness of
our proposed power allocation algorithm and to show the advantage of aerial
CoMP by using only the large-scale CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05453</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05453</id><created>2019-05-14</created><authors><author><keyname>Malandrino</keyname><forenames>Francesco</forenames></author><author><keyname>Rottondi</keyname><forenames>Cristina</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author><author><keyname>Bianco</keyname><forenames>Andrea</forenames></author><author><keyname>Stavrakakis</keyname><forenames>Ioannis</forenames></author></authors><title>Multiservice UAVs for Emergency Tasks in Post-disaster Scenarios</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UAVs are increasingly being employed to carry out surveillance, parcel
delivery, communication-support and other specific tasks. Their equipment and
mission plan are carefully selected to minimize the carried load an overall
resource consumption. Typically, several single task UAVs are dispatched to
perform different missions. In certain cases, (part of) the geographical area
of operation may be common to these single task missions (such as those
supporting post-disaster recovery) and it may be more efficient to have
multiple tasks carried out as part of a single UAV mission using common or even
additional specialized equipment.
  In this paper, we propose and investigate a joint planning of multitask
missions leveraging a fleet of UAVs equipped with a standard set of accessories
enabling heterogeneous tasks. To this end, an optimization problem is
formulated yielding the optimal joint planning and deriving the resulting
quality of the delivered tasks. In addition, a heuristic solution is developed
for large-scale environments to cope with the increased complexity of the
optimization framework. The developed joint planning of multitask missions is
applied to a specific post-disaster recovery scenario of a flooding in the San
Francisco area. The results show the effectiveness of the proposed solutions
and the potential savings in the number of UAVs needed to carry out all the
tasks with the required level of quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05468</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05468</id><created>2019-05-14</created><updated>2019-11-19</updated><authors><author><keyname>Li</keyname><forenames>Weida</forenames></author><author><keyname>Liu</keyname><forenames>Mingxia</forenames></author><author><keyname>Chen</keyname><forenames>Fang</forenames></author><author><keyname>Zhang</keyname><forenames>Daoqiang</forenames></author></authors><title>Graph-Based Decoding Model for Functional Alignment of Unaligned fMRI
  Data</title><categories>cs.LG eess.IV stat.ML</categories><comments>17 pages, 10 figures, Proceedings of the Association for the
  Advancement of Artificial Intelligence (AAAI-20)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aggregating multi-subject functional magnetic resonance imaging (fMRI) data
is indispensable for generating valid and general inferences from patterns
distributed across human brains. The disparities in anatomical structures and
functional topographies of human brains warrant aligning fMRI data across
subjects. However, the existing functional alignment methods cannot handle well
various kinds of fMRI datasets today, especially when they are not
temporally-aligned, i.e., some of the subjects probably lack the responses to
some stimuli, or different subjects might follow different sequences of
stimuli. In this paper, a cross-subject graph that depicts the
(dis)similarities between samples across subjects is used as a priori for
developing a more flexible framework that suits an assortment of fMRI datasets.
However, the high dimension of fMRI data and the use of multiple subjects makes
the crude framework time-consuming or unpractical. To address this issue, we
further regularize the framework, so that a novel feasible kernel-based
optimization, which permits nonlinear feature extraction, could be
theoretically developed. Specifically, a low-dimension assumption is imposed on
each new feature space to avoid overfitting caused by the
highspatial-low-temporal resolution of fMRI data. Experimental results on five
datasets suggest that the proposed method is not only superior to several
state-of-the-art methods on temporally-aligned fMRI data, but also suitable for
dealing `with temporally-unaligned fMRI data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05520</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05520</id><created>2019-05-14</created><authors><author><keyname>M.</keyname><forenames>Pavan Reddy</forenames></author><author><keyname>D.</keyname><forenames>Harish Kumar</forenames></author><author><keyname>Amuru</keyname><forenames>Saidhiraj</forenames></author><author><keyname>Kuchi</keyname><forenames>Kiran</forenames></author></authors><title>A Novel Beamformed Control Channel Design for LTE with Full
  Dimension-MIMO</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Full Dimension-MIMO (FD-MIMO) technology is capable of achieving huge
improvements in network throughput with simultaneous connectivity of a large
number of mobile wireless devices, unmanned aerial vehicles, and the Internet
of Things (IoT). In FD-MIMO, with a large number of antennae at the base
station and the ability to perform beamforming, the capacity of the physical
downlink shared channel (PDSCH) has increased a lot. However, the current
specifications of the 3rd Generation Partnership Project (3GPP) does not allow
the base station to perform beamforming techniques for the physical downlink
control channel (PDCCH), and hence, PDCCH has neither the capacity nor the
coverage of PDSCH. Therefore, PDCCH capacity will still limit the performance
of a network as it dictates the number of users that can be scheduled at a
given time instant. In Release 11, 3GPP introduced enhanced PDCCH (EPDCCH) to
increase the PDCCH capacity at the cost of sacrificing the PDSCH resources. The
problem of enhancing the PDCCH capacity within the available control channel
resources has not been addressed yet in the literature. Hence, in this paper,
we propose a novel beamformed PDCCH (BF-PDCCH) design which is aligned to the
3GPP specifications and requires simple software changes at the base station.
We rely on the sounding reference signals transmitted in the uplink to decide
the best beam for a user and ingeniously schedule the users in PDCCH. We
perform system level simulations to evaluate the performance of the proposed
design and show that the proposed BF-PDCCH achieves larger network throughput
when compared with the current state of art algorithms, PDCCH and EPDCCH
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05595</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05595</id><created>2019-05-06</created><authors><author><keyname>Al-Hmood</keyname><forenames>Hussien</forenames></author><author><keyname>Al-Raweshidy</keyname><forenames>H. S.</forenames></author></authors><title>Selection Combining Scheme over Non-identically Distributed
  Fisher-Snedecor $\mathcal{F}$ Fading Channels</title><categories>cs.IT cs.PF eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the performance of the selection combining (SC) scheme over
Fisher-Snedecor $\mathcal{F}$ fading channels with independent and
non-identically distributed (i.n.i.d.) branches is analysed. The probability
density function (PDF) and the moment generating function (MGF) of the maximum
i.n.i.d. Fisher-Snedecor $\mathcal{F}$ variates are derived first in terms of
the multivariate Fox's $H$-function that has been efficiently implemented in
the technical literature by various software codes. Based on this, the average
bit error probability (ABEP) and the average channel capacity (ACC) of SC
diversity with i.n.i.d. receivers are investigated. Moreover, we analyse the
performance of the energy detection that is widely employed to perform the
spectrum sensing in cognitive radio networks via deriving the average detection
probability (ADP) and the average area under the receiver operating
characteristics curve (AUC). To validate our analysis, the numerical results
are affirmed by the Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05605</identifier>
 <datestamp>2019-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05605</id><created>2019-05-10</created><authors><author><keyname>Zhang</keyname><forenames>Shi-Xiong</forenames></author><author><keyname>Gong</keyname><forenames>Yifan</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Encrypted Speech Recognition using Deep Polynomial Networks</title><categories>cs.CR cs.CL cs.SD eess.AS stat.ML</categories><comments>ICASSP 2019, slides@
  https://www.researchgate.net/publication/333005422_Encrypted_Speech_Recognition_using_deep_polynomial_networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cloud-based speech recognition/API provides developers or enterprises an
easy way to create speech-enabled features in their applications. However,
sending audios about personal or company internal information to the cloud,
raises concerns about the privacy and security issues. The recognition results
generated in cloud may also reveal some sensitive information. This paper
proposes a deep polynomial network (DPN) that can be applied to the encrypted
speech as an acoustic model. It allows clients to send their data in an
encrypted form to the cloud to ensure that their data remains confidential, at
mean while the DPN can still make frame-level predictions over the encrypted
speech and return them in encrypted form. One good property of the DPN is that
it can be trained on unencrypted speech features in the traditional way. To
keep the cloud away from the raw audio and recognition results, a cloud-local
joint decoding framework is also proposed. We demonstrate the effectiveness of
model and framework on the Switchboard and Cortana voice assistant tasks with
small performance degradation and latency increased comparing with the
traditional cloud-based DNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05643</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05643</id><created>2019-05-14</created><updated>2019-10-30</updated><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Li</keyname><forenames>Jerry</forenames></author><author><keyname>Musco</keyname><forenames>Cameron</forenames></author><author><keyname>Musco</keyname><forenames>Christopher</forenames></author></authors><title>Sample Efficient Toeplitz Covariance Estimation</title><categories>eess.SP cs.DS cs.LG math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the sample complexity of estimating the covariance matrix $T$ of a
distribution $\mathcal{D}$ over $d$-dimensional vectors, under the assumption
that $T$ is Toeplitz. This assumption arises in many signal processing
problems, where the covariance between any two measurements only depends on the
time or distance between those measurements. We are interested in estimation
strategies that may choose to view only a subset of entries in each vector
sample $x \sim \mathcal{D}$, which often equates to reducing hardware and
communication requirements in applications ranging from wireless signal
processing to advanced imaging. Our goal is to minimize both 1) the number of
vector samples drawn from $\mathcal{D}$ and 2) the number of entries accessed
in each sample.
  We provide some of the first non-asymptotic bounds on these sample complexity
measures that exploit $T$'s Toeplitz structure, and by doing so, significantly
improve on results for generic covariance matrices. Our bounds follow from a
novel analysis of classical and widely used estimation algorithms (along with
some new variants), including methods based on selecting entries from each
vector sample according to a so-called sparse ruler. In many cases, we pair our
upper bounds with matching or nearly matching lower bounds.
  In addition to results that hold for any Toeplitz $T$, we further study the
important setting when $T$ is close to low-rank, which is often the case in
practice. We show that methods based on sparse rulers perform even better in
this setting, with sample complexity scaling sublinearly in $d$. Motivated by
this finding, we develop a new covariance estimation strategy that further
improves on all existing methods in the low-rank case: when $T$ is rank-$k$ or
nearly rank-$k$, it achieves sample complexity depending polynomially on $k$
and only logarithmically on $d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05797</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05797</id><created>2019-05-14</created><authors><author><keyname>Chu</keyname><forenames>Lei</forenames></author><author><keyname>Wen</keyname><forenames>Fei</forenames></author><author><keyname>Qiu</keyname><forenames>Robert Caiming</forenames></author></authors><title>Robust Precoding Design for Coarsely Quantized MU-MIMO Under Channel
  Uncertainties</title><categories>eess.SP cs.IT math.IT</categories><comments>To appear in IEEE ICC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, multi-user multiple input multiple output (MU-MIMO) systems with
low-resolution digital-to-analog converters (DACs) has received considerable
attention, owing to the capability of dramatically reducing the hardware cost.
Besides, it has been shown that the use of low-resolution DACs enable great
reduction in power consumption while maintain the performance loss within
acceptable margin, under the assumption of perfect knowledge of channel state
information (CSI). In this paper, we investigate the precoding problem for the
coarsely quantized MU-MIMO system without such an assumption. The channel
uncertainties are modeled to be a random matrix with finite second-order
statistics. By leveraging a favorable relation between the multi-bit DACs
outputs and the single-bit ones, we first reformulate the original complex
precoding problem into a nonconvex binary optimization problem. Then, using the
S-procedure lemma, the nonconvex problem is recast into a tractable formulation
with convex constraints and finally solved by the semidefinite relaxation (SDR)
method. Compared with existing representative methods, the proposed precoder is
robust to various channel uncertainties and is able to support a MUMIMO system
with higher-order modulations, e.g., 16QAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05822</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05822</id><created>2019-05-14</created><authors><author><keyname>Li</keyname><forenames>Yichen</forenames></author><author><keyname>Tsonev</keyname><forenames>Dobroslav</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>Performance Analysis of Non-DC-Biased OFDM</title><categories>cs.IT cs.PF eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance analysis of a novel optical modulation scheme is presented in
this paper. The basic concept is to transmit signs of modulated optical
orthogonal frequency division multiplexing (O-OFDM) symbols and absolute values
of the symbols separately by two information carrying units: 1) indices of two
light emitting diodes (LED) transmitters that represent positive and negative
signs separately; and 2) optical intensity symbols that carry the absolute
values of signals. The new approach, referred as to non-DC-biased OFDM
(NDC-OFDM), uses the optical spatial modulation (OSM) technique to eliminate
the effect of the clipping distortion in DC-biased optical OFDM (DCO-OFDM). In
addition, it can achieve similar advantages as the conventional unipolar
modulation scheme, asymmetrically clipped optical OFDM (ACO-OFDM), without
using additional subcarriers. In this paper, the analytical BER performance is
compared with the Monte Carlo result in order to prove the reliability of the
new method. Moreover, the practical BER performance of NDC-OFDM with DCO-OFDM
and ACO-OFDM is compared for different constellation sizes to verify the
improvement of NDC-OFDM on the spectral and power efficiencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05848</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05848</id><created>2019-05-14</created><authors><author><keyname>Goossens</keyname><forenames>Thomas</forenames></author><author><keyname>Geelen</keyname><forenames>Bert</forenames></author><author><keyname>Lambrechts</keyname><forenames>Andy</forenames></author><author><keyname>Van Hoof</keyname><forenames>Chris</forenames></author></authors><title>Vignetted-aperture correction for spectral cameras with integrated
  thin-film Fabry-P\'erot filters</title><categories>physics.optics eess.IV</categories><journal-ref>Appl. Opt. 58, 1789-1799 (2019)</journal-ref><doi>10.1364/AO.58.001789</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral cameras with integrated thin-film Fabry-P\'erot filters have become
increasingly important in many applications. These applications often require
the detection of spectral features at specific wavelengths or to quantify small
variations in the spectrum. This can be challenging since thin-film filters are
sensitive to the angle of incidence of the light. In prior work we modeled and
corrected for the distribution of incident angles for an ideal finite aperture.
Many real lenses however experience vignetting. Therefore in this article we
generalize our model to the more common case of a vignetted aperture, which
changes the distribution of incident angles. We propose a practical method to
estimate the model parameters and correct undesired shifts in measured spectra.
This is experimentally validated for a lens mounted on a visible to
near-infrared spectral camera.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05861</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05861</id><created>2019-05-14</created><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames><affiliation>for the Alzheimer's Disease Neuroimaging Initiative</affiliation></author><author><keyname>Giancardo</keyname><forenames>Luca</forenames><affiliation>for the Alzheimer's Disease Neuroimaging Initiative</affiliation></author><author><keyname>Pena</keyname><forenames>Danilo A.</forenames><affiliation>for the Alzheimer's Disease Neuroimaging Initiative</affiliation></author><author><keyname>Kim</keyname><forenames>Yejin</forenames><affiliation>for the Alzheimer's Disease Neuroimaging Initiative</affiliation></author><author><keyname>Tong</keyname><forenames>Hanghang</forenames><affiliation>for the Alzheimer's Disease Neuroimaging Initiative</affiliation></author><author><keyname>Jiang</keyname><forenames>Xiaoqian</forenames><affiliation>for the Alzheimer's Disease Neuroimaging Initiative</affiliation></author></authors><title>From Brain Imaging to Graph Analysis: a study on ADNI's patient cohort</title><categories>eess.IV cs.IR q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we studied the association between the change of structural
brain volumes to the potential development of Alzheimer's disease (AD). Using a
simple abstraction technique, we converted regional cortical and subcortical
volume differences over two time points for each study subject into a graph. We
then obtained substructures of interest using a graph decomposition algorithm
in order to extract pivotal nodes via multi-view feature selection. Intensive
experiments using robust classification frameworks were conducted to evaluate
the performance of using the brain substructures obtained under different
thresholds. The results indicated that compact substructures acquired by
examining the differences between patient groups were sufficient to
discriminate between AD and healthy controls with an area under the receiver
operating curve of 0.72.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05879</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05879</id><created>2019-05-14</created><updated>2019-06-06</updated><authors><author><keyname>Qian</keyname><forenames>Kaizhi</forenames></author><author><keyname>Zhang</keyname><forenames>Yang</forenames></author><author><keyname>Chang</keyname><forenames>Shiyu</forenames></author><author><keyname>Yang</keyname><forenames>Xuesong</forenames></author><author><keyname>Hasegawa-Johnson</keyname><forenames>Mark</forenames></author></authors><title>AUTOVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss</title><categories>eess.AS cs.AI cs.LG cs.SD stat.ML</categories><comments>To Appear in Thirty-sixth International Conference on Machine
  Learning (ICML 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-parallel many-to-many voice conversion, as well as zero-shot voice
conversion, remain under-explored areas. Deep style transfer algorithms, such
as generative adversarial networks (GAN) and conditional variational
autoencoder (CVAE), are being applied as new solutions in this field. However,
GAN training is sophisticated and difficult, and there is no strong evidence
that its generated speech is of good perceptual quality. On the other hand,
CVAE training is simple but does not come with the distribution-matching
property of a GAN. In this paper, we propose a new style transfer scheme that
involves only an autoencoder with a carefully designed bottleneck. We formally
show that this scheme can achieve distribution-matching style transfer by
training only on a self-reconstruction loss. Based on this scheme, we proposed
AUTOVC, which achieves state-of-the-art results in many-to-many voice
conversion with non-parallel data, and which is the first to perform zero-shot
voice conversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05916</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05916</id><created>2019-05-14</created><updated>2019-12-09</updated><authors><author><keyname>Shin</keyname><forenames>Yong-Goo</forenames></author><author><keyname>Park</keyname><forenames>Seung</forenames></author><author><keyname>Yeo</keyname><forenames>Yoon-Jae</forenames></author><author><keyname>Yoo</keyname><forenames>Min-Jae</forenames></author><author><keyname>Ko</keyname><forenames>Sung-Jea</forenames></author></authors><title>Unsupervised Deep Contrast Enhancement with Power Constraint for OLED
  Displays</title><categories>eess.IV cs.CV</categories><comments>Accepted to IEEE transactions on Image Processing. To be published</comments><doi>10.1109/TIP.2019.2953352</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various power-constrained contrast enhancement (PCCE) techniques have been
applied to an organic light emitting diode (OLED) display for reducing the
power demands of the display while preserving the image quality. In this paper,
we propose a new deep learning-based PCCE scheme that constrains the power
consumption of the OLED displays while enhancing the contrast of the displayed
image. In the proposed method, the power consumption is constrained by simply
reducing the brightness a certain ratio, whereas the perceived visual quality
is preserved as much as possible by enhancing the contrast of the image using a
convolutional neural network (CNN). Furthermore, our CNN can learn the PCCE
technique without a reference image by unsupervised learning. Experimental
results show that the proposed method is superior to conventional ones in terms
of image quality assessment metrics such as a visual saliency-induced index
(VSI) and a measure of enhancement (EME).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05953</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.05953</id><created>2019-05-15</created><authors><author><keyname>Wei</keyname><forenames>Hongjiang</forenames></author><author><keyname>Cao</keyname><forenames>Steven</forenames></author><author><keyname>Zhang</keyname><forenames>Yuyao</forenames></author><author><keyname>Guan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Yan</keyname><forenames>Fuhua</forenames></author><author><keyname>Yeom</keyname><forenames>Kristen W.</forenames></author><author><keyname>Liu</keyname><forenames>Chunlei</forenames></author></authors><title>Learning-based Single-step Quantitative Susceptibility Mapping
  Reconstruction Without Brain Extraction</title><categories>eess.IV cs.AI</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative susceptibility mapping (QSM) estimates the underlying tissue
magnetic susceptibility from MRI gradient-echo phase signal and typically
requires several processing steps. These steps involve phase unwrapping, brain
volume extraction, background phase removal and solving an ill-posed inverse
problem. The resulting susceptibility map is known to suffer from inaccuracy
near the edges of the brain tissues, in part due to imperfect brain extraction,
edge erosion of the brain tissue and the lack of phase measurement outside the
brain. This inaccuracy has thus hindered the application of QSM for measuring
the susceptibility of tissues near the brain edges, e.g., quantifying cortical
layers and generating superficial venography. To address these challenges, we
propose a learning-based QSM reconstruction method that directly estimates the
magnetic susceptibility from total phase images without the need for brain
extraction and background phase removal, referred to as autoQSM. The neural
network has a modified U-net structure and is trained using QSM maps computed
by a two-step QSM method. 209 healthy subjects with ages ranging from 11 to 82
years were employed for patch-wise network training. The network was validated
on data dissimilar to the training data, e.g. in vivo mouse brain data and
brains with lesions, which suggests that the network has generalized and
learned the underlying mathematical relationship between magnetic field
perturbation and magnetic susceptibility. AutoQSM was able to recover magnetic
susceptibility of anatomical structures near the edges of the brain including
the veins covering the cortical surface, spinal cord and nerve tracts near the
mouse brain boundaries. The advantages of high-quality maps, no need for brain
volume extraction and high reconstruction speed demonstrate its potential for
future applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06008</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06008</id><created>2019-05-15</created><authors><author><keyname>Nguyen</keyname><forenames>Van Hoa</forenames></author><author><keyname>Nguyen</keyname><forenames>Tung Lam</forenames></author><author><keyname>Tran</keyname><forenames>Quoc Tuan</forenames></author><author><keyname>Besanger</keyname><forenames>Yvon</forenames></author><author><keyname>Caire</keyname><forenames>Raphael</forenames></author></authors><title>Integration of SCADA services in cross-infrastructure holistic tests of
  cyber-physical energy systems</title><categories>eess.SP</categories><comments>Accepted for presentation in the IEEE EEEIC 2019 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber-Physical Energy System, due to its multi-domain nature, requires a
holistic validation methodology, which may involve the integration of assets
and expertise from various research infrastructures. In this paper, the
integration of Supervisory Control and Data Acquisition services to
cross-infrastructure experiment is proposed. The method requires a high degree
of interoperability among the participating partners and can be applied to
extend the capacity as well as the degree of realism of advanced validation
method such as co-simulation, remote hardware-in-the-loop or hybrid simulation.
The proposed method is applied to a case study of multi-agent system based
control for islanded microgrid where real devices from one platform is
integrated to real-time simulation and control platform in a distanced
infrastructure, in a holistic experimental implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06058</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06058</id><created>2019-05-15</created><updated>2020-01-31</updated><authors><author><keyname>Mason</keyname><forenames>Jonathan H.</forenames></author><author><keyname>Davies</keyname><forenames>Mike E.</forenames></author><author><keyname>Bagnaninchi</keyname><forenames>Pierre O.</forenames></author></authors><title>Blur resolved OCT: full-range interferometric synthetic aperture
  microscopy through dispersion encoding</title><categories>eess.IV physics.med-ph physics.optics</categories><comments>17 pages, 7 figures. The images have been compressed for arxiv -
  please follow DOI for full resolution</comments><journal-ref>Opt. Express 28, 3879-3894 (2020)</journal-ref><doi>10.1364/OE.379216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a computational method for full-range interferometric synthetic
aperture microscopy (ISAM) under dispersion encoding. With this, one can
effectively double the depth range of optical coherence tomography (OCT),
whilst dramatically enhancing the spatial resolution away from the focal plane.
To this end, we propose a model-based iterative reconstruction (MBIR) method,
where ISAM is directly considered in an optimization approach, and we make the
discovery that sparsity promoting regularization effectively recovers the
full-range signal. Within this work, we adopt an optimal nonuniform discrete
fast Fourier transform (NUFFT) implementation of ISAM, which is both fast and
numerically stable throughout iterations. We validate our method with several
complex samples, scanned with a commercial SD-OCT system with no hardware
modification. With this, we both demonstrate full-range ISAM imaging, and
significantly outperform combinations of existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06118</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06118</id><created>2019-05-14</created><updated>2019-07-26</updated><authors><author><keyname>Gillick</keyname><forenames>Jon</forenames></author><author><keyname>Roberts</keyname><forenames>Adam</forenames></author><author><keyname>Engel</keyname><forenames>Jesse</forenames></author><author><keyname>Eck</keyname><forenames>Douglas</forenames></author><author><keyname>Bamman</keyname><forenames>David</forenames></author></authors><title>Learning to Groove with Inverse Sequence Transformations</title><categories>cs.SD cs.LG cs.MM eess.AS stat.ML</categories><comments>Blog post and links: https://g.co/magenta/groovae</comments><acm-class>J.5; I.2</acm-class><journal-ref>Proceedings of the 36th International Conference on Machine
  Learning, PMLR 97:2269-2279, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore models for translating abstract musical ideas (scores, rhythms)
into expressive performances using Seq2Seq and recurrent Variational
Information Bottleneck (VIB) models. Though Seq2Seq models usually require
painstakingly aligned corpora, we show that it is possible to adapt an approach
from the Generative Adversarial Network (GAN) literature (e.g. Pix2Pix (Isola
et al., 2017) and Vid2Vid (Wang et al. 2018a)) to sequences, creating large
volumes of paired data by performing simple transformations and training
generative models to plausibly invert these transformations. Music, and
drumming in particular, provides a strong test case for this approach because
many common transformations (quantization, removing voices) have clear
semantics, and models for learning to invert them have real-world applications.
Focusing on the case of drum set players, we create and release a new dataset
for this purpose, containing over 13 hours of recordings by professional
drummers aligned with fine-grained timing and dynamics information. We also
explore some of the creative potential of these models, including demonstrating
improvements on state-of-the-art methods for Humanization (instantiating a
performance from a musical score).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06133</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06133</id><created>2019-05-14</created><authors><author><keyname>Wan</keyname><forenames>Sheng</forenames></author><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Zhong</keyname><forenames>Ping</forenames></author><author><keyname>Du</keyname><forenames>Bo</forenames></author><author><keyname>Zhang</keyname><forenames>Lefei</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author></authors><title>Multi-scale Dynamic Graph Convolutional Network for Hyperspectral Image
  Classification</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Network (CNN) has demonstrated impressive ability to
represent hyperspectral images and to achieve promising results in
hyperspectral image classification. However, traditional CNN models can only
operate convolution on regular square image regions with fixed size and
weights, so they cannot universally adapt to the distinct local regions with
various object distributions and geometric appearances. Therefore, their
classification performances are still to be improved, especially in class
boundaries. To alleviate this shortcoming, we consider employing the recently
proposed Graph Convolutional Network (GCN) for hyperspectral image
classification, as it can conduct the convolution on arbitrarily structured
non-Euclidean data and is applicable to the irregular image regions represented
by graph topological information. Different from the commonly used GCN models
which work on a fixed graph, we enable the graph to be dynamically updated
along with the graph convolution process, so that these two steps can be
benefited from each other to gradually produce the discriminative embedded
features as well as a refined graph. Moreover, to comprehensively deploy the
multi-scale information inherited by hyperspectral images, we establish
multiple input graphs with different neighborhood scales to extensively exploit
the diversified spectral-spatial correlations at multiple scales. Therefore,
our method is termed 'Multi-scale Dynamic Graph Convolutional Network' (MDGCN).
The experimental results on three typical benchmark datasets firmly demonstrate
the superiority of the proposed MDGCN to other state-of-the-art methods in both
qualitative and quantitative aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06148</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06148</id><created>2019-05-15</created><updated>2019-06-21</updated><authors><author><keyname>Ram&#xed;rez</keyname><forenames>Marco A. Mart&#xed;nez</forenames></author><author><keyname>Benetos</keyname><forenames>Emmanouil</forenames></author><author><keyname>Reiss</keyname><forenames>Joshua D.</forenames></author></authors><title>A general-purpose deep learning approach to model time-varying audio
  effects</title><categories>eess.AS cs.LG cs.SD eess.SP</categories><comments>audio files: https://mchijmma.github.io/modeling-time-varying/</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Audio processors whose parameters are modified periodically over time are
often referred as time-varying or modulation based audio effects. Most existing
methods for modeling these type of effect units are often optimized to a very
specific circuit and cannot be efficiently generalized to other time-varying
effects. Based on convolutional and recurrent neural networks, we propose a
deep learning architecture for generic black-box modeling of audio processors
with long-term memory. We explore the capabilities of deep neural networks to
learn such long temporal dependencies and we show the network modeling various
linear and nonlinear, time-varying and time-invariant audio effects. In order
to measure the performance of the model, we propose an objective metric based
on the psychoacoustics of modulation frequency perception. We also analyze what
the model is actually learning and how the given task is accomplished.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06236</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06236</id><created>2019-05-13</created><updated>2019-12-09</updated><authors><author><keyname>Dong</keyname><forenames>Wushi</forenames></author><author><keyname>Keceli</keyname><forenames>Murat</forenames></author><author><keyname>Vescovi</keyname><forenames>Rafael</forenames></author><author><keyname>Li</keyname><forenames>Hanyu</forenames></author><author><keyname>Adams</keyname><forenames>Corey</forenames></author><author><keyname>Jennings</keyname><forenames>Elise</forenames></author><author><keyname>Flender</keyname><forenames>Samuel</forenames></author><author><keyname>Uram</keyname><forenames>Tom</forenames></author><author><keyname>Vishwanath</keyname><forenames>Venkatram</forenames></author><author><keyname>Ferrier</keyname><forenames>Nicola</forenames></author><author><keyname>Kasthuri</keyname><forenames>Narayanan</forenames></author><author><keyname>Littlewood</keyname><forenames>Peter</forenames></author></authors><title>Scaling Distributed Training of Flood-Filling Networks on HPC
  Infrastructure for Brain Mapping</title><categories>cs.DC cs.LG eess.IV q-bio.NC</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mapping all the neurons in the brain requires automatic reconstruction of
entire cells from volume electron microscopy data. The flood-filling network
(FFN) architecture has demonstrated leading performance for segmenting
structures from this data. However, the training of the network is
computationally expensive. In order to reduce the training time, we implemented
synchronous and data-parallel distributed training using the Horovod library,
which is different from the asynchronous training scheme used in the published
FFN code. We demonstrated that our distributed training scaled well up to 2048
Intel Knights Landing (KNL) nodes on the Theta supercomputer. Our trained
models achieved similar level of inference performance, but took less training
time compared to previous methods. Our study on the effects of different batch
sizes on FFN training suggests ways to further improve training efficiency. Our
findings on optimal learning rate and batch sizes agree with previous works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06286</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06286</id><created>2019-05-15</created><updated>2019-05-27</updated><authors><author><keyname>Gu</keyname><forenames>Rongzhi</forenames></author><author><keyname>Wu</keyname><forenames>Jian</forenames></author><author><keyname>Zhang</keyname><forenames>Shi-Xiong</forenames></author><author><keyname>Chen</keyname><forenames>Lianwu</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Yu</keyname><forenames>Meng</forenames></author><author><keyname>Su</keyname><forenames>Dan</forenames></author><author><keyname>Zou</keyname><forenames>Yuexian</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>End-to-End Multi-Channel Speech Separation</title><categories>cs.SD cs.LG eess.AS</categories><comments>submitted to interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The end-to-end approach for single-channel speech separation has been studied
recently and shown promising results. This paper extended the previous approach
and proposed a new end-to-end model for multi-channel speech separation. The
primary contributions of this work include 1) an integrated waveform-in
waveform-out separation system in a single neural network architecture. 2) We
reformulate the traditional short time Fourier transform (STFT) and
inter-channel phase difference (IPD) as a function of time-domain convolution
with a special kernel. 3) We further relaxed those fixed kernels to be
learnable, so that the entire architecture becomes purely data-driven and can
be trained from end-to-end. We demonstrate on the WSJ0 far-field speech
separation task that, with the benefit of learnable spatial features, our
proposed end-to-end multi-channel model significantly improved the performance
of previous end-to-end single-channel method and traditional multi-channel
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06302</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06302</id><created>2019-05-15</created><authors><author><keyname>Li</keyname><forenames>Yichen</forenames></author><author><keyname>Safari</keyname><forenames>Majid</forenames></author><author><keyname>Henderson</keyname><forenames>Robert</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>Performance Analysis of SPAD-based OFDM</title><categories>cs.IT cs.PF eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an analytical approach for the nonlinear distorted bit error
rate performance of optical orthogonal frequency division multiplexing (O-OFDM)
with single photon avalanche diode (SPAD) receivers is presented. Major
distortion effects of passive quenching (PQ) and active quenching (AQ) SPAD
receivers are analysed in this study. The performance analysis of DC-biased
O-OFDM and asymmetrically clipped O-OFDM with PQ and AQ SPAD are derived. The
comparison results show the maximum optical irradiance caused by the nonlinear
distortion, which limits the transmission power and bit rate. The theoretical
maximum bit rate of SPAD-based OFDM is found which is up to 1~Gbits/s. This
approach supplies a closed-form analytical solution for designing an optimal
SPAD-based system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06312</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06312</id><created>2019-05-15</created><updated>2019-07-01</updated><authors><author><keyname>Zhao</keyname><forenames>Ziyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Kerui</forenames></author><author><keyname>Hao</keyname><forenames>Xuejie</forenames></author><author><keyname>Tian</keyname><forenames>Jing</forenames></author><author><keyname>Chua</keyname><forenames>Matthew Chin Heng</forenames></author><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Xu</keyname><forenames>Xin</forenames></author></authors><title>BiRA-Net: Bilinear Attention Net for Diabetic Retinopathy Grading</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted at ICIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diabetic retinopathy (DR) is a common retinal disease that leads to
blindness. For diagnosis purposes, DR image grading aims to provide automatic
DR grade classification, which is not addressed in conventional research
methods of binary DR image classification. Small objects in the eye images,
like lesions and microaneurysms, are essential to DR grading in medical
imaging, but they could easily be influenced by other objects. To address these
challenges, we propose a new deep learning architecture, called BiRA-Net, which
combines the attention model for feature extraction and bilinear model for
fine-grained classification. Furthermore, in considering the distance between
different grades of different DR categories, we propose a new loss function,
called grading loss, which leads to improved training convergence of the
proposed approach. Experimental results are provided to demonstrate the
superior performance of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06327</identifier>
 <datestamp>2019-05-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06327</id><created>2019-04-25</created><authors><author><keyname>Takbiri-Borujeni</keyname><forenames>Ali</forenames></author><author><keyname>Kazemi</keyname><forenames>Hadi</forenames></author><author><keyname>Nasrabadi</keyname><forenames>Nasser</forenames></author></authors><title>A data-driven proxy to Stoke's flow in porous media</title><categories>eess.IV cs.CE cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective for this work is to develop a data-driven proxy to
high-fidelity numerical flow simulations using digital images. The proposed
model can capture the flow field and permeability in a large verity of digital
porous media based on solid grain geometry and pore size distribution by
detailed analyses of the local pore geometry and the local flow fields. To
develop the model, the detailed pore space geometry and simulation runs data
from 3500 two-dimensional high-fidelity Lattice Boltzmann simulation runs are
used to train and to predict the solutions with a high accuracy in much less
computational time. The proposed methodology harness the enormous amount of
generated data from high-fidelity flow simulations to decode the often
under-utilized patterns in simulations and to accurately predict solutions to
new cases. The developed model can truly capture the physics of the problem and
enhance prediction capabilities of the simulations at a much lower cost. These
predictive models, in essence, do not spatio-temporally reduce the order of the
problem. They, however, possess the same numerical resolutions as their Lattice
Boltzmann simulations equivalents do with the great advantage that their
solutions can be achieved by significant reduction in computational costs
(speed and memory).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06329</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06329</id><created>2019-05-14</created><authors><author><keyname>Chu</keyname><forenames>Lei</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert Caiming</forenames></author></authors><title>LEMO: Learn to Equalize for MIMO-OFDM Systems with Low-Resolution ADCs</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a new deep neural network optimized equalization
framework for massive multiple input multiple output orthogonal frequency
division multiplexing (MIMO-OFDM) systems that employ low-resolution
analog-to-digital converters (ADCs) at the base station (BS). The use of
low-resolution ADCs could largely reduce hardware complexity and circuit power
consumption, however, makes the channel station information almost blind to the
BS, hence causing difficulty in solving the equalization problem. In this
paper, we consider a supervised learning architecture, where the goal is to
learn a representative function that can predict the targets (constellation
points) from the inputs (outputs of the low-resolution ADCs) based on the
labeled training data (pilot signals). Specially, our main contributions are
two-fold: 1) First, we design a new activation function, whose outputs are
close to the constellation points when the parameters are finally optimized, to
help us fully exploit the stochastic gradient descent method for the discrete
optimization problem. 2) Second, an unsupervised loss is designed and then
added to the optimization objective, aiming to enhance the representation
ability (so-called generalization). The experimental results reveal that the
proposed equalizer is robust to different channel taps (i.e., Gaussian, and
Poisson), significantly outperforms the linearized MMSE equalizer, and shows
potential for pilot saving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06330</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06330</id><created>2019-05-14</created><authors><author><keyname>Zhou</keyname><forenames>Weimin</forenames></author><author><keyname>Li</keyname><forenames>Hua</forenames></author><author><keyname>Anastasio</keyname><forenames>Mark A.</forenames></author></authors><title>Approximating the Ideal Observer and Hotelling Observer for binary
  signal detection tasks by use of supervised learning methods</title><categories>eess.SP cs.CV cs.LG stat.ML</categories><comments>IEEE Transactions on Medical Imaging (Early Access), 2019</comments><doi>10.1109/TMI.2019.2911211</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is widely accepted that optimization of medical imaging system performance
should be guided by task-based measures of image quality (IQ). Task-based
measures of IQ quantify the ability of an observer to perform a specific task
such as detection or estimation of a signal (e.g., a tumor). For binary signal
detection tasks, the Bayesian Ideal Observer (IO) sets an upper limit of
observer performance and has been advocated for use in optimizing medical
imaging systems and data-acquisition designs. Except in special cases,
determination of the IO test statistic is analytically intractable.
Markov-chain Monte Carlo (MCMC) techniques can be employed to approximate IO
detection performance, but their reported applications have been limited to
relatively simple object models. In cases where the IO test statistic is
difficult to compute, the Hotelling Observer (HO) can be employed. To compute
the HO test statistic, potentially large covariance matrices must be accurately
estimated and subsequently inverted, which can present computational
challenges. This work investigates supervised learning-based methodologies for
approximating the IO and HO test statistics. Convolutional neural networks
(CNNs) and single-layer neural networks (SLNNs) are employed to approximate the
IO and HO test statistics, respectively. Numerical simulations were conducted
for both signal-known-exactly (SKE) and signal-known-statistically (SKS) signal
detection tasks. The performances of the supervised learning methods are
assessed via receiver operating characteristic (ROC) analysis and the results
are compared to those produced by use of traditional numerical methods or
analytical calculations when feasible. The potential advantages of the proposed
supervised learning approaches for approximating the IO and HO test statistics
are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06372</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06372</id><created>2019-05-15</created><authors><author><keyname>Maymon</keyname><forenames>Shay</forenames></author><author><keyname>Barel</keyname><forenames>Hila</forenames></author></authors><title>Contrast Optimization And Local Adaptation (COALA) for HDR Compression</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a novel approach for high dynamic-range compression. It
relies on the widely accepted assumption that the human visual system is not
very sensitive to absolute luminance reaching the retina, but rather responds
to relative luminance ratios. Dynamic-range compression is then formulated as a
regularized optimization in which the image dynamic range is reduced while the
local contrast of the original scene is preserved. Our method is shown to be
capable of drastic dynamic-range compression, while preserving fine details and
avoiding common artifacts such as halos, gradient reversals, or loss of local
contrast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06380</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06380</id><created>2019-05-13</created><authors><author><keyname>Joseph</keyname><forenames>Jan Moritz</forenames></author><author><keyname>Ermel</keyname><forenames>Dominik</forenames></author><author><keyname>Drewes</keyname><forenames>Tobias</forenames></author><author><keyname>Bamberg</keyname><forenames>Lennart</forenames></author><author><keyname>Garcia-Oritz</keyname><forenames>Alberto</forenames></author><author><keyname>Pionteck</keyname><forenames>Thilo</forenames></author></authors><title>Area Optimization with Non-linear Models in Core Mapping for
  System-on-Chips</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear models are regularly used for mapping cores to tiles in a chip.
System-on-Chip (SoC) design requires integration of functional units with
varying sizes, but conventional models only account for identical-sized cores.
Linear models cannot calculate the varying areas of cores in SoCs directly and
must rely on approximations. We propose using non-linear models: Semi-definite
programming (SDP) allows easy model definitions and achieves approximately 20%
reduced area and up to 80% reduced white space. As computational time is
similar to linear models, they can be applied, practically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06383</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06383</id><created>2019-05-05</created><authors><author><keyname>Huang</keyname><forenames>Pingmu</forenames></author><author><keyname>Hao</keyname><forenames>Yunqin</forenames></author><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author><author><keyname>Xing</keyname><forenames>Jintao</forenames></author><author><keyname>Yang</keyname><forenames>Jie</forenames></author><author><keyname>Mathiopoulos</keyname><forenames>P. Takis</forenames></author></authors><title>Secure Beamforming Design in Relay-Assisted Internet of Things</title><categories>eess.SP</categories><comments>IEEE Internet of Things Journal, Accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A secure downlink transmission system which is exposed to multiple
eavesdroppers and is appropriate for Internet of Things (IoT) applications is
considered. A worst case scenario is assumed, in the sense that, in order to
enhance their interception ability all eavesdroppers are located close to each
other, near the controller and collude to form joint receive beamforming. For
such a system, a novel cooperative non-orthogonal multiple access (NOMA) secure
transmission scheme for which an IoT device with a stronger channel condition
acts as an energy harvesting relay in order to assist a second IoT device
operating under weaker channel conditions, is proposed and its performance is
analyzed and evaluated. A secrecy sum rate (SSR) maximization problem is
formulated and solved under three constraints: i) Transmit power; ii)
Successive interference cancellation; iii) Quality of Service. By considering
both passive and active eavesdroppers scenarios, two optimization schemes are
proposed to improve the overall system SSR. On the one hand, for the passive
eavesdropper scenario, an artificial noise-aided secure beamforming scheme is
proposed. Since this optimization problem is nonconvex, instead of using
traditional but highly complex, bruteforce two-dimensional search, it is
conveniently transformed into a convex one by using an epigraph reformulation.
On the other hand, for the active multi-antennas eavesdroppers' scenario, the
orthogonal-projection-based beamforming scheme is considered, and by employing
the successive convex approximation method, a suboptimal solution is proposed.
Furthermore, since for single antenna transmission the
orthogonal-projection-based scheme may not be applicable a simple power control
scheme is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06384</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06384</id><created>2019-05-13</created><authors><author><keyname>Arsalan</keyname><forenames>Aamir</forenames></author><author><keyname>Majid</keyname><forenames>Muhammad</forenames></author><author><keyname>Anwar</keyname><forenames>Syed Muhammad</forenames></author><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author></authors><title>Classification of Perceived Human Stress using Physiological Signals</title><categories>eess.SP cs.HC cs.LG stat.ML</categories><comments>Accepted for publication in EMBC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an experimental study for the classification of
perceived human stress using non-invasive physiological signals. These include
electroencephalography (EEG), galvanic skin response (GSR), and
photoplethysmography (PPG). We conducted experiments consisting of steps
including data acquisition, feature extraction, and perceived human stress
classification. The physiological data of $28$ participants are acquired in an
open eye condition for a duration of three minutes. Four different features are
extracted in time domain from EEG, GSR and PPG signals and classification is
performed using multiple classifiers including support vector machine, the
Naive Bayes, and multi-layer perceptron (MLP). The best classification accuracy
of 75% is achieved by using MLP classifier. Our experimental results have shown
that our proposed scheme outperforms existing perceived stress classification
methods, where no stress inducers are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06386</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06386</id><created>2019-05-10</created><authors><author><keyname>McEwan</keyname><forenames>Dave</forenames></author><author><keyname>Hlond</keyname><forenames>Marcin</forenames></author><author><keyname>Nunez-Yanez</keyname><forenames>Jose</forenames></author></authors><title>Visualizations for Understanding SoC Behaviour</title><categories>eess.SP</categories><comments>4 pages, PRIME2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel method of analysis for SoC development building
upon commonly used tools and techniques to approximate and automate the human
process of investigation. Knowledge of the interactions between components
within a SoC is essential for understanding how a system works so the presented
method provides a way of visualizing these interactions. The mathematical basis
for the method is explained and justified, then the method is demonstrated
using two representative case studies. Visualizations from the case studies are
used to exhibit the usefulness of the method for system optimization,
monitoring, and validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06420</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06420</id><created>2019-04-24</created><authors><author><keyname>Jia</keyname><forenames>Mengshuo</forenames></author><author><keyname>Shen</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Zhaojian</forenames></author></authors><title>A Distributed Privacy-preserving Incremental Update Algorithm for
  Probability Distribution of Wind Power Forecast Error</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Establishing the conditional probability distribution (PD) of wind power
forecast error (WFE) is a prerequisite for many stochastic analysis considering
wind power integration. However, with the increasingly emergence of new data,
the update burden of the conditional PD is getting heavier as the size of
training data set grows rapidly. Meanwhile, the centralized training manner of
the conditional PD may reveals the data privacy of wind farms (WFs) belonging
to different stakeholders. To solve these problems, we propose a distributed
privacy-preserving (DPP) incremental update algorithm (DPP-IUA) for updating
each WF's conditional PD of WFE considering their correlation. This algorithm
consists of two original methods: (1) a DPP incremental Gaussian-mixture-model
algorithm (DPP-IGA) for updating the joint PD of the correlated WFs; and (2) a
DPP mechanism for deriving each WF's conditional PD of WFE under a given
forecast vector. The DPP-IUA keeps each WF's conditional PD of WFE up to date
with extremely low update burden. Meanwhile, this algorithm is also fully
distributed and strictly protects the data privacy of different WFs. The
effectiveness, correctness and efficiency of the proposed DPP-IUA is
empirically verified using historical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06442</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06442</id><created>2019-05-15</created><authors><author><keyname>Izadyyazdanabadi</keyname><forenames>Mohammadhassan</forenames></author><author><keyname>Belykh</keyname><forenames>Evgenii</forenames></author><author><keyname>Zhao</keyname><forenames>Xiaochun</forenames></author><author><keyname>Moreira</keyname><forenames>Leandro Borba</forenames></author><author><keyname>Gandhi</keyname><forenames>Sirin</forenames></author><author><keyname>Cavallo</keyname><forenames>Claudio</forenames></author><author><keyname>Eschbacher</keyname><forenames>Jennifer</forenames></author><author><keyname>Nakaji</keyname><forenames>Peter</forenames></author><author><keyname>Preul</keyname><forenames>Mark C.</forenames></author><author><keyname>Yang</keyname><forenames>Yezhou</forenames></author></authors><title>Fluorescence Image Histology Pattern Transformation using Image Style
  Transfer</title><categories>cs.CV eess.IV</categories><comments>Submitted to Frontiers in Oncology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Confocal laser endomicroscopy (CLE) allow on-the-fly in vivo intraoperative
imaging in a discreet field of view, especially for brain tumors, rather than
extracting tissue for examination ex vivo with conventional light microscopy.
Fluorescein sodium-driven CLE imaging is more interactive, rapid, and portable
than conventional hematoxylin and eosin (H&amp;E)-staining. However, it has several
limitations: CLE images may be contaminated with artifacts (motion, red blood
cells, noise), and neuropathologists are mainly trained on colorful stained
histology slides like H&amp;E while the CLE images are gray. To improve the
diagnostic quality of CLE, we used a micrograph of an H&amp;E slide from a glioma
tumor biopsy and image style transfer, a neural network method for integrating
the content and style of two images. This was done through minimizing the
deviation of the target image from both the content (CLE) and style (H&amp;E)
images. The style transferred images were assessed and compared to conventional
H&amp;E histology by neurosurgeons and a neuropathologist who then validated the
quality enhancement in 100 pairs of original and transformed images. Average
reviewers' score on test images showed 84 out of 100 transformed images had
fewer artifacts and more noticeable critical structures compared to their
original CLE form. By providing images that are more interpretable than the
original CLE images and more rapidly acquired than H&amp;E slides, the style
transfer method allows a real-time, cellular-level tissue examination using CLE
technology that closely resembles the conventional appearance of H&amp;E staining
and may yield better diagnostic recognition than original CLE grayscale images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06474</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06474</id><created>2019-05-15</created><authors><author><keyname>Lahiri</keyname><forenames>Anish</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A</forenames></author><author><keyname>Hernandez-Garcia</keyname><forenames>Luis</forenames></author></authors><title>Optimizing MRF-ASL Scan Design for Precise Quantification of Brain
  Hemodynamics using Neural Network Regression</title><categories>eess.IV cs.LG eess.SP stat.ML</categories><comments>Submitted to Magnetic Resonance in Medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Arterial Spin Labeling (ASL) is a quantitative, non-invasive
alternative to perfusion imaging with contrast agents. Fixing values of certain
model parameters in traditional ASL, which actually vary from region to region,
may introduce bias in perfusion estimates. Adopting Magnetic Resonance
Fingerprinting (MRF) for ASL is an alternative where these parameters are
estimated alongside perfusion, but multiparametric estimation can degrade
precision. We aim to improve the sensitivity of ASL-MRF signals to underlying
parameters to counter this problem, and provide precise estimates. We also
propose a regression based estimation framework for MRF-ASL.
  Methods: To improve the sensitivity of MRF-ASL signals to underlying
parameters, we optimize ASL labeling durations using the Cramer-Rao Lower Bound
(CRLB). This paper also proposes a neural network regression based estimation
framework trained using noisy synthetic signals generated from our ASL signal
model.
  Results: We test our methods in silico and in vivo, and compare with multiple
post labeling delay (multi-PLD) ASL and unoptimized MRF-ASL. We present
comparisons of estimated maps for six parameters accounted for in our signal
model.
  Conclusions: The scan design process facilitates precise estimates of
multiple hemodynamic parameters and tissue properties from a single scan, in
regions of gray and white matter, as well as regions with anomalous perfusion
activity in the brain. The regression based estimation approach provides
perfusion estimates rapidly, and bypasses problems with quantization error.
  Keywords: Arterial Spin Labeling, Magnetic Resonance Fingerprinting,
Optimization, Cramer-Rao Bound, Scan Design, Regression, Neural Networks, Deep
Learning, Precision, Estimation, Brain Hemodynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06528</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06528</id><created>2019-05-16</created><authors><author><keyname>Alaudah</keyname><forenames>Yazeed</forenames></author><author><keyname>Alfarraj</keyname><forenames>Motaz</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Structure Label Prediction Using Similarity-Based Retrieval and
  Weakly-Supervised Label Mapping</title><categories>eess.IV physics.geo-ph</categories><comments>Published at SEG Geophysics Journal in Dec 2018</comments><journal-ref>GEOPHYSICS 2019 84:1, V67-V79</journal-ref><doi>10.1190/geo2018-0028.1</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently, there has been significant interest in various supervised machine
learning techniques that can help reduce the time and effort consumed by manual
interpretation workflows. However, most successful supervised machine learning
algorithms require huge amounts of annotated training data. Obtaining these
labels for large seismic volumes is a very time-consuming and laborious task.
We address this problem by presenting a weakly-supervised approach for
predicting the labels of various seismic structures. By having an interpreter
select a very small number of exemplar images for every class of subsurface
structures, we use a novel similarity-based retrieval technique to extract
thousands of images that contain similar subsurface structures from the seismic
volume. By assuming that similar images belong to the same class, we obtain
thousands of image-level labels for these images; we validate this assumption
in our results section. We then introduce a novel weakly-supervised algorithm
for mapping these rough image-level labels into more accurate pixel-level
labels that localize the different subsurface structures within the image. This
approach dramatically simplifies the process of obtaining labeled data for
training supervised machine learning algorithms on seismic interpretation
tasks. Using our method we generate thousands of automatically-labeled images
from the Netherlands Offshore F3 block with reasonably accurate pixel-level
labels. We believe this work will allow for more advances in machine
learning-enabled seismic interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06533</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06533</id><created>2019-05-16</created><updated>2019-05-20</updated><authors><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Mitra</keyname><forenames>Vikramjit</forenames></author><author><keyname>Sivaraman</keyname><forenames>Ganesh</forenames></author><author><keyname>Franco</keyname><forenames>Horacio</forenames></author></authors><title>Articulatory and bottleneck features for speaker-independent ASR of
  dysarthric speech</title><categories>cs.CL cs.SD eess.AS</categories><comments>to appear in Computer Speech &amp; Language -
  https://doi.org/10.1016/j.csl.2019.05.002 - arXiv admin note: substantial
  text overlap with arXiv:1807.10948</comments><doi>10.1016/j.csl.2019.05.002</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The rapid population aging has stimulated the development of assistive
devices that provide personalized medical support to the needies suffering from
various etiologies. One prominent clinical application is a computer-assisted
speech training system which enables personalized speech therapy to patients
impaired by communicative disorders in the patient's home environment. Such a
system relies on the robust automatic speech recognition (ASR) technology to be
able to provide accurate articulation feedback. With the long-term aim of
developing off-the-shelf ASR systems that can be incorporated in clinical
context without prior speaker information, we compare the ASR performance of
speaker-independent bottleneck and articulatory features on dysarthric speech
used in conjunction with dedicated neural network-based acoustic models that
have been shown to be robust against spectrotemporal deviations. We report ASR
performance of these systems on two dysarthric speech datasets of different
characteristics to quantify the achieved performance gains. Despite the
remaining performance gap between the dysarthric and normal speech, significant
improvements have been reported on both datasets using speaker-independent ASR
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06567</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06567</id><created>2019-05-16</created><authors><author><keyname>Liu</keyname><forenames>Jiaying</forenames></author><author><keyname>Xia</keyname><forenames>Sifeng</forenames></author><author><keyname>Yang</keyname><forenames>Wenhan</forenames></author></authors><title>Deep Reference Generation with Multi-Domain Hierarchical Constraints for
  Inter Prediction</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inter prediction is an important module in video coding for temporal
redundancy removal, where similar reference blocks are searched from previously
coded frames and employed to predict the block to be coded. Although
traditional video codecs can estimate and compensate for block-level motions,
their inter prediction performance is still heavily affected by the remaining
inconsistent pixel-wise displacement caused by irregular rotation and
deformation. In this paper, we address the problem by proposing a deep frame
interpolation network to generate additional reference frames in coding
scenarios. First, we summarize the previous adaptive convolutions used for
frame interpolation and propose a factorized kernel convolutional network to
improve the modeling capacity and simultaneously keep its compact form. Second,
to better train this network, multi-domain hierarchical constraints are
introduced to regularize the training of our factorized kernel convolutional
network. For spatial domain, we use a gradually down-sampled and up-sampled
auto-encoder to generate the factorized kernels for frame interpolation at
different scales. For quality domain, considering the inconsistent quality of
the input frames, the factorized kernel convolution is modulated with
quality-related features to learn to exploit more information from high quality
frames. For frequency domain, a sum of absolute transformed difference loss
that performs frequency transformation is utilized to facilitate network
optimization from the view of coding performance. With the well-designed frame
interpolation network regularized by multi-domain hierarchical constraints, our
method surpasses HEVC on average 6.1% BD-rate saving and up to 11.0% BD-rate
saving for the luma component under the random access configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06568</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06568</id><created>2019-05-16</created><updated>2019-05-20</updated><authors><author><keyname>Hernandez-Ortega</keyname><forenames>Javier</forenames></author><author><keyname>Nagae</keyname><forenames>Shigenori</forenames></author><author><keyname>Fierrez</keyname><forenames>Julian</forenames></author><author><keyname>Morales</keyname><forenames>Aythami</forenames></author></authors><title>Quality-based Pulse Estimation from NIR Face Video with Application to
  Driver Monitoring</title><categories>cs.CV eess.IV eess.SP</categories><comments>Preprint of the paper presented to IbPRIA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a robust for heart rate (HR) estimation method using
face video for challenging scenarios with high variability sources such as head
movement, illumination changes, vibration, blur, etc. Our method employs a
quality measure Q to extract a remote Plethysmography (rPPG) signal as clean as
possible from a specific face video segment. Our main motivation is developing
robust technology for driver monitoring. Therefore, for our experiments we use
a self-collected dataset consisting of Near Infrared (NIR) videos acquired with
a camera mounted in the dashboard of a real moving car. We compare the
performance of a classic rPPG algorithm, and the performance of the same
method, but using Q for selecting which video segments present a lower amount
of variability. Our results show that using the video segments with the highest
quality in a realistic driving setup improves the HR estimation with a relative
accuracy improvement larger than 20%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06598</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06598</id><created>2019-05-16</created><updated>2019-12-16</updated><authors><author><keyname>Henter</keyname><forenames>Gustav Eje</forenames></author><author><keyname>Alexanderson</keyname><forenames>Simon</forenames></author><author><keyname>Beskow</keyname><forenames>Jonas</forenames></author></authors><title>MoGlow: Probabilistic and controllable motion synthesis using
  normalising flows</title><categories>cs.LG cs.GR eess.IV stat.ML</categories><comments>12 pages, 7 figures</comments><acm-class>I.3.7; G.3; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven modelling and synthesis of motion is an active research area with
applications that include animation, games, and social robotics. This paper
introduces a new class of probabilistic, generative, and controllable
motion-data models based on normalising flows. Models of this kind can describe
highly complex distributions, yet can be trained efficiently using exact
maximum likelihood, unlike GANs or VAEs. Our proposed model is autoregressive
and uses LSTMs to enable arbitrarily long time-dependencies. Importantly, is is
also causal, meaning that each pose in the output sequence is generated without
access to poses or control inputs from future time steps; this absence of
algorithmic latency is important for interactive applications with real-time
motion control. The approach can in principle be applied to any type of motion
since it does not make restrictive assumptions such as the motion being cyclic
in nature. We evaluate the models on motion-capture datasets of human and
quadruped locomotion. Objective and subjective results show that
randomly-sampled motion from the proposed method attains a motion quality close
to recorded motion capture for both humans and animals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06655</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06655</id><created>2019-05-16</created><authors><author><keyname>Shin</keyname><forenames>Joongbo</forenames></author><author><keyname>Lee</keyname><forenames>Yoonhyung</forenames></author><author><keyname>Jung</keyname><forenames>Kyomin</forenames></author></authors><title>Effective Sentence Scoring Method using Bidirectional Language Model for
  Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>submitted to INTERSPEECH 2019, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In automatic speech recognition, many studies have shown performance
improvements using language models (LMs). Recent studies have tried to use
bidirectional LMs (biLMs) instead of conventional unidirectional LMs (uniLMs)
for rescoring the $N$-best list decoded from the acoustic model. In spite of
their theoretical benefits, the biLMs have not given notable improvements
compared to the uniLMs in their experiments. This is because their biLMs do not
consider the interaction between the two directions. In this paper, we propose
a novel sentence scoring method considering the interaction between the past
and the future words on the biLM. Our experimental results on the LibriSpeech
corpus show that the biLM with the proposed sentence scoring outperforms the
uniLM for the $N$-best list rescoring, consistently and significantly in all
experimental conditions. The analysis of WERs by word position demonstrates
that the biLM is more robust than the uniLM especially when a recognized
sentence is short or a misrecognized word is at the beginning of the sentence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06667</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06667</id><created>2019-05-16</created><authors><author><keyname>Kant</keyname><forenames>Shashi</forenames></author><author><keyname>Fodor</keyname><forenames>Gabor</forenames></author><author><keyname>Bengtsson</keyname><forenames>Mats</forenames></author><author><keyname>G&#xf6;ransson</keyname><forenames>Bo</forenames></author><author><keyname>Fischione</keyname><forenames>Carlo</forenames></author></authors><title>Low-Complexity OFDM Spectral Precoding</title><categories>eess.SP</categories><comments>Accepted in IEEE International Workshop on Signal Processing Advances
  in Wireless Communications (SPAWC), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new large-scale mask-compliant spectral precoder
(LS-MSP) for orthogonal frequency division multiplexing systems. In this paper,
we first consider a previously proposed mask-compliant spectral precoding
scheme that utilizes a generic convex optimization solver which suffers from
high computational complexity, notably in large-scale systems. To mitigate the
complexity of computing the LS-MSP, we propose a divide-and-conquer approach
that breaks the original problem into smaller rank 1 quadratic-constraint
problems and each small problem yields closed-form solution. Based on these
solutions, we develop three specialized first-order low-complexity algorithms,
based on 1) projection on convex sets and 2) the alternating direction method
of multipliers. We also develop an algorithm that capitalizes on the
closed-form solutions for the rank 1 quadratic constraints, which is referred
to as 3) semi-analytical spectral precoding. Numerical results show that the
proposed LS-MSP techniques outperform previously proposed techniques in terms
of the computational burden while complying with the spectrum mask. The results
also indicate that 3) typically needs 3 iterations to achieve similar results
as 1) and 2) at the expense of a slightly increased computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06681</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06681</id><created>2019-05-16</created><updated>2019-10-24</updated><authors><author><keyname>Saggese</keyname><forenames>Fabio</forenames></author><author><keyname>Abrardo</keyname><forenames>Andrea</forenames></author><author><keyname>Moretti</keyname><forenames>Marco</forenames></author><author><keyname>Morelli</keyname><forenames>Michele</forenames></author></authors><title>Low Complexity WMMSE Power Allocation In NOMA-FD Systems</title><categories>eess.SP</categories><comments>5 pages conference paper, 3 figures. Submitted on ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of power and channel allocation with the
objective of maximizing the system sum-rate for multicarrier non-orthogonal
multiple access (NOMA) full duplex (FD) systems. Such an allocation problem is
non-convex and, thus, with the goal of designing a low complexity solution, we
propose a scheme based on the minimization of the weighted mean square error,
which achieves performance reasonably close to the optimum and allows to
clearly outperforms a conventional orthogonal multiple access approach.
Numerical results assess the effectiveness of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06683</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06683</id><created>2019-05-16</created><updated>2019-09-05</updated><authors><author><keyname>Wu</keyname><forenames>Hao</forenames></author><author><keyname>Xu</keyname><forenames>Xiangrong</forenames></author><author><keyname>Gao</keyname><forenames>Wenbin</forenames></author></authors><title>Uneven illumination surface defects inspection based on convolutional
  neural network</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surface defect inspection based on machine vision is often affected by uneven
illumination. In order to improve the inspection rate of surface defects
inspection under uneven illumination condition, this paper proposes a method
for detecting surface image defects based on convolutional neural network,
which is based on the adjustment of convolutional neural networks, training
parameters, changing the structure of the network, to achieve the purpose of
accurately identifying various defects. Experimental on defect inspection of
copper strip and steel images shows that the convolutional neural network can
automatically learn features without preprocessing the image, and correct
identification of various types of image defects affected by uneven
illumination, thus overcoming the drawbacks of traditional machine vision
inspection methods under uneven illumination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06700</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06700</id><created>2019-05-16</created><updated>2019-10-04</updated><authors><author><keyname>Tachella</keyname><forenames>Juli&#xe1;n</forenames></author><author><keyname>Altmann</keyname><forenames>Yoann</forenames></author><author><keyname>Mellado</keyname><forenames>Nicolas</forenames></author><author><keyname>McCarthy</keyname><forenames>Aongus</forenames></author><author><keyname>Tobin</keyname><forenames>Rachael</forenames></author><author><keyname>Buller</keyname><forenames>Gerald S.</forenames></author><author><keyname>Tourneret</keyname><forenames>Jean-Yves</forenames></author><author><keyname>McLaughlin</keyname><forenames>Stephen</forenames></author></authors><title>Real-time 3D reconstruction from single-photon lidar data using
  plug-and-play point cloud denoisers</title><categories>eess.IV physics.optics</categories><doi>10.1038/s41467-019-12943-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-photon lidar has emerged as a prime candidate technology for depth
imaging through challenging environments. Until now, a major limitation has
been the significant amount of time required for the analysis of the recorded
data. Here we show a new computational framework for real-time
three-dimensional (3D) scene reconstruction from single-photon data. By
combining statistical models with highly scalable computational tools from the
computer graphics community, we demonstrate 3D reconstruction of complex
outdoor scenes with processing times of the order of 20 ms, where the lidar
data was acquired in broad daylight from distances up to 320 metres. The
proposed method can handle an unknown number of surfaces in each pixel,
allowing for target detection and imaging through cluttered scenes. This
enables robust, real-time target reconstruction of complex moving scenes,
paving the way for single-photon lidar at video rates for practical 3D imaging
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06703</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06703</id><created>2019-05-16</created><authors><author><keyname>Jaafar</keyname><forenames>Wael</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>Dynamics of Quadrotor UAVs for Aerial Networks: An Energy Perspective</title><categories>eess.SP</categories><comments>14 pages, 7 figures, submitted to IEEE Wireless Communications
  Letters (14-May-2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we present a model for quadrotor unmanned aerial vehicles
(UAVs), including control, communication, and wireless charging. In so doing,
we investigate associated energy and battery dynamics. Indeed, energy and
battery expressions are derived by leveraging motors' and battery electrical
models. Through an experiment, their performances are evaluated for different
parameters. The objective is to provide a simple yet practical model of
quadrotor UAV consumed/harvested energy and battery dynamics for researchers
conducting work on energy-efficient aerial networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06717</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06717</id><created>2019-05-16</created><authors><author><keyname>Favory</keyname><forenames>Xavier</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Multi Web Audio Sequencer: Collaborative Music Making</title><categories>cs.SD cs.HC eess.AS</categories><comments>4 pages, 4 figures, short paper of the Web Audio Conference 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent advancements in web-based audio systems have enabled sufficiently
accurate timing control and real-time sound processing capabilities. Numerous
specialized music tools, as well as digital audio workstations, are now
accessible from browsers. Features such as the large accessibility of data and
real-time communication between clients make the web attractive for
collaborative data manipulation. However, this innovative field has yet to
produce effective tools for multiple-user coordination on specialized music
creation tasks. The Multi Web Audio Sequencer is a prototype of an application
for segment-based sequencing of Freesound sound clips, with an emphasis on
seamless remote collaboration. In this work we consider a fixed-grid step
sequencer as a probe for understanding the necessary features of crowd-shared
music creation sessions. This manuscript describes the sequencer and the
functionalities and types of interactions required for effective and attractive
collaboration of remote people during creative music creation activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06723</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06723</id><created>2019-05-16</created><updated>2019-05-18</updated><authors><author><keyname>Wu</keyname><forenames>Yan</forenames></author><author><keyname>Rosca</keyname><forenames>Mihaela</forenames></author><author><keyname>Lillicrap</keyname><forenames>Timothy</forenames></author></authors><title>Deep Compressed Sensing</title><categories>cs.LG eess.SP stat.ML</categories><comments>ICML 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) provides an elegant framework for recovering sparse
signals from compressed measurements. For example, CS can exploit the structure
of natural images and recover an image from only a few random measurements. CS
is flexible and data efficient, but its application has been restricted by the
strong assumption of sparsity and costly reconstruction process. A recent
approach that combines CS with neural network generators has removed the
constraint of sparsity, but reconstruction remains slow. Here we propose a
novel framework that significantly improves both the performance and speed of
signal recovery by jointly training a generator and the optimisation process
for reconstruction via meta-learning. We explore training the measurements with
different objectives, and derive a family of models based on minimising
measurement errors. We show that Generative Adversarial Nets (GANs) can be
viewed as a special case in this family of models. Borrowing insights from the
CS perspective, we develop a novel way of improving GANs using gradient
information from the discriminator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06744</identifier>
 <datestamp>2019-11-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06744</id><created>2019-05-15</created><updated>2019-11-01</updated><authors><author><keyname>Sun</keyname><forenames>Chengyao</forenames></author><author><keyname>Guo</keyname><forenames>Weisi</forenames></author></authors><title>Forecasting Wireless Demand with Extreme Values using Feature Embedding
  in Gaussian Processes</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless traffic prediction is a fundamental enabler to proactive network
optimisation in beyond 5G. Forecasting extreme demand spikes and troughs due to
traffic mobility is essential to avoiding outages and improving energy
efficiency. Current state-of-the-art deep learning forecasting methods
predominantly focus on overall forecast performance and do not offer
probabilistic uncertainty quantification (UQ). Whilst Gaussian Process (GP)
models have UQ capability, it is not able to predict extreme values very well.
Here, we design a feature embedding (FE) kernel for a GP model to forecast
traffic demand with extreme values. Using real 4G base station data, we compare
our FE-GP performance against both conventional naive GPs, ARIMA models, as
well as demonstrate the UQ output. For short-term extreme value prediction, we
demonstrated a 32\% reduction vs. S-ARIMA and 17\% reduction vs. Naive-GP. For
long-term average value prediction, we demonstrated a 21\% reduction vs.
S-ARIMA and 12\% reduction vs. Naive-GP. The FE kernel also enabled us to
create a flexible trade-off between overall forecast accuracy against
peak-trough accuracy. The advantage over neural network (e.g. CNN, LSTM) is
that the probabilistic forecast uncertainty can inform us of the risk of
predictions, as well as the full posterior distribution of the forecast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06791</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06791</id><created>2019-05-13</created><updated>2019-05-21</updated><authors><author><keyname>Ren</keyname><forenames>Yi</forenames></author><author><keyname>Tan</keyname><forenames>Xu</forenames></author><author><keyname>Qin</keyname><forenames>Tao</forenames></author><author><keyname>Zhao</keyname><forenames>Sheng</forenames></author><author><keyname>Zhao</keyname><forenames>Zhou</forenames></author><author><keyname>Liu</keyname><forenames>Tie-Yan</forenames></author></authors><title>Almost Unsupervised Text to Speech and Automatic Speech Recognition</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted by ICML2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text to speech (TTS) and automatic speech recognition (ASR) are two dual
tasks in speech processing and both achieve impressive performance thanks to
the recent advance in deep learning and large amount of aligned speech and text
data. However, the lack of aligned data poses a major practical problem for TTS
and ASR on low-resource languages. In this paper, by leveraging the dual nature
of the two tasks, we propose an almost unsupervised learning method that only
leverages few hundreds of paired data and extra unpaired data for TTS and ASR.
Our method consists of the following components: (1) a denoising auto-encoder,
which reconstructs speech and text sequences respectively to develop the
capability of language modeling both in speech and text domain; (2) dual
transformation, where the TTS model transforms the text $y$ into speech
$\hat{x}$, and the ASR model leverages the transformed pair $(\hat{x},y)$ for
training, and vice versa, to boost the accuracy of the two tasks; (3)
bidirectional sequence modeling, which addresses error propagation especially
in the long speech and text sequence when training with few paired data; (4) a
unified model structure, which combines all the above components for TTS and
ASR based on Transformer model. Our method achieves 99.84% in terms of word
level intelligible rate and 2.68 MOS for TTS, and 11.7% PER for ASR on LJSpeech
dataset, by leveraging only 200 paired speech and text data (about 20 minutes
audio), together with extra unpaired speech and text data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06809</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06809</id><created>2019-05-16</created><authors><author><keyname>Galluzzi</keyname><forenames>Paolo</forenames></author><author><keyname>Longo</keyname><forenames>Edoardo</forenames></author><author><keyname>Redondi</keyname><forenames>Alessandro E. C.</forenames></author><author><keyname>Cesana</keyname><forenames>Matteo</forenames></author></authors><title>Occupancy Estimation Using Low-Cost Wi-Fi Sniffers</title><categories>cs.NI eess.SP</categories><comments>Submitted to Balkancom 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-time measurements on the occupancy status of indoor and outdoor spaces
can be exploited in many scenarios (HVAC and lighting system control, building
energy optimization, allocation and reservation of spaces, etc.). Traditional
systems for occupancy estimation rely on environmental sensors (CO2,
temperature, humidity) or video cameras. In this paper, we depart from such
traditional approaches and propose a novel occupancy estimation system which is
based on the capture of Wi-Fi management packets from users' devices. The
system, implemented on a low-cost ESP8266 microcontroller, leverages a
supervised learning model to adapt to different spaces and transmits occupancy
information through the MQTT protocol to a web-based dashboard. Experimental
results demonstrate the validity of the proposed solution in four different
indoor university spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06810</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06810</id><created>2019-05-08</created><authors><author><keyname>Ghasemi</keyname><forenames>Parnian</forenames></author><author><keyname>Lin</keyname><forenames>Shibin</forenames></author><author><keyname>Rollins</keyname><forenames>Derrick K.</forenames></author><author><keyname>Williams</keyname><forenames>R. Christopher</forenames></author></authors><title>Predicting Dynamic Modulus of Asphalt Mixture Using Data Obtained from
  Indirect Tension Mode of Testing</title><categories>cs.CE eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding stress-strain behavior of asphalt pavement under repetitive
traffic loading is of critical importance to predict pavement performance and
service life. For viscoelastic materials, the stress-strain relationship can be
represented by the dynamic modulus. The dynamic modulus test in indirect
tension mode can be used to measure the modulus of each specific layer of
asphalt pavements using representative samples. Dynamic modulus is a function
of material properties, loading, and environmental conditions. Developing
predictive models for dynamic modulus is efficient and cost effective. This
article focuses on developing an accurate Finite Element (FE) model using
mixture elastic modulus and asphalt binder properties to predict dynamic
modulus of asphalt mix in indirect tension mode. An Artificial Neural Network
(ANN) is used to back-calculate the elastic modulus of asphalt mixtures. The
developed FE model was verified against experimental results of field cores
from nine different pavement sections from five districts in the State of
Minnesota. It is demonstrated that the ANN modeling is a powerful tool to
back-calculate the elastic modulus and FE model is capable of accurately
predicting dynamic modulus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06820</identifier>
 <datestamp>2019-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06820</id><created>2019-05-16</created><authors><author><keyname>Dercksen</keyname><forenames>Koen</forenames></author><author><keyname>Bulten</keyname><forenames>Wouter</forenames></author><author><keyname>Litjens</keyname><forenames>Geert</forenames></author></authors><title>Dealing with Label Scarcity in Computational Pathology: A Use Case in
  Prostate Cancer Classification</title><categories>cs.CV eess.IV</categories><comments>4 pages, 3 figures,MIDL 2019 [arXiv:1907.08612] extended abstract</comments><report-no>MIDL/2019/ExtendedAbstract/SJlq_10N94</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large amounts of unlabelled data are commonplace for many applications in
computational pathology, whereas labelled data is often expensive, both in time
and cost, to acquire. We investigate the performance of unsupervised and
supervised deep learning methods when few labelled data are available. Three
methods are compared: clustering autoencoder latent vectors (unsupervised), a
single layer classifier combined with a pre-trained autoencoder
(semi-supervised), and a supervised CNN. We apply these methods on hematoxylin
and eosin (H&amp;E) stained prostatectomy images to classify tumour versus
non-tumour tissue. Results show that semi-/unsupervised methods have an
advantage over supervised learning when few labels are available. Additionally,
we show that incorporating immunohistochemistry (IHC) stained data provides an
increase in performance over only using H&amp;E.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06851</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06851</id><created>2019-05-15</created><authors><author><keyname>Li</keyname><forenames>Ya-Xin</forenames></author><author><keyname>Yu</keyname><forenames>Wen-Kai</forenames></author><author><keyname>Wang</keyname><forenames>Shuo-Fei</forenames></author></authors><title>Domino successive-deviation ghost imaging</title><categories>eess.IV physics.optics</categories><comments>11 pages, 5 figures</comments><journal-ref>Optics Express 27(24), 35166-35181 (2019)</journal-ref><doi>10.1364/OE.27.035166</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional ghost imaging acquires images via the correlation of the
intensity fluctuations of reference patterns and bucket values, and can even
generate positive-negative images by conditionally averaging partial patterns.
Here, we propose a domino successive-deviation ghost imaging method, which owns
a good image quality comparable to that of differential ghost imaging with
real-time fast computation, and a better robustness in practical scenarios
where measurement noise and the instability of illuminating source coexists.
Furthermore, it happens to generate real-time positive and negative images,
giving a new insight into physical essence of positive-negative ghost image
phenomenon. Both simulation and experimental results have demonstrated the
feasibility of our approach. Therefore, this work complements the theory of
ghost imaging and opens a door to practical applications of real-time
single-pixel imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06860</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06860</id><created>2019-05-14</created><authors><author><keyname>Abdelaziz</keyname><forenames>Ahmed Hussen</forenames></author><author><keyname>Theobald</keyname><forenames>Barry-John</forenames></author><author><keyname>Binder</keyname><forenames>Justin</forenames></author><author><keyname>Fanelli</keyname><forenames>Gabriele</forenames></author><author><keyname>Dixon</keyname><forenames>Paul</forenames></author><author><keyname>Apostoloff</keyname><forenames>Nicholas</forenames></author><author><keyname>Weise</keyname><forenames>Thibaut</forenames></author><author><keyname>Kajareker</keyname><forenames>Sachin</forenames></author></authors><title>Speaker-Independent Speech-Driven Visual Speech Synthesis using
  Domain-Adapted Acoustic Models</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>9 pages, 2 figures, 2 tables</comments><acm-class>I.2.m; I.3.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech-driven visual speech synthesis involves mapping features extracted
from acoustic speech to the corresponding lip animation controls for a face
model. This mapping can take many forms, but a powerful approach is to use deep
neural networks (DNNs). However, a limitation is the lack of synchronized
audio, video, and depth data required to reliably train the DNNs, especially
for speaker-independent models. In this paper, we investigate adapting an
automatic speech recognition (ASR) acoustic model (AM) for the visual speech
synthesis problem. We train the AM on ten thousand hours of audio-only data.
The AM is then adapted to the visual speech synthesis domain using ninety hours
of synchronized audio-visual speech. Using a subjective assessment test, we
compared the performance of the AM-initialized DNN to one with a random
initialization. The results show that viewers significantly prefer animations
generated from the AM-initialized DNN than the ones generated using the
randomly initialized model. We conclude that visual speech synthesis can
significantly benefit from the powerful representation of speech in the ASR
acoustic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06902</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06902</id><created>2019-05-16</created><authors><author><keyname>Ying</keyname><forenames>Xingde</forenames></author><author><keyname>Guo</keyname><forenames>Heng</forenames></author><author><keyname>Ma</keyname><forenames>Kai</forenames></author><author><keyname>Wu</keyname><forenames>Jian</forenames></author><author><keyname>Weng</keyname><forenames>Zhengxin</forenames></author><author><keyname>Zheng</keyname><forenames>Yefeng</forenames></author></authors><title>X2CT-GAN: Reconstructing CT from Biplanar X-Rays with Generative
  Adversarial Networks</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computed tomography (CT) can provide a 3D view of the patient's internal
organs, facilitating disease diagnosis, but it incurs more radiation dose to a
patient and a CT scanner is much more cost prohibitive than an X-ray machine
too. Traditional CT reconstruction methods require hundreds of X-ray
projections through a full rotational scan of the body, which cannot be
performed on a typical X-ray machine. In this work, we propose to reconstruct
CT from two orthogonal X-rays using the generative adversarial network (GAN)
framework. A specially designed generator network is exploited to increase data
dimension from 2D (X-rays) to 3D (CT), which is not addressed in previous
research of GAN. A novel feature fusion method is proposed to combine
information from two X-rays.The mean squared error (MSE) loss and adversarial
loss are combined to train the generator, resulting in a high-quality CT volume
both visually and quantitatively. Extensive experiments on a publicly available
chest CT dataset demonstrate the effectiveness of the proposed method. It could
be a nice enhancement of a low-cost X-ray machine to provide physicians a
CT-like 3D volume in several niche applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.06907</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.06907</id><created>2019-05-16</created><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Su</keyname><forenames>Dan</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Feng</keyname><forenames>Shulin</forenames></author><author><keyname>Ma</keyname><forenames>Dongpeng</forenames></author><author><keyname>Li</keyname><forenames>Na</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Learning discriminative features in sequence training without requiring
  framewise labelled data</title><categories>cs.LG cs.SD eess.AS</categories><comments>Accepted in ICASSP 2019 lecture session</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we try to answer two questions: Can deeply learned features
with discriminative power benefit an ASR system's robustness to acoustic
variability? And how to learn them without requiring framewise labelled
sequence training data? As existing methods usually require knowing where the
labels occur in the input sequence, they have so far been limited to many
real-world sequence learning tasks. We propose a novel method which
simultaneously models both the sequence discriminative training and the feature
discriminative learning within a single network architecture, so that it can
learn discriminative deep features in sequence training that obviates the need
for presegmented training data. Our experiment in a realistic industrial ASR
task shows that, without requiring any specific fine-tuning or additional
complexity, our proposed models have consistently outperformed state-of-the-art
models and significantly reduced Word Error Rate (WER) under all test
conditions, and especially with highest improvements under unseen noise
conditions, by relative 12.94%, 8.66% and 5.80%, showing our proposed models
can generalize better to acoustic variability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07018</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07018</id><created>2019-05-16</created><authors><author><keyname>Dixit</keyname><forenames>Rishabh</forenames></author><author><keyname>Bedi</keyname><forenames>Amrit Singh</forenames></author><author><keyname>Rajawat</keyname><forenames>Ketan</forenames></author></authors><title>Online Learning over Dynamic Graphs via Distributed Proximal Gradient
  Algorithm</title><categories>math.OC cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of tracking the minimum of a time-varying convex
optimization problem over a dynamic graph. Motivated by target tracking and
parameter estimation problems in intermittently connected robotic and sensor
networks, the goal is to design a distributed algorithm capable of handling
non-differentiable regularization penalties. The proposed proximal online
gradient descent algorithm is built to run in a fully decentralized manner and
utilizes consensus updates over possibly disconnected graphs. The performance
of the proposed algorithm is analyzed by developing bounds on its dynamic
regret in terms of the cumulative path length of the time-varying optimum. It
is shown that as compared to the centralized case, the dynamic regret incurred
by the proposed algorithm over $T$ time slots is worse by a factor of $\log(T)$
only, despite the disconnected and time-varying network topology. The empirical
performance of the proposed algorithm is tested on the distributed dynamic
sparse recovery problem, where it is shown to incur a dynamic regret that is
close to that of the centralized algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07039</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07039</id><created>2019-05-16</created><authors><author><keyname>Siddharth</keyname><forenames>Siddharth</forenames></author><author><keyname>Jung</keyname><forenames>Tzyy-Ping</forenames></author><author><keyname>Sejnowski</keyname><forenames>Terrence J.</forenames></author></authors><title>Utilizing Deep Learning Towards Multi-modal Bio-sensing and Vision-based
  Affective Computing</title><categories>cs.LG cs.HC eess.SP stat.ML</categories><comments>Accepted for publication in IEEE Transactions on Affective Computing.
  This version on the arXiv is the updated version of the same manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the use of bio-sensing signals such as electroencephalogram
(EEG), electrocardiogram (ECG), etc. have garnered interest towards
applications in affective computing. The parallel trend of deep-learning has
led to a huge leap in performance towards solving various vision-based research
problems such as object detection. Yet, these advances in deep-learning have
not adequately translated into bio-sensing research. This work applies novel
deep-learning-based methods to various bio-sensing and video data of four
publicly available multi-modal emotion datasets. For each dataset, we first
individually evaluate the emotion-classification performance obtained by each
modality. We then evaluate the performance obtained by fusing the features from
these modalities. We show that our algorithms outperform the results reported
by other studies for emotion/valence/arousal/liking classification on DEAP and
MAHNOB-HCI datasets and set up benchmarks for the newer AMIGOS and DREAMER
datasets. We also evaluate the performance of our algorithms by combining the
datasets and by using transfer learning to show that the proposed method
overcomes the inconsistencies between the datasets. Hence, we do a thorough
analysis of multi-modal affective data from more than 120 subjects and 2,800
trials. Finally, utilizing a convolution-deconvolution network, we propose a
new technique towards identifying salient brain regions corresponding to
various affective states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07058</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07058</id><created>2019-05-16</created><updated>2019-05-20</updated><authors><author><keyname>Sadeghzadehyazdi</keyname><forenames>Nasrin</forenames></author><author><keyname>Batabyal</keyname><forenames>Tamal</forenames></author><author><keyname>Dhar</keyname><forenames>Nibir K.</forenames></author><author><keyname>Familoni</keyname><forenames>B. O.</forenames></author><author><keyname>Iftekharuddin</keyname><forenames>K. M.</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author></authors><title>GlidarCo: gait recognition by 3D skeleton estimation and biometric
  feature correction of flash lidar data</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Gait recognition using noninvasively acquired data has been attracting an
increasing interest in the last decade. Among various modalities of data
sources, it is experimentally found that the data involving skeletal
representation are amenable for reliable feature compaction and fast
processing. Model-based gait recognition methods that exploit features from a
fitted model, like skeleton, are recognized for their view and scale-invariant
properties. We propose a model-based gait recognition method, using sequences
recorded by a single flash lidar. Existing state-of-the-art model-based
approaches that exploit features from high quality skeletal data collected by
Kinect and Mocap are limited to controlled laboratory environments. The
performance of conventional research efforts is negatively affected by poor
data quality. We address the problem of gait recognition under challenging
scenarios, such as lower quality and noisy imaging process of lidar, that
degrades the performance of state-of-the-art skeleton-based systems. We present
GlidarCo to attain high accuracy on gait recognition under the described
conditions. A filtering mechanism corrects faulty skeleton joint measurements,
and robust statistics are integrated to conventional feature moments to encode
the dynamic of the motion. As a comparison, length-based and vector-based
features extracted from the noisy skeletons are investigated for outlier
removal. Experimental results illustrate the efficacy of the proposed
methodology in improving gait recognition given noisy low resolution lidar
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07082</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07082</id><created>2019-05-16</created><updated>2019-09-13</updated><authors><author><keyname>Miao</keyname><forenames>Yuantian</forenames></author><author><keyname>Zhao</keyname><forenames>Ben Zi Hao</forenames></author><author><keyname>Xue</keyname><forenames>Minhui</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Pan</keyname><forenames>Lei</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Kaafar</keyname><forenames>Dali</forenames></author><author><keyname>Xiang</keyname><forenames>Yang</forenames></author></authors><title>The Audio Auditor: Participant-Level Membership Inference in Internet of
  Things Voice Services</title><categories>cs.CR cs.SD eess.AS</categories><comments>Accepted by CCS workshop --- PPML. 4-pages except figures,
  references, and appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice interfaces and assistants implemented by various services have become
increasingly sophisticated, powered by increased availability of data. However,
users' audio data needs to be guarded while enforcing data-protection
regulations, such as the GDPR law and the COPPA law. To check the unauthorized
use of audio data, we propose an audio auditor for users to audit speech
recognition models. Specifically, users can check whether their audio
recordings were used as a member of the model's training dataset or not. In
this paper, we focus our work on a DNN-HMM-based automatic speech recognition
model over the TIMIT audio data. As a proof-of-concept, the success rate of
participant-level membership inference can reach up to 90\% with eight audio
samples per user, resulting in an audio auditor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07094</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07094</id><created>2019-05-16</created><authors><author><keyname>Kourani</keyname><forenames>Ali</forenames></author><author><keyname>Lu</keyname><forenames>Ruochen</forenames></author><author><keyname>Gao</keyname><forenames>Anming</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>A 300-500 MHz Tunable Oscillator Exploiting Ten Overtones in Single
  Lithium Niobate Resonator</title><categories>eess.SP</categories><doi>10.1109/FCS.2019.8856145</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the first voltage-controlled MEMS oscillator (VCMO) based
on a Lithium Niobate (LiNbO3) lateral overtone bulk acoustic resonator (LOBAR).
The VCMO consists of a LOBAR in a closed loop with 2 amplification stages and a
varactor-embedded tunable LC tank. By adjusting the bias voltage applied to the
varactor, the tank can be tuned to change the closed-loop gain and phase
responses of the oscillator so that Barkhausen conditions are satisfied for a
particular resonance mode. The tank is designed to allow the proposed VCMO to
lock to any of the ten overtones ranging from 300 to 500 MHz. Owing to the
high-quality factors of the LiNbO3 LOBAR, the measured VCMO shows a low
close-in phase noise of -100 dBc/Hz at 1 kHz offset from a 300 MHz carrier and
a noise floor of -153 dBc/Hz while consuming 9 mW. With further optimization,
this VCMO can lead to direct radio frequency (RF) synthesis for ultra-low-power
transceivers in multi-mode Internet-of-Things (IoT) nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07097</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07097</id><created>2019-05-16</created><authors><author><keyname>Liang</keyname><forenames>Dequn</forenames></author><author><keyname>Dou</keyname><forenames>Xinyu</forenames></author></authors><title>Discussions on Signal Uncertainty Principle in Shannon Channel Capacity
  Equation and Research on Breaking Shannon Limit Method</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  So far, the transmission rate of digital communication has approached the
theoretical upper limit proposed by Shannon 70 years ago, and the academia and
industry circles are puzzled by the lack of new theories to point out the
direction of further increasing the transmission rate. In this paper, the
completeness of Shannon channel capacity equation is analyzed in the framework
of signal uncertainty principle, which brings the Shannon theory a more solid
physical theoretical basis. Then the theoretical method of breaking through the
Shannon Limit is proposed. Finally, it is proved that the time-shifted
non-orthogonal multi-carrier digital modulation technology which we have
studied for more than 20 years is a practical method to break through the
Shannon Limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07117</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07117</id><created>2019-05-17</created><authors><author><keyname>Yan</keyname><forenames>Han</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>DSP Linearization for Millimeter-Wave All-Digital Receiver Array with
  Low-Resolution ADCs</title><categories>eess.SP</categories><comments>2019 IEEE 20th International Workshop on Signal Processing Advances
  in Wireless Communications (SPAWC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave (mmWave) communications and cell densification are the key
techniques for the future evolution of cellular systems beyond 5G. Although the
current mmWave radio designs are focused on hybrid digital and analog receiver
array architectures, the fully digital architecture is an appealing option due
to its flexibility and support for multi-user multiple-input multiple-output
(MIMO). In order to achieve reasonable power consumption and hardware cost, the
specifications of analog circuits are expected to be compromised, including the
resolution of analog-to-digital converter (ADC) and the linearity of
radio-frequency (RF) front end. Although the state-of-the-art studies focus on
the ADC, the nonlinearity can also lead to severe system performance
degradation when strong input signals introduce inter-modulation distortion
(IMD). The impact of RF nonlinearity becomes more severe with densely deployed
mmWave cells since signal sources closer to the receiver array are more likely
to occur. In this work, we design and analyze the digital IMD compensation
algorithm, and study the relaxation of the required linearity in the RF-chain.
We propose novel algorithms that jointly process digitized samples to recover
amplifier saturation, and relies on beam space operation which reduces the
computational complexity as compared to per-antenna IMD compensation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07136</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07136</id><created>2019-05-17</created><authors><author><keyname>Harada</keyname><forenames>Shota</forenames></author><author><keyname>Hayashi</keyname><forenames>Hideaki</forenames></author><author><keyname>Uchida</keyname><forenames>Seiichi</forenames></author></authors><title>Biosignal Generation and Latent Variable Analysis with Recurrent
  Generative Adversarial Networks</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effectiveness of biosignal generation and data augmentation with
biosignal generative models based on generative adversarial networks (GANs),
which are a type of deep learning technique, was demonstrated in our previous
paper. GAN-based generative models only learn the projection between a random
distribution as input data and the distribution of training data.Therefore, the
relationship between input and generated data is unclear, and the
characteristics of the data generated from this model cannot be controlled.
This study proposes a method for generating time-series data based on GANs and
explores their ability to generate biosignals with certain classes and
characteristics. Moreover, in the proposed method, latent variables are
analyzed using canonical correlation analysis (CCA) to represent the
relationship between input and generated data as canonical loadings. Using
these loadings, we can control the characteristics of the data generated by the
proposed method. The influence of class labels on generated data is analyzed by
feeding the data interpolated between two class labels into the generator of
the proposed GANs. The CCA of the latent variables is shown to be an effective
method of controlling the generated data characteristics. We are able to model
the distribution of the time-series data without requiring domain-dependent
knowledge using the proposed method. Furthermore, it is possible to control the
characteristics of these data by analyzing the model trained using the proposed
method. To the best of our knowledge, this work is the first to generate
biosignals using GANs while controlling the characteristics of the generated
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07144</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07144</id><created>2019-05-17</created><authors><author><keyname>Nakashima</keyname><forenames>Kota</forenames></author><author><keyname>Kamiya</keyname><forenames>Shotaro</forenames></author><author><keyname>Ohtsu</keyname><forenames>Kazuki</forenames></author><author><keyname>Yamamoto</keyname><forenames>Koji</forenames></author><author><keyname>Nishio</keyname><forenames>Takayuki</forenames></author><author><keyname>Morikura</keyname><forenames>Masahiro</forenames></author></authors><title>Deep Reinforcement Learning-Based Channel Allocation for Wireless LANs
  with Graph Convolutional Networks</title><categories>eess.SP cs.LG cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Last year, IEEE 802.11 Extremely High Throughput Study Group (EHT Study
Group) was established to initiate discussions on new IEEE 802.11 features.
Coordinated control methods of the access points (APs) in the wireless local
area networks (WLANs) are discussed in EHT Study Group. The present study
proposes a deep reinforcement learning-based channel allocation scheme using
graph convolutional networks (GCNs). As a deep reinforcement learning method,
we use a well-known method double deep Q-network. In densely deployed WLANs,
the number of the available topologies of APs is extremely high, and thus we
extract the features of the topological structures based on GCNs. We apply GCNs
to a contention graph where APs within their carrier sensing ranges are
connected to extract the features of carrier sensing relationships.
Additionally, to improve the learning speed especially in an early stage of
learning, we employ a game theory-based method to collect the training data
independently of the neural network model. The simulation results indicate that
the proposed method can appropriately control the channels when compared to
extant methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07149</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07149</id><created>2019-05-17</created><updated>2019-06-24</updated><authors><author><keyname>Tsunoo</keyname><forenames>Emiru</forenames></author><author><keyname>Kashiwagi</keyname><forenames>Yosuke</forenames></author><author><keyname>Asakawa</keyname><forenames>Satoshi</forenames></author><author><keyname>Kumakura</keyname><forenames>Toshiyuki</forenames></author></authors><title>End-to-end Adaptation with Backpropagation through WFST for On-device
  Speech Recognition System</title><categories>eess.AS cs.CL cs.SD</categories><comments>accepted for Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An on-device DNN-HMM speech recognition system efficiently works with a
limited vocabulary in the presence of a variety of predictable noise. In such a
case, vocabulary and environment adaptation is highly effective. In this paper,
we propose a novel method of end-to-end (E2E) adaptation, which adjusts not
only an acoustic model (AM) but also a weighted finite-state transducer (WFST).
We convert a pretrained WFST to a trainable neural network and adapt the system
to target environments/vocabulary by E2E joint training with an AM. We
replicate Viterbi decoding with forward--backward neural network computation,
which is similar to recurrent neural networks (RNNs). By pooling output score
sequences, a vocabulary posterior for each utterance is obtained and used for
discriminative loss computation. Experiments using 2--10 hours of
English/Japanese adaptation datasets indicate that the fine-tuning of only
WFSTs and that of only AMs are both comparable to a state-of-the-art adaptation
method, and E2E joint training of the two components achieves the best
recognition performance. We also adapt each language system to the other
language using the adaptation data, and the results show that the proposed
method also works well for language adaptations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07195</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07195</id><created>2019-05-17</created><updated>2019-06-04</updated><authors><author><keyname>Wan</keyname><forenames>Vincent</forenames></author><author><keyname>Chan</keyname><forenames>Chun-an</forenames></author><author><keyname>Kenter</keyname><forenames>Tom</forenames></author><author><keyname>Vit</keyname><forenames>Jakub</forenames></author><author><keyname>Clark</keyname><forenames>Rob</forenames></author></authors><title>CHiVE: Varying Prosody in Speech Synthesis with a Linguistically Driven
  Dynamic Hierarchical Conditional Variational Network</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prosodic aspects of speech signals produced by current text-to-speech
systems are typically averaged over training material, and as such lack the
variety and liveliness found in natural speech. To avoid monotony and averaged
prosody contours, it is desirable to have a way of modeling the variation in
the prosodic aspects of speech, so audio signals can be synthesized in multiple
ways for a given text. We present a new, hierarchically structured conditional
variational autoencoder to generate prosodic features (fundamental frequency,
energy and duration) suitable for use with a vocoder or a generative model like
WaveNet. At inference time, an embedding representing the prosody of a sentence
may be sampled from the variational layer to allow for prosodic variation. To
efficiently capture the hierarchical nature of the linguistic input (words,
syllables and phones), both the encoder and decoder parts of the auto-encoder
are hierarchical, in line with the linguistic structure, with layers being
clocked dynamically at the respective rates. We show in our experiments that
our dynamic hierarchical network outperforms a non-hierarchical
state-of-the-art baseline, and, additionally, that prosody transfer across
sentences is possible by employing the prosody embedding of one sentence to
generate the speech signal of another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07198</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07198</id><created>2019-05-17</created><authors><author><keyname>Gomez</keyname><forenames>Alberto</forenames></author><author><keyname>Schmitz</keyname><forenames>Cornelia</forenames></author><author><keyname>Henningsson</keyname><forenames>Markus</forenames></author><author><keyname>Housden</keyname><forenames>James</forenames></author><author><keyname>Noh</keyname><forenames>Yohan</forenames></author><author><keyname>Zimmer</keyname><forenames>Veronika A.</forenames></author><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Oksuz</keyname><forenames>Ilkay</forenames></author><author><keyname>Toussaint</keyname><forenames>Nicolas</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author><author><keyname>Schnabel</keyname><forenames>Julia A.</forenames></author></authors><title>Mechanically Powered Motion Imaging Phantoms: Proof of Concept</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>Accepted for publication at IEEE EMBC (41st International Engineering
  in Medicine and Biology Conference) 2019</comments><msc-class>68U10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion imaging phantoms are expensive, bulky and difficult to transport and
set-up. The purpose of this paper is to demonstrate a simple approach to the
design of multi-modality motion imaging phantoms that use mechanically stored
energy to produce motion. We propose two phantom designs that use mainsprings
and elastic bands to store energy. A rectangular piece was attached to an axle
at the end of the transmission chain of each phantom, and underwent a rotary
motion upon release of the mechanical motor. The phantoms were imaged with MRI
and US, and the image sequences were embedded in a 1D non linear manifold
(Laplacian Eigenmap) and the spectrogram of the embedding was used to derive
the angular velocity over time. The derived velocities were consistent and
reproducible within a small error. The proposed motion phantom concept showed
great potential for the construction of simple and affordable motion phantoms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07230</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07230</id><created>2019-05-17</created><updated>2019-07-08</updated><authors><author><keyname>Krishnamurthy</keyname><forenames>Vikram</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>How to Calibrate your Adversary's Capabilities? Inverse Filtering for
  Counter-Autonomous Systems</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2956676</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an adversarial Bayesian signal processing problem involving &quot;us&quot;
and an &quot;adversary&quot;. The adversary observes our state in noise; updates its
posterior distribution of the state and then chooses an action based on this
posterior. Given knowledge of &quot;our&quot; state and sequence of adversary's actions
observed in noise, we consider three problems: (i) How can the adversary's
posterior distribution be estimated? Estimating the posterior is an inverse
filtering problem involving a random measure - we formulate and solve several
versions of this problem in a Bayesian setting. (ii) How can the adversary's
observation likelihood be estimated? This tells us how accurate the adversary's
sensors are. We compute the maximum likelihood estimator for the adversary's
observation likelihood given our measurements of the adversary's actions where
the adversary's actions are in response to estimating our state. (iii) How can
the state be chosen by us to minimize the covariance of the estimate of the
adversary's observation likelihood? &quot;Our&quot; state can be viewed as a probe signal
which causes the adversary to act; so choosing the optimal state sequence is an
input design problem. The above questions are motivated by the design of
counter-autonomous systems: given measurements of the actions of a
sophisticated autonomous adversary, how can our counter-autonomous system
estimate the underlying belief of the adversary, predict future actions and
therefore guard against these actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07263</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07263</id><created>2019-05-16</created><authors><author><keyname>Horisaki</keyname><forenames>Ryoichi</forenames></author><author><keyname>Okamoto</keyname><forenames>Yuka</forenames></author><author><keyname>Tanida</keyname><forenames>Jun</forenames></author></authors><title>Single-shot non-invasive three-dimensional imaging through scattering
  media</title><categories>eess.IV physics.optics</categories><doi>10.1364/OL.44.004032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for single-shot three-dimensional imaging through
scattering media with a three-dimensional memory effect. In the proposed
computational process, a captured speckle image is two-dimensionally correlated
with different scales, and the object is three-dimensionally recovered with
three-dimensional phase retrieval. Our method was experimentally demonstrated
with a lensless setup and was compared with a multi-shot approach used in our
previous work [Y. Okamoto, et al., Opt. Lett. 44, 2526-2529 (2019)].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07284</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07284</id><created>2019-05-17</created><authors><author><keyname>Zhang</keyname><forenames>Jinwei</forenames></author><author><keyname>Liu</keyname><forenames>Zhe</forenames></author><author><keyname>Zhang</keyname><forenames>Shun</forenames></author><author><keyname>Zhang</keyname><forenames>Hang</forenames></author><author><keyname>Spincemaille</keyname><forenames>Pascal</forenames></author><author><keyname>Nguyen</keyname><forenames>Thanh D.</forenames></author><author><keyname>Sabuncu</keyname><forenames>Mert R.</forenames></author><author><keyname>Wang</keyname><forenames>Yi</forenames></author></authors><title>Fidelity Imposed Network Edit (FINE) for Solving Ill-Posed Image
  Reconstruction</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning (DL) is increasingly used to solve ill-posed inverse problems
in imaging, such as reconstruction from noisy or incomplete data, as DL offers
advantages over explicit image feature extractions in defining the needed
prior. However, DL typically does not incorporate the precise physics of data
generation or data fidelity. Instead, DL networks are trained to output some
average response to an input. Consequently, DL image reconstruction contains
errors, and may perform poorly when the test data deviates significantly from
the training data, such as having new pathological features. To address this
lack of data fidelity problem in DL image reconstruction, a novel approach,
which we call fidelity-imposed network edit (FINE), is proposed. In FINE, a
pre-trained prior network's weights are modified according to the physical
model, on a test case. Our experiments demonstrate that FINE can achieve
superior performance in two important inverse problems in neuroimaging:
quantitative susceptibility mapping (QSM) and under-sampled reconstruction in
MRI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07286</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07286</id><created>2019-05-17</created><authors><author><keyname>Anantrasirichai</keyname><forenames>Nantheera</forenames></author><author><keyname>Biggs</keyname><forenames>Juliet</forenames></author><author><keyname>Albino</keyname><forenames>Fabien</forenames></author><author><keyname>Bull</keyname><forenames>David</forenames></author></authors><title>A deep learning approach to detecting volcano deformation from satellite
  imagery using synthetic datasets</title><categories>cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Satellites enable widespread, regional or global surveillance of volcanoes
and can provide the first indication of volcanic unrest or eruption. Here we
consider Interferometric Synthetic Aperture Radar (InSAR), which can be
employed to detect surface deformation with a strong statistical link to
eruption. The ability of machine learning to automatically identify signals of
interest in these large InSAR datasets has already been demonstrated, but
data-driven techniques, such as convolutional neutral networks (CNN) require
balanced training datasets of positive and negative signals to effectively
differentiate between real deformation and noise. As only a small proportion of
volcanoes are deforming and atmospheric noise is ubiquitous, the use of machine
learning for detecting volcanic unrest is more challenging. In this paper, we
address this problem using synthetic interferograms to train the AlexNet. The
synthetic interferograms are composed of 3 parts: 1) deformation patterns based
on a Monte Carlo selection of parameters for analytic forward models, 2)
stratified atmospheric effects derived from weather models and 3) turbulent
atmospheric effects based on statistical simulations of correlated noise. The
AlexNet architecture trained with synthetic data outperforms that trained using
real interferograms alone, based on classification accuracy and positive
predictive value (PPV). However, the models used to generate the synthetic
signals are a simplification of the natural processes, so we retrain the CNN
with a combined dataset consisting of synthetic models and selected real
examples, achieving a final PPV of 82%. Although applying atmospheric
corrections to the entire dataset is computationally expensive, it is
relatively simple to apply them to the small subset of positive results. This
further improves the detection performance without a significant increase in
computational burden.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07290</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07290</id><created>2019-05-17</created><authors><author><keyname>Sallab</keyname><forenames>Ahmad El</forenames></author><author><keyname>Sobh</keyname><forenames>Ibrahim</forenames></author><author><keyname>Zahran</keyname><forenames>Mohamed</forenames></author><author><keyname>Essam</keyname><forenames>Nader</forenames></author></authors><title>LiDAR Sensor modeling and Data augmentation with GANs for Autonomous
  driving</title><categories>cs.CV cs.LG cs.RO eess.IV</categories><comments>Accepted at ICML Workshop on AI for Autonomous Driving</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the autonomous driving domain, data collection and annotation from real
vehicles are expensive and sometimes unsafe. Simulators are often used for data
augmentation, which requires realistic sensor models that are hard to formulate
and model in closed forms. Instead, sensors models can be learned from real
data. The main challenge is the absence of paired data set, which makes
traditional supervised learning techniques not suitable. In this work, we
formulate the problem as image translation from unpaired data and employ
CycleGANs to solve the sensor modeling problem for LiDAR, to produce realistic
LiDAR from simulated LiDAR (sim2real). Further, we generate high-resolution,
realistic LiDAR from lower resolution one (real2real). The LiDAR 3D point cloud
is processed in Bird-eye View and Polar 2D representations. The experimental
results show a high potential of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07293</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07293</id><created>2019-05-17</created><authors><author><keyname>Schroeter</keyname><forenames>Julien</forenames></author><author><keyname>Sidorov</keyname><forenames>Kirill</forenames></author><author><keyname>Marshall</keyname><forenames>David</forenames></author></authors><title>Weakly-Supervised Temporal Localization via Occurrence Count Learning</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Accepted at ICML 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel model for temporal detection and localization which allows
the training of deep neural networks using only counts of event occurrences as
training labels. This powerful weakly-supervised framework alleviates the
burden of the imprecise and time-consuming process of annotating event
locations in temporal data. Unlike existing methods, in which localization is
explicitly achieved by design, our model learns localization implicitly as a
byproduct of learning to count instances. This unique feature is a direct
consequence of the model's theoretical properties. We validate the
effectiveness of our approach in a number of experiments (drum hit and piano
onset detection in audio, digit detection in images) and demonstrate
performance comparable to that of fully-supervised state-of-the-art methods,
despite much weaker training requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07302</identifier>
 <datestamp>2019-05-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07302</id><created>2019-05-17</created><authors><author><keyname>Singh</keyname><forenames>Manokamna</forenames></author><author><keyname>Domijan</keyname><forenames>Katarina</forenames></author></authors><title>Comparison of Machine Learning Models in Food Authentication Studies</title><categories>stat.ML cs.LG eess.SP</categories><comments>Accepted for 2019 30th Irish Signals and Systems Conference (ISSC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The underlying objective of food authentication studies is to determine
whether unknown food samples have been correctly labelled. In this paper we
study three near infrared (NIR) spectroscopic datasets from food samples of
different types: meat samples (labelled by species), olive oil samples
(labelled by their geographic origin) and honey samples (labelled as pure or
adulterated by different adulterants). We apply and compare a large number of
classification, dimension reduction and variable selection approaches to these
datasets. NIR data pose specific challenges to classification and variable
selection: the datasets are high - dimensional where the number of cases ($n$)
$&lt;&lt;$ number of features ($p$) and the recorded features are highly serially
correlated. In this paper we carry out comparative analysis of different
approaches and find that partial least squares, a classic tool employed for
these types of data, outperforms all the other approaches considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07432</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07432</id><created>2019-05-17</created><authors><author><keyname>Barina</keyname><forenames>David</forenames></author><author><keyname>Chlubna</keyname><forenames>Tomas</forenames></author><author><keyname>Solony</keyname><forenames>Marek</forenames></author><author><keyname>Dlabaja</keyname><forenames>Drahomir</forenames></author><author><keyname>Zemcik</keyname><forenames>Pavel</forenames></author></authors><title>Evaluation of 4D Light Field Compression Methods</title><categories>eess.IV cs.GR cs.MM</categories><comments>accepted for publication and presentation at the WSCG 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light field data records the amount of light at multiple points in space,
captured e.g. by an array of cameras or by a light-field camera that uses
microlenses. Since the storage and transmission requirements for such data are
tremendous, compression techniques for light fields are gaining momentum in
recent years. Although plenty of efficient compression formats do exist for
still and moving images, only a little research on the impact of these methods
on light field imagery is performed. In this paper, we evaluate the impact of
state-of-the-art image and video compression methods on quality of images
rendered from light field data. The methods include recent video compression
standards, especially AV1 and XVC finalised in 2018. To fully exploit the
potential of common image compression methods on four-dimensional light field
imagery, we have extended these methods into three and four dimensions. In this
paper, we show that the four-dimensional light field data can be compressed
much more than independent still images while maintaining the same visual
quality of a perceived picture. We gradually compare the compression
performance of all image and video compression methods, and eventually answer
the question, &quot;What is the best compression method for light field data?&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07466</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07466</id><created>2019-05-17</created><authors><author><keyname>Motro</keyname><forenames>Michael</forenames></author><author><keyname>Ghosh</keyname><forenames>Joydeep</forenames></author></authors><title>Scaling Data Association for Hypothesis-Oriented MHT</title><categories>eess.SP</categories><comments>To appear in IEEE FUSION 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-hypothesis tracking is a flexible and intuitive approach to tracking
multiple nearby objects. However, the original formulation of its data
association step is widely thought to scale poorly with the number of tracked
objects. We propose enhancements including handling undetected objects and
false measurements without inflating the size of the problem, early stopping
during solution calculation, and providing for sparse or gated input. These
changes collectively improve the computational time and space requirements of
data association so that hundreds or thousands of hypotheses over hundreds of
objects may be considered in real time. A multi-sensor simulation demonstrates
that scaling up the hypothesis count can significantly improve performance in
some applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07469</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07469</id><created>2019-05-16</created><authors><author><keyname>Etienam</keyname><forenames>Clement</forenames></author></authors><title>4D Seismic History Matching Incorporating Unsupervised Learning</title><categories>eess.IV cs.LG math.OC stat.CO</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The work discussed and presented in this paper focuses on the history
matching of reservoirs by integrating 4D seismic data into the inversion
process using machine learning techniques. A new integrated scheme for the
reconstruction of petrophysical properties with a modified Ensemble Smoother
with Multiple Data Assimilation (ES-MDA) in a synthetic reservoir is proposed.
The permeability field inside the reservoir is parametrised with an
unsupervised learning approach, namely K-means with Singular Value
Decomposition (K-SVD). This is combined with the Orthogonal Matching Pursuit
(OMP) technique which is very typical for sparsity promoting regularisation
schemes. Moreover, seismic attributes, in particular, acoustic impedance, are
parametrised with the Discrete Cosine Transform (DCT). This novel combination
of techniques from machine learning, sparsity regularisation, seismic imaging
and history matching aims to address the ill-posedness of the inversion of
historical production data efficiently using ES-MDA. In the numerical
experiments provided, I demonstrate that these sparse representations of the
petrophysical properties and the seismic attributes enables to obtain better
production data matches to the true production data and to quantify the
propagating waterfront better compared to more traditional methods that do not
use comparable parametrisation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07475</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07475</id><created>2019-05-17</created><updated>2019-10-04</updated><authors><author><keyname>Qin</keyname><forenames>Rongjun</forenames></author></authors><title>Automated 3D recovery from very high resolution multi-view satellite
  images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an automated pipeline for processing multi-view satellite
images to 3D digital surface models (DSM). The proposed pipeline performs
automated geo-referencing and generates high-quality densely matched point
clouds. In particular, a novel approach is developed that fuses multiple depth
maps derived by stereo matching to generate high-quality 3D maps. By learning
critical configurations of stereo pairs from sample LiDAR data, we rank the
image pairs based on the proximity of the results to the sample data. Multiple
depth maps derived from individual image pairs are fused with an adaptive 3D
median filter that considers the image spectral similarities. We demonstrate
that the proposed adaptive median filter generally delivers better results in
general as compared to normal median filter, and achieved an accuracy of
improvement of 0.36 meters RMSE in the best case. Results and analysis are
introduced in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07476</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07476</id><created>2019-05-17</created><authors><author><keyname>Qin</keyname><forenames>Rongjun</forenames></author></authors><title>Analysis of critical parameters of satellite stereo image for 3D
  reconstruction and mapping</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although nowadays advanced dense image matching (DIM) algorithms are able to
produce LiDAR (Light Detection And Ranging) comparable dense point clouds from
satellite stereo images, the accuracy and completeness of such point clouds
heavily depend on the geometric parameters of the satellite stereo images. The
intersection angle between two images are normally seen as the most important
one in stereo data acquisition, as the state-of-the-art DIM algorithms work
best on narrow baseline (smaller intersection angle) stereos (E.g. Semi-Global
Matching regards 15-25 degrees as good intersection angle). This factor is in
line with the traditional aerial photogrammetry configuration, as the
intersection angle directly relates to the base-high ratio and texture
distortion in the parallax direction, thus both affecting the horizontal and
vertical accuracy. However, our experiments found that even with very similar
(and good) intersection angles, the same DIM algorithm applied on different
stereo pairs (of the same area) produced point clouds with dramatically
different accuracy as compared to the ground truth LiDAR data. This raises a
very practical question that is often asked by practitioners: what factors
constitute a good satellite stereo pair, such that it produces accurate and
optimal results for mapping purpose? In this work, we provide a comprehensive
analysis on this matter by performing stereo matching over 1,000 satellite
stereo pairs with different acquisition parameters including their intersection
angles, off-nadir angles, sun elevation &amp; azimuth angles, as well as time
differences, thus to offer a thorough answer to this question. This work will
potentially provide a valuable reference to researchers working on multi-view
satellite image reconstruction, as well as industrial practitioners minimizing
costs for high-quality large-scale mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07486</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07486</id><created>2019-05-17</created><authors><author><keyname>Zhang</keyname><forenames>Jiankang</forenames></author><author><keyname>Chen</keyname><forenames>Taihai</forenames></author><author><keyname>Zhong</keyname><forenames>Shida</forenames></author><author><keyname>Wang</keyname><forenames>Jingjing</forenames></author><author><keyname>Zhang</keyname><forenames>Wenbo</forenames></author><author><keyname>Zuo</keyname><forenames>Xin</forenames></author><author><keyname>Maunder</keyname><forenames>Robert G.</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Aeronautical Ad Hoc Networking for the Internet-Above-The-Clouds</title><categories>cs.NI eess.SP</categories><journal-ref>Proceedings of the IEEE ( Volume: 107 , Issue: 5 , May 2019 )</journal-ref><doi>10.1109/JPROC.2019.2909694</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The engineering vision of relying on the ``smart sky&quot; for supporting air
traffic and the ``Internet above the clouds&quot; for in-flight entertainment has
become imperative for the future aircraft industry. Aeronautical ad hoc
Networking (AANET) constitutes a compelling concept for providing broadband
communications above clouds by extending the coverage of Air-to-Ground (A2G)
networks to oceanic and remote airspace via autonomous and self-configured
wireless networking amongst commercial passenger airplanes. The AANET concept
may be viewed as a new member of the family of Mobile ad hoc Networks (MANETs)
in action above the clouds. However, AANETs have more dynamic topologies,
larger and more variable geographical network size, stricter security
requirements and more hostile transmission conditions. These specific
characteristics lead to more grave challenges in aircraft mobility modeling,
aeronautical channel modeling and interference mitigation as well as in network
scheduling and routing. This paper provides an overview of AANET solutions by
characterizing the associated scenarios, requirements and challenges.
Explicitly, the research addressing the key techniques of AANETs, such as their
mobility models, network scheduling and routing, security and interference are
reviewed. Furthermore, we also identify the remaining challenges associated
with developing AANETs and present their prospective solutions as well as open
issues. The design framework of AANETs and the key technical issues are
investigated along with some recent research results. Furthermore, a range of
performance metrics optimized in designing AANETs and a number of
representative multi-objective optimization algorithms are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07497</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07497</id><created>2019-05-17</created><updated>2019-07-23</updated><authors><author><keyname>Bahmaninezhad</keyname><forenames>Fahimeh</forenames></author><author><keyname>Wu</keyname><forenames>Jian</forenames></author><author><keyname>Gu</keyname><forenames>Rongzhi</forenames></author><author><keyname>Zhang</keyname><forenames>Shi-Xiong</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Yu</keyname><forenames>Meng</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>A comprehensive study of speech separation: spectrogram vs waveform
  separation</title><categories>cs.SD cs.LG eess.AS</categories><comments>INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech separation has been studied widely for single-channel close-talk
microphone recordings over the past few years; developed solutions are mostly
in frequency-domain. Recently, a raw audio waveform separation network (TasNet)
is introduced for single-channel data, with achieving high Si-SNR
(scale-invariant source-to-noise ratio) and SDR (source-to-distortion ratio)
comparing against the state-of-the-art solution in frequency-domain. In this
study, we incorporate effective components of the TasNet into a
frequency-domain separation method. We compare both for alternative scenarios.
We introduce a solution for directly optimizing the separation criterion in
frequency-domain networks. In addition to speech separation objective and
subjective measurements, we evaluate the separation performance on a speech
recognition task as well. We study the speech separation problem for far-field
data (more similar to naturalistic audio streams) and develop multi-channel
solutions for both frequency and time-domain separators with utilizing
spectral, spatial and speaker location information. For our experiments, we
simulated multi-channel spatialized reverberate WSJ0-2mix dataset. Our
experimental results show that spectrogram separation can achieve competitive
performance with better network design. Multi-channel framework as well is
shown to improve the single-channel performance relatively up to +35.5% and
+46% in terms of WER and SDR, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07498</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07498</id><created>2019-05-17</created><authors><author><keyname>Chimitt</keyname><forenames>Nicholas</forenames></author><author><keyname>Mao</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Hong</keyname><forenames>Guanzhe</forenames></author><author><keyname>Chan</keyname><forenames>Stanley H.</forenames></author></authors><title>Rethinking Atmospheric Turbulence Mitigation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art atmospheric turbulence image restoration methods utilize
standard image processing tools such as optical flow, lucky region and blind
deconvolution to restore the images. While promising results have been reported
over the past decade, many of the methods are agnostic to the physical model
that generates the distortion. In this paper, we revisit the turbulence
restoration problem by analyzing the reference frame generation and the blind
deconvolution steps in a typical restoration pipeline. By leveraging tools in
large deviation theory, we rigorously prove the minimum number of frames
required to generate a reliable reference for both static and dynamic scenes.
We discuss how a turbulence agnostic model can lead to potential flaws, and how
to configure a simple spatial-temporal non-local weighted averaging method to
generate references. For blind deconvolution, we present a new data-driven
prior by analyzing the distributions of the point spread functions. We
demonstrate how a simple prior can outperform state-of-the-art blind
deconvolution methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07536</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07536</id><created>2019-05-18</created><updated>2019-09-22</updated><authors><author><keyname>Padhee</keyname><forenames>Malhar</forenames></author><author><keyname>Pal</keyname><forenames>Anamitra</forenames></author><author><keyname>Mishra</keyname><forenames>Chetan</forenames></author><author><keyname>Vance</keyname><forenames>Katelynn A.</forenames></author></authors><title>A Fixed-Flexible BESS Allocation Scheme for Transmission Networks
  Considering Uncertainties</title><categories>eess.SP cs.SY math.OC</categories><comments>Accepted for publication in IEEE Transactions on Sustainable Energy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Battery energy storage systems (BESSs) can play a key role in mitigating the
intermittency and uncertainty associated with adding large amounts of renewable
energy to the bulk power system (BPS). Two BESS technologies that have gained
prominence in this regard are Lithium-ion (LI) BESS and Vanadium redox flow
(VRF) BESS. This paper proposes a fixed-flexible BESS allocation scheme that
exploits the complementary characteristics of LI and VRF BESSs to attain
optimal techno-economic benefits in a wind-integrated BPS. Studies carried out
on relatively large transmission networks demonstrate that benefits such as
reduction in system operation cost, wind spillage, voltage fluctuations, and
discounted payback period, can be realized by using the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07543</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07543</id><created>2019-05-18</created><authors><author><keyname>Zhao</keyname><forenames>Zhuang</forenames></author><author><keyname>Bai</keyname><forenames>Lianfa</forenames></author><author><keyname>Han</keyname><forenames>Jing</forenames></author><author><keyname>Yue</keyname><forenames>Jiang</forenames></author></authors><title>High-SNR snapshot multiplex spectrometer with sub-Hadamard-S matrix
  coding</title><categories>eess.IV physics.optics</categories><doi>10.1016/j.optcom.2019.124322</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a robust high signal-to-noise ratio (SNR) snapshot multiplex
spectrometer with sub-Hadamard-S matrix coding. We demonstrated for the first
time that the sub-Hadamard-S matrix coding could provide comparable SNR
improvement with Hadamard-S matrix in Hadamard transform spectrometer (HTS).
Normally, HTS should change the coding mask to obtain a reasonable spectrum
result, causing unexpected time-consuming. An extra imaging path to collect the
light intensity of the aperture is added in this paper. Both light intensity of
the aperture and overlapped spectra are captured within one shot, turning
Hadamard-S matrix coding into sub-Hadamard-S matrix coding. Simulations and
experiments show that the proposed method could obtain comparable SNR
improvement with the traditional HTS, maintaining snapshot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07555</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07555</id><created>2019-05-18</created><authors><author><keyname>Abraham</keyname><forenames>Jens</forenames></author><author><keyname>Ekman</keyname><forenames>Torbj&#xf6;rn</forenames></author></authors><title>Power Inversion of the Massive MIMO Channel</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 2 figures, 40th WIC / IEEE SP Symposium on Information
  Theory in the Benelux (SITB 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel hardening characterises the diminishing influence of small scale
fading on large scale antenna systems. The effective massive MIMO time domain
channel is introduced and applied to a maximum diversity channel with
rectangular power delay profile. This model bounds channel hardening and allows
a proper interpretation from a radio design perspective. The reduced
variability of the effective channel enables power inversion to obtain a
downlink channel that only depends on the large scale fading properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07589</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07589</id><created>2019-05-18</created><authors><author><keyname>Zhang</keyname><forenames>Luyao</forenames></author><author><keyname>Zhao</keyname><forenames>Hui</forenames></author><author><keyname>Pan</keyname><forenames>Gaofeng</forenames></author><author><keyname>Yang</keyname><forenames>Liang</forenames></author><author><keyname>Chen</keyname><forenames>Jiawei</forenames></author></authors><title>Secure Analysis Over Generalized-K Channels</title><categories>eess.SP</categories><comments>1 figure, 3 pages</comments><doi>10.1007/s11432-019-9892-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we adopt the SOP definition in [4] and the simplified model
of [8], and derive a closed-form expression for the proposed SOP over GK fading
channels. To simplify this expression and obtain additional insights, we also
perform an asymptotic analysis of the main link in the high SNR region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07617</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07617</id><created>2019-05-18</created><authors><author><keyname>Byrd</keyname><forenames>Thomas</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Jover</keyname><forenames>Roger Piqueras</forenames></author></authors><title>CSAI: Open-Source Cellular Radio Access Network Security Analysis
  Instrument</title><categories>cs.CR cs.NI eess.SP</categories><comments>6 pages, 6 figures, Submitted to IEEE GLOBECOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents our methodology and toolbox that allows analyzing the
radio access network security of laboratory and commercial 4G and future 5G
cellular networks. We leverage a free open-source software suite that
implements the LTE UE and eNB enabling real-time signaling using software radio
peripherals. We modify the UE software processing stack to act as an LTE packet
collection and examination tool. This is possible because of the openness of
the 3GPP specifications. Hence, we are able to receive and decode LTE downlink
messages for the purpose of analyzing potential security problems of the
standard. This paper shows how to rapidly prototype LTE tools and build a
software-defined radio access network (RAN) analysis instrument for research
and education. Using CSAI, the Cellular RAN Security Analysis Instrument, a
researcher can analyze broadcast and paging messages of cellular networks. CSAI
is also able to test networks to aid in the identification of vulnerabilities
and verify functionality post-remediation. Additionally, we found that it can
crash an eNB which motivates equivalent analyses of commercial network
equipment and its robustness against denial of service attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07624</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07624</id><created>2019-05-18</created><authors><author><keyname>Sokooti</keyname><forenames>Hessam</forenames></author><author><keyname>Saygili</keyname><forenames>Gorkem</forenames></author><author><keyname>Glocker</keyname><forenames>Ben</forenames></author><author><keyname>Lelieveldt</keyname><forenames>Boudewijn P. F.</forenames></author><author><keyname>Staring</keyname><forenames>Marius</forenames></author></authors><title>Quantitative Error Prediction of Medical Image Registration using
  Regression Forests</title><categories>eess.IV cs.LG stat.ML</categories><journal-ref>Medical Image Analysis, 2019, ISSN 1361-8415</journal-ref><doi>10.1016/j.media.2019.05.005</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Predicting registration error can be useful for evaluation of registration
procedures, which is important for the adoption of registration techniques in
the clinic. In addition, quantitative error prediction can be helpful in
improving the registration quality. The task of predicting registration error
is demanding due to the lack of a ground truth in medical images. This paper
proposes a new automatic method to predict the registration error in a
quantitative manner, and is applied to chest CT scans. A random regression
forest is utilized to predict the registration error locally. The forest is
built with features related to the transformation model and features related to
the dissimilarity after registration. The forest is trained and tested using
manually annotated corresponding points between pairs of chest CT scans in two
experiments: SPREAD (trained and tested on SPREAD) and inter-database
(including three databases SPREAD, DIR-Lab-4DCT and DIR-Lab-COPDgene). The
results show that the mean absolute errors of regression are 1.07 $\pm$ 1.86
and 1.76 $\pm$ 2.59 mm for the SPREAD and inter-database experiment,
respectively. The overall accuracy of classification in three classes (correct,
poor and wrong registration) is 90.7% and 75.4%, for SPREAD and inter-database
respectively. The good performance of the proposed method enables important
applications such as automatic quality control in large-scale image analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07686</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07686</id><created>2019-05-18</created><updated>2019-12-16</updated><authors><author><keyname>Raj</keyname><forenames>Raghu G.</forenames></author></authors><title>An Online Stochastic Kernel Machine for Robust Signal Classification</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel variation of online kernel machines in which we exploit a
consensus based optimization mechanism to guide the evolution of decision
functions drawn from a reproducing kernel Hilbert space, which efficiently
models the observed stationary process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07698</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07698</id><created>2019-05-19</created><authors><author><keyname>Guo</keyname><forenames>Mengyu</forenames></author><author><keyname>Wang</keyname><forenames>Pin</forenames></author><author><keyname>Chan</keyname><forenames>Ching-Yao</forenames></author><author><keyname>Askary</keyname><forenames>Sid</forenames></author></authors><title>A Reinforcement Learning Approach for Intelligent Traffic Signal Control
  at Urban Intersections</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ineffective and inflexible traffic signal control at urban intersections can
often lead to bottlenecks in traffic flows and cause congestion, delay, and
environmental problems. How to manage traffic smartly by intelligent signal
control is a significant challenge in urban traffic management. With recent
advances in machine learning, especially reinforcement learning (RL), traffic
signal control using advanced machine learning techniques represents a
promising solution to tackle this problem. In this paper, we propose a RL
approach for traffic signal control at urban intersections. Specifically, we
use neural networks as Q-function approximator (a.k.a. Q-network) to deal with
the complex traffic signal control problem where the state space is large and
the action space can be discrete. The state space is defined based on real-time
traffic information, i.e. vehicle position, direction and speed. The action
space includes various traffic signal phases which are critical in generating a
reasonable and realistic control mechanism, given the prominent
spatial-temporal characteristics of urban traffic. In the simulation
experiment, we use SUMO, an open source traffic simulator, to construct
realistic urban intersection settings. Moreover, we use different traffic
patterns, such as major/minor road traffic, through/left-turn lane traffic,
tidal traffic, and varying demand traffic, to train a generalized traffic
signal control model that can be adapted to various traffic conditions. The
simulation results demonstrate the convergence and generalization performance
of our RL approach as well as its significant benefits in terms of queue length
and wait time over several benchmarking methods in traffic signal control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07709</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07709</id><created>2019-05-19</created><updated>2019-05-25</updated><authors><author><keyname>Kiaei</keyname><forenames>Ali A.</forenames></author><author><keyname>Khotanlou</keyname><forenames>Hassan</forenames></author><author><keyname>Abbasi</keyname><forenames>Mahdi</forenames></author><author><keyname>Kiaei</keyname><forenames>Paniz</forenames></author><author><keyname>Bhrouzi</keyname><forenames>Yasin</forenames></author></authors><title>An Objective Evaluation Metric for image fusion based on Del Operator</title><categories>eess.IV cs.CV</categories><comments>22 pages, 14 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel objective evaluation metric for image fusion is
presented. Remarkable and attractive points of the proposed metric are that it
has no parameter, the result is probability in the range of [0, 1] and it is
free from illumination dependence. This metric is easy to implement and the
result is computed in four steps: (1) Smoothing the images using Gaussian
filter. (2) Transforming images to a vector field using Del operator. (3)
Computing the normal distribution function ({\mu},{\sigma}) for each
corresponding pixel, and converting to the standard normal distribution
function. (4) Computing the probability of being well-behaved fusion method as
the result. To judge the quality of the proposed metric, it is compared to
thirteen well-known non-reference objective evaluation metrics, where eight
fusion methods are employed on seven experiments of multimodal medical images.
The experimental results and statistical comparisons show that in contrast to
the previously objective evaluation metrics the proposed one performs better in
terms of both agreeing with human visual perception and evaluating fusion
methods that are not performed at the same level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07710</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07710</id><created>2019-05-19</created><authors><author><keyname>Vesal</keyname><forenames>Sulaiman</forenames></author><author><keyname>Ravikumar</keyname><forenames>Nishant</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>A 2D dilated residual U-Net for multi-organ segmentation in thoracic CT</title><categories>cs.CV eess.IV</categories><comments>ISBI-SegTHOR 2019 Challenge</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic segmentation of organs-at-risk (OAR) in computed tomography (CT) is
an essential part of planning effective treatment strategies to combat lung and
esophageal cancer. Accurate segmentation of organs surrounding tumours helps
account for the variation in position and morphology inherent across patients,
thereby facilitating adaptive and computer-assisted radiotherapy. Although
manual delineation of OARs is still highly prevalent, it is prone to errors due
to complex variations in the shape and position of organs across patients, and
low soft tissue contrast between neighbouring organs in CT images. Recently,
deep convolutional neural networks (CNNs) have gained tremendous traction and
achieved state-of-the-art results in medical image segmentation. In this paper,
we propose a deep learning framework to segment OARs in thoracic CT images,
specifically for the: heart, esophagus, trachea and aorta. Our approach employs
dilated convolutions and aggregated residual connections in the bottleneck of a
U-Net styled network, which incorporates global context and dense information.
Our method achieved an overall Dice score of 91.57% on 20 unseen test samples
from the ISBI 2019 SegTHOR challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07722</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07722</id><created>2019-05-19</created><authors><author><keyname>Mohammad</keyname><forenames>Hadeel</forenames></author><author><keyname>Shubair</keyname><forenames>Raed M.</forenames></author></authors><title>Nanoscale Communication: State-of-Art and Recent Advances</title><categories>eess.SP</categories><comments>15 pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The engineering community is witnessing a new frontier in the communication
industry. Among others, the tools provided by nanotechnologies enable the
development of novel nanosensors and nanomachines. On the one hand, nanosensors
are capable of detecting events with unprecedented accuracy. On the other hand,
nanomachines are envisioned to accomplish tasks ranging from computing and data
storing to sensing and actuation. Recently, in vivo wireless nanosensor
networks (iWNSNs) have been presented to provide fast and accurate disease
diagnosis and treatment. These networks are capable of operating inside the
human body in real time and will be of great benefit for medical monitoring and
medical implant communication. Despite the fact that nanodevice technology has
been witnessing great advancements, enabling the communication among
nanomachines is still a major challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07792</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07792</id><created>2019-05-19</created><authors><author><keyname>Jacobsson</keyname><forenames>Sven</forenames></author><author><keyname>Lindquist</keyname><forenames>Carl</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Eriksson</keyname><forenames>Thomas</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Timing and Frequency Synchronization for 1-bit Massive MU-MIMO-OFDM
  Downlink</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider timing and frequency synchronization for the massive multiuser
(MU) multiple-input multiple-output (MIMO) downlink where 1-bit
digital-to-analog converters (DACs) are used at the base station (BS). We focus
on the practically relevant scenario in which orthogonal-frequency division
multiplexing (OFDM) is used to communicate over frequency-selective channels.
Our contributions are twofold. First, we use Bussgang's theorem to analyze the
impact on performance caused by timing and frequency offsets in the presence of
1-bit DACs at the BS. Second, we demonstrate the efficacy of the widely used
Schmidl-Cox synchronization algorithm. Our results demonstrate that the 1-bit
massive MU-MIMO-OFDM downlink is resilient against timing and frequency
offsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07813</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07813</id><created>2019-05-19</created><updated>2019-09-10</updated><authors><author><keyname>Preti</keyname><forenames>Maria Giulia</forenames></author><author><keyname>Van De Ville</keyname><forenames>Dimitri</forenames></author></authors><title>Decoupling of brain function from structure reveals regional behavioral
  specialization in humans</title><categories>q-bio.NC eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The brain is an assembly of neuronal populations interconnected by structural
pathways. Brain activity is expressed on and constrained by this substrate.
Therefore, statistical dependencies between functional signals in directly
connected areas can be expected higher. However, the degree to which brain
function is bound by the underlying wiring diagram remains a complex question
that has been only partially answered. Here, we introduce the
structural-decoupling index to quantify the coupling strength between structure
and function, and we reveal a macroscale gradient from brain regions more
strongly coupled, to regions more strongly decoupled, than expected by
realistic surrogate data. This gradient spans behavioral domains from
lower-level sensory function to high-level cognitive ones and shows for the
first time that the strength of structure-function coupling is spatially
varying in line with evidence derived from other modalities, such as functional
connectivity, gene expression, microstructural properties and temporal
hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07877</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07877</id><created>2019-05-20</created><authors><author><keyname>Kolos</keyname><forenames>Maria</forenames></author><author><keyname>Marin</keyname><forenames>Anton</forenames></author><author><keyname>Artemov</keyname><forenames>Alexey</forenames></author><author><keyname>Burnaev</keyname><forenames>Evgeny</forenames></author></authors><title>Procedural Synthesis of Remote Sensing Images for Robust Change
  Detection with Neural Networks</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>17 pages, 11 figures</comments><journal-ref>16th International Symposium on Neural Networks, ISNN 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-driven methods such as convolutional neural networks (CNNs) are known to
deliver state-of-the-art performance on image recognition tasks when the
training data are abundant. However, in some instances, such as change
detection in remote sensing images, annotated data cannot be obtained in
sufficient quantities. In this work, we propose a simple and efficient method
for creating realistic targeted synthetic datasets in the remote sensing
domain, leveraging the opportunities offered by game development engines. We
provide a description of the pipeline for procedural geometry generation and
rendering as well as an evaluation of the efficiency of produced datasets in a
change detection scenario. Our evaluations demonstrate that our pipeline helps
to improve the performance and convergence of deep learning models when the
amount of real-world data is severely limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07880</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07880</id><created>2019-05-20</created><updated>2019-08-07</updated><authors><author><keyname>Scheibler</keyname><forenames>Robin</forenames></author><author><keyname>Ono</keyname><forenames>Nobutaka</forenames></author></authors><title>Independent Vector Analysis with more Microphones than Sources</title><categories>cs.SD eess.AS</categories><comments>Accepted to WASPAA 2019, 5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend frequency-domain blind source separation based on independent
vector analysis to the case where there are more microphones than sources. The
signal is modelled as non-Gaussian sources in a Gaussian background. The
proposed algorithm is based on a parametrization of the demixing matrix
decreasing the number of parameters to estimate. Furthermore, orthogonal
constraints between the signal and background subspaces are imposed to
regularize the separation. The problem can then be posed as a constrained
likelihood maximization. We propose efficient alternating updates guaranteed to
converge to a stationary point of the cost function. The performance of the
algorithm is assessed on simulated signals. We find that the separation
performance is on par with that of the conventional determined algorithm at a
fraction of the computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07918</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07918</id><created>2019-05-20</created><authors><author><keyname>Bonnard</keyname><forenames>Jennifer</forenames><affiliation>CRESTIC</affiliation></author><author><keyname>Valette</keyname><forenames>Gilles</forenames><affiliation>CRESTIC</affiliation></author><author><keyname>Loscos</keyname><forenames>C&#xe9;line</forenames><affiliation>CRESTIC</affiliation></author></authors><title>Disparity-based HDR imaging</title><categories>cs.CV eess.IV</categories><comments>Digital Image &amp; Signal Processing, Apr 2019, St Hugh's College,
  Oxford University, United Kingdom, United Kingdom</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-dynamic range imaging permits to extend the dynamic range of intensity
values to get close to what the human eye is able to perceive. Although there
has been a huge progress in the digital camera sensor range capacity, the need
of capturing several exposures in order to reconstruct high-dynamic range
values persist. In this paper, we present a study on how to acquire
high-dynamic range values for multi-stereo images. In many papers, disparity
has been used to register pixels of different images and guide the
reconstruction. In this paper, we show the limitations of such approaches and
propose heuristics as solutions to identified problematic cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07920</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07920</id><created>2019-05-20</created><updated>2019-05-30</updated><authors><author><keyname>Guo</keyname><forenames>Huayan</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Weighted Sum-Rate Optimization for Intelligent Reflecting Surface
  Enhanced Wireless Networks</title><categories>eess.SP</categories><comments>13 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) is a promising solution to build a
programmable wireless environment for future communication systems. In
practice, an IRS consists of massive low-cost elements, which can steer the
incident signal in fully customizable ways by passive beamforming. In this
paper, we consider an IRS-aided multiuser multiple-input single-output (MISO)
downlink communication system. In particular, the weighted sum-rate of all
users is maximized by joint optimizing the active beamforming at the
base-station (BS) and the passive beamforming at the IRS. In addition, we
consider a practical IRS assumption, in which the passive elements can only
shift the incident signal to discrete phase levels. This non-convex problem is
firstly decoupled via Lagrangian dual transform, and then the active and
passive beamforming can be optimized alternatingly. The active beamforming at
BS is optimized based on the fractional programming method. Then, three
efficient algorithms with closed-form expressions are proposed for the passive
beamforming at IRS. Simulation results have verified the effectiveness of the
proposed algorithms as compared to different benchmark schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07923</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07923</id><created>2019-05-20</created><authors><author><keyname>Morin</keyname><forenames>Cyrille</forenames><affiliation>MARACAS</affiliation></author><author><keyname>Cardoso</keyname><forenames>Leonardo</forenames><affiliation>MARACAS</affiliation></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames><affiliation>MARACAS</affiliation></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames><affiliation>MARACAS</affiliation></author><author><keyname>Vial</keyname><forenames>Thibaud</forenames></author></authors><title>Transmitter Classification With Supervised Deep Learning</title><categories>eess.SP cs.LG cs.NE</categories><proxy>ccsd</proxy><journal-ref>Crowncom, Jun 2019, Poznan, Poland</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hardware imperfections in RF transmitters introduce features that can be used
to identify a specific transmitter amongst others. Supervised deep learning has
shown good performance in this task but using datasets not applicable to real
world situations where topologies evolve over time. To remedy this, the work
rests on a series of datasets gathered in the Future Internet of Things /
Cognitive Radio Testbed [4] (FIT/CorteXlab) to train a convolutional neural
network (CNN), where focus has been given to reduce channel bias that has
plagued previous works and constrained them to a constant environment or to
simulations. The most challenging scenarios provide the trained neural network
with resilience and show insight on the best signal type to use for
identification , namely packet preamble. The generated datasets are published
on the Machine Learning For Communications Emerging Technologies Initiatives
web site 4 in the hope that they serve as stepping stones for future progress
in the area. The community is also invited to reproduce the studied scenarios
and results by generating new datasets in FIT/CorteXlab.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07948</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07948</id><created>2019-05-20</created><updated>2019-08-22</updated><authors><author><keyname>He</keyname><forenames>Zhen-Qing</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author></authors><title>Cascaded Channel Estimation for Large Intelligent Metasurface Assisted
  Massive MIMO</title><categories>cs.IT eess.SP math.IT</categories><comments>3 figures, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider the problem of channel estimation for large
intelligent metasurface (LIM) assisted massive multiple-input multiple-output
(MIMO) systems. The main challenge of this problem is that the LIM integrated
with a large number of low-cost metamaterial antennas can only passively
reflect the incident signal by a certain phase shift, and does not have any
signal processing capability. To deal with this, we introduce a general
framework for the estimation of the transmitter-LIM and LIM-receiver cascaded
channel, and propose a two-stage algorithm that includes a sparse matrix
factorization stage and a matrix completion stage. Simulation results
illustrate that the proposed method can achieve accurate channel estimation for
LIM-assisted massive MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07954</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07954</id><created>2019-05-20</created><authors><author><keyname>Sahu</keyname><forenames>Nitesh</forenames></author><author><keyname>Babu</keyname><forenames>Prabhu</forenames></author><author><keyname>Kumar</keyname><forenames>Arun</forenames></author><author><keyname>Bahl</keyname><forenames>Rajendar</forenames></author></authors><title>A novel Algorithm for Optimal Placement of Multiple Inertial Sensors to
  Improve the Sensing Accuracy</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2957639</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel algorithm to determine the optimal placement of
redundant inertial sensors such as accelerometers and gyroscopes (gyros) for
increasing the sensing accuracy. In this paper, we have proposed a novel
iterative algorithm to find the optimal sensor configuration. The proposed
algorithm utilizes the majorization-minimization (MM) algorithm and the duality
principle to find the optimal configuration. Unlike the state-of-the-art which
are mainly geometrical in nature and restricted to certain noise statistics,
the proposed algorithm gives the exact positions of the sensors, and moreover,
the proposed algorithm is independent of the nature of the noise at different
sensors. The proposed alogrithm has been implemented and tested via numerical
simulation in the MATLAB. The simulation results show that the algorithm
converges to the optimal configurations and show the effectiveness of the
proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07984</identifier>
 <datestamp>2020-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07984</id><created>2019-05-20</created><updated>2020-02-12</updated><authors><author><keyname>Sidorov</keyname><forenames>Oleksii</forenames></author><author><keyname>Pedersen</keyname><forenames>Marius</forenames></author><author><keyname>Kim</keyname><forenames>Nam Wook</forenames></author><author><keyname>Shekhar</keyname><forenames>Sumit</forenames></author></authors><title>Are all the frames equally important?</title><categories>cs.HC eess.IV</categories><comments>CHI'20 Late Breaking Works</comments><doi>10.1145/3334480.3382980</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this work, we address the problem of measuring and predicting temporal
video saliency - a metric which defines the importance of a video frame for
human attention. Unlike the conventional spatial saliency which defines the
location of the salient regions within a frame (as it is done for still
images), temporal saliency considers importance of a frame as a whole and may
not exist apart from context. The proposed interface is an interactive
cursor-based algorithm for collecting experimental data about temporal
saliency. We collect the first human responses and perform their analysis. As a
result, we show that qualitatively, the produced scores have very explicit
meaning of the semantic changes in a frame, while quantitatively being highly
correlated between all the observers. Apart from that, we show that the
proposed tool can simultaneously collect fixations similar to the ones produced
by eye-tracker in a more affordable way. Further, this approach may be used for
creation of first temporal saliency datasets which will allow training
computational predictive algorithms. The proposed interface does not rely on
any special equipment, which allows to run it remotely and cover a wide
audience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.07991</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.07991</id><created>2019-05-20</created><authors><author><keyname>Gessert</keyname><forenames>Nils</forenames></author><author><keyname>Bengs</keyname><forenames>Marcel</forenames></author><author><keyname>Wittig</keyname><forenames>Lukas</forenames></author><author><keyname>Dr&#xf6;mann</keyname><forenames>Daniel</forenames></author><author><keyname>Keck</keyname><forenames>Tobias</forenames></author><author><keyname>Schlaefer</keyname><forenames>Alexander</forenames></author><author><keyname>Ellebrecht</keyname><forenames>David B.</forenames></author></authors><title>Deep Transfer Learning Methods for Colon Cancer Classification in
  Confocal Laser Microscopy Images</title><categories>cs.CV eess.IV</categories><comments>Accepted for publication in the International Journal of Computer
  Assisted Radiology and Surgery (IJCARS)</comments><doi>10.1007/s11548-019-02004-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: The gold standard for colorectal cancer metastases detection in the
peritoneum is histological evaluation of a removed tissue sample. For feedback
during interventions, real-time in-vivo imaging with confocal laser microscopy
has been proposed for differentiation of benign and malignant tissue by manual
expert evaluation. Automatic image classification could improve the surgical
workflow further by providing immediate feedback.
  Methods: We analyze the feasibility of classifying tissue from confocal laser
microscopy in the colon and peritoneum. For this purpose, we adopt both
classical and state-of-the-art convolutional neural networks to directly learn
from the images. As the available dataset is small, we investigate several
transfer learning strategies including partial freezing variants and full
fine-tuning. We address the distinction of different tissue types, as well as
benign and malignant tissue.
  Results: We present a thorough analysis of transfer learning strategies for
colorectal cancer with confocal laser microscopy. In the peritoneum, metastases
are classified with an AUC of 97.1 and in the colon, the primarius is
classified with an AUC of 73.1. In general, transfer learning substantially
improves performance over training from scratch. We find that the optimal
transfer learning strategy differs for models and classification tasks.
  Conclusions: We demonstrate that convolutional neural networks and transfer
learning can be used to identify cancer tissue with confocal laser microscopy.
We show that there is no generally optimal transfer learning strategy and model
as well as task-specific engineering is required. Given the high performance
for the peritoneum, even with a small dataset, application for intraoperative
decision support could be feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08008</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08008</id><created>2019-05-20</created><authors><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>Li</keyname><forenames>Jianwu</forenames></author><author><keyname>Song</keyname><forenames>Ge</forenames></author><author><keyname>Li</keyname><forenames>Tieling</forenames></author></authors><title>Less Memory, Faster Speed: Refining Self-Attention Module for Image
  Reconstruction</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-attention (SA) mechanisms can capture effectively global dependencies in
deep neural networks, and have been applied to natural language processing and
image processing successfully. However, SA modules for image reconstruction
have high time and space complexity, which restrict their applications to
higher-resolution images. In this paper, we refine the SA module in
self-attention generative adversarial networks (SAGAN) via adapting a non-local
operation, revising the connectivity among the units in SA module and
re-implementing its computational pattern, such that its time and space
complexity is reduced from $\text{O}(n^2)$ to $\text{O}(n)$, but it is still
equivalent to the original SA module. Further, we explore the principles behind
the module and discover that our module is a special kind of channel attention
mechanisms. Experimental results based on two benchmark datasets of image
reconstruction, verify that under the same computational environment, two
models can achieve comparable effectiveness for image reconstruction, but the
proposed one runs faster and takes up less memory space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08054</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08054</id><created>2019-05-16</created><authors><author><keyname>Zhang</keyname><forenames>Xiwen</forenames></author><author><keyname>Seyfi</keyname><forenames>Tolunay</forenames></author><author><keyname>Ju</keyname><forenames>Shengtai</forenames></author><author><keyname>Ramjee</keyname><forenames>Sharan</forenames></author><author><keyname>Gamal</keyname><forenames>Aly El</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Deep Learning for Interference Identification: Band, Training SNR, and
  Sample Selection</title><categories>eess.SP cs.LG stat.ML</categories><comments>5 pages, 8 figures, In Proc. IEEE International Workshop on Signal
  Processing Advances in Wireless Communications (SPAWC) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of interference source identification, through the lens
of recognizing one of 15 different channels that belong to 3 different wireless
technologies: Bluetooth, Zigbee, and WiFi. We employ deep learning algorithms
trained on received samples taken from a 10 MHz band in the 2.4 GHz ISM Band.
We obtain a classification accuracy of around 89.5% using any of four different
deep neural network architectures: CNN, ResNet, CLDNN, and LSTM, which
demonstrate the generality of the effectiveness of deep learning at the
considered task. Interestingly, our proposed CNN architecture requires
approximately 60% of the training time required by the state of the art while
achieving slightly larger classification accuracy. We then focus on the CNN
architecture and further optimize its training time while incurring minimal
loss in classification accuracy using three different approaches: 1- Band
Selection, where we only use samples belonging to the lower and uppermost 2 MHz
bands, 2- SNR Selection, where we only use training samples belonging to a
single SNR value, and 3- Sample Selection, where we try various sub-Nyquist
sampling methods to select the subset of samples most relevant to the
classification task. Our results confirm the feasibility of fast deep learning
for wireless interference identification, by showing that the training time can
be reduced by as much as 30x with minimal loss in accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08059</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08059</id><created>2019-05-16</created><authors><author><keyname>Olesen</keyname><forenames>Alexander Neergaard</forenames></author><author><keyname>Chambon</keyname><forenames>Stanislas</forenames></author><author><keyname>Thorey</keyname><forenames>Valentin</forenames></author><author><keyname>Jennum</keyname><forenames>Poul</forenames></author><author><keyname>Mignot</keyname><forenames>Emmanuel</forenames></author><author><keyname>Sorensen</keyname><forenames>Helge B. D.</forenames></author></authors><title>Towards a Flexible Deep Learning Method for Automatic Detection of
  Clinically Relevant Multi-Modal Events in the Polysomnogram</title><categories>eess.SP cs.LG stat.ML</categories><comments>Accepted for publication in 41st International Engineering in
  Medicine and Biology Conference (EMBC), July 23-27, 2019</comments><doi>10.1109/EMBC.2019.8856570</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much attention has been given to automatic sleep staging algorithms in past
years, but the detection of discrete events in sleep studies is also crucial
for precise characterization of sleep patterns and possible diagnosis of sleep
disorders. We propose here a deep learning model for automatic detection and
annotation of arousals and leg movements. Both of these are commonly seen
during normal sleep, while an excessive amount of either is linked to disrupted
sleep patterns, excessive daytime sleepiness impacting quality of life, and
various sleep disorders. Our model was trained on 1,485 subjects and tested on
1,000 separate recordings of sleep. We tested two different experimental setups
and found optimal arousal detection was attained by including a recurrent
neural network module in our default model with a dynamic default event window
(F1 = 0.75), while optimal leg movement detection was attained using a static
event window (F1 = 0.65). Our work show promise while still allowing for
improvements. Specifically, future research will explore the proposed model as
a general-purpose sleep analysis model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08061</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08061</id><created>2019-05-16</created><updated>2019-12-05</updated><authors><author><keyname>AlMomani</keyname><forenames>Abd AlRahman R.</forenames></author><author><keyname>Sun</keyname><forenames>Jie</forenames></author><author><keyname>Bollt</keyname><forenames>Erik</forenames></author></authors><title>How Entropic Regression Beats the Outliers Problem in Nonlinear System
  Identification</title><categories>eess.SP cs.IT math.IT nlin.CD physics.data-an</categories><doi>10.1063/1.5133386</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we developed a nonlinear System Identification (SID) method
that we called Entropic Regression. Our method adopts an information-theoretic
measure for the data-driven discovery of the underlying dynamics. Our method
shows robustness toward noise and outliers and it outperforms many of the
current state-of-the-art methods. Moreover, the method of Entropic Regression
overcomes many of the major limitations of the current methods such as sloppy
parameters, diverse scale, and SID in high dimensional systems such as complex
networks. The use of information-theoretic measures in entropic regression
poses unique advantages, due to the Asymptotic Equipartition Property (AEP) of
probability distributions, that outliers and other low-occurrence events are
conveniently and intrinsically de-emphasized as not-typical, by definition. We
provide a numerical comparison with the current state-of-the-art methods in
sparse regression, and we apply the methods to different chaotic systems such
as the Lorenz System, the Kuramoto-Sivashinsky equations, and the Double Well
Potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08076</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08076</id><created>2019-05-17</created><authors><author><keyname>herremans</keyname><forenames>Dorien</forenames></author><author><keyname>Martens</keyname><forenames>David</forenames></author><author><keyname>S&#xf6;rensen</keyname><forenames>Kenneth</forenames></author></authors><title>Dance Hit Song Prediction</title><categories>cs.SD cs.IR cs.LG eess.AS stat.ML</categories><proxy>Dorien Herremans</proxy><journal-ref>Journal of New music Research. 43:302 (2014)</journal-ref><doi>10.1080/09298215.2014.881888</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Record companies invest billions of dollars in new talent around the globe
each year. Gaining insight into what actually makes a hit song would provide
tremendous benefits for the music industry. In this research we tackle this
question by focussing on the dance hit song classification problem. A database
of dance hit songs from 1985 until 2013 is built, including basic musical
features, as well as more advanced features that capture a temporal aspect. A
number of different classifiers are used to build and test dance hit prediction
models. The resulting best model has a good performance when predicting whether
a song is a &quot;top 10&quot; dance hit versus a lower listed position.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08111</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08111</id><created>2019-05-20</created><authors><author><keyname>Khan</keyname><forenames>Irfan Ahmad</forenames></author><author><keyname>Akber</keyname><forenames>Adnan</forenames></author><author><keyname>Xu</keyname><forenames>Yinliang</forenames></author></authors><title>Sliding Window Regression based Short-Term Load Forecasting of a
  Multi-Area Power System</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short term load forecasting has an essential medium for the reliable,
economical and efficient operation of the power system. Most of the existing
forecasting approaches utilize fixed statistical models with large historical
data for training the models. However, due to the recent integration of large
distributed generation, the nature of load demand has become dynamic. Thus
because of the dynamic nature of the power load demand, the performance of
these models may deteriorate over time. To accommodate the dynamic nature of
the load demands, we propose a sliding window regression based dynamic model to
predict the load demands of the multiarea power system. The proposed algorithm
is tested on five zones of New York ISO. Results from our proposed algorithm
are compared with four existing techniques to validate the performance
superiority of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08186</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08186</id><created>2019-05-20</created><updated>2019-06-04</updated><authors><author><keyname>Jeltsema</keyname><forenames>Dimitri</forenames></author></authors><title>Load Characterization and Power Conditioner Synthesis Using Higher-Order
  Elements</title><categories>eess.SP math.OC</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that virtually all nonlinear and/or time-varying loads that
generate harmonic current distortion can be characterized in terms of so-called
higher-order circuit elements. The most relevant higher-order elements
exploited in this paper are the memristor, meminductor, and memcapacitor. Such
elements naturally arise by introducing constitutive relationships in terms of
higher-order voltage and current differentials and integrals. Consequently, the
power conditioner necessary to compensate for the load current distortions is
synthesized similarly. The new characterization and compensation synthesis is
applied to the half-wave rectifier and the controlled bridge converter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08315</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08315</id><created>2019-05-20</created><updated>2019-05-25</updated><authors><author><keyname>Mondal</keyname><forenames>Shanka Subhra</forenames></author><author><keyname>Sathish</keyname><forenames>Rachana</forenames></author><author><keyname>Sheet</keyname><forenames>Debdoot</forenames></author></authors><title>Multitask Learning of Temporal Connectionism in Convolutional Networks
  using a Joint Distribution Loss Function to Simultaneously Identify Tools and
  Phase in Surgical Videos</title><categories>eess.IV cs.CV cs.LG</categories><comments>15 pages, 8 figures, 5th MedImage Workshop of 11th Indian Conference
  on Computer Vision, Graphics and Image Processing, Hyderabad, India, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surgical workflow analysis is of importance for understanding onset and
persistence of surgical phases and individual tool usage across surgery and in
each phase. It is beneficial for clinical quality control and to hospital
administrators for understanding surgery planning. Video acquired during
surgery typically can be leveraged for this task. Currently, a combination of
convolutional neural network (CNN) and recurrent neural networks (RNN) are
popularly used for video analysis in general, not only being restricted to
surgical videos. In this paper, we propose a multi-task learning framework
using CNN followed by a bi-directional long short term memory (Bi-LSTM) to
learn to encapsulate both forward and backward temporal dependencies. Further,
the joint distribution indicating set of tools associated with a phase is used
as an additional loss during learning to correct for their co-occurrence in any
predictions. Experimental evaluation is performed using the Cholec80 dataset.
We report a mean average precision (mAP) score of 0.99 and 0.86 for tool and
phase identification respectively which are higher compared to prior-art in the
field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08340</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08340</id><created>2019-05-20</created><authors><author><keyname>Alvarez-Melcon</keyname><forenames>A.</forenames></author><author><keyname>Wu</keyname><forenames>X.</forenames></author><author><keyname>Zang</keyname><forenames>J.</forenames></author><author><keyname>Liu</keyname><forenames>X.</forenames></author><author><keyname>Gomez-Diaz</keyname><forenames>J. S.</forenames></author></authors><title>Coupling Matrix Representation of Nonreciprocal Filters Based on Time
  Modulated Resonators</title><categories>eess.SP</categories><doi>10.1109/TMTT.2019.2945756</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the analysis and design of non-reciprocal filters based
on time modulated resonators. We analytically show that time modulating a
resonator leads to a set of harmonic resonators composed of the unmodulated
lumped elements plus a frequency invariant element that accounts for
differences in the resonant frequencies. We then demonstrate that harmonic
resonators of different order are coupled through non-reciprocal admittance
inverters whereas harmonic resonators of the same order couple with the
admittance inverter coming from the unmodulated filter network. This coupling
topology provides useful insights to understand and quickly design
non-reciprocal filters and permits their characterization using an
asynchronously tuned coupled resonators network together with the coupling
matrix formalism. Two designed filters, of orders three and four, are
experimentally demonstrated using quarter wavelength resonators implemented in
microstrip technology and terminated by a varactor on one side. The varactors
are biased using coplanar waveguides integrated in the ground plane of the
device. Measured results are found to be in good agreement with numerical
results, validating the proposed theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08352</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08352</id><created>2019-05-20</created><updated>2019-10-29</updated><authors><author><keyname>Lostanlen</keyname><forenames>Vincent</forenames></author><author><keyname>Salamon</keyname><forenames>Justin</forenames></author><author><keyname>Farnsworth</keyname><forenames>Andrew</forenames></author><author><keyname>Kelling</keyname><forenames>Steve</forenames></author><author><keyname>Bello</keyname><forenames>Juan Pablo</forenames></author></authors><title>Robust sound event detection in bioacoustic sensor networks</title><categories>cs.SD cs.AI cs.LG eess.AS</categories><comments>32 pages, in English. Submitted to PLOS ONE journal in February 2019;
  revised August 2019; published October 2019</comments><doi>10.1371/journal.pone.0214168</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bioacoustic sensors, sometimes known as autonomous recording units (ARUs),
can record sounds of wildlife over long periods of time in scalable and
minimally invasive ways. Deriving per-species abundance estimates from these
sensors requires detection, classification, and quantification of animal
vocalizations as individual acoustic events. Yet, variability in ambient noise,
both over time and across sensors, hinders the reliability of current automated
systems for sound event detection (SED), such as convolutional neural networks
(CNN) in the time-frequency domain. In this article, we develop, benchmark, and
combine several machine listening techniques to improve the generalizability of
SED models across heterogeneous acoustic environments. As a case study, we
consider the problem of detecting avian flight calls from a ten-hour recording
of nocturnal bird migration, recorded by a network of six ARUs in the presence
of heterogeneous background noise. Starting from a CNN yielding
state-of-the-art accuracy on this task, we introduce two noise adaptation
techniques, respectively integrating short-term (60 milliseconds) and long-term
(30 minutes) context. First, we apply per-channel energy normalization (PCEN)
in the time-frequency domain, which applies short-term automatic gain control
to every subband in the mel-frequency spectrogram. Secondly, we replace the
last dense layer in the network by a context-adaptive neural network (CA-NN)
layer. Combining them yields state-of-the-art results that are unmatched by
artificial data augmentation alone. We release a pre-trained version of our
best performing system under the name of BirdVoxDetect, a ready-to-use detector
of avian flight calls in field recordings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08410</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08410</id><created>2019-05-20</created><updated>2019-08-07</updated><authors><author><keyname>Soret</keyname><forenames>Beatriz</forenames></author><author><keyname>Leyva-Mayorga</keyname><forenames>Israel</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author></authors><title>Inter-plane satellite matching in dense LEO constellations</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dense constellations of Low Earth Orbit (LEO) small satellites are envisioned
to make extensive use of the inter-satellite link (ISL). Within the same
orbital plane, the inter-satellite distances are preserved and the links are
rather stable. In contrast, the relative motion between planes makes the
inter-plane ISL challenging. In a dense set-up, each spacecraft has several
satellites in its coverage volume, but the time duration of each of these links
is small and the maximum number of active connections is limited by the
hardware. We analyze the matching problem of connecting satellites using the
inter-plane ISL for unicast transmissions. We present and evaluate the
performance of two solutions to the matching problem with any number of orbital
planes and up to two transceivers: a heuristic solution with the aim of
minimizing the total cost; and a Markovian solution to maintain the on-going
connections as long as possible. The Markovian algorithm reduces the time
needed to solve the matching up to 1000x and 10x with respect to the optimal
solution and to the heuristic solution, respectively, without compromising the
total cost. Our model includes power adaptation and optimizes the network
energy consumption as the exemplary cost in the evaluations, but any other
QoS-oriented KPI can be used instead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08413</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08413</id><created>2019-05-20</created><authors><author><keyname>Cao</keyname><forenames>Haichao</forenames></author><author><keyname>Liu</keyname><forenames>Hong</forenames></author><author><keyname>Song</keyname><forenames>Enmin</forenames></author><author><keyname>Hung</keyname><forenames>Chih-Cheng</forenames></author><author><keyname>Ma</keyname><forenames>Guangzhi</forenames></author><author><keyname>Xu</keyname><forenames>Xiangyang</forenames></author><author><keyname>Jin</keyname><forenames>Renchao</forenames></author><author><keyname>Lu</keyname><forenames>Jianguo</forenames></author></authors><title>Dual-branch residual network for lung nodule segmentation</title><categories>cs.CV eess.IV</categories><comments>24 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An accurate segmentation of lung nodules in computed tomography (CT) images
is critical to lung cancer analysis and diagnosis. However, due to the variety
of lung nodules and the similarity of visual characteristics between nodules
and their surroundings, a robust segmentation of nodules becomes a challenging
problem. In this study, we propose the Dual-branch Residual Network (DB-ResNet)
which is a data-driven model. Our approach integrates two new schemes to
improve the generalization capability of the model: 1) the proposed model can
simultaneously capture multi-view and multi-scale features of different nodules
in CT images; 2) we combine the features of the intensity and the convolution
neural networks (CNN). We propose a pooling method, called the central
intensity-pooling layer (CIP), to extract the intensity features of the center
voxel of the block, and then use the CNN to obtain the convolutional features
of the center voxel of the block. In addition, we designed a weighted sampling
strategy based on the boundary of nodules for the selection of those voxels
using the weighting score, to increase the accuracy of the model. The proposed
method has been extensively evaluated on the LIDC dataset containing 986
nodules. Experimental results show that the DB-ResNet achieves superior
segmentation performance with an average dice score of 82.74% on the dataset.
Moreover, we compared our results with those of four radiologists on the same
dataset. The comparison showed that our average dice score was 0.49% higher
than that of human experts. This proves that our proposed method is as good as
the experienced radiologist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08459</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08459</id><created>2019-05-21</created><updated>2019-06-05</updated><authors><author><keyname>Peng</keyname><forenames>Kainan</forenames></author><author><keyname>Ping</keyname><forenames>Wei</forenames></author><author><keyname>Song</keyname><forenames>Zhao</forenames></author><author><keyname>Zhao</keyname><forenames>Kexin</forenames></author></authors><title>Parallel Neural Text-to-Speech</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>v2: we improve the synthesis speed of ParaNet by sharing the
  attention masking at all attention layers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a non-autoregressive seq2seq model that converts
text to spectrogram. It is fully convolutional and obtains about 46.7 times
speed-up over Deep Voice 3 at synthesis while maintaining comparable speech
quality using a WaveNet vocoder. Interestingly, it has even fewer attention
errors than the autoregressive model on the challenging test sentences.
Furthermore, we build the first fully parallel neural text-to-speech system by
applying the inverse autoregressive flow~(IAF) as the parallel neural vocoder.
Our system can synthesize speech from text through a single feed-forward pass.
We also explore a novel approach to train the IAF from scratch as a generative
model for raw waveform, which avoids the need for distillation from a
separately trained WaveNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08468</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08468</id><created>2019-05-21</created><updated>2019-08-19</updated><authors><author><keyname>Ammanouil</keyname><forenames>Rita</forenames></author><author><keyname>Ferrari</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Mary</keyname><forenames>David</forenames></author><author><keyname>Ferrari</keyname><forenames>Chiara</forenames></author><author><keyname>Loi</keyname><forenames>Francesca</forenames></author></authors><title>A parallel &amp; automatically tuned algorithm for multispectral image
  deconvolution</title><categories>astro-ph.IM eess.IV</categories><journal-ref>Monthly Notices of the Royal Astronomical Society 2019</journal-ref><doi>10.1093/mnras/stz2193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the era of big data, radio astronomical image reconstruction algorithms
are challenged to estimate clean images given limited computing resources and
time. This article is driven by the need for large scale image reconstruction
for the future Square Kilometre Array (SKA), which will become in the next
decades the largest low and intermediate frequency radio telescope in the
world. This work proposes a scalable wideband deconvolution algorithm called
MUFFIN, which stands for &quot;MUlti Frequency image reconstruction For radio
INterferometry&quot;. MUFFIN estimates the sky images in various frequency bands
given the corresponding dirty images and point spread functions. The
reconstruction is achieved by minimizing a data fidelity term and joint spatial
and spectral sparse analysis regularization terms. It is consequently
non-parametric w.r.t. the spectral behaviour of radio sources. MUFFIN algorithm
is endowed with a parallel implementation and an automatic tuning of the
regularization parameters, making it scalable and well suited for big data
applications such as SKA. Comparisons between MUFFIN and the state-of-the-art
wideband reconstruction algorithm are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08486</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08486</id><created>2019-05-21</created><authors><author><keyname>Kwon</keyname><forenames>Ohsung</forenames></author><author><keyname>Song</keyname><forenames>Eunwoo</forenames></author><author><keyname>Kim</keyname><forenames>Jae-Min</forenames></author><author><keyname>Kang</keyname><forenames>Hong-Goo</forenames></author></authors><title>Effective parameter estimation methods for an ExcitNet model in
  generative text-to-speech systems</title><categories>eess.AS cs.LG cs.SD</categories><comments>5 pages, 3 figures, 3 tables, submitted to Speech Synthesis Workshop
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a high-quality generative text-to-speech (TTS)
system using an effective spectrum and excitation estimation method. Our
previous research verified the effectiveness of the ExcitNet-based speech
generation model in a parametric TTS framework. However, the challenge remains
to build a high-quality speech synthesis system because auxiliary conditional
features estimated by a simple deep neural network often contain large
prediction errors, and the errors are inevitably propagated throughout the
autoregressive generation process of the ExcitNet vocoder. To generate more
natural speech signals, we exploited a sequence-to-sequence (seq2seq) acoustic
model with an attention-based generative network (e.g., Tacotron 2) to estimate
the condition parameters of the ExcitNet vocoder. Because the seq2seq acoustic
model accurately estimates spectral parameters, and because the ExcitNet model
effectively generates the corresponding time-domain excitation signals,
combining these two models can synthesize natural speech signals. Furthermore,
we verified the merit of the proposed method in producing expressive speech
segments by adopting a global style token-based emotion embedding method. The
experimental results confirmed that the proposed system significantly
outperforms the systems with a similarly configured conventional WaveNet
vocoder and our best prior parametric TTS counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08492</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08492</id><created>2019-05-21</created><authors><author><keyname>Tammen</keyname><forenames>Marvin</forenames></author><author><keyname>Fischer</keyname><forenames>D&#xf6;rte</forenames></author><author><keyname>Doclo</keyname><forenames>Simon</forenames></author></authors><title>DNN-Based Multi-Frame MVDR Filtering for Single-Microphone Speech
  Enhancement</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-frame approaches for single-microphone speech enhancement, e.g., the
multi-frame minimum-variance-distortionless-response (MVDR) filter, are able to
exploit speech correlations across neighboring time frames. In contrast to
single-frame approaches such as the Wiener gain, it has been shown that
multi-frame approaches achieve a substantial noise reduction with hardly any
speech distortion, provided that an accurate estimate of the correlation
matrices and especially the speech interframe correlation vector is available.
Typical estimation procedures of the correlation matrices and the speech
interframe correlation (IFC) vector require an estimate of the speech presence
probability (SPP) in each time-frequency bin. In this paper, we propose to use
a bi-directional long short-term memory deep neural network (DNN) to estimate a
speech mask and a noise mask for each time-frequency bin, using which two
different SPP estimates are derived. Aiming at achieving a robust performance,
the DNN is trained for various noise types and signal-to-noise ratios.
Experimental results show that the multi-frame MVDR in combination with the
proposed data-driven SPP estimator yields an increased speech quality compared
to a state-of-the-art model-based estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08545</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08545</id><created>2019-05-21</created><authors><author><keyname>Kushol</keyname><forenames>Rafsanjany</forenames></author><author><keyname>Raihan</keyname><forenames>Md. Nishat</forenames></author><author><keyname>Salekin</keyname><forenames>Md Sirajus</forenames></author><author><keyname>Rahman</keyname><forenames>A. B. M. Ashikur</forenames></author></authors><title>Contrast Enhancement of Medical X-Ray Image Using Morphological
  Operators with Optimal Structuring Element</title><categories>cs.CV eess.IV</categories><comments>5 pages, 4 figures, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To guide surgical and medical treatment X-ray images have been used by
physicians in every modern healthcare organization and hospitals. Doctor's
evaluation process and disease identification in the area of skeletal system
can be performed in a faster and efficient way with the help of X-ray imaging
technique as they can depict bone structure painlessly. This paper presents an
efficient contrast enhancement technique using morphological operators which
will help to visualize important bone segments and soft tissues more clearly.
Top-hat and Bottom-hat transform are utilized to enhance the image where
gradient magnitude value is calculated for automatically selecting the
structuring element (SE) size. Experimental evaluation on different x-ray
imaging databases shows the effectiveness of our method which also produces
comparatively better output against some existing image enhancement techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08546</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08546</id><created>2019-05-21</created><updated>2019-05-24</updated><authors><author><keyname>Adavanne</keyname><forenames>Sharath</forenames></author><author><keyname>Politis</keyname><forenames>Archontis</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>A multi-room reverberant dataset for sound event localization and
  detection</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper presents the sound event localization and detection (SELD) task
setup for the DCASE 2019 challenge. The goal of the SELD task is to detect the
temporal activities of a known set of sound event classes, and further localize
them in space when active. As part of the challenge, a synthesized dataset with
each sound event associated with a spatial coordinate represented using azimuth
and elevation angles is provided. These sound events are spatialized using
real-life impulse responses collected at multiple spatial coordinates in five
different rooms with varying dimensions and material properties. A baseline
SELD method employing a convolutional recurrent neural network is used to
generate benchmark scores for this reverberant dataset. The benchmark scores
are obtained using the recommended cross-validation setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08557</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08557</id><created>2019-05-21</created><authors><author><keyname>Shi</keyname><forenames>Liming</forenames></author><author><keyname>Nielsen</keyname><forenames>Jesper Kjaer</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper Rindom</forenames></author><author><keyname>Little</keyname><forenames>Max A.</forenames></author><author><keyname>Christensen</keyname><forenames>Mads Graesboll</forenames></author></authors><title>Bayesian Pitch Tracking Based on the Harmonic Model</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fundamental frequency is one of the most important characteristics of speech
and audio signals. Harmonic model-based fundamental frequency estimators offer
a higher estimation accuracy and robustness against noise than the widely used
autocorrelation-based methods. However, the traditional harmonic model-based
estimators do not take the temporal smoothness of the fundamental frequency,
the model order, and the voicing into account as they process each data segment
independently. In this paper, a fully Bayesian fundamental frequency tracking
algorithm based on the harmonic model and a first-order Markov process model is
proposed. Smoothness priors are imposed on the fundamental frequencies, model
orders, and voicing using first-order Markov process models. Using these Markov
models, fundamental frequency estimation and voicing detection errors can be
reduced. Using the harmonic model, the proposed fundamental frequency tracker
has an improved robustness to noise. An analytical form of the likelihood
function, which can be computed efficiently, is derived. Compared to the
state-of-the-art neural network and non-parametric approaches, the proposed
fundamental frequency tracking algorithm reduces the mean absolute errors and
gross errors by 15\% and 20\% on the Keele pitch database and 36\% and 26\% on
sustained /a/ sounds from a database of Parkinson's disease voices under 0 dB
white Gaussian noise. A MATLAB version of the proposed algorithm is made freely
available for reproduction of the results\footnote{An implementation of the
proposed algorithm using MATLAB may be found in
\url{https://tinyurl.com/yxn4a543}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08601</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08601</id><created>2019-05-21</created><updated>2019-07-01</updated><authors><author><keyname>Lostanlen</keyname><forenames>Vincent</forenames></author></authors><title>Une ou deux composantes ? La r\'eponse de la diffusion en ondelettes</title><categories>cs.SD eess.AS</categories><comments>4 pages, in French. Submitted to the GRETSI workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the aim of constructing a biologically plausible model of machine
listening, we study the representation of a multicomponent stationary signal by
a wavelet scattering network. First, we show that renormalizing second-order
nodes by their first-order parents gives a simple numerical criterion to
establish whether two neighboring components will interfere psychoacoustically.
Secondly, we generalize the `one or two components' framework to three sine
waves or more, and show that a network of depth $M = \log_2 N$ suffices to
characterize the relative amplitudes of the first $N$ terms in a Fourier
series, while enjoying properties of invariance to frequency transposition and
component-wise phase shifts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08603</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08603</id><created>2019-05-21</created><updated>2019-06-10</updated><authors><author><keyname>Kaji</keyname><forenames>Shizuo</forenames></author><author><keyname>Kida</keyname><forenames>Satoshi</forenames></author></authors><title>Overview of image-to-image translation by use of deep neural networks:
  denoising, super-resolution, modality conversion, and reconstruction in
  medical imaging</title><categories>physics.med-ph eess.IV</categories><comments>many typos are fixed. to appear in Radiological Physics and
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the advent of deep convolutional neural networks (DNNs), computer
vision has seen an extremely rapid progress that has led to huge advances in
medical imaging. This article does not aim to cover all aspects of the field
but focuses on a particular topic, image-to-image translation. Although the
topic may not sound familiar, it turns out that many seemingly irrelevant
applications can be understood as instances of image-to-image translation. Such
applications include (1) noise reduction, (2) super-resolution, (3) image
synthesis, and (4) reconstruction. The same underlying principles and
algorithms work for various tasks. Our aim is to introduce some of the key
ideas on this topic from a uniform point of view. We introduce core ideas and
jargon that are specific to image processing by use of DNNs. Having an
intuitive grasp of the core ideas of and a knowledge of technical terms would
be of great help to the reader for understanding the existing and future
applications. Most of the recent applications which build on image-to-image
translation are based on one of two fundamental architectures, called pix2pix
and CycleGAN, depending on whether the available training data are paired or
unpaired. We provide computer codes which implement these two architectures
with various enhancements. Our codes are available online with use of the very
permissive MIT license. We provide a hands-on tutorial for training a model for
denoising based on our codes. We hope that this article, together with the
codes, will provide both an overview and the details of the key algorithms, and
that it will serve as a basis for the development of new applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08607</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08607</id><created>2019-05-13</created><authors><author><keyname>Chung</keyname><forenames>Yu-Min</forenames></author><author><keyname>Hu</keyname><forenames>Chuan-Shen</forenames></author><author><keyname>Lawson</keyname><forenames>Austin</forenames></author><author><keyname>Smyth</keyname><forenames>Clifford</forenames></author></authors><title>TopoResNet: A hybrid deep learning architecture and its application to
  skin lesion classification</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skin cancer is one of the most common cancers in the United States. As
technological advancements are made, algorithmic diagnosis of skin lesions is
becoming more important. In this paper, we develop algorithms for segmenting
the actual diseased area of skin in a given image of a skin lesion, and for
classifying different types of skin lesions pictured in a given image. The
cores of the algorithms used were based in persistent homology, an algebraic
topology technique that is part of the rising field of Topological Data
Analysis (TDA). The segmentation algorithm utilizes a similar concept to
persistent homology that captures the robustness of segmented regions. For
classification, we design two families of topological features from persistence
diagrams---which we refer to as {\em persistence statistics} (PS) and {\em
persistence curves} (PC), and use linear support vector machine as classifiers.
We also combined those topological features, PS and PC, into ResNet-101 model,
which we call {\em TopoResNet-101}, the results show that PS and PC are
effective in two folds---improving classification performances and stabilizing
the training process. Although convolutional features are the most important
learning targets in CNN models, global information of images may be lost in the
training process. Because topological features were extracted globally, our
results show that the global property of topological features provide
additional information to machine learning models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08610</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08610</id><created>2019-05-14</created><authors><author><keyname>Rokad</keyname><forenames>Brij</forenames></author><author><keyname>Nagarajan</keyname><forenames>Dr. Sureshkumar</forenames></author></authors><title>Skin Cancer Recognition using Deep Residual Network</title><categories>cs.CV eess.IV</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advances in technology have enabled people to access internet from every
part of the world. But to date, access to healthcare in remote areas is sparse.
This proposed solution aims to bridge the gap between specialist doctors and
patients. This prototype will be able to detect skin cancer from an image
captured by the phone or any other camera. The network is deployed on cloud
server-side processing for an even more accurate result. The Deep Residual
learning model has been used for predicting the probability of cancer for
server side The ResNet has three parametric layers. Each layer has
Convolutional Neural Network, Batch Normalization, Maxpool and ReLU. Currently
the model achieves an accuracy of 77% on the ISIC - 2017 challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08613</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08613</id><created>2019-05-15</created><authors><author><keyname>Ruffino</keyname><forenames>Cyprien</forenames><affiliation>LITIS, INSA Rouen Normandie, NU</affiliation></author><author><keyname>H&#xe9;rault</keyname><forenames>Romain</forenames><affiliation>DocApp - LITIS</affiliation></author><author><keyname>Laloy</keyname><forenames>Eric</forenames><affiliation>SCK-CEN</affiliation></author><author><keyname>Gasso</keyname><forenames>Gilles</forenames><affiliation>LITIS</affiliation></author></authors><title>Dilated Spatial Generative Adversarial Networks for Ergodic Image
  Generation</title><categories>cs.CV cs.LG eess.IV</categories><proxy>ccsd</proxy><journal-ref>Conf{\'e}rence sur l'Apprentissage Automatique, Jun 2018, Rouen,
  France</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative models have recently received renewed attention as a result of
adversarial learning. Generative adversarial networks consist of samples
generation model and a discrimination model able to distinguish between genuine
and synthetic samples. In combination with convolutional (for the
discriminator) and de-convolutional (for the generator) layers, they are
particularly suitable for image generation, especially of natural scenes.
However, the presence of fully connected layers adds global dependencies in the
generated images. This may lead to high and global variations in the generated
sample for small local variations in the input noise. In this work we propose
to use architec-tures based on fully convolutional networks (including among
others dilated layers), architectures specifically designed to generate
globally ergodic images, that is images without global dependencies. Conducted
experiments reveal that these architectures are well suited for generating
natural textures such as geologic structures .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08627</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08627</id><created>2019-05-21</created><updated>2019-08-22</updated><authors><author><keyname>Marinescu</keyname><forenames>Razvan V.</forenames></author><author><keyname>Eshaghi</keyname><forenames>Arman</forenames></author><author><keyname>Alexander</keyname><forenames>Daniel C.</forenames></author><author><keyname>Golland</keyname><forenames>Polina</forenames></author></authors><title>BrainPainter: A software for the visualisation of brain structures,
  biomarkers and associated pathological processes</title><categories>cs.GR eess.IV</categories><comments>Accepted at the MICCAI Multimodal Brain Imaging Analysis (MBIA)
  workshop, 2019</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present BrainPainter, a software that automatically generates images of
highlighted brain structures given a list of numbers corresponding to the
output colours of each region. Compared to existing visualisation software
(i.e. Freesurfer, SPM, 3D Slicer), BrainPainter has three key advantages: (1)
it does not require the input data to be in a specialised format, allowing
BrainPainter to be used in combination with any neuroimaging analysis tools,
(2) it can visualise both cortical and subcortical structures and (3) it can be
used to generate movies showing dynamic processes, e.g. propagation of
pathology on the brain. We highlight three use cases where BrainPainter was
used in existing neuroimaging studies: (1) visualisation of the degree of
atrophy through interpolation along a user-defined gradient of colours, (2)
visualisation of the progression of pathology in Alzheimer's disease as well as
(3) visualisation of pathology in subcortical regions in Huntington's disease.
Moreover, through the design of BrainPainter we demonstrate the possibility of
using a powerful 3D computer graphics engine such as Blender to generate brain
visualisations for the neuroscience community. Blender's capabilities, e.g.
particle simulations, motion graphics, UV unwrapping, raster graphics editing,
raytracing and illumination effects, open a wealth of possibilities for brain
visualisation not available in current neuroimaging software. BrainPainter is
customisable, easy to use, and can run straight from the web browser:
https://brainpainter.csail.mit.edu , as well as from source-code packaged in a
docker container: https://github.com/mrazvan22/brain-coloring . It can be used
to visualise biomarker data from any brain imaging modality, or simply to
highlight a particular brain structure for e.g. anatomy courses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08632</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08632</id><created>2019-05-19</created><authors><author><keyname>Huang</keyname><forenames>Andrew</forenames></author><author><keyname>Bao</keyname><forenames>Puwei</forenames></author></authors><title>Human Vocal Sentiment Analysis</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>NYU Shanghai CSCS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use several techniques with conventional vocal feature
extraction (MFCC, STFT), along with deep-learning approaches such as CNN, and
also context-level analysis, by providing the textual data, and combining
different approaches for improved emotion-level classification. We explore
models that have not been tested to gauge the difference in performance and
accuracy. We apply hyperparameter sweeps and data augmentation to improve
performance. Finally, we see if a real-time approach is feasible, and can be
readily integrated into existing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08671</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08671</id><created>2019-05-21</created><updated>2019-05-27</updated><authors><author><keyname>Yesilli</keyname><forenames>Melih C.</forenames></author><author><keyname>Khasawneh</keyname><forenames>Firas A.</forenames></author><author><keyname>Otto</keyname><forenames>Andreas</forenames></author></authors><title>Topological Feature Vectors for Chatter Detection in Turning Processes</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machining processes are most accurately described using complex dynamical
systems that include nonlinearities, time delays and stochastic effects. Due to
the nature of these models as well as the practical challenges which include
time-varying parameters, the transition from numerical/analytical modeling of
machining to the analysis of real cutting signals remains challenging. Some
studies have focused on studying the time series of cutting processes using
machine learning algorithms with the goal of identifying and predicting
undesirable vibrations during machining referred to as chatter. These tools
typically decompose the signal using Wavelet Packet Transforms (WPT) or
Ensemble Empirical Mode Decomposition (EEMD). However, these methods require a
significant overhead in identifying the feature vectors before a classifier can
be trained. In this study, we present an alternative approach based on
featurizing the time series of the cutting process using its topological
features. We utilize support vector machine classifier combined with feature
vectors derived from persistence diagrams, a tool from persistent homology, to
encode distinguishing characteristics based on embedding the time series as a
point cloud using Takens embedding. We present the results for several choices
of the topological feature vectors, and we compare our results to the WPT and
EEMD methods using experimental time series from a turning cutting test. Our
results show that in most cases combining the TDA-based features with a simple
Support Vector Machine (SVM) yields accuracies that either exceed or are within
the error bounds of their WPT and EEMD counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08708</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08708</id><created>2019-05-21</created><authors><author><keyname>Zemen</keyname><forenames>Thomas</forenames></author><author><keyname>Loeschenbrand</keyname><forenames>David</forenames></author></authors><title>Combating Massive MIMO Channel Aging by Orthogonal Precoding</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><journal-ref>IEEE 5G World Forum (WF-5G), Dresden, Germany, September 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we investigate ultra-reliable low-latency massive multiple-input
multiple-output (MIMO) communication links in vehicular scenarios, where
coherence between uplink and downlink cannot be assumed. In such scenarios the
channel state information obtained in the uplink will be outdated for the
following downlink phase. To compensate for this channel aging we will utilize
orthogonal precoding with two-dimensional precoding sequences in the
time-frequency domain within an orthogonal frequency division multiplexing
system. The channel hardening effect of massive MIMO transmission decreases,
due to channel aging, with increasing frame duration and increasing velocity,
while the channel hardening effect of orthogonal precoding (OP) increases with
increasing time- and frequency-selectivity of the wireless communication
channel. By combining massive MIMO and OP we can show by numeric link level
simulation that the performance with outdated channel state information in
terms of bit-error rate versus signal-to-noise ratio can be improved by two
orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08720</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08720</id><created>2019-05-21</created><updated>2019-06-22</updated><authors><author><keyname>Ren</keyname><forenames>Xuhua</forenames></author><author><keyname>Zhang</keyname><forenames>Lichi</forenames></author><author><keyname>Ahmad</keyname><forenames>Sahar</forenames></author><author><keyname>Nie</keyname><forenames>Dong</forenames></author><author><keyname>Yang</keyname><forenames>Fan</forenames></author><author><keyname>Xiang</keyname><forenames>Lei</forenames></author><author><keyname>Wang</keyname><forenames>Qian</forenames></author><author><keyname>Shen</keyname><forenames>Dinggang</forenames></author></authors><title>Task Decomposition and Synchronization for Semantic Biomedical Image
  Segmentation</title><categories>cs.CV eess.IV</categories><comments>IEEE Transactions on Medical Imaging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic segmentation is essentially important to biomedical image analysis.
Many recent works mainly focus on integrating the Fully Convolutional Network
(FCN) architecture with sophisticated convolution implementation and deep
supervision. In this paper, we propose to decompose the single segmentation
task into three subsequent sub-tasks, including (1) pixel-wise image
segmentation, (2) prediction of the class labels of the objects within the
image, and (3) classification of the scene the image belonging to. While these
three sub-tasks are trained to optimize their individual loss functions of
different perceptual levels, we propose to let them interact by the task-task
context ensemble. Moreover, we propose a novel sync-regularization to penalize
the deviation between the outputs of the pixel-wise segmentation and the class
prediction tasks. These effective regularizations help FCN utilize context
information comprehensively and attain accurate semantic segmentation, even
though the number of the images for training may be limited in many biomedical
applications. We have successfully applied our framework to three diverse 2D/3D
medical image datasets, including Robotic Scene Segmentation Challenge 18
(ROBOT18), Brain Tumor Segmentation Challenge 18 (BRATS18), and Retinal Fundus
Glaucoma Challenge (REFUGE18). We have achieved top-tier performance in all
three challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08749</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08749</id><created>2019-05-21</created><updated>2019-10-27</updated><authors><author><keyname>Stein</keyname><forenames>Manuel S.</forenames></author><author><keyname>Fau&#xdf;</keyname><forenames>Michael</forenames></author></authors><title>Latency Analysis for Sequential Detection in Low-Complexity Binary Radio
  Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of making a quick decision in favor of one of two
possible physical signal models while the numerical measurements are acquired
by sensing devices featuring minimal digitization complexity. Therefore, the
digital data streams available for statistical processing are binary and
exhibit temporal and spatial dependencies. To handle the intractable
multivariate binary data model, we first consider sequential tests for
exponential family distributions. Within this generic probabilistic framework,
we identify adaptive approximations for the log-likelihood ratio and the
Kullback-Leibler divergence. The results allow designing sequential detectors
for binary radio systems and analyzing their average run-time along classical
arguments of Wald. In particular, the derived tests exploit the spatio-temporal
correlation structure of the analog sensor signals engraved into the binary
measurements. As an application, we consider the specification of binary
sensing architectures for cognitive radio and GNSS spectrum monitoring where
our results characterize the sequential detection latency as a function of the
temporal oversampling and the number of antennas. Finally, we evaluate the
efficiency of the proposed algorithms and illustrate the accuracy of our
analysis via Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08750</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08750</id><created>2019-05-21</created><updated>2019-06-01</updated><authors><author><keyname>Nassif</keyname><forenames>Roula</forenames></author><author><keyname>Vlaski</keyname><forenames>Stefan</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Adaptation and learning over networks under subspace constraints -- Part
  I: Stability Analysis</title><categories>cs.MA eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers optimization problems over networks where agents have
individual objectives to meet, or individual parameter vectors to estimate,
subject to subspace constraints that require the objectives across the network
to lie in low-dimensional subspaces. This constrained formulation includes
consensus optimization as a special case, and allows for more general task
relatedness models such as smoothness. While such formulations can be solved
via projected gradient descent, the resulting algorithm is not distributed.
Starting from the centralized solution, we propose an iterative and distributed
implementation of the projection step, which runs in parallel with the
stochastic gradient descent update. We establish in this Part I of the work
that, for small step-sizes $\mu$, the proposed distributed adaptive strategy
leads to small estimation errors on the order of $\mu$. We examine in the
accompanying Part II [2] the steady-state performance. The results will reveal
explicitly the influence of the gradient noise, data characteristics, and
subspace constraints, on the network performance. The results will also show
that in the small step-size regime, the iterates generated by the distributed
algorithm achieve the centralized steady-state performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08792</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08792</id><created>2019-05-21</created><updated>2020-01-29</updated><authors><author><keyname>T&#xea;tu</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Trudeau</keyname><forenames>Louis-Charles</forenames></author><author><keyname>Van Beirendonck</keyname><forenames>Michiel</forenames></author><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author><author><keyname>Giard</keyname><forenames>Pascal</forenames></author></authors><title>A Standalone FPGA-based Miner for Lyra2REv2 Cryptocurrencies</title><categories>cs.CR eess.SP</categories><comments>13 pages, accepted for publication in IEEE Trans. Circuits Syst. I.
  arXiv admin note: substantial text overlap with arXiv:1807.05764</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lyra2REv2 is a hashing algorithm that consists of a chain of individual
hashing algorithms, and it is used as a proof-of-work function in several
cryptocurrencies. The most crucial and exotic hashing algorithm in the
Lyra2REv2 chain is a specific instance of the general Lyra2 algorithm. This
work presents the first hardware implementation of the specific instance of
Lyra2 that is used in Lyra2REv2. Several properties of the aforementioned
algorithm are exploited in order to optimize the design. In addition, an
FPGA-based hardware implementation of a standalone miner for Lyra2REv2 on a
Xilinx Multi-Processor System on Chip is presented. The proposed Lyra2REv2
miner is shown to be significantly more energy efficient than both a GPU and a
commercially available FPGA-based miner. Finally, we also explain how the
simplified Lyra2 and Lyra2REv2 architectures can be modified with minimal
effort to also support the recent Lyra2REv3 chained hashing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08795</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08795</id><created>2019-05-21</created><authors><author><keyname>Caciularu</keyname><forenames>Avi</forenames></author><author><keyname>Burshtein</keyname><forenames>David</forenames></author></authors><title>Unsupervised Linear and Nonlinear Channel Equalization and Decoding
  using Variational Autoencoders</title><categories>cs.LG cs.IT eess.SP math.IT stat.ML</categories><comments>Submitted for publication. Includes 30 pages, 17 figures, 2 tables.
  arXiv admin note: text overlap with arXiv:1803.01526</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach for blind channel equalization and decoding, using variational
autoencoders (VAEs), is introduced. We first consider the reconstruction of
uncoded data symbols transmitted over a noisy linear intersymbol interference
(ISI) channel, with an unknown impulse response, without using pilot symbols.
We derive an approximated maximum likelihood estimate to the channel parameters
and reconstruct the transmitted data. We demonstrate significant and consistent
improvements in the error rate of the reconstructed symbols, compared to
existing blind equalization methods such as constant modulus, thus enabling
faster channel acquisition. The VAE equalizer uses a fully convolutional neural
network with a small number of free parameters. These results are extended to
blind equalization over a noisy nonlinear ISI channel with unknown parameters.
We then consider coded communication using low-density parity-check (LDPC)
codes transmitted over a noisy linear or nonlinear ISI channel. The goal is to
reconstruct the transmitted message from the channel observations corresponding
to a transmitted codeword, without using pilot symbols. We demonstrate
substantial improvements compared to expectation maximization (EM) using turbo
equalization. Furthermore, in our simulations we demonstrate a relatively small
gap between the performance of the new unsupervised equalization method and
that of the fully channel informed (non-blind) turbo equalizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08796</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08796</id><created>2019-05-21</created><authors><author><keyname>Kim</keyname><forenames>Suyoun</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Acoustic-to-Word Models with Conversational Context Information</title><categories>cs.CL cs.LG eess.AS</categories><comments>NAACL 2019. arXiv admin note: text overlap with arXiv:1808.02171</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conversational context information, higher-level knowledge that spans across
sentences, can help to recognize a long conversation. However, existing speech
recognition models are typically built at a sentence level, and thus it may not
capture important conversational context information. The recent progress in
end-to-end speech recognition enables integrating context with other available
information (e.g., acoustic, linguistic resources) and directly recognizing
words from speech. In this work, we present a direct acoustic-to-word,
end-to-end speech recognition model capable of utilizing the conversational
context to better process long conversations. We evaluate our proposed approach
on the Switchboard conversational speech corpus and show that our system
outperforms a standard end-to-end speech recognition system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08831</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08831</id><created>2019-05-21</created><updated>2019-05-30</updated><authors><author><keyname>Manickam</keyname><forenames>Indu</forenames></author><author><keyname>Lan</keyname><forenames>Andrew S.</forenames></author><author><keyname>Dasarathy</keyname><forenames>Gautam</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>IdeoTrace: A Framework for Ideology Tracing with a Case Study on the
  2016 U.S. Presidential Election</title><categories>cs.SI cs.LG eess.SP stat.ML</categories><comments>9 pages, 4 figures, submitted to ASONAM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 2016 United States presidential election has been characterized as a
period of extreme divisiveness that was exacerbated on social media by the
influence of fake news, trolls, and social bots. However, the extent to which
the public became more polarized in response to these influences over the
course of the election is not well understood. In this paper we propose
IdeoTrace, a framework for (i) jointly estimating the ideology of social media
users and news websites and (ii) tracing changes in user ideology over time. We
apply this framework to the last two months of the election period for a group
of 47508 Twitter users and demonstrate that both liberal and conservative users
became more polarized over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08860</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08860</id><created>2019-05-21</created><authors><author><keyname>Baker</keyname><forenames>Kyri</forenames></author></authors><title>Learning Warm-Start Points for AC Optimal Power Flow</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large amount of data has been generated by grid operators solving AC
optimal power flow (ACOPF) throughout the years, and we explore how leveraging
this data can be used to help solve future ACOPF problems. We use this data to
train a Random Forest to predict solutions of future ACOPF problems. To
preserve correlations and relationships between predicted variables, we utilize
a multi-target approach to learn approximate voltage and generation solutions
to ACOPF problems directly by only using network loads, without the knowledge
of other network parameters or the system topology. We explore the benefits of
using the learned solution as an intelligent warm start point for solving the
ACOPF, and the proposed framework is evaluated numerically using multiple IEEE
test networks. The benefit of using learned ACOPF solutions is shown to be
solver and network dependent, but shows promise for quickly finding approximate
solutions to the ACOPF problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08869</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08869</id><created>2019-05-21</created><authors><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author><author><keyname>Yazdani</keyname><forenames>Hassan</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author><author><keyname>Rahnavard</keyname><forenames>Nazanin</forenames></author></authors><title>Source Localization and Tracking for Dynamic Radio Cartography using
  Directional Antennas</title><categories>eess.SP cs.IT math.IT stat.AP</categories><comments>SECON 2019 workshop on Edge Computing for Cyber Physical Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Utilization of directional antennas is a promising solution for efficient
spectrum sensing and accurate source localization and tracking. Spectrum
sensors equipped with directional antennas should constantly scan the space in
order to track emitting sources and discover new activities in the area of
interest. In this paper, we propose a new formulation that unifies
received-signal-strength (RSS) and direction of arrival (DoA) in a compressive
sensing (CS) framework. The underlying CS measurement matrix is a function of
beamforming vectors of sensors and is referred to as the propagation matrix.
Comparing to the omni-directional antenna case, our employed propagation matrix
provides more incoherent projections, an essential factor in the compressive
sensing theory. Based on the new formulation, we optimize the antenna beams,
enhance spectrum sensing efficiency, track active primary users accurately and
monitor spectrum activities in an area of interest. In many practical scenarios
there is no fusion center to integrate received data from spectrum sensors. We
propose the distributed version of our algorithm for such cases. Experimental
results show a significant improvement in source localization accuracy,
compared with the scenario when sensors are equipped with omni-directional
antennas. Applicability of the proposed framework for dynamic radio cartography
is shown. Moreover, comparing the estimated dynamic RF map over time with the
ground truth demonstrates the effectiveness of our proposed method for accurate
signal estimation and recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08886</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08886</id><created>2019-05-21</created><authors><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>Mathew</keyname><forenames>Melvin J.</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author><author><keyname>Khalifa</keyname><forenames>Yousuf M.</forenames></author></authors><title>Automated Pupillary Light Reflex Test on a Portable Platform</title><categories>eess.IV cs.CV eess.SP</categories><comments>7 pages, 11 figures, 3 tables</comments><acm-class>I.4</acm-class><journal-ref>International Symposium on Medical Robotics (ISMR), Atlanta, GA,
  USA, 2019, pp. 1-7</journal-ref><doi>10.1109/ISMR.2019.8710182</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a portable eye imaging device denoted as
lab-on-a-headset, which can automatically perform a swinging flashlight test.
We utilized this device in a clinical study to obtain high-resolution
recordings of eyes while they are exposed to a varying light stimuli. Half of
the participants had relative afferent pupillary defect (RAPD) while the other
half was a control group. In case of positive RAPD, patients pupils constrict
less or do not constrict when light stimuli swings from the unaffected eye to
the affected eye. To automatically diagnose RAPD, we propose an algorithm based
on pupil localization, pupil size measurement, and pupil size comparison of
right and left eye during the light reflex test. We validate the algorithmic
performance over a dataset obtained from 22 subjects and show that proposed
algorithm can achieve a sensitivity of 93.8% and a specificity of 87.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08895</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08895</id><created>2019-05-21</created><updated>2019-05-28</updated><authors><author><keyname>Safarpour</keyname><forenames>Mehdi</forenames></author><author><keyname>Inanlou</keyname><forenames>Reza</forenames></author><author><keyname>Silven</keyname><forenames>Olli</forenames></author><author><keyname>Rahkonen</keyname><forenames>Timo</forenames></author><author><keyname>Shoaei</keyname><forenames>Omid</forenames></author></authors><title>A Reconfigurable Dual-Mode Tracking SAR ADC without Analog Subtraction</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, it is proposes to limit the quantization search space
of a successive approximation analog-to-digital converter through an analytic
derivation of maximum possible sample-to-sample variation. The presented
example design of the proposed ADC is an 8-bit 1MS/s ADC with SAR logic
customized to incorporate this priori information while no modification has
been required to the analog circuitry. In comparison to conventional SAR
conversion, the proposed tracking approach yields significant reduction in
total power consumption in oversampling mode. The power savings are due to the
reduced number of SAR cycles, and voltage variation minimization across DAC
capacitors. The design is reconfigurable both to conventional SAR sampling and
the proposed tracking scheme. The approach is attractive for SAR ADCs embedded
in very low power micro-controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08905</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08905</id><created>2019-05-20</created><authors><author><keyname>Jailin</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>LMT</affiliation></author><author><keyname>Buljac</keyname><forenames>Ante</forenames><affiliation>LMT</affiliation></author><author><keyname>Bouterf</keyname><forenames>Amine</forenames><affiliation>LMT</affiliation></author><author><keyname>Hild</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LMT</affiliation></author><author><keyname>Roux</keyname><forenames>St&#xe9;phane</forenames><affiliation>LMT</affiliation></author></authors><title>Projection-based measurement and identification</title><categories>physics.comp-ph eess.SP physics.class-ph</categories><comments>SEM 2019, Jun 2019, Reno, United States</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recently developed Projection-based Digital Image Correlation (P-DVC)
method is here extended to 4D (space and time) displacement field measurement
and mechanical identification based on a single radiograph per loading step
instead of volumes as in standard DVC methods. Two levels of data reductions
are exploited, namely, reduction of the data acquisition (and time) by a factor
of 1000 and reduction of the solution space by exploiting model reduction
techniques. The analysis of a complete tensile elastoplastic test composed of
127 loading steps performed in 6 minutes is presented. The 4D displacement
field as well as the elastoplastic constitutive law are identified. Keywords:
Image-based identification, Model reduction, Fast 4D identification, In-situ
tomography measurements. INTRODUCTION Identification and validation of
increasingly complex mechanical models is a major concern in experimental solid
mechanics. The recent developments of computed tomography coupled with in-situ
tests provide extremely rich and non-destructive analyses [1]. In the latter
cases, the sample was imaged inside a tomograph, either with interrupted
mechanical load or with a continuously evolving loading and on-the-fly
acquisitions (as ultra-fast X-ray synchrotron tomography, namely, 20 Hz full
scan acquisition for the study of crack propagation [2]). Visualization of fast
transformations, crack openings, or unsteady behavior become accessible.
Combined with full-field measurements, in-situ tests offer a quantitative basis
for identifying a broad range of mechanical behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08948</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08948</id><created>2019-05-22</created><authors><author><keyname>Chen</keyname><forenames>Kaixuan</forenames></author><author><keyname>Yao</keyname><forenames>Lina</forenames></author><author><keyname>Zhang</keyname><forenames>Dalin</forenames></author><author><keyname>Guo</keyname><forenames>Bin</forenames></author><author><keyname>Yu</keyname><forenames>Zhiwen</forenames></author></authors><title>Multi-agent Attentional Activity Recognition</title><categories>cs.HC cs.LG eess.SP</categories><comments>Accepted by IJCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-modality is an important feature of sensor based activity recognition.
In this work, we consider two inherent characteristics of human activities, the
spatially-temporally varying salience of features and the relations between
activities and corresponding body part motions. Based on these, we propose a
multi-agent spatial-temporal attention model. The spatial-temporal attention
mechanism helps intelligently select informative modalities and their active
periods. And the multiple agents in the proposed model represent activities
with collective motions across body parts by independently selecting modalities
associated with single motions. With a joint recognition goal, the agents share
gained information and coordinate their selection policies to learn the optimal
recognition model. The experimental results on four real-world datasets
demonstrate that the proposed model outperforms the state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08967</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08967</id><created>2019-05-22</created><updated>2019-11-14</updated><authors><author><keyname>Lu</keyname><forenames>Zhiqing</forenames></author><author><keyname>Yin</keyname><forenames>Zhaoxia</forenames></author><author><keyname>Luo</keyname><forenames>Bin</forenames></author></authors><title>Multiple reconstruction compression framework based on PNG image</title><categories>cs.MM eess.IV</categories><comments>The experimental results cannot reproduced</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that neural networks (NNs) achieve excellent performances in
image compression and reconstruction. However, there are still many
shortcomings in the practical application, which eventually lead to the loss of
neural network image processing ability. Based on this, this paper proposes a
joint framework based on neural network and zoom compression. The framework
first encodes the incoming PNG or JPEG image information, and then the image is
converted into binary input decoder to reconstruct the intermediate state
image, next we import the intermediate state image into the zooming compressor
and re-pressurize it, and reconstruct the final image. From the experimental
results, this method can better process the digital image and suppress the
reverse expansion problem, and the compression effect can be improved by 4 to
10 times as much as that of using RNN alone, showing better ability in
application. In this paper, the method is transmitted over a digital image, the
effect is far better than the existing compression method alone, the Human
visual system can not feel the change of the effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.08990</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.08990</id><created>2019-05-22</created><authors><author><keyname>Yashashwi</keyname><forenames>Kumar</forenames></author><author><keyname>Anand</keyname><forenames>Deepak</forenames></author><author><keyname>Pillai</keyname><forenames>Sibi Raj B</forenames></author><author><keyname>Chaporkar</keyname><forenames>Prasanna</forenames></author><author><keyname>Ganesh</keyname><forenames>K</forenames></author></authors><title>MIST: A Novel Training Strategy for Low-latency Scalable Neural Net
  Decoders</title><categories>eess.SP cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a low latency, robust and scalable neural net based
decoder for convolutional and low-density parity-check (LPDC) coding schemes.
The proposed decoders are demonstrated to have bit error rate (BER) and block
error rate (BLER) performances at par with the state-of-the-art neural net
based decoders while achieving more than 8 times higher decoding speed. The
enhanced decoding speed is due to the use of convolutional neural network (CNN)
as opposed to recurrent neural network (RNN) used in the best known neural net
based decoders. This contradicts existing doctrine that only RNN based decoders
can provide a performance close to the optimal ones. The key ingredient to our
approach is a novel Mixed-SNR Independent Samples based Training (MIST), which
allows for training of CNN with only 1\% of possible datawords, even for block
length as high as 1000. The proposed decoder is robust as, once trained, the
same decoder can be used for a wide range of SNR values. Finally, in the
presence of channel outages, the proposed decoders outperform the best known
decoders, {\it viz.} unquantized Viterbi decoder for convolutional code, and
belief propagation for LDPC. This gives the CNN decoder a significant advantage
in 5G millimeter wave systems, where channel outages are prevalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09000</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09000</id><created>2019-05-22</created><authors><author><keyname>Hashisho</keyname><forenames>Yousif</forenames></author><author><keyname>Albadawi</keyname><forenames>Mohamad</forenames></author><author><keyname>Krause</keyname><forenames>Tom</forenames></author><author><keyname>von Lukas</keyname><forenames>Uwe Freiherr</forenames></author></authors><title>Underwater Color Restoration Using U-Net Denoising Autoencoder</title><categories>cs.CV cs.AI eess.IV</categories><comments>6 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Visual inspection of underwater structures by vehicles, e.g. remotely
operated vehicles (ROVs), plays an important role in scientific, military, and
commercial sectors. However, the automatic extraction of information using
software tools is hindered by the characteristics of water which degrade the
quality of captured videos. As a contribution for restoring the color of
underwater images, Underwater Denoising Autoencoder (UDAE) model is developed
using a denoising autoencoder with U-Net architecture. The proposed network
takes into consideration the accuracy and the computation cost to enable
real-time implementation on underwater visual tasks using end-to-end
autoencoder network. Underwater vehicles perception is improved by
reconstructing captured frames; hence obtaining better performance in
underwater tasks. Related learning methods use generative adversarial networks
(GANs) to generate color corrected underwater images, and to our knowledge this
paper is the first to deal with a single autoencoder capable of producing same
or better results. Moreover, image pairs are constructed for training the
proposed network, where it is hard to obtain such dataset from underwater
scenery. At the end, the proposed model is compared to a state-of-the-art
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09010</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09010</id><created>2019-05-22</created><updated>2020-01-21</updated><authors><author><keyname>Shin</keyname><forenames>Yong-Goo</forenames></author><author><keyname>Sagong</keyname><forenames>Min-Cheol</forenames></author><author><keyname>Yeo</keyname><forenames>Yoon-Jae</forenames></author><author><keyname>Kim</keyname><forenames>Seung-Wook</forenames></author><author><keyname>Ko</keyname><forenames>Sung-Jea</forenames></author></authors><title>PEPSI++: Fast and Lightweight Network for Image Inpainting</title><categories>cs.CV eess.IV</categories><comments>Submitted to IEEE transactions on Neural Networks and Learning
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among the various generative adversarial network (GAN)-based image inpainting
methods, a coarse-to-fine network with a contextual attention module (CAM) has
shown remarkable performance. However, owing to two stacked generative
networks, the coarse-to-fine network needs numerous computational resources
such as convolution operations and network parameters, which result in low
speed. To address this problem, we propose a novel network architecture called
PEPSI: parallel extended-decoder path for semantic inpainting network, which
aims at reducing the hardware costs and improving the inpainting performance.
PEPSI consists of a single shared encoding network and parallel decoding
networks called coarse and inpainting paths. The coarse path produces a
preliminary inpainting result to train the encoding network for the prediction
of features for the CAM. Simultaneously, the inpainting path generates higher
inpainting quality using the refined features reconstructed via the CAM. In
addition, we propose Diet-PEPSI that significantly reduces the network
parameters while maintaining the performance. In Diet-PEPSI, to capture the
global contextual information with low hardware costs, we propose novel
rate-adaptive dilated convolutional layers, which employ the common weights but
produce dynamic features depending on the given dilation rates. Extensive
experiments comparing the performance with state-of-the-art image inpainting
methods demonstrate that both PEPSI and Diet-PEPSI improve the qualitative
scores, i.e. the peak signal-to-noise ratio (PSNR) and structural similarity
(SSIM), as well as significantly reduce hardware costs such as computational
time and the number of network parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09015</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09015</id><created>2019-05-22</created><authors><author><keyname>Giordani</keyname><forenames>Marco</forenames></author><author><keyname>Higuchi</keyname><forenames>Takamasa</forenames></author><author><keyname>Zanella</keyname><forenames>Andrea</forenames></author><author><keyname>Altintas</keyname><forenames>Onur</forenames></author><author><keyname>Zorzi</keyname><forenames>Michele</forenames></author></authors><title>A Framework to Assess Value of Information in Future Vehicular Networks</title><categories>eess.SP cs.NI</categories><comments>6 pages, 6 figures, 2 tables, accepted for publication to the 2019
  1st ACM Workshop on Technologies, mOdels, and Protocols for Cooperative
  Connected Cars (TOP-Cars)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicles are becoming increasingly intelligent and connected, incorporating
more and more sensors to support safer and more efficient driving. The large
volume of data generated by such sensors, however, will likely saturate the
capacity of vehicular communication technologies, making it challenging to
guarantee the required quality of service. In this perspective, it is essential
to assess the value of information (VoI) provided by each data source, to
prioritize the transmissions that have the greatest importance for the target
applications. In this paper, we propose and evaluate a framework that uses
analytic hierarchy multicriteria decision processes to predict VoI based on
space, time, and quality attributes. Our results shed light on the impact of
the propagation scenario, the sensor resolution, the type of observation, and
the communication distance on the value assessment performance. In particular,
we show that VoI evolves at different rates as a function of the target
application's characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09018</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09018</id><created>2019-05-22</created><authors><author><keyname>Steimle</keyname><forenames>Markus</forenames></author><author><keyname>Menzel</keyname><forenames>Till</forenames></author><author><keyname>Maurer</keyname><forenames>Markus</forenames></author></authors><title>A Method for Classifying Test Bench Configurations in a Scenario-Based
  Test Approach for Automated Vehicles</title><categories>eess.SP</categories><comments>Declined at 2019 IEEE Intelligent Vehicles Symposium, will be updated
  in near future, 7 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The introduction of automated vehicles demands a way to prove their safe
operation. However, validating the safety of automated vehicles is still an
unsolved problem. While the scenario-based test approach seems to provide a
possible solution, it requires the execution of a high amount of test cases.
Several test benches, from actual test vehicles to partly or fully simulated
environments, are available, but choosing the optimal test bench, e.g. in terms
of required execution time and costs, is a difficult task. Every test bench
provides different elements, e.g. simulation models which can be used for test
case execution. The composition of elements at a specific test bench is called
test bench configuration. This test bench configuration determines the actual
performance of a test bench and, therefore, whether the run of a particular
test case provides valid test case results with respect to the intended
purpose, e.g. a safety validation. For an effective and efficient test case
execution, a method is required to assign test cases to the most appropriate
test bench configuration. Therefore, it is indispensable to have a method to
classify test bench configurations in a clear and reproducible manner. In this
paper, we propose a method for classifying test benches and test bench
configurations and illustrate the classification method with some examples. The
classification method serves as a basis for a systematic assignment of test
cases to test bench configurations which allows for an effective and efficient
test case execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09049</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09049</id><created>2019-05-22</created><authors><author><keyname>You</keyname><forenames>Jia</forenames></author><author><keyname>Yu</keyname><forenames>Philip L. H.</forenames></author><author><keyname>Tsang</keyname><forenames>Anderson C. O.</forenames></author><author><keyname>Tsui</keyname><forenames>Eva L. H.</forenames></author><author><keyname>Woo</keyname><forenames>Pauline P. S.</forenames></author><author><keyname>Leung</keyname><forenames>Gilberto K. K.</forenames></author></authors><title>Automated Segmentation for Hyperdense Middle Cerebral Artery Sign of
  Acute Ischemic Stroke on Non-Contrast CT Images</title><categories>cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The hyperdense middle cerebral artery (MCA) dot sign has been reported as an
important factor in the diagnosis of acute ischemic stroke due to large vessel
occlusion. Interpreting the initial CT brain scan in these patients requires
high level of expertise, and has high inter-observer variability. An automated
computerized interpretation of the urgent CT brain image, with an emphasis to
pick up early signs of ischemic stroke will facilitate early patient diagnosis,
triage, and shorten the door-to-revascularization time for these group of
patients. In this paper, we present an automated detection method of segmenting
the MCA dot sign on non-contrast CT brain image scans based on powerful deep
learning technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09065</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09065</id><created>2019-05-22</created><authors><author><keyname>M&#xfc;ller</keyname><forenames>Johannes</forenames></author><author><keyname>Meuser</keyname><forenames>Tobias</forenames></author><author><keyname>Steinmetz</keyname><forenames>Ralf</forenames></author><author><keyname>Buchholz</keyname><forenames>Michael</forenames></author></authors><title>A Trust Management and Misbehaviour Detection Mechanism for Multi-Agent
  Systems and its Application to Intelligent Transportation Systems</title><categories>eess.SP cs.MA cs.SY</categories><comments>7 pages, accepted on 15th IEEE International Conference on Control
  and Automation (IEEE ICCA 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative information shared among a multi-agent system (MAS) can be useful
to agents to efficiently fulfill their missions. Relying on wrong information,
however, can have severe consequences. While classical approaches only consider
measurement uncertainty, reliability information on the incoming data can be
useful for decision making. In this work, a subjective logic based mechanism is
proposed that amends reliability information to the data shared among the MAS.
  If multiple agents report the same event, their information is fused. In
order to maintain high reliability, the mechanism detects and isolates
misbehaving agents. Therefore, an attacker model is specified that includes
faulty as well as malicious agents. The mechanism is applied to Intelligent
Transportation Systems (ITS) and it is shown in simulation that the approach
scales well with the size of the MAS and that it is able to efficiently
detected and isolated misbehaving agents.
  Keywords: Multi-agent systems, Fault Detection, Sensor/data fusion, Control
Applications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09068</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09068</id><created>2019-05-22</created><authors><author><keyname>Nikolaidis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Kristiansen</keyname><forenames>Stein</forenames></author><author><keyname>Goebel</keyname><forenames>Vera</forenames></author><author><keyname>Plagemann</keyname><forenames>Thomas</forenames></author><author><keyname>Liest&#xf8;l</keyname><forenames>Knut</forenames></author><author><keyname>Kankanhalli</keyname><forenames>Mohan</forenames></author></authors><title>Augmenting Physiological Time Series Data: A Case Study for Sleep Apnea
  Detection</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised machine learning applications in the health domain often face the
problem of insufficient training datasets. The quantity of labelled data is
small due to privacy concerns and the cost of data acquisition and labelling by
a medical expert. Furthermore, it is quite common that collected data are
unbalanced and getting enough data to personalize models for individuals is
very expensive or even infeasible. This paper addresses these problems by (1)
designing a recurrent Generative Adversarial Network to generate realistic
synthetic data and to augment the original dataset, (2) enabling the generation
of balanced datasets based on heavily unbalanced dataset, and (3) to control
the data generation in such a way that the generated data resembles data from
specific individuals. We apply these solutions for sleep apnea detection and
study in the evaluation the performance of four well-known techniques, i.e.,
K-Nearest Neighbour, Random Forest, Multi-Layer Perceptron, and Support Vector
Machine. All classifiers exhibit in the experiments a consistent increase in
sensitivity and a kappa statistic increase by between 0.007 and 0.182.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09120</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09120</id><created>2019-05-22</created><authors><author><keyname>Xia</keyname><forenames>ChenYang</forenames></author><author><keyname>Fan</keyname><forenames>YouZhe</forenames></author><author><keyname>Tsui</keyname><forenames>Chi-ying</forenames></author></authors><title>High Throughput Polar Decoding Using Two-Staged Adaptive Successive
  Cancellation List Decoding</title><categories>eess.SP</categories><comments>12 pages, 12 figures, 7 tables, Submitted to IEEE Transactions on
  Circuits and Systems I: Regular Papers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes are the first class of capacity-achieving forward error
correction (FEC) codes. They have been selected as one of the coding schemes
for the 5G communication systems due to their excellent error correction
performance when successive cancellation list (SCL) decoding with cyclic
redundancy check (CRC) is used. A large list size is necessary for SCL decoding
to achieve a low error rate. However, it impedes SCL decoding from achieving a
high throughput as the computational complexity is very high when a large list
size is used. In this paper, we propose a two-staged adaptive SCL (TA-SCL)
decoding scheme and the corresponding hardware architecture to accelerate SCL
decoding with a large list size. Constant system latency and data rate are
supported by TA-SCL decoding. To analyse the decoding performance of TA-SCL, an
accurate mathematical model based on Markov Chain is derived, which can be used
to determine the parameters for practical designs. A VLSI architecture
implementing TA-SCL decoding is then proposed. The proposed architecture is
implemented using UMC 90nm technology. Experimental results show that TA-SCL
can achieve throughputs of 3.00 and 2.35 Gbps when the list sizes are 8 and 32,
respectively, which are nearly 3 times as that of the state-ofthe-art SCL
decoding architectures, with negligible performance degradation on a wide
signal-to-noise ratio (SNR) range and small hardware overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09148</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09148</id><created>2019-05-22</created><authors><author><keyname>Zhang</keyname><forenames>Jingjing</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author></authors><title>LAGC: Lazily Aggregated Gradient Coding for Straggler-Tolerant and
  Communication-Efficient Distributed Learning</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gradient-based distributed learning in Parameter Server (PS) computing
architectures is subject to random delays due to straggling worker nodes, as
well as to possible communication bottlenecks between PS and workers. Solutions
have been recently proposed to separately address these impairments based on
the ideas of gradient coding, worker grouping, and adaptive worker selection.
This paper provides a unified analysis of these techniques in terms of
wall-clock time, communication, and computation complexity measures.
Furthermore, in order to combine the benefits of gradient coding and grouping
in terms of robustness to stragglers with the communication and computation
load gains of adaptive selection, novel strategies, named Lazily Aggregated
Gradient Coding (LAGC) and Grouped-LAG (G-LAG), are introduced. Analysis and
results show that G-LAG provides the best wall-clock time and communication
performance, while maintaining a low computational cost, for two representative
distributions of the computing times of the worker nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09152</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09152</id><created>2019-05-22</created><authors><author><keyname>Huang</keyname><forenames>Xu</forenames></author><author><keyname>Qin</keyname><forenames>Rongjun</forenames></author></authors><title>Multi-View Large-Scale Bundle Adjustment Method for High-Resolution
  Satellite Images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given enough multi-view image corresponding points (also called tie points)
and ground control points (GCP), bundle adjustment for high-resolution
satellite images is used to refine the orientations or most often used
geometric parameters Rational Polynomial Coefficients (RPC) of each satellite
image in a unified geodetic framework, which is very critical in many
photogrammetry and computer vision applications. However, the growing number of
high resolution spaceborne optical sensors has brought two challenges to the
bundle adjustment: 1) images come from different satellite cameras may have
different imaging dates, viewing angles, resolutions, etc., thus resulting in
geometric and radiometric distortions in the bundle adjustment; 2) The
large-scale mapping area always corresponds to vast number of bundle adjustment
corrections (including RPC bias and object space point coordinates). Due to the
limitation of computer memory, it is hard to refine all corrections at the same
time. Hence, how to efficiently realize the bundle adjustment in large-scale
regions is very important. This paper particularly addresses the multi-view
large-scale bundle adjustment problem by two steps: 1) to get robust tie points
among different satellite images, we design a multi-view, multi-source tie
point matching algorithm based on plane rectification and epipolar constraints,
which is able to compensate geometric and local nonlinear radiometric
distortions among satellite datasets, and 2) to solve dozens of thousands or
even millions of variables bundle adjustment corrections in the large scale
bundle adjustment, we use an efficient solution with only a little computer
memory. Experiments on in-track and off-track satellite datasets show that the
proposed method is capable of computing sub-pixel accuracy bundle adjustment
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09231</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09231</id><created>2019-05-22</created><authors><author><keyname>Montazeri</keyname><forenames>Zahra</forenames></author><author><keyname>M</keyname><forenames>Gopi</forenames></author></authors><title>Separating Overlapping Tissue Layers from Microscopy Images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manual preparation of tissue slices for microscopy imaging can introduce
tissue tears and overlaps. Typically, further digital processing algorithms
such as registration and 3D reconstruction from tissue image stacks cannot
handle images with tissue tear/overlap artifacts, and so such images are
usually discarded. In this paper, we propose an imaging model and an algorithm
to digitally separate overlapping tissue data of mouse brain images into two
layers. We show the correctness of our model and the algorithm by comparing our
results with the ground truth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09263</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09263</id><created>2019-05-22</created><updated>2019-11-20</updated><authors><author><keyname>Ren</keyname><forenames>Yi</forenames></author><author><keyname>Ruan</keyname><forenames>Yangjun</forenames></author><author><keyname>Tan</keyname><forenames>Xu</forenames></author><author><keyname>Qin</keyname><forenames>Tao</forenames></author><author><keyname>Zhao</keyname><forenames>Sheng</forenames></author><author><keyname>Zhao</keyname><forenames>Zhou</forenames></author><author><keyname>Liu</keyname><forenames>Tie-Yan</forenames></author></authors><title>FastSpeech: Fast, Robust and Controllable Text to Speech</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted by NeurIPS2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural network based end-to-end text to speech (TTS) has significantly
improved the quality of synthesized speech. Prominent methods (e.g., Tacotron
2) usually first generate mel-spectrogram from text, and then synthesize speech
from the mel-spectrogram using vocoder such as WaveNet. Compared with
traditional concatenative and statistical parametric approaches, neural network
based end-to-end models suffer from slow inference speed, and the synthesized
speech is usually not robust (i.e., some words are skipped or repeated) and
lack of controllability (voice speed or prosody control). In this work, we
propose a novel feed-forward network based on Transformer to generate
mel-spectrogram in parallel for TTS. Specifically, we extract attention
alignments from an encoder-decoder based teacher model for phoneme duration
prediction, which is used by a length regulator to expand the source phoneme
sequence to match the length of the target mel-spectrogram sequence for
parallel mel-spectrogram generation. Experiments on the LJSpeech dataset show
that our parallel model matches autoregressive models in terms of speech
quality, nearly eliminates the problem of word skipping and repeating in
particularly hard cases, and can adjust voice speed smoothly. Most importantly,
compared with autoregressive Transformer TTS, our model speeds up
mel-spectrogram generation by 270x and the end-to-end speech synthesis by 38x.
Therefore, we call our model FastSpeech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09282</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09282</id><created>2019-05-22</created><authors><author><keyname>Gessert</keyname><forenames>Nils</forenames></author><author><keyname>Priegnitz</keyname><forenames>Torben</forenames></author><author><keyname>Saathoff</keyname><forenames>Thore</forenames></author><author><keyname>Antoni</keyname><forenames>Sven-Thomas</forenames></author><author><keyname>Meyer</keyname><forenames>David</forenames></author><author><keyname>Hamann</keyname><forenames>Moritz Franz</forenames></author><author><keyname>J&#xfc;nemann</keyname><forenames>Klaus-Peter</forenames></author><author><keyname>Otte</keyname><forenames>Christoph</forenames></author><author><keyname>Schlaefer</keyname><forenames>Alexander</forenames></author></authors><title>Spatio-Temporal Deep Learning Models for Tip Force Estimation During
  Needle Insertion</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in the International Journal of Computer
  Assisted Radiology and Surgery</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose. Precise placement of needles is a challenge in a number of clinical
applications such as brachytherapy or biopsy. Forces acting at the needle cause
tissue deformation and needle deflection which in turn may lead to misplacement
or injury. Hence, a number of approaches to estimate the forces at the needle
have been proposed. Yet, integrating sensors into the needle tip is challenging
and a careful calibration is required to obtain good force estimates.
  Methods. We describe a fiber-optical needle tip force sensor design using a
single OCT fiber for measurement. The fiber images the deformation of an epoxy
layer placed below the needle tip which results in a stream of 1D depth
profiles. We study different deep learning approaches to facilitate calibration
between this spatio-temporal image data and the related forces. In particular,
we propose a novel convGRU-CNN architecture for simultaneous spatial and
temporal data processing.
  Results. The needle can be adapted to different operating ranges by changing
the stiffness of the epoxy layer. Likewise, calibration can be adapted by
training the deep learning models. Our novel convGRU-CNN architecture results
in the lowest mean absolute error of 1.59 +- 1.3 mN and a cross-correlation
coefficient of 0.9997, and clearly outperforms the other methods. Ex vivo
experiments in human prostate tissue demonstrate the needle's application.
  Conclusions. Our OCT-based fiber-optical sensor presents a viable alternative
for needle tip force estimation. The results indicate that the rich
spatio-temporal information included in the stream of images showing the
deformation throughout the epoxy layer can be effectively used by deep learning
models. Particularly, we demonstrate that the convGRU-CNN architecture performs
favorably, making it a promising approach for other spatio-temporal learning
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09324</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09324</id><created>2019-05-22</created><authors><author><keyname>Weiss</keyname><forenames>Tomer</forenames></author><author><keyname>Vedula</keyname><forenames>Sanketh</forenames></author><author><keyname>Senouf</keyname><forenames>Ortal</forenames></author><author><keyname>Bronstein</keyname><forenames>Alex</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Zibulevsky</keyname><forenames>Michael</forenames></author></authors><title>Learning Fast Magnetic Resonance Imaging</title><categories>eess.IV cs.CV eess.SP physics.med-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Magnetic Resonance Imaging (MRI) is considered today the golden-standard
modality for soft tissues. The long acquisition times, however, make it more
prone to motion artifacts as well as contribute to the relatively high costs of
this examination. Over the years, multiple studies concentrated on designing
reduced measurement schemes and image reconstruction schemes for MRI, however,
these problems have been so far addressed separately. On the other hand, recent
works in optical computational imaging have demonstrated growing success of the
simultaneous learning-based design of the acquisition and reconstruction
schemes manifesting significant improvement in the reconstruction quality with
a constrained time budget. Inspired by these successes, in this work, we
propose to learn accelerated MR acquisition schemes (in the form of Cartesian
trajectories) jointly with the image reconstruction operator. To this end, we
propose an algorithm for training the combined acquisition-reconstruction
pipeline end-to-end in a differentiable way. We demonstrate the significance of
using the learned Cartesian trajectories at different speed up rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09325</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09325</id><created>2019-05-22</created><authors><author><keyname>Senouf</keyname><forenames>Ortal</forenames></author><author><keyname>Vedula</keyname><forenames>Sanketh</forenames></author><author><keyname>Weiss</keyname><forenames>Tomer</forenames></author><author><keyname>Bronstein</keyname><forenames>Alex</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Zibulevsky</keyname><forenames>Michael</forenames></author></authors><title>Self-supervised learning of inverse problem solvers in medical imaging</title><categories>eess.IV cs.CV eess.SP</categories><comments>preprint</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In the past few years, deep learning-based methods have demonstrated enormous
success for solving inverse problems in medical imaging. In this work, we
address the following question:\textit{Given a set of measurements obtained
from real imaging experiments, what is the best way to use a learnable model
and the physics of the modality to solve the inverse problem and reconstruct
the latent image?} Standard supervised learning based methods approach this
problem by collecting data sets of known latent images and their corresponding
measurements. However, these methods are often impractical due to the lack of
availability of appropriately sized training sets, and, more generally, due to
the inherent difficulty in measuring the &quot;groundtruth&quot; latent image. In light
of this, we propose a self-supervised approach to training inverse models in
medical imaging in the absence of aligned data. Our method only requiring
access to the measurements and the forward model at training. We showcase its
effectiveness on inverse problems arising in accelerated magnetic resonance
imaging (MRI).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09339</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09339</id><created>2019-05-22</created><authors><author><keyname>Alegro</keyname><forenames>Maryana</forenames></author><author><keyname>Alho</keyname><forenames>Eduardo J. L.</forenames></author><author><keyname>Martin</keyname><forenames>Maria da Graca Morais</forenames></author><author><keyname>Grinberg</keyname><forenames>Lea Teneholz</forenames></author><author><keyname>Heinsen</keyname><forenames>Helmut</forenames></author><author><keyname>Lopes</keyname><forenames>Roseli de Deus</forenames></author><author><keyname>Amaro-Jr</keyname><forenames>Edson</forenames></author><author><keyname>Z&#xf6;llei</keyname><forenames>Lilla</forenames></author></authors><title>Automating Whole Brain Histology to MRI Registration: Implementation of
  a Computational Pipeline</title><categories>cs.CV eess.IV q-bio.TO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the latest advances in MRI technology have allowed the acquisition
of higher resolution images, reliable delineation of cytoarchitectural or
subcortical nuclei boundaries is not possible. As a result, histological images
are still required to identify the exact limits of neuroanatomical structures.
However, histological processing is associated with tissue distortion and
fixation artifacts, which prevent a direct comparison between the two
modalities. Our group has previously proposed a histological procedure based on
celloidin embedding that reduces the amount of artifacts and yields high
quality whole brain histological slices. Celloidin embedded tissue,
nevertheless, still bears distortions that must be corrected. We propose a
computational pipeline designed to semi-automatically process the celloidin
embedded histology and register them to their MRI counterparts. In this paper
we report the accuracy of our pipeline in two whole brain volumes from the
Brain Bank of the Brazilian Aging Brain Study Group (BBBABSG). Results were
assessed by comparison of manual segmentations from two experts in both MRIs
and the registered histological volumes. The two whole brain histology/MRI
datasets were successfully registered using minimal user interaction. We also
point to possible improvements based on recent implementations that could be
added to this pipeline, potentially allowing for higher precision and further
performance gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09369</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09369</id><created>2019-05-22</created><updated>2019-12-16</updated><authors><author><keyname>Prasadan</keyname><forenames>Arvind</forenames></author><author><keyname>Nadakuditi</keyname><forenames>Raj Rao</forenames></author><author><keyname>Paul</keyname><forenames>Debashis</forenames></author></authors><title>Sparse Equisigned PCA: Algorithms and Performance Bounds in the Noisy
  Rank-1 Setting</title><categories>math.ST cs.LG eess.SP stat.TH</categories><comments>To appear, Electronic Journal of Statistics, 2020</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Singular value decomposition (SVD) based principal component analysis (PCA)
breaks down in the high-dimensional and limited sample size regime below a
certain critical eigen-SNR that depends on the dimensionality of the system and
the number of samples. Below this critical eigen-SNR, the estimates returned by
the SVD are asymptotically uncorrelated with the latent principal components.
We consider a setting where the left singular vector of the underlying rank one
signal matrix is assumed to be sparse and the right singular vector is assumed
to be equisigned, that is, having either only nonnegative or only nonpositive
entries. We consider six different algorithms for estimating the sparse
principal component based on different statistical criteria and prove that by
exploiting sparsity, we recover consistent estimates in the low eigen-SNR
regime where the SVD fails. Our analysis reveals conditions under which a
coordinate selection scheme based on a \textit{sum-type decision statistic}
outperforms schemes that utilize the $\ell_1$ and $\ell_2$ norm-based
statistics. We derive lower bounds on the size of detectable coordinates of the
principal left singular vector and utilize these lower bounds to derive lower
bounds on the worst-case risk. Finally, we verify our findings with numerical
simulations and illustrate the performance with a video data example, where the
interest is in identifying objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09384</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09384</id><created>2019-05-17</created><authors><author><keyname>Kuhestani</keyname><forenames>Ali</forenames></author><author><keyname>Mamaghani</keyname><forenames>Milad Tatar</forenames></author><author><keyname>Behroozi</keyname><forenames>Hamid</forenames></author></authors><title>A new secure multi-hop untrusted relaying scheme</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 3 figures , submitted for possible journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative relaying is utilized as an efficient method for data
communication in wireless sensor networks and Internet of Things (IoT).
However, sometimes due to the necessity of multi-hop relaying in such
communication networks, it is challenging to guarantee the secrecy of
cooperative transmissions when the relays may themselves be eavesdroppers,
i.e., we may face with the untrusted relaying scenario where the relays are
both necessary helpers and potential eavesdroppers. To obviate this issue, a
new cooperative jamming scheme is proposed in this paper, in which the data can
be confidentially communicated from the source to the destination through
multi-hop untrusted relays. Toward this end, we first consider a two successive
untrusted relaying network, i.e, a three-hop communication network. In our
proposed secure transmission scheme, all the legitimate nodes contribute to
provide secure communication by smartly injecting artificial noises to the
network in different communication phases. Given this system model, a novel
closed-form expression is presented in the high signal-to-noise ratio (SNR)
regime for the ergodic secrecy rate (ESR). Furthermore, we evaluate the high
SNR slope and power offset of the ESR to gain a basic comparison of the
proposed secure transmission scheme and the state-of-arts. Our numerical
results highlight that the proposed secure transmission scheme provides better
secrecy rate compared with the two-hop untrusted relaying scheme as well as the
direct transmission scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09386</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09386</id><created>2019-05-18</created><updated>2019-07-16</updated><authors><author><keyname>Ghanbari</keyname><forenames>Mohammad Meraj</forenames></author><author><keyname>Piech</keyname><forenames>David K.</forenames></author><author><keyname>Shen</keyname><forenames>Konlin</forenames></author><author><keyname>Alamouti</keyname><forenames>Sina Faraji</forenames></author><author><keyname>Yalcin</keyname><forenames>Cem</forenames></author><author><keyname>Johnson</keyname><forenames>Benjamin C.</forenames></author><author><keyname>Carmena</keyname><forenames>Jose M.</forenames></author><author><keyname>Maharbiz</keyname><forenames>Michel M.</forenames></author><author><keyname>Muller</keyname><forenames>Rikky</forenames></author></authors><title>A Sub-mm$^3$ Ultrasonic Free-floating Implant for Multi-mote Neural
  Recording</title><categories>eess.SP cs.ET</categories><comments>11 pages, 22 figures, Submitted to Journal of Solid-State Circuits</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 0.8 mm$^3$ wireless, ultrasonically powered, free-floating neural recording
implant is presented. The device is comprised only of a 0.25 mm$^2$ recording
IC and a single piezoceramic resonator that is used for both power harvesting
and data transmission. Uplink data transmission is performed by analog
amplitude modulation of the ultrasound echo. Using a 1.78 MHz main carrier, &gt;35
kbps/mote equivalent uplink data rate is achieved. A technique to linearize the
echo amplitude modulation is introduced, resulting in &lt;1.2\% static
nonlinearity of the received signal over a $\pm$10 mV input range. The IC
dissipates 37.7 $\mu$W, while the neural recording front-end consumes 4 $\mu$W
and achieves a noise floor of 5.3 $\mu$V$_{rms}$ in a 5 kHz bandwidth. This
work improves sub-mm recording mote depth by &gt;2.5x, resulting in the highest
measured depth/volume ratio by $\sim$3x. Orthogonal subcarrier modulation
enables simultaneous operation of multiple implants, using a single-element
ultrasound external transducer. Dual-mote simultaneous power up and data
transmission is demonstrated at a rate of 7 kS/s at the depth of 50 mm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09387</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09387</id><created>2019-05-21</created><authors><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Ma</keyname><forenames>Xu</forenames></author><author><keyname>Arce</keyname><forenames>Gonzalo R.</forenames></author></authors><title>Compressive spectral imaging based on hexagonal blue noise coded
  apertures</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coded aperture snapshot spectral imager (CASSI) is a computational imaging
system that acquires a three dimensional (3D) spectral data cube by single or a
few two dimensional (2D) measurements. Binary random coded apertures with
square pixels are primarily implemented in CASSI systems to modulate the
spectral images in spatial domain. The design and optimization of coded
apertures was shown to improve the imaging performance of these systems
significantly. This work proposes a different approach to code design. Instead
of traditional squared tiled coded elements, hexagonal tiled elements are used.
The dislocation between the binary hexagonal pixels on coded apertures and the
square pixels on detector introduces equivalent grey-scale spatial modulation
to increase the degrees of freedom in the sensing matrix, thus further
improving the spectral imaging performance. Then, this paper presents an
optimal structure under the criterion of satisfying the restricted isometry
property (RIP) with high probability, coined blue noise (BN) coded apertures.
In addition, this paper studies and verifies the proposed hexagonal blue noise
coded aperture method on a general CASSI system, where the resolution of the
coded aperture is equivalent to that of the detector. Based on the RIP
criterion, this paper theoretically proves the superiority of the hexagonal
blue noise coded aperture over the traditional random coded aperture with
square lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09388</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09388</id><created>2019-05-19</created><updated>2019-08-26</updated><authors><author><keyname>Gopalakrishnan</keyname><forenames>Soorya</forenames></author><author><keyname>Cekic</keyname><forenames>Metehan</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author></authors><title>Robust Wireless Fingerprinting via Complex-Valued Neural Networks</title><categories>eess.SP cs.LG stat.ML</categories><comments>Accepted at IEEE Global Communications Conference (Globecom) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A &quot;wireless fingerprint&quot; which exploits hardware imperfections unique to each
device is a potentially powerful tool for wireless security. Such a fingerprint
should be able to distinguish between devices sending the same message, and
should be robust against standard spoofing techniques. Since the information in
wireless signals resides in complex baseband, in this paper, we explore the use
of neural networks with complex-valued weights to learn fingerprints using
supervised learning. We demonstrate that, while there are potential benefits to
using sections of the signal beyond just the preamble to learn fingerprints,
the network cheats when it can, using information such as transmitter ID (which
can be easily spoofed) to artificially inflate performance. We also show that
noise augmentation by inserting additional white Gaussian noise can lead to
significant performance gains, which indicates that this counter-intuitive
strategy helps in learning more robust fingerprints. We provide results for two
different wireless protocols, WiFi and ADS-B, demonstrating the effectiveness
of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09440</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09440</id><created>2019-05-22</created><authors><author><keyname>Jin</keyname><forenames>Benzhou</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Wu</keyname><forenames>Qihui</forenames></author><author><keyname>Zhang</keyname><forenames>Yuhong</forenames></author><author><keyname>Xu</keyname><forenames>Zhiwei</forenames></author></authors><title>One-bit LFMCW Radar: Spectrum Analysis and Target Detection</title><categories>eess.SP cs.IT math.IT</categories><comments>32 pages in single column, 11 figures. Comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-bit radar involving direct one-bit sampling is a promising technology for
many civilian applications due to its low-cost and low-power consumptions. In
this paper, problems encountered by one-bit LFMCW radar are studied and a
two-stage target detection approach termed as DR-GAMP is proposed. Firstly, the
spectrum of one-bit signal in a scenario of multiple targets is analyzed. It is
indicated that high-order harmonics may result in false alarms (FAs) and cannot
be neglected. Secondly, DR-GAMP is used to suppress the high order harmonics.
Specifically, linear preprocessing and predetection are proposed to perform
dimension reduction (DR), and then, generalized approximate message passing
(GAMP) is utilized to suppress high-order harmonics. Finally, numerical
simulations are conducted to evaluate the performance of one-bit LFMCW radar
with typical parameters. It is shown that compared to conventional radar with
linear processing approach, one-bit LFMCW radar has $0.5$ dB performance gain
when the input signal-to-noise ratios (SNRs) of targets are low. Moreover, it
has $1.6$ dB performance loss in a scenario with an additional high SNR target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09454</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09454</id><created>2019-05-23</created><updated>2020-01-06</updated><authors><author><keyname>Sahay</keyname><forenames>Shubham</forenames></author><author><keyname>Bavandpour</keyname><forenames>Mohammad</forenames></author><author><keyname>Mahmoodi</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Strukov</keyname><forenames>Dmitri</forenames></author></authors><title>Energy-Efficient Moderate Precision Time-Domain Mixed-signal
  Vector-by-Matrix Multiplier Exploiting 1T-1R Arrays</title><categories>eess.SP cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emerging mobile devices in this era of internet-of-things (IoT) require a
dedicated processor to enable computationally intensive applications such as
neuromorphic computing and signal processing. Vector-by-matrix multiplication
(VMM) is the most prominent operation in these applications. Therefore, there
is a critical need for compact and ultralow-power VMM blocks to perform
resource-intensive low-to-moderate precision computations. To this end, in this
work, for the first time, we propose a time-domain mixed-signal VMM exploiting
a modified configuration of 1MOSFET-1RRAM (1T-1R) array. The proposed VMM
overcomes the energy inefficiency of the current-mode VMM approaches based on
RRAMs. A rigorous analysis of the different non-ideal factors affecting the
computational precision indicates that the non-negligible minimum cell
currents, channel length modulation (CLM) and drain-induced barrier lowering
(DIBL) are the dominant mechanisms degrading the precision of the proposed VMM.
Our results also indicate that there exists a trade-off between the
computational precision, dynamic range, and the area- and energy-efficiency of
the proposed VMM approach. Therefore, we provide the necessary design
guidelines for optimizing the performance. Our preliminary results show that an
effective computational precision of 6-bits is achievable owing to an inherent
compensation effect in the modified 1T-1R blocks. Furthermore, a 4-bit 200x200
VMM utilizing the proposed approach exhibits a significantly high energy
efficiency of ~1.5 POps/J and a throughput of 2.5 TOps/s including the
contribution from the input/output (I/O) circuitry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09472</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09472</id><created>2019-05-22</created><updated>2020-02-07</updated><authors><author><keyname>Mokatren</keyname><forenames>Lubna Shibly</forenames></author><author><keyname>Ansari</keyname><forenames>Rashid</forenames></author><author><keyname>Cetin</keyname><forenames>Ahmet Enis</forenames></author><author><keyname>Leow</keyname><forenames>Alex D</forenames></author><author><keyname>Klumpp</keyname><forenames>Heide</forenames></author><author><keyname>Ajilore</keyname><forenames>Olusola</forenames></author><author><keyname>Vural</keyname><forenames>Fatos Yarman</forenames></author></authors><title>EEG Classification by factoring in Sensor Configuration</title><categories>eess.SP cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1812.02865</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalography (EEG) serves as an effective diagnostic tool for
mental disorders and neurological abnormalities. Enhanced analysis and
classification of EEG signals can help improve detection performance. A new
approach is examined here for enhancing EEG classification performance by
leveraging knowledge of spatial layout of EEG sensors. Performance of two
classification models - model 1 that ignores the sensor layout and model 2 that
factors it in - is investigated and found to achieve consistently higher
detection accuracy. The analysis is based on the information content of these
signals represented in two different ways: concatenation of the channels of the
frequency bands and an image-like 2D representation of the EEG channel
locations. Performance of these models is examined on two tasks, social anxiety
disorder (SAD) detection, and emotion recognition using a dataset for emotion
analysis using physiological signals (DEAP). We hypothesized that model 2 will
significantly outperform model 1 and this was validated in our results as model
2 yielded $5$--$8\%$ higher accuracy in all machine learning algorithms
investigated. Convolutional Neural Networks (CNN) provided the best performance
far exceeding that of Support Vector Machine (SVM) and k-Nearest Neighbors
(kNNs) algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09490</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09490</id><created>2019-05-23</created><updated>2019-05-31</updated><authors><author><keyname>Seynnes</keyname><forenames>Olivier R.</forenames></author><author><keyname>Cronin</keyname><forenames>Neil J.</forenames></author></authors><title>Simple Muscle Architecture Analysis (SMA): an ImageJ macro tool to
  automate measurements in B-mode ultrasound scans</title><categories>eess.IV physics.med-ph q-bio.TO</categories><comments>8 pages, 7 figures, 1 appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In vivo measurements of muscle architecture (i.e. the spatial arrangement of
muscle fascicles) are routinely included in research and clinical settings to
monitor muscle structure, function and plasticity. However, in most cases such
measurements are performed manually, and more reliable and time-efficient
automated methods are either lacking completely, or are inaccessible to those
without expertise in image analysis. In this work, we propose an ImageJ script
to automate the entire analysis process of muscle architecture in ultrasound
images: Simple Muscle Architecture Analysis (SMA). Images are filtered in the
spatial and frequency domains with built-in commands and external plugins to
highlight aponeuroses and fascicles. Fascicle dominant orientation is then
computed in regions of interest using the OrientationJ plugin. Bland-Altman
plots of analyses performed manually or with SMA indicates that the automated
analysis does not induce any systematic bias and that both methods agree
equally through the range of measurements. Our test results illustrate the
suitability of SMA to analyse images from superficial muscles acquired with a
broad range of ultrasound settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09498</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09498</id><created>2019-05-23</created><authors><author><keyname>Azuatalam</keyname><forenames>Donald</forenames></author><author><keyname>Paridari</keyname><forenames>Kaveh</forenames></author><author><keyname>Ma</keyname><forenames>Yiju</forenames></author><author><keyname>F&#xf6;rstl</keyname><forenames>Markus</forenames></author><author><keyname>Chapman</keyname><forenames>Archie C.</forenames></author><author><keyname>Verbi&#x10d;</keyname><forenames>Gregor</forenames></author></authors><title>Energy management of small-scale PV-battery systems: A systematic review
  considering practical implementation, computational requirements, quality of
  input data and battery degradation</title><categories>eess.SP</categories><doi>10.1016/j.rser.2019.06.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The home energy management problem has many different facets, including
economic viability, data uncertainty and quality of strategy employed. The
existing literature in this area focuses on individual aspects of this problem
without a detailed, holistic analysis of the results with regards to
practicality in implementation. In this paper, we fill this gap by performing a
comprehensive comparison of seven different energy management strategies, each
with different levels of practicality, sophistication and computational
requirements. We analyse the results in the context of these three
characteristics, and also critique the modelling assumptions made by each
strategy. Our analysis finds that using a more sophisticated energy management
strategy may not necessarily improve the performance and economic viability of
the PV-battery system due to the effects of modeling assumptions, such as the
treatment of uncertainties in the input data and battery degradation effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09514</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09514</id><created>2019-05-23</created><authors><author><keyname>Qiu</keyname><forenames>Min</forenames></author><author><keyname>Huang</keyname><forenames>Yu-Chih</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Downlink Non-Orthogonal Multiple Access without SIC for Block Fading
  Channels: An Algebraic Rotation Approach</title><categories>cs.IT eess.SP math.IT</categories><comments>15 pages, 8 figures, accepted by IEEE Transactions on Wireless
  Communications</comments><doi>10.1109/TWC.2019.2919292</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the problem of downlink non-orthogonal multiple
access (NOMA) over block fading channels. For the single antenna case, we
propose a class of NOMA schemes where all the users' signals are mapped into
$n$-dimensional constellations corresponding to the same algebraic lattices
from a number field, allowing every user attains full diversity gain with
single-user decoding, i.e., no successive interference cancellation (SIC). The
minimum product distances of the proposed scheme with arbitrary power
allocation factor are analyzed and their upper bounds are derived. Within the
proposed class of schemes, we also identify a special family of NOMA schemes
based on lattice partitions of the underlying ideal lattices, whose minimum
product distances can be easily controlled. Our analysis shows that among the
proposed schemes, the lattice-partition-based schemes achieve the largest
minimum product distances of the superimposed constellations, which are closely
related to the symbol error rates for receivers with single-user decoding.
Simulation results are presented to verify our analysis and to show the
effectiveness of the proposed schemes as compared to benchmark NOMA schemes.
Extensions of our design to the multi-antenna case are also considered where
similar analysis and results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09525</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09525</id><created>2019-05-23</created><authors><author><keyname>Wang</keyname><forenames>Haifeng</forenames></author><author><keyname>Cheng</keyname><forenames>Jing</forenames></author><author><keyname>Jia</keyname><forenames>Sen</forenames></author><author><keyname>Qiu</keyname><forenames>Zhilang</forenames></author><author><keyname>Shi</keyname><forenames>Caiyun</forenames></author><author><keyname>Zou</keyname><forenames>Lixian</forenames></author><author><keyname>Su</keyname><forenames>Shi</forenames></author><author><keyname>Chang</keyname><forenames>Yuchou</forenames></author><author><keyname>Zhu</keyname><forenames>Yanjie</forenames></author><author><keyname>Ying</keyname><forenames>Leslie</forenames></author><author><keyname>Liang</keyname><forenames>Dong</forenames></author></authors><title>Accelerating MR Imaging via Deep Chambolle-Pock Network</title><categories>eess.IV physics.med-ph</categories><comments>4 pages, 5 figures, 1 table, Accepted at 2019 IEEE 41st Engineering
  in Medicine and Biology Conference (EMBC 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) has been introduced to accelerate data acquisition in
MR Imaging. However, CS-MRI methods suffer from detail loss with large
acceleration and complicated parameter selection. To address the limitations of
existing CS-MRI methods, a model-driven MR reconstruction is proposed that
trains a deep network, named CP-net, which is derived from the Chambolle-Pock
algorithm to reconstruct the in vivo MR images of human brains from highly
undersampled complex k-space data acquired on different types of MR scanners.
The proposed deep network can learn the proximal operator and parameters among
the Chambolle-Pock algorithm. All of the experiments show that the proposed
CP-net achieves more accurate MR reconstruction results, outperforming
state-of-the-art methods across various quantitative metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09533</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09533</id><created>2019-05-23</created><authors><author><keyname>Mei</keyname><forenames>Jilin</forenames></author><author><keyname>Zhao</keyname><forenames>Huijing</forenames></author></authors><title>Incorporating Human Domain Knowledge in 3D LiDAR-based Semantic
  Segmentation</title><categories>cs.RO cs.CV eess.IV</categories><comments>8 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies semantic segmentation using 3D LiDAR data. Popular deep
learning methods applied for this task require a large number of manual
annotations to train the parameters. We propose a new method that makes full
use of the advantages of traditional methods and deep learning methods via
incorporating human domain knowledge into the neural network model to reduce
the demand for large numbers of manual annotations and improve the training
efficiency. We first pretrain a model with autogenerated samples from a
rule-based classifier so that human knowledge can be propagated into the
network. Based on the pretrained model, only a small set of annotations is
required for further fine-tuning. Quantitative experiments show that the
pretrained model achieves better performance than random initialization in
almost all cases; furthermore, our method can achieve similar performance with
fewer manual annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09588</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09588</id><created>2019-05-23</created><authors><author><keyname>Ichimaru</keyname><forenames>Kazuto</forenames></author><author><keyname>Kawasaki</keyname><forenames>Hiroshi</forenames></author></authors><title>Underwater Stereo using Refraction-free Image Synthesized from Light
  Field Camera</title><categories>eess.IV cs.CV</categories><comments>Accepted in 2019 IEEE International Conference on Image Processing
  (ICIP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a strong demand on capturing underwater scenes without distortions
caused by refraction. Since a light field camera can capture several light rays
at each point of an image plane from various directions, if geometrically
correct rays are chosen, it is possible to synthesize a refraction-free image.
In this paper, we propose a novel technique to efficiently select such rays to
synthesize a refraction-free image from an underwater image captured by a light
field camera. In addition, we propose a stereo technique to reconstruct 3D
shapes using a pair of our refraction-free images, which are central
projection. In the experiment, we captured several underwater scenes by two
light field cameras, synthesized refraction free images and applied stereo
technique to reconstruct 3D shapes. The results are compared with previous
techniques which are based on approximation, showing the strength of our
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09589</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09589</id><created>2019-05-23</created><authors><author><keyname>Chen</keyname><forenames>Qijian</forenames></author><author><keyname>Wang</keyname><forenames>Lihui</forenames></author><author><keyname>Wang</keyname><forenames>Li</forenames></author><author><keyname>Deng</keyname><forenames>Zeyu</forenames></author><author><keyname>Zhang</keyname><forenames>Jian</forenames></author><author><keyname>Zhu</keyname><forenames>Yuemin</forenames></author></authors><title>Glioma Grade Predictions using Scattering Wavelet Transform-Based
  Radiomics</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Glioma grading before the surgery is very critical for the prognosis
prediction and treatment plan making. In this paper, we present a novel
scattering wavelet-based radiomics method to predict noninvasively and
accurately the glioma grades. The multimodal magnetic resonance images of 285
patients were used, with the intratumoral and peritumoral regions well labeled.
The wavelet scattering-based features and traditional radiomics features were
firstly extracted from both intratumoral and peritumoral regions respectively.
The support vector machine (SVM), logistic regression (LR) and random forest
(RF) were then trained with 5-fold cross validation to predict the glioma
grades. The prediction obtained with different features was finally evaluated
in terms of quantitative metrics. The area under the receiver operating
characteristic curve (AUC) of glioma grade prediction based on scattering
wavelet features was up to 0.99 when considering both intratumoral and
peritumoral features in multimodal images, which increases by about 17%
compared to traditional radiomics. Such results shown that the local invariant
features extracted from the scattering wavelet transform allows improving the
prediction accuracy for glioma grading. In addition, the features extracted
from peritumoral regions further increases the accuracy of glioma grading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09611</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09611</id><created>2019-05-23</created><authors><author><keyname>Alt&#x131;n&#x131;&#x15f;&#x131;k</keyname><forenames>Enes</forenames></author><author><keyname>Ta&#x15f;demir</keyname><forenames>Kas&#x131;m</forenames></author><author><keyname>Sencar</keyname><forenames>H&#xfc;srev Taha</forenames></author></authors><title>Mitigation of H.264 and H.265 Video Compression for Reliable PRNU
  Estimation</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The photo-response non-uniformity (PRNU) is a distinctive image sensor
characteristic, and an imaging device inadvertently introduces its sensor's
PRNU into all media it captures. Therefore, the PRNU can be regarded as a
camera fingerprint and used for source attribution. The imaging pipeline in a
camera, however, involves various processing steps that are detrimental to PRNU
estimation. In the context of photographic images, these challenges are
successfully addressed and the method for estimating a sensor's PRNU pattern is
well established. However, various additional challenges related to generation
of videos remain largely untackled. With this perspective, this work introduces
methods to mitigate disruptive effects of widely deployed H.264 and H.265 video
compression standards on PRNU estimation. Our approach involves an intervention
in the decoding process to eliminate a filtering procedure applied at the
decoder to reduce blockiness. It also utilizes decoding parameters to develop a
weighting scheme and adjust the contribution of video frames at the macroblock
level to PRNU estimation process. Results obtained on videos captured by 28
cameras show that our approach increases the PRNU matching metric up to more
than five times over the conventional estimation method tailored for photos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09616</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09616</id><created>2019-05-23</created><authors><author><keyname>Kwak</keyname><forenames>Jong Woo</forenames></author><author><keyname>Sim</keyname><forenames>Min Soo</forenames></author><author><keyname>Kang</keyname><forenames>In-Woong</forenames></author><author><keyname>Park</keyname><forenames>Jong Sung</forenames></author><author><keyname>Park</keyname><forenames>Jaedon</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author></authors><title>A Comparative Study of Analog/Digital Self-Interference Cancellation for
  Full Duplex Radios</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-interference (SI) is the main obstacle to full-duplex radios. To
overcome the SI, researchers have proposed several analog and digital domain
self-interference cancellation (SIC) techniques. How well the digital
cancellation works depends on the results of analog cancellation. Therefore, to
analyze overall SIC performance, one should do so in an integrated manner. In
this paper, we build a simulator that can analyze the performance of analog and
digital SIC techniques. Through this simulator, we can analyze the overall SIC
performance within various system parameters such as the resolution of an
analog-to-digital converter (ADC) and/or nonlinearity of a power amplifier
(PA). With our simulator, we expect that configurations and tuning algorithms
of an active analog canceller can be optimized before real hardware
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09698</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09698</id><created>2019-05-22</created><authors><author><keyname>Islam</keyname><forenames>Muhammad Aminul</forenames></author><author><keyname>Anderson</keyname><forenames>Derek T.</forenames></author><author><keyname>Ball</keyname><forenames>John E.</forenames></author><author><keyname>Younan</keyname><forenames>Nicolas H.</forenames></author></authors><title>Fusion of heterogeneous bands and kernels in hyperspectral image
  processing</title><categories>eess.IV cs.LG stat.ML</categories><journal-ref>J. Appl. Remote Sens. 13(2), 026508 (2019)</journal-ref><doi>10.1117/1.JRS.13.026508</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral imaging is a powerful technology that is plagued by large
dimensionality. Herein, we explore a way to combat that hindrance via
non-contiguous and contiguous (simpler to realize sensor) band grouping for
dimensionality reduction. Our approach is different in the respect that it is
flexible and it follows a well-studied process of visual clustering in
high-dimensional spaces. Specifically, we extend the improved visual assessment
of cluster tendency and clustering in ordered dissimilarity data unsupervised
clustering algorithms for supervised hyperspectral learning. In addition, we
propose a way to extract diverse features via the use of different proximity
metrics (ways to measure the similarity between bands) and kernel functions.
The discovered features are fused with $l_{\infty}$-norm multiple kernel
learning. Experiments are conducted on two benchmark datasets and our results
are compared to related work. These datasets indicate that contiguous or not is
application specific, but heterogeneous features and kernels usually lead to
performance gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09712</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09712</id><created>2019-05-23</created><updated>2020-01-30</updated><authors><author><keyname>Ren</keyname><forenames>Jinke</forenames></author><author><keyname>Yu</keyname><forenames>Guanding</forenames></author><author><keyname>Ding</keyname><forenames>Guangyao</forenames></author></authors><title>Accelerating DNN Training in Wireless Federated Edge Learning System</title><categories>cs.LG eess.SP</categories><comments>This paper has been submitted for possible journal publication; Typos
  corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training task in classical machine learning models, such as deep neural
networks (DNN), is generally implemented at the remote computationally-adequate
cloud center for centralized learning, which is typically time-consuming and
resource-hungry. It also incurs serious privacy issue and long communication
latency since massive data are transmitted to the centralized node. To overcome
these shortcomings, we consider a newly-emerged framework, namely federated
edge learning (FEEL), to aggregate the local learning updates at the edge
server instead of users' raw data. Aiming at accelerating the training process
while guaranteeing the learning accuracy, we first define a novel performance
evaluation criterion, called learning efficiency and formulate a training
acceleration optimization problem in the CPU scenario, where each user device
is equipped with CPU. The closed-form expressions for joint batchsize selection
and communication resource allocation are developed and some insightful results
are also highlighted. Further, we extend our learning framework into the GPU
scenario and propose a novel training function to characterize the learning
property of general GPU modules. The optimal solution in this case is
manifested to have the similar structure as that of the CPU scenario,
recommending that our proposed algorithm is applicable in more general systems.
Finally, extensive experiments validate our theoretical analysis and
demonstrate that our proposal can reduce the training time and improve the
learning accuracy simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09754</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09754</id><created>2019-05-23</created><updated>2019-08-18</updated><authors><author><keyname>Zhao</keyname><forenames>Ziyue</forenames></author><author><keyname>Elshamy</keyname><forenames>Samy</forenames></author><author><keyname>Fingscheidt</keyname><forenames>Tim</forenames></author></authors><title>A Perceptual Weighting Filter Loss for DNN Training in Speech
  Enhancement</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-channel speech enhancement with deep neural networks (DNNs) has shown
promising performance and is thus intensively being studied. In this paper,
instead of applying the mean squared error (MSE) as the loss function during
DNN training for speech enhancement, we design a perceptual weighting filter
loss motivated by the weighting filter as it is employed in
analysis-by-synthesis speech coding, e.g., in code-excited linear prediction
(CELP). The experimental results show that the proposed simple loss function
improves the speech enhancement performance compared to a reference DNN with
MSE loss in terms of perceptual quality and noise attenuation. The proposed
loss function can be advantageously applied to an existing DNN-based speech
enhancement system, without modification of the DNN topology for speech
enhancement. The source code for the proposed approach is made available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09771</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09771</id><created>2019-05-23</created><authors><author><keyname>Zhang</keyname><forenames>Chaoyun</forenames></author><author><keyname>Fiore</keyname><forenames>Marco</forenames></author><author><keyname>Patras</keyname><forenames>Paul</forenames></author></authors><title>Multi-Service Mobile Traffic Forecasting via Convolutional Long
  Short-Term Memories</title><categories>cs.LG cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network slicing is increasingly used to partition network infrastructure
between different mobile services. Precise service-wise mobile traffic
forecasting becomes essential in this context, as mobile operators seek to
pre-allocate resources to each slice in advance, to meet the distinct
requirements of individual services. This paper attacks the problem of
multi-service mobile traffic forecasting using a sequence-to-sequence (S2S)
learning paradigm and convolutional long short-term memories (ConvLSTMs). The
proposed architecture is designed so as to effectively extract complex
spatiotemporal features of mobile network traffic and predict with high
accuracy the future demands for individual services at city scale. We conduct
experiments on a mobile traffic dataset collected in a large European
metropolis, demonstrating that the proposed S2S-ConvLSTM can forecast the
mobile traffic volume produced by tens of different services in advance of up
to one hour, by just using measurements taken during the past hour. In
particular, our solution achieves mean absolute errors (MAE) at antenna level
that are below 13KBps, outperforming other deep learning approaches by up to
31.2%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09824</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09824</id><created>2019-05-23</created><authors><author><keyname>Mehrizi</keyname><forenames>Sajad</forenames></author><author><keyname>Tsakmalis</keyname><forenames>Anestis</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bjorn</forenames></author></authors><title>A Feature-Based Bayesian Method for Content Popularity Prediction in
  Edge-Caching Networks</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1903.03065</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Edge-caching is recognized as an efficient technique for future wireless
cellular networks to improve network capacity and user-perceived quality of
experience. Due to the random content requests and the limited cache memory,
designing an efficient caching policy is a challenge. To enhance the
performance of caching systems, an accurate content request prediction
algorithm is essential. Here, we introduce a flexible model, a Poisson
regressor based on a Gaussian process, for the content request distribution in
stationary environments. Our proposed model can incorporate the content
features as side information for prediction enhancement. In order to learn the
model parameters, which yield the Poisson rates or alternatively content
popularities, we invoke the Bayesian approach which is very robust against
over-fitting.
  However, the posterior distribution in the Bayes formula is analytically
intractable to compute. To tackle this issue, we apply a Monte Carlo Markov
Chain (MCMC) method to approximate the posterior distribution. Two types of
predictive distributions are formulated for the requests of existing contents
and for the requests of a newly-added content. Finally, simulation results are
provided to confirm the accuracy of the developed content popularity learning
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09826</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09826</id><created>2019-05-23</created><authors><author><keyname>Sivera</keyname><forenames>Rapha&#xeb;l</forenames><affiliation>EPIONE</affiliation></author><author><keyname>Delingette</keyname><forenames>Herv&#xe9;</forenames><affiliation>EPIONE</affiliation></author><author><keyname>Lorenzi</keyname><forenames>Marco</forenames><affiliation>EPIONE</affiliation></author><author><keyname>Pennec</keyname><forenames>Xavier</forenames><affiliation>EPIONE</affiliation></author><author><keyname>Ayache</keyname><forenames>Nicholas</forenames><affiliation>EPIONE</affiliation></author></authors><title>A model of brain morphological changes related to aging and Alzheimer's
  disease from cross-sectional assessments</title><categories>q-bio.NC cs.CV eess.IV q-bio.QM</categories><comments>NeuroImage, Elsevier, In press</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study we propose a deformation-based framework to jointly model the
influence of aging and Alzheimer's disease (AD) on the brain morphological
evolution. Our approach combines a spatio-temporal description of both
processes into a generative model. A reference morphology is deformed along
specific trajectories to match subject specific morphologies. It is used to
define two imaging progression markers: 1) a morphological age and 2) a disease
score. These markers can be computed locally in any brain region. The approach
is evaluated on brain structural magnetic resonance images (MRI) from the ADNI
database. The generative model is first estimated on a control population,
then, for each subject, the markers are computed for each acquisition. The
longitudinal evolution of these markers is then studied in relation with the
clinical diagnosis of the subjects and used to generate possible morphological
evolution. In the model, the morphological changes associated with normal aging
are mainly found around the ventricles, while the Alzheimer's disease specific
changes are more located in the temporal lobe and the hippocampal area. The
statistical analysis of these markers highlights differences between clinical
conditions even though the inter-subject variability is quiet high. In this
context, the model can be used to generate plausible morphological trajectories
associated with the disease. Our method gives two interpretable scalar imaging
biomarkers assessing the effects of aging and disease on brain morphology at
the individual and population level. These markers confirm an acceleration of
apparent aging for Alzheimer's subjects and can help discriminate clinical
conditions even in prodromal stages. More generally, the joint modeling of
normal and pathological evolutions shows promising results to describe
age-related brain diseases over long time scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09843</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09843</id><created>2019-05-23</created><updated>2020-01-19</updated><authors><author><keyname>Shirani</keyname><forenames>Farhad</forenames></author><author><keyname>Shahsavari</keyname><forenames>Shahram</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>On the Rates of Convergence in Learning of Optimal Temporally Fair
  Schedulers</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-user schedulers are designed to achieve optimal average system utility
(e.g. throughput) subject to a set of fairness criteria. In this work,
scheduling under temporal fairness constraints is considered. Prior works have
shown that a class of scheduling strategies called threshold based strategies
(TBSs) achieve optimal system utility under temporal fairness constraints. The
optimal TBS thresholds are determined as a function of the channel statistics.
In order to provide performance guarantees for TBSs in practical scenarios ---
where the scheduler learns the optimal thresholds based on the empirical
observations of the channel realizations --- it is necessary to evaluate the
rates of convergence of TBS thresholds to the optimal value. In this work,
these rates of convergence and the effect on the resulting system utility are
investigated. It is shown that the best estimate of the threshold vector is at
least $\omega(\frac{1}{\sqrt{t}})$ away from the optimal value, where $t$ is
the number of observations of the independent and identically distributed
channel realizations. Furthermore, it is shown that under long-term fairness
constraints, the scheduler may achieve an average utility that is higher than
the optimal long-term utility by violating the fairness criteria for a long
initial period. Consequently, the resulting system utility may converge to its
optimal long-term value from above. The results are verified by providing
simulations of practical scheduling scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09877</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09877</id><created>2019-05-23</created><authors><author><keyname>Ong</keyname><forenames>Yong Zheng</forenames></author><author><keyname>Chui</keyname><forenames>Charles K.</forenames></author><author><keyname>Yang</keyname><forenames>Haizhao</forenames></author></authors><title>CASS: Cross Adversarial Source Separation via Autoencoder</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a cross adversarial source separation (CASS) framework
via autoencoder, a new model that aims at separating an input signal consisting
of a mixture of multiple components into individual components defined via
adversarial learning and autoencoder fitting. CASS unifies popular generative
networks like auto-encoders (AEs) and generative adversarial networks (GANs) in
a single framework. The basic building block that filters the input signal and
reconstructs the $i$-th target component is a pair of deep neural networks
$\mathcal{EN}_i$ and $\mathcal{DE}_i$ as an encoder for dimension reduction and
a decoder for component reconstruction, respectively. The decoder
$\mathcal{DE}_i$ as a generator is enhanced by a discriminator network
$\mathcal{D}_i$ that favors signal structures of the $i$-th component in the
$i$-th given dataset as guidance through adversarial learning. In contrast with
existing practices in AEs which trains each Auto-Encoder independently, or in
GANs that share the same generator, we introduce cross adversarial training
that emphasizes adversarial relation between any arbitrary network pairs
$(\mathcal{DE}_i,\mathcal{D}_j)$, achieving state-of-the-art performance
especially when target components share similar data structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09880</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09880</id><created>2019-05-23</created><authors><author><keyname>Ali</keyname><forenames>Samad</forenames></author><author><keyname>Asgharimoghaddam</keyname><forenames>Hossein</forenames></author><author><keyname>Rajatheva</keyname><forenames>Nandana</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Haapola</keyname><forenames>Jussi</forenames></author></authors><title>Contextual Bandit Learning for Machine Type Communications in the Null
  Space of Multi-Antenna Systems</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel approach based on the concept of opportunistic spatial
orthogonalization (OSO) is proposed for interference management between machine
type communications (MTC) and conventional cellular communications. In
particular, a cellular system is considered with a multi-antenna BS in which a
receive beamformer is designed to maximize the rate of a cellular user, and, a
machine type aggregator (MTA) that receives data from a large set of MTDs. If
there is a large number of MTDs to choose from for transmission at each time
for each beamformer, one MTD can be selected such that it causes almost no
interference on the BS. A comprehensive analytical study of the characteristics
of such interference from several MTDs on the same beamformer is carried out.
It is proven that, for each beamformer, an MTD exists such that the
interference on the BS is negligible. However, the optimal implementation of
OSO requires the CSI of all the links in the BS, which is not practical for
MTC. To solve this problem, an online learning method based on the concept of
contextual multi-armed bandits (MAB) learning is proposed. Simulation results
show that is possible to implement OSO with no CSI from MTDs to the BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09888</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09888</id><created>2019-05-23</created><updated>2019-08-21</updated><authors><author><keyname>Zhang</keyname><forenames>Yucheng</forenames></author><author><keyname>Lobo-Mueller</keyname><forenames>Edrise M.</forenames></author><author><keyname>Karanicolas</keyname><forenames>Paul</forenames></author><author><keyname>Gallinger</keyname><forenames>Steven</forenames></author><author><keyname>Haider</keyname><forenames>Masoom A.</forenames></author><author><keyname>Khalvati</keyname><forenames>Farzad</forenames></author></authors><title>Prognostic Value of Transfer Learning Based Features in Resectable
  Pancreatic Ductal Adenocarcinoma</title><categories>q-bio.QM cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pancreatic Ductal Adenocarcinoma (PDAC) is one of the most aggressive cancers
with an extremely poor prognosis. Radiomics has shown prognostic ability in
multiple types of cancer including PDAC. However, the prognostic value of
traditional radiomics pipelines, which are based on hand-crafted radiomic
features alone is limited. Convolutional neural networks (CNNs) have been shown
to outperform these feature-based models in computer vision tasks. However,
training a CNN from scratch needs a large sample size which is not feasible in
most medical imaging studies. As an alternative solution, CNN-based transfer
learning has shown potential for achieving reasonable performance using small
datasets. In this work, we developed and validated a CNN-based transfer
learning approach for prognostication of PDAC patients for overall survival
using two independent resectable PDAC cohorts. The proposed deep transfer
learning model for prognostication of PDAC achieved the area under the receiver
operating characteristic curve of 0.74, which was significantly higher than
that of the traditional radiomics model (0.56) as well as a CNN model trained
from scratch (0.50). These results suggest that deep transfer learning may
significantly improve prognosis performance using small datasets in medical
imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09919</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09919</id><created>2019-05-23</created><authors><author><keyname>Hashemi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Ghasemi</keyname><forenames>Mahsa</forenames></author><author><keyname>Vikalo</keyname><forenames>Haris</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author></authors><title>Submodular Observation Selection and Information Gathering for Quadratic
  Models</title><categories>eess.SP</categories><comments>To be published in proceedings of International Conference on Machine
  Learning (ICML) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of selecting most informative subset of a large
observation set to enable accurate estimation of unknown parameters. This
problem arises in a variety of settings in machine learning and signal
processing including feature selection, phase retrieval, and target
localization. Since for quadratic measurement models the moment matrix of the
optimal estimator is generally unknown, majority of prior work resorts to
approximation techniques such as linearization of the observation model to
optimize the alphabetical optimality criteria of an approximate moment matrix.
Conversely, by exploiting a connection to the classical Van Trees' inequality,
we derive new alphabetical optimality criteria without distorting the
relational structure of the observation model. We further show that under
certain conditions on parameters of the problem these optimality criteria are
monotone and (weak) submodular set functions. These results enable us to
develop an efficient greedy observation selection algorithm uniquely tailored
for quadratic models, and provide theoretical bounds on its achievable utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09940</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09940</id><created>2019-05-23</created><authors><author><keyname>Yang</keyname><forenames>Sijung</forenames></author><author><keyname>Deane</keyname><forenames>Grant</forenames></author><author><keyname>Preisig</keyname><forenames>James C.</forenames></author><author><keyname>Sev&#xfc;ktekin</keyname><forenames>Noyan C.</forenames></author><author><keyname>Choi</keyname><forenames>Jae W.</forenames></author><author><keyname>Singer</keyname><forenames>Andrew C.</forenames></author></authors><title>On the Reusability of Post-Experimental Field Data for Underwater
  Acoustic Communications R&amp;D</title><categories>eess.SP</categories><comments>The manuscript is 39 pages long, including 17 figures and 2 tables.
  The manuscript was submitted into IEEE Journal of Oceanic Engineering in Jan
  2019 and under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Field data is often expensive to collect, time-consuming to prepare to
collect, and even more time-consuming to process after the experiment has
concluded. However, it is often the practice that such data are used for little
after the funded research activity that was concomitant with the experiment is
completed. Immutability of the original experimental configuration either
results in re-gathering of expensive field-data, or in absence of such data,
model-dependent analysis that partially captures the real-world dynamics. For
underwater acoustic research and development, the standard communication
pipeline might be modified to enable greater re-usability of experimental field
data. This paper first characterizes the necessary modifications to the
standard communication pipeline to prepare signals for transmission and
subsequent recording such that research trades for different modulation and
coding schemes may be undertaken post-experiment, without the need for
re-transmission of additional waveforms. Then, using the modified mathematical
framework, sufficient conditions for reliable post-experimental replay of the
environment are recognized. Finally, techniques are discussed to collect
sufficient environmental statistics such that subsequent research can be
accomplished long after the experiment has been completed, and that results
from a given experiment may be reasonably compared with those of another.
Examples are provided using both synthetic and experimental data collected from
at-sea field tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09961</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09961</id><created>2019-05-23</created><updated>2019-12-21</updated><authors><author><keyname>Akrami</keyname><forenames>Haleh</forenames></author><author><keyname>Joshi</keyname><forenames>Anand A.</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Aydore</keyname><forenames>Sergul</forenames></author><author><keyname>Leahy</keyname><forenames>Richard M.</forenames></author></authors><title>Robust Variational Autoencoder</title><categories>stat.ML cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning methods often need a large amount of labeled training data.
Since the training data is assumed to be the ground truth, outliers can
severely degrade learned representations and performance of trained models.
Here we apply concepts from robust statistics to derive a novel variational
autoencoder that is robust to outliers in the training data. Variational
autoencoders (VAEs) extract a lower-dimensional encoded feature representation
from which we can generate new data samples. Robustness of autoencoders to
outliers is critical for generating a reliable representation of particular
data types in the encoded space when using corrupted training data. Our robust
VAE is based on beta-divergence rather than the standard Kullback-Leibler (KL)
divergence. Our proposed lower bound lead to a RVAE model that has the same
computational complexity as the VAE and contains a single tuning parameter to
control the degree of robustness. We demonstrate the performance of our
$\beta$-divergence based autoencoder for a range of image datasets, showing
improved robustness to outliers both qualitatively and quantitatively. We also
illustrate the use of our robust VAE for outlier detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09976</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.09976</id><created>2019-05-23</created><authors><author><keyname>Al-Marzouqi</keyname><forenames>Hasan</forenames></author><author><keyname>Hu</keyname><forenames>Yuting</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Texture retrieval using periodically extended and adaptive curvelets</title><categories>eess.IV cs.CV</categories><journal-ref>Signal Processing: Image Communication, Volume 76, 2019, Pages
  252-260, ISSN 0923-5965</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image retrieval is an important problem in the area of multimedia processing.
This paper presents two new curvelet-based algorithms for texture retrieval
which are suitable for use in constrained-memory devices. The developed
algorithms are tested on three publicly available texture datasets: CUReT,
Mondial-Marmi, and STex-fabric. Our experiments confirm the effectiveness of
the proposed system. Furthermore, a weighted version of the proposed retrieval
algorithm is proposed, which is shown to achieve promising results in the
classification of seismic activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10010</identifier>
 <datestamp>2019-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10010</id><created>2019-05-23</created><updated>2019-11-25</updated><authors><author><keyname>Hirsch</keyname><forenames>Lukas</forenames></author><author><keyname>Huang</keyname><forenames>Yu</forenames></author><author><keyname>Parra</keyname><forenames>Lucas C</forenames></author></authors><title>Segmentation of lesioned brain anatomy with deep volumetric neural
  networks and multiple spatial priors achieves human-level performance</title><categories>eess.IV cs.LG q-bio.NC stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Conventional automated segmentation of MRI of the brain and head
distinguishes different tissues based on image intensities and prior tissue
probability maps (TPM). This works well for normal head anatomies, but fails in
the presence of unexpected lesions. Deep convolutional neural networks leverage
instead spatial patterns and can learn to segment lesions, but have thus far
not leveraged prior probabilities. Here we add to a three-dimensional
convolutional network spatial priors with a TPM, morphological priors with
conditional random fields, and context with a wider field-of-view at lower
resolution. We train and test these networks on images of 43 stroke patients
and 4 healthy individuals which have been manually segmented. The analysis
demonstrates the benefits of leveraging the three sources of prior information.
We also provide an out-of-sample validation and clinical application of the
approach on an additional 47 patients with disorders of consciousness.
Importantly, we demonstrate that the new architecture, which we call MultiPrior
network, surpaces the performance of expert human segmenters. We make the code
and trained networks freely available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10058</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10058</id><created>2019-05-24</created><authors><author><keyname>Zhang</keyname><forenames>Weile</forenames></author><author><keyname>Hu</keyname><forenames>Zhinan</forenames></author><author><keyname>Zhang</keyname><forenames>Shun</forenames></author><author><keyname>Wang</keyname><forenames>Gongpu</forenames></author></authors><title>High-Mobility Massive MIMO Communications:Doppler Compensation and
  Transmit Diversity</title><categories>eess.SP</categories><comments>4 pages,4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-mobility wireless communications have been receiving a lot attentions.
In this paper, we consider the highmobility uplink transmission from a
high-speed terminal (HST) to a base station (BS). We propose two transmit
diversity schemes for high-mobility massive communications with angle domain
Doppler compensation. In the first scheme, we propose the idea of block-wise
angle domain Doppler compensation, such that the uplink equivalent channel
would exhibit the feature of nearly perfect independent block fading. The
signal space diversity encoding technique is then exploited to achieve transmit
diversity. In the second scheme, the multiple parallel beamformers with Doppler
compensation are exclusively occupied to transmit multiple orthogonal
space-time block coding (OSTBC) data streams. Both analysis and numerical
results verify that both the proposed schemes can achieve transmit diversity
and outperform the conventional scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10088</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10088</id><created>2019-05-24</created><authors><author><keyname>Xia</keyname><forenames>Guiyang</forenames></author><author><keyname>Lin</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>Tingting</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Transmit Antenna Selection and Beamformer Design for Secure Spatial
  Modulation with rough CSI of Eve</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The security of spatial modulation (SM) aided networks can always be improved
by reducing the desired link's power at the cost of degrading its bit error
ratio performance and assuming the power consumed to artificial noise (AN)
projection (ANP). We formulate the joint optimization problem of maximizing the
secrecy rate (Max-SR) over the transmit antenna selection and ANP in the
context of secure SM-aided networks, which is mathematically a non-linear mixed
integer programming problem. In order to solve this problem, we provide a pair
of solutions, namely joint and separate solutions. Specifically, an accurate
approximation of the SR is used for reducing the computational complexity, and
the optimal AN covariance matrix (ANCM) is found by convex optimization for any
given active antenna group (AAG). Then, given a large set of AAGs, simulated
annealing mechanism is invoked for optimizing the choice of AAG, where the
corresponding ANCM is recomputed by this optimization method as well when the
AAG changes. To further reduce the complexity of the above-mentioned joint
optimization, a low-complexity two-stage separate optimization method is also
proposed. Furthermore, when the number of transmit antennas tends to infinity,
the Max-SR problem becomes equivalent to that of maximizing the ratio of the
desired user's signal-to-interference-plus-noise ratio to the eavesdropper's.
Thus our original problem reduces to a fractional programming problem, hence a
significant computational complexity reduction can be achieved for the
optimization problem. Our simulation results show that the proposed algorithms
outperform the existing leakage-based null-space projection scheme in terms of
the SR performance attained, and drastically reduces the complexity at a slight
SR performance reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10091</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10091</id><created>2019-05-24</created><updated>2019-09-19</updated><authors><author><keyname>Lin</keyname><forenames>Liwei</forenames></author><author><keyname>Wang</keyname><forenames>Xiangdong</forenames></author><author><keyname>Liu</keyname><forenames>Hong</forenames></author><author><keyname>Qian</keyname><forenames>Yueliang</forenames></author></authors><title>Specialized Decision Surface and Disentangled Feature for
  Weakly-Supervised Polyphonic Sound Event Detection</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound event detection (SED) consists in recognizing the presence of sound
events in the segment of audio and detecting their onset as well as offset. In
this paper, we focus on two common problems on SED: how to carry out efficient
weakly-supervised learning and how to learn better from the unbalanced dataset
in which multiple sound events often occur in co-occurrence.
  We approach SED as a multiple instance learning (MIL) problem and utilize a
neural network framework with different pooling modules to solve it. General
MIL approaches includes two approaches: the instance-level approach and the
embedding-level approach. Since the embedding-level approach tends to perform
better than the instance-level approach in terms of bag-level classification
but can not provide instance-level probabilities, we present how to generate
instance-level probabilities for it. Moreover, we further propose a specialized
decision surface (SDS) for the embedding-level attention pooling. We analyze
and explained why an embedding-level attention module with SDS is better than
other typical pooling modules from the perspective of the high-level feature
space. As for the problem of unbalanced dataset and the co-occurrence of
multiple categories in the polyphonic event detection task, we propose a
disentangled feature (DF) to reduce interference among categories, which
optimizes the high-level feature space by disentangling it based on class-wise
identifiable information and obtaining multiple different subspaces.
Experiments on the dataset of DCASE 2018 Task 4 show that the proposed SDS and
DF significantly improve the detection performance of the embedding-level MIL
approach with an attention pooling module and outperform the first place system
in the challenge by 6.2 percentage points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10218</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10218</id><created>2019-05-24</created><authors><author><keyname>Tirunagari</keyname><forenames>Santosh</forenames></author><author><keyname>Poh</keyname><forenames>Norman</forenames></author><author><keyname>Wells</keyname><forenames>Kevin</forenames></author><author><keyname>Bober</keyname><forenames>Miroslaw</forenames></author><author><keyname>Gorden</keyname><forenames>Isky</forenames></author><author><keyname>Windridge</keyname><forenames>David</forenames></author></authors><title>Functional Segmentation through Dynamic Mode Decomposition: Automatic
  Quantification of Kidney Function in DCE-MRI Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantification of kidney function in Dynamic Contrast-Enhanced Magnetic
Resonance Imaging (DCE-MRI) requires careful segmentation of the renal region
of interest (ROI). Traditionally, human experts are required to manually
delineate the kidney ROI across multiple images in the dynamic sequence. This
approach is costly, time-consuming and labour intensive, and therefore acts to
limit patient throughout and acts as one of the factors limiting the wider
adoption of DCR-MRI in clinical practice. Therefore, to address this issue, we
present the first use of Dynamic Mode Decomposition (DMD) as a basis for
automatic segmentation of a dynamic sequence, in this case, kidney ROIs in
DCE-MRI. Using DMD coupled combined with thresholding and connected component
analysis is first validated on synthetically generated data with known
ground-truth, and then applied to ten healthy volunteers' DCE-MRI datasets. We
find that the segmentation result obtained from our proposed DMD framework is
comparable to that of expert observers and very significantly better than that
of an a-priori bounding box segmentation. Our result gives a mean Jaccard
coefficient of 0.87, compared to mean scores of 0.85, 0.88 and 0.87 produced
from three independent manual annotations. This represents the first use of DMD
as a robust automatic data-driven segmentation approach without requiring any
human intervention. This is a viable, efficient alternative approach to current
manual methods of isolation of kidney function in DCE-MRI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10236</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10236</id><created>2019-05-24</created><authors><author><keyname>Li</keyname><forenames>Ling</forenames></author><author><keyname>Hu</keyname><forenames>Junxing</forenames></author><author><keyname>Wu</keyname><forenames>Fengge</forenames></author><author><keyname>Zhao</keyname><forenames>Junsuo</forenames></author></authors><title>A Research and Strategy of Remote Sensing Image Denoising Algorithms</title><categories>eess.IV cs.CV</categories><comments>9 pages, 4 figures, ICNC-FSKD 2019</comments><doi>10.1007/978-3-030-32591-6_75</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most raw data download from satellites are useless, resulting in transmission
waste, one solution is to process data directly on satellites, then only
transmit the processed results to the ground. Image processing is the main data
processing on satellites, in this paper, we focus on image denoising which is
the basic image processing. There are many high-performance denoising
approaches at present, however, most of them rely on advanced computing
resources or rich images on the ground. Considering the limited computing
resources of satellites and the characteristics of remote sensing images, we do
some research on these high-performance ground image denoising approaches and
compare them in simulation experiments to analyze whether they are suitable for
satellites. According to the analysis results, we propose two feasible image
denoising strategies for satellites based on satellite TianZhi-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10246</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10246</id><created>2019-05-24</created><updated>2019-09-24</updated><authors><author><keyname>Shevchenko</keyname><forenames>Nikita A.</forenames></author><author><keyname>Xu</keyname><forenames>Tianhua</forenames></author><author><keyname>Jin</keyname><forenames>Cenqin</forenames></author><author><keyname>Lavery</keyname><forenames>Domani&#xe7;</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>Information Rate in Ultra-Wideband Optical Fiber Communication Systems
  Accounting for High-Order Dispersion</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effect of Kerr-induced optical fiber nonlinearities in C-band (5 THz)
EDFA and C+L-band (12.5 THz) Raman-amplified optical communication systems has
been studied considering the impact of third-order fiber dispersion. The
performance of digital nonlinearity compensation with single channel and
250-GHz bandwidth in both EDFA and Raman amplified systems has been
investigated, respectively. The achievable information rates (AIRs) and optimum
code rates in each individual transmission channel have been evaluated for the
DP-64QAM, the DP-256QAM and the DP-1024QAM modulation formats, both with and
without the use of the probabilistic shaping technique. It is found that, for
all considered modulation formats, the signal-to-noise ratios, AIRs and code
rates exhibit significantly asymmetric behavior about the central channel due
to the presence of the third-order dispersion. This provides a new insight that
the forward error correction schemes have to be optimized asymmetrically, on a
per-channel basis, to maximize the overall throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10343</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10343</id><created>2019-05-24</created><authors><author><keyname>Wang</keyname><forenames>Lingda</forenames></author><author><keyname>Zhao</keyname><forenames>Zhizhen</forenames></author></authors><title>Two-Dimensional Tomography From Noisy Projection Tilt Series Taken At
  Unknown View Angles With Non-Uniform Distribution</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a problem that recovers a 2-D object and the underlying view
angle distribution from its noisy projection tilt series taken at unknown view
angles. Traditional approaches rely on the estimation of the view angles of the
projections, which do not scale well with the sample size and are sensitive to
noise. We introduce a new approach using the moment features to simultaneously
recover the underlying object and the distribution of view angles. This problem
is formulated as constrained nonlinear least squares in terms of the truncated
Fourier-Bessel expansion coefficients of the object and is solved by a new
alternating direction method of multipliers (ADMM)-based algorithm. Our
numerical experiments show that the new approach outperforms the expectation
maximization (EM)-based maximum marginalized likelihood estimation in
efficiency and accuracy. Furthermore, the hybrid method that uses EM to refine
ADMM solution achieves the best performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10364</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10364</id><created>2019-05-24</created><authors><author><keyname>He</keyname><forenames>Yu-Hang</forenames></author><author><keyname>Zhang</keyname><forenames>Ai-Xin</forenames></author><author><keyname>Li</keyname><forenames>Ming-Fei</forenames></author><author><keyname>Huang</keyname><forenames>Yi-Yi</forenames></author><author><keyname>Quan</keyname><forenames>Bao-Gang</forenames></author><author><keyname>Li</keyname><forenames>Da-Zhang</forenames></author><author><keyname>Wu</keyname><forenames>Ling-An</forenames></author><author><keyname>Chen</keyname><forenames>Li-Ming</forenames></author></authors><title>Deep learning based high-resolution incoherent x-ray imaging with a
  single-pixel detector</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X-ray &quot;ghost&quot; imaging has drawn great attention for its potential to lower
radiation dose in medical diagnosis. For practical implementation, however, the
efficiency and image quality have to be greatly improved. Here we demonstrate a
computational ghost imaging scheme where a bucket detector and specially
designed modulation masks are used, together with a new robust deep learning
algorithm in which a compressed set of Hadamard matrices is incorporated into a
multi-level wavelet convolutional neural network. By this means we have
obtained an image of a real object from only 18.75% of the Nyquist sampling
rate, using a portable tabletop incoherent x-ray source of ~37 {\mu}m diameter.
A high imaging resolution of ~10 {\mu}m is achieved, which represents a
concrete step towards the realization of a practical low cost x-ray ghost
imaging camera for applications in biomedicine, archeology, material science,
and so forth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10371</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10371</id><created>2019-05-24</created><authors><author><keyname>Aytekin</keyname><forenames>Caglar</forenames></author><author><keyname>Cricri</keyname><forenames>Francesco</forenames></author><author><keyname>Hallapuro</keyname><forenames>Antti</forenames></author><author><keyname>Lainema</keyname><forenames>Jani</forenames></author><author><keyname>Aksu</keyname><forenames>Emre</forenames></author><author><keyname>Hannuksela</keyname><forenames>Miska</forenames></author></authors><title>A Compression Objective and a Cycle Loss for Neural Image Compression</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted in Challenge and Workshop on Learned Image Compression
  (CLIC) as a part of CVPR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript we propose two objective terms for neural image
compression: a compression objective and a cycle loss. These terms are applied
on the encoder output of an autoencoder and are used in combination with
reconstruction losses. The compression objective encourages sparsity and low
entropy in the activations. The cycle loss term represents the distortion
between encoder outputs computed from the original image and from the
reconstructed image (code-domain distortion). We train different autoencoders
by using the compression objective in combination with different losses: a)
MSE, b) MSE and MSSSIM, c) MSE, MS-SSIM and cycle loss. We observe that images
encoded by these differently-trained autoencoders fall into different points of
the perception-distortion curve (while having similar bit-rates). In
particular, MSE-only training favors low image-domain distortion, whereas cycle
loss training favors high perceptual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10399</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10399</id><created>2019-05-24</created><authors><author><keyname>Schlittenlacher</keyname><forenames>Josef</forenames></author><author><keyname>Turner</keyname><forenames>Richard E.</forenames></author><author><keyname>Moore</keyname><forenames>Brian C. J.</forenames></author></authors><title>Fast computation of loudness using a deep neural network</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper introduces a deep neural network (DNN) for predicting the
instantaneous loudness of a sound from its time waveform. The DNN was trained
using the output of a more complex model, called the Cambridge loudness model.
While a modern PC can perform a few hundred loudness computations per second
using the Cambridge loudness model, it can perform more than 100,000 per second
using the DNN, allowing real-time calculation of loudness. The root-mean-square
deviation between the predictions of instantaneous loudness level using the two
models was less than 0.5 phon for unseen types of sound. We think that the
general approach of simulating a complex perceptual model by a much faster DNN
can be applied to other perceptual models to make them run in real time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10433</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10433</id><created>2019-05-24</created><authors><author><keyname>Du</keyname><forenames>Ming</forenames></author><author><keyname>Nashed</keyname><forenames>Youssef S. G.</forenames></author><author><keyname>Kandel</keyname><forenames>Saugat</forenames></author><author><keyname>Gursoy</keyname><forenames>Doga</forenames></author><author><keyname>Jacobsen</keyname><forenames>Chris</forenames></author></authors><title>Three dimensions, two microscopes, one code: automatic differentiation
  for x-ray nanotomography beyond the depth of focus limit</title><categories>eess.IV physics.app-ph physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional tomographic reconstruction algorithms assume that one has
obtained pure projection images, involving no within-specimen diffraction
effects nor multiple scattering. Advances in x-ray nanotomography are leading
towards the violation of these assumptions, by combining the high penetration
power of x-rays which enables thick specimens to be imaged, with improved
spatial resolution which decreases the depth of focus of the imaging system. We
describe a reconstruction method where multiple scattering and diffraction
effects in thick samples are modeled by multislice propagation, and the 3D
object function is retrieved through iterative optimization. We show that the
same proposed method works for both full-field microscopy, and for coherent
scanning techniques like ptychography. Our implementation utilizes the
optimization toolbox and the automatic differentiation capability of the
open-source deep learning package TensorFlow, which demonstrates a much
straightforward way to solve optimization problems in computational imaging,
and endows our program great flexibility and portability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10443</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10443</id><created>2019-05-22</created><authors><author><keyname>Cherfaoui</keyname><forenames>Farah</forenames></author><author><keyname>Emiya</keyname><forenames>Valentin</forenames></author><author><keyname>Ralaivola</keyname><forenames>Liva</forenames></author><author><keyname>Anthoine</keyname><forenames>Sandrine</forenames></author></authors><title>Recovery and convergence rate of the Frank-Wolfe Algorithm for the
  m-EXACT-SPARSE Problem</title><categories>math.OC eess.SP math.CT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the properties of the Frank-Wolfe algorithm to solve the
m-EXACT-SPARSE reconstruction problem, where a signal y must be expressed as a
sparse linear combination of a predefined set of atoms, called dictionary. We
prove that when the signal is sparse enough with respect to the coherence of
the dictionary, then the iterative process implemented by the Frank-Wolfe
algorithm only recruits atoms from the support of the signal, that is the
smallest set of atoms from the dictionary that allows for a perfect
reconstruction of y. We also prove that under this same condition, there exists
an iteration beyond which the algorithm converges exponentially.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10456</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10456</id><created>2019-05-24</created><authors><author><keyname>Ma</keyname><forenames>Meng</forenames></author><author><keyname>Li</keyname><forenames>Bingcong</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Tight Linear Convergence Rate of ADMM for Decentralized Optimization</title><categories>math.OC cs.DC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper considers leveraging network topology information to
improve the convergence rate of ADMM for decentralized optimization, where
networked nodes work collaboratively to minimize the objective. Such problems
can be solved efficiently using ADMM via decomposing the objective into easier
subproblems. Properly exploiting network topology can significantly improve the
algorithm performance. Hybrid ADMM explores the direction of exploiting node
information by taking into account node centrality but fails to utilize edge
information. This paper fills the gap by incorporating both node and edge
information and provides a novel convergence rate bound for decentralized ADMM
that explicitly depends on network topology. Such a novel bound is attainable
for certain class of problems, thus tight. The explicit dependence further
suggests possible directions to optimal design of edge weights to achieve the
best performance. Numerical experiments show that simple heuristic methods
could achieve better performance, and also exhibits robustness to topology
changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10459</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10459</id><created>2019-05-24</created><updated>2019-11-03</updated><authors><author><keyname>Yonel</keyname><forenames>Bariscan</forenames></author><author><keyname>Son</keyname><forenames>Il-Young</forenames></author><author><keyname>Yazici</keyname><forenames>Birsen</forenames></author></authors><title>Exact Imaging of Extended Targets Using Multistatic Interferometric
  Measurements</title><categories>eess.SP eess.IV</categories><comments>16 pages, in revision for IEEE Transactions on Computational Imaging</comments><doi>10.1109/TCI.2020.2967151</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel approach that can exactly recover extended
targets in wave-based multistatic interferometric imaging, based on Generalized
Wirtinger Flow (GWF) theory [1]. Interferometric imaging is a generalization of
phase retrieval, which arises from cross-correlation of measurements from pairs
of receivers in multistatic configuration. Unlike standard Wirtinger Flow, GWF
theory guarantees exact recovery for arbitrary lifted forward models that
satisfy the restricted isometry property over rank-1, positive semi-definite
(PSD) matrices with a sufficiently small restricted isometry constant (RIC). To
this end, we design a deterministic, lifted forward model for interferometric
multistatic radar satisfying the exact recovery conditions of the GWF theory.
Our results quantify a lower limit on the pixel spacing and the minimal sample
complexity for exact multistatic radar imaging via GWF. We provide a numerical
study of our RIC and pixel spacing bounds, which shows that GWF can achieve
exact recovery with super-resolution. While our primary interest lies in radar
imaging, our method is also applicable to other multistatic wave-based imaging
problems such as those arising in acoustics and geophysics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10468</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10468</id><created>2019-05-24</created><authors><author><keyname>Schmitz</keyname><forenames>Johannes</forenames></author><author><keyname>von Lengerke</keyname><forenames>Caspar</forenames></author><author><keyname>Airee</keyname><forenames>Nikita</forenames></author><author><keyname>Behboodi</keyname><forenames>Arash</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>A Deep Learning Wireless Transceiver with Fully Learned Modulation and
  Synchronization</title><categories>eess.SP cs.IT math.IT</categories><comments>Presented at ICC 2019- 2nd Workshop on Machine Learning in Wireless
  Communications (ML4COM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a deep learning based wireless transceiver. We
describe in detail the corresponding artificial neural network architecture,
the training process, and report on excessive over-the-air measurement results.
We employ the end-to-end training approach with an autoencoder model that
includes a channel model in the middle layers as previously proposed in the
literature. In contrast to other state-of-the-art results, our architecture
supports learning time synchronization without any manually designed signal
processing operations. Moreover, the neural transceiver has been tested over
the air with an implementation in software defined radio. Our experimental
results for the implemented single antenna system demonstrate a raw bit-rate of
0.5 million bits per second. This exceeds results from comparable systems
presented in the literature and suggests the feasibility of high throughput
deep learning transceivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10476</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10476</id><created>2019-05-24</created><authors><author><keyname>Nikitin</keyname><forenames>Alexei V.</forenames></author><author><keyname>Davidchack</keyname><forenames>Ruslan L.</forenames></author></authors><title>Hidden outlier noise and its mitigation</title><categories>eess.SP</categories><comments>14 pages, 34 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In addition to ever-present thermal noise, various communication and sensor
systems can contain significant amounts of interference with outlier (e.g.
impulsive) characteristics. Such outlier noise can be efficiently mitigated in
real-time using intermittently nonlinear filters. Depending on the noise nature
and composition, improvements in the quality of the signal of interest will
vary from &quot;no harm&quot; to substantial. In this paper, we explain in detail why the
underlying outlier nature of interference often remains obscured, discussing
the many challenges and misconceptions associated with state-of-art analog
and/or digital nonlinear mitigation techniques, especially when addressing
complex practical interference scenarios. We then focus on the methodology and
tools for real-time outlier noise mitigation, demonstrating how the &quot;excess
band&quot; observation of outlier noise enables its efficient in-band mitigation. We
introduce the basic real-time nonlinear components that are used for outlier
noise filtering, and provide examples of their implementation. We further
describe complementary nonlinear filtering arrangements for wide- and
narrow-band outlier noise reduction, providing several illustrations of their
performance and the effect on channel capacity. Finally, we outline
&quot;effectively analog&quot; digital implementations of these filtering structures,
discuss their broader applications, and comment on the ongoing development of
the platform for their demonstration and testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10480</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10480</id><created>2019-05-24</created><authors><author><keyname>Akella</keyname><forenames>Shailaja</forenames></author><author><keyname>Principe</keyname><forenames>Jose C.</forenames></author></authors><title>Correntropy Based Robust Decomposition of Neuromodulations</title><categories>eess.SP q-bio.NC</categories><comments>4 pages, Engineering in Medicine and Biology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuromodulations as observed in the extracellular electrical potential
recordings obtained from Electroencephalograms (EEG) manifest as organized,
transient patterns that differ statistically from their featureless noisy
background. Leveraging on this statistical dissimilarity, we propose a
noniterative robust classification algorithm to isolate, in time, these
neuromodulations from the temporally disorganized but structured background
activity while simultaneously incorporating temporal sparsity of the events.
Specifically, we exploit the ability of correntropy to asses higher - order
moments as well as imply the degree of similarity between two random variables
in the joint space regulated by the kernel bandwidth. We test our algorithm on
DREAMS Sleep Spindle Database and further elaborate on the hyperparameters
introduced. Finally, we compare the performance of the algorithm with two
algorithms designed on similar ideas; one of which is a quick, simple norm
based technique while the other parallels the state-of-the-art Robust Principal
Component Analysis (RPCA) to achieve classification. The algorithm is able to
match the performance of the state-of-the-art techniques while saving
tremendously on computation time and complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10488</identifier>
 <datestamp>2019-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10488</id><created>2019-05-24</created><updated>2019-12-19</updated><authors><author><keyname>Cha</keyname><forenames>Sungmin</forenames></author><author><keyname>Moon</keyname><forenames>Taesup</forenames></author></authors><title>GAN2GAN: Generative Noise Learning for Blind Image Denoising with Single
  Noisy Images</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle a challenging blind image denoising problem, in which only single
distinct noisy images are available for training a denoiser, and no information
about noise is known, except for it being zero-mean, additive, and independent
of the clean image. In such a setting, which often occurs in practice, it is
not possible to train a denoiser with the standard discriminative training or
with the recently developed Noise2Noise (N2N) training; the former requires the
underlying clean image for the given noisy image, and the latter requires two
independently realized noisy image pair for a clean image. To that end, we
propose GAN2GAN (Generated-Artificial-Noise to Generated-Artificial-Noise)
method that first learns a generative model that can synthesize noisy image
pairs based on simulating independent realizations of the noise in given single
noisy images, then iteratively trains a denoiser with those synthesized pairs,
as in the N2N training. In results, we show the denoiser trained with our
GAN2GAN method for the blind denoising setting achieves an impressive denoising
performance; it almost approaches the performance of the standard
discriminatively-trained or N2N-trained models that have more information than
ours, and significantly outperforms the recent baseline for the same setting,
i.e., Noise2Void, and a more conventional yet strong one, BM3D.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10502</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10502</id><created>2019-05-24</created><authors><author><keyname>He</keyname><forenames>Yunfeng</forenames></author><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author></authors><title>TurboNet: A Model-driven DNN Decoder Based on Max-Log-MAP Algorithm for
  Turbo Code</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents TurboNet, a novel model-driven deep learning (DL)
architecture for turbo decoding that combines DL with the traditional
max-log-maximum a posteriori (MAP) algorithm. To design TurboNet, we unfold the
original iterative structure for turbo decoding and replace each iteration by a
deep neural network (DNN) decoding unit. In particular, the DNN decoding unit
is obtained by parameterizing the max-log-MAP algorithm rather than replace the
whole decoder with a black box fully connected DNN architecture. With the
proposed architecture, the parameters can be efficiently learned from training
data, and thus TurboNet learns to appropriately use systematic and parity
information to offer higher error correction capabilities and decrease
computational complexity compared with existing methods. Furthermore,
simulation results prove TurboNet's superiority in signal-to-noise ratio
generalizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10519</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10519</id><created>2019-05-25</created><authors><author><keyname>Huang</keyname><forenames>Yongwei</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author></authors><title>Quadratic Matrix Inequality Approach to Robust Adaptive Beamforming for
  General-Rank Signal Model</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The worst-case robust adaptive beamforming problem for general-rank signal
model is considered. This is a nonconvex problem, and an approximate version of
it (obtained by introducing a matrix decomposition on the presumed covariance
matrix of the desired signal) has been well studied in the literature.
Different from the existing literature, herein however the original beamforming
problem is tackled. Resorting to the strong duality of linear conic
programming, the robust adaptive beamforming problem for general-rank signal
model is reformulated into an equivalent quadratic matrix inequality (QMI)
problem. By employing a linear matrix inequality (LMI) relaxation technique,
the QMI problem is turned into a convex semidefinite programming problem. Using
the fact that there is often a positive gap between the QMI problem and its LMI
relaxation, an approximate algorithm is proposed to solve the robust adaptive
beamforming in the QMI form. Besides, several sufficient optimality conditions
for the nonconvex QMI problem are built. To validate our results, simulation
examples are presented, which also demonstrate the improved performance of the
new robust beamformer in terms of the output signal-to-interference-plus-noise
ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10550</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10550</id><created>2019-05-25</created><authors><author><keyname>Pominova</keyname><forenames>Marina</forenames></author><author><keyname>Kuzina</keyname><forenames>Anna</forenames></author><author><keyname>Kondrateva</keyname><forenames>Ekaterina</forenames></author><author><keyname>Sushchinskaya</keyname><forenames>Svetlana</forenames></author><author><keyname>Sharaev</keyname><forenames>Maxim</forenames></author><author><keyname>Burnaev</keyname><forenames>Evgeny</forenames></author><author><keyname>Yarkin</keyname><forenames>and Vyacheslav</forenames></author></authors><title>Ensemble of 3D CNN regressors with data fusion for fluid intelligence
  prediction</title><categories>eess.IV cs.CV cs.LG stat.AP</categories><comments>10 pages, 1 figure, 2 tables</comments><journal-ref>ABCD Neurocognitive Prediction Challenge, Springer LNCS, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we aim at predicting children's fluid intelligence scores based
on structural T1-weighted MR images from the largest long-term study of brain
development and child health. The target variable was regressed on a data
collection site, socio-demographic variables and brain volume, thus being
independent to the potentially informative factors, which are not directly
related to the brain functioning. We investigate both feature extraction and
deep learning approaches as well as different deep CNN architectures and their
ensembles. We propose an advanced architecture of VoxCNNs ensemble, which yield
MSE (92.838) on blind test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10553</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10553</id><created>2019-05-25</created><authors><author><keyname>Sun</keyname><forenames>H.</forenames></author><author><keyname>Al-Marzouqi</keyname><forenames>H.</forenames></author><author><keyname>Vega</keyname><forenames>S.</forenames></author></authors><title>EPCI: A New Tool for Predicting Absolute Permeability from CT images</title><categories>physics.geo-ph cs.CE eess.IV</categories><journal-ref>Geophysics 84.3 (2019): 1-29</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new and fast Matlab algorithm for predicting absolute permeability is
presented. The developed tool relies on measuring the connectivity of pores in
a given three-dimensional (3D) micro-CT rock image. An index of pore
connectivity is introduced. After a calibration step, the developed index is
used to estimate permeability in a variety of rocks with challenging pore
structures (e.g. complex carbonate formations). The developed algorithm was
tested on sandstone and carbonate rock samples. It offers large computational
and memory savings when compared with algorithms based on the Lattice Boltzmann
Method (LBM). Permeability estimates were, in general, in good agreement with
laboratory measurements and numerical simulation results. Source code for
computing the developed index along with an associated GUI panel are available
online at https://github.com/cupbkust/EPCI.git
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10595</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10595</id><created>2019-05-25</created><updated>2019-05-28</updated><authors><author><keyname>Gupta</keyname><forenames>Honey</forenames></author><author><keyname>Mitra</keyname><forenames>Kaushik</forenames></author></authors><title>Unsupervised Single Image Underwater Depth Estimation</title><categories>cs.CV eess.IV</categories><comments>Accepted for publication at IEEE International Conference on Image
  Processing (ICIP), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Depth estimation from a single underwater image is one of the most
challenging problems and is highly ill-posed. Due to the absence of large
generalized underwater depth datasets and the difficulty in obtaining ground
truth depth-maps, supervised learning techniques such as direct depth
regression cannot be used. In this paper, we propose an unsupervised method for
depth estimation from a single underwater image taken `in the wild' by using
haze as a cue for depth. Our approach is based on indirect depth-map estimation
where we learn the mapping functions between unpaired RGB-D terrestrial images
and arbitrary underwater images to estimate the required depth-map. We propose
a method which is based on the principles of cycle-consistent learning and uses
dense-block based auto-encoders as generator networks. We evaluate and compare
our method both quantitatively and qualitatively on various underwater images
with diverse attenuation and scattering conditions and show that our method
produces state-of-the-art results for unsupervised depth estimation from a
single underwater image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10604</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10604</id><created>2019-05-25</created><updated>2019-05-31</updated><authors><author><keyname>Wen</keyname><forenames>Yandong</forenames></author><author><keyname>Singh</keyname><forenames>Rita</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>Reconstructing faces from voices</title><categories>cs.SD cs.CV cs.LG eess.AS eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice profiling aims at inferring various human parameters from their speech,
e.g. gender, age, etc. In this paper, we address the challenge posed by a
subtask of voice profiling - reconstructing someone's face from their voice.
The task is designed to answer the question: given an audio clip spoken by an
unseen person, can we picture a face that has as many common elements, or
associations as possible with the speaker, in terms of identity? To address
this problem, we propose a simple but effective computational framework based
on generative adversarial networks (GANs). The network learns to generate faces
from voices by matching the identities of generated faces to those of the
speakers, on a training set. We evaluate the performance of the network by
leveraging a closely related task - cross-modal matching. The results show that
our model is able to generate faces that match several biometric
characteristics of the speaker, and results in matching accuracies that are
much better than chance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10624</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10624</id><created>2019-05-25</created><authors><author><keyname>Yu</keyname><forenames>Xianghao</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Doubling Phase Shifters for Efficient Hybrid Precoder Design in
  Millimeter-Wave Communication Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>32 pages, 6 figures, 1 table, submitted to Journal of Communications
  and Information Networks, Apr. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid precoding is a cost-effective approach to support directional
transmissions for millimeter-wave (mm-wave) communications, but its precoder
design is highly complicated. In this paper, we propose a new hybrid precoder
implementation, namely the double phase shifter (DPS) implementation, which
enables highly tractable hybrid precoder design. Efficient algorithms are then
developed for two popular hybrid precoder structures, i.e., the fully- and
partially-connected structures. For the fully-connected one, the RF-only
precoding and hybrid precoding problems are formulated as a least absolute
shrinkage and selection operator (LASSO) problem and a low-rank matrix
approximation problem, respectively. In this way, computationally efficient
algorithms are provided to approach the performance of the fully digital one
with a small number of radio frequency (RF) chains. On the other hand, the
hybrid precoder design in the partially-connected structure is identified as an
eigenvalue problem. To enhance the performance of this cost-effective
structure, dynamic mapping from RF chains to antennas is further proposed, for
which a greedy algorithm and a modified K-means algorithm are developed.
Simulation results demonstrate the performance gains of the proposed hybrid
precoding algorithms over existing ones. It shows that, with the proposed DPS
implementation, the fully-connected structure enjoys both satisfactory
performance and low design complexity while the partially-connected one serves
as an economic solution with low hardware complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10692</identifier>
 <datestamp>2019-12-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10692</id><created>2019-05-25</created><updated>2019-12-19</updated><authors><author><keyname>Nair</keyname><forenames>Manu V</forenames></author><author><keyname>Indiveri</keyname><forenames>Giacomo</forenames></author></authors><title>Mapping high-performance RNNs to in-memory neuromorphic chips</title><categories>cs.NE cs.ET eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing need for compact and low-power computing solutions for machine
learning applications has triggered significant interest in energy-efficient
neuromorphic systems. However, most of these architectures rely on spiking
neural networks, which typically perform poorly compared to their non-spiking
counterparts in terms of accuracy. In this paper, we propose a new adaptive
spiking neuron model that can be abstracted as a low-pass filter. This
abstraction enables faster and better training of spiking networks using
back-propagation, without simulating spikes. We show that this model
dramatically improves the inference performance of a recurrent neural network
and validate it with three complex spatio-temporal learning tasks: the temporal
addition task, the temporal copying task, and a spoken-phrase recognition task.
We estimate at least 500x higher energy-efficiency using our models on
compatible neuromorphic chips in comparison to Cortex-M4, a popular embedded
microprocessor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10731</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10731</id><created>2019-05-26</created><updated>2019-05-28</updated><authors><author><keyname>Xu</keyname><forenames>Dongfang</forenames></author><author><keyname>Sun</keyname><forenames>Yan</forenames></author><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Multiuser MISO UAV Communications in Uncertain Environments with No-fly
  Zones: Robust Trajectory and Resource Allocation Design</title><categories>eess.SP cs.IT math.IT</categories><comments>30 pages, 11 figures, submitted to TCOM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate robust resource allocation algorithm design for
multiuser downlink multiple-input single-output (MISO) unmanned aerial vehicle
(UAV) communication systems, where we account for the various uncertainties
that are unavoidable in such systems and, if left unattended, may severely
degrade system performance. We jointly optimize the two-dimensional (2-D)
trajectory and the transmit beamforming vector of the UAV for minimization of
the total power consumption. The algorithm design is formulated as a non-convex
optimization problem taking into account the imperfect knowledge of the angle
of departure (AoD) caused by UAV jittering, user location uncertainty, wind
speed uncertainty, and polygonal no-fly zones (NFZs). Despite the non-convexity
of the optimization problem, we solve it optimally by employing monotonic
optimization theory and semidefinite programming relaxation which yields the
optimal 2-D trajectory and beamforming policy. Since the developed optimal
resource allocation algorithm entails a high computational complexity, we also
propose a suboptimal iterative low-complexity scheme based on successive convex
approximation to strike a balance between optimality and computational
complexity. Our simulation results reveal not only the significant power
savings enabled by the proposed algorithms compared to two baseline schemes,
but also confirm their robustness with respect to UAV jittering, wind speed
uncertainty, and user location uncertainty. Moreover, our results unveil that
the joint presence of wind speed uncertainty and NFZs has a considerable impact
on the UAV trajectory. Nevertheless, by counteracting the wind speed
uncertainty with the proposed robust design, we can simultaneously minimize the
total UAV power consumption and ensure a secure trajectory that does not
trespass any NFZ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10750</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10750</id><created>2019-05-26</created><authors><author><keyname>Shlezinger</keyname><forenames>Nir</forenames></author><author><keyname>Farsad</keyname><forenames>Nariman</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>ViterbiNet: A Deep Learning Based Viterbi Algorithm for Symbol Detection</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symbol detection plays an important role in the implementation of digital
receivers. In this work, we propose ViterbiNet, which is a data-driven symbol
detector that does not require channel state information (CSI). ViterbiNet is
obtained by integrating deep neural networks (DNNs) into the Viterbi algorithm.
We identify the specific parts of the Viterbi algorithm that are
channel-model-based, and design a DNN to implement only those computations,
leaving the rest of the algorithm structure intact. We then propose a
meta-learning based approach to train ViterbiNet online based on recent
decisions, allowing the receiver to track dynamic channel conditions without
requiring new training samples for every coherence block. Our numerical
evaluations demonstrate that the performance of ViterbiNet, which is ignorant
of the CSI, approaches that of the CSI-based Viterbi algorithm, and is capable
of tracking time-varying channels without needing instantaneous CSI or
additional training data. Moreover, unlike conventional Viterbi detection,
ViterbiNet is robust to CSI uncertainty, and it can be reliably implemented in
complex channel models with constrained computational burden. More broadly, our
results demonstrate the conceptual benefit of designing communication systems
to that integrate DNNs into established algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10751</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10751</id><created>2019-05-26</created><authors><author><keyname>Mobin</keyname><forenames>Shariq</forenames></author><author><keyname>Olshausen</keyname><forenames>Bruno</forenames></author></authors><title>Auditory Separation of a Conversation from Background via Attentional
  Gating</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a model for separating a set of voices out of a sound mixture
containing an unknown number of sources. Our Attentional Gating Network (AGN)
uses a variable attentional context to specify which speakers in the mixture
are of interest. The attentional context is specified by an embedding vector
which modifies the processing of a neural network through an additive bias.
Individual speaker embeddings are learned to separate a single speaker while
superpositions of the individual speaker embeddings are used to separate sets
of speakers. We first evaluate AGN on a traditional single speaker separation
task and show an improvement of 9% with respect to comparable models. Then, we
introduce a new task to separate an arbitrary subset of voices from a mixture
of an unknown-sized set of voices, inspired by the human ability to separate a
conversation of interest from background chatter at a cafeteria. We show that
AGN is the only model capable of solving this task, performing only 7% worse
than on the single speaker separation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10805</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10805</id><created>2019-05-26</created><authors><author><keyname>Proskura</keyname><forenames>P.</forenames></author><author><keyname>Zaytsev</keyname><forenames>A.</forenames></author><author><keyname>Braslavsky</keyname><forenames>I.</forenames></author><author><keyname>Egorov</keyname><forenames>E.</forenames></author><author><keyname>Burnaev</keyname><forenames>E.</forenames></author></authors><title>Usage of multiple RTL features for Earthquake prediction</title><categories>stat.AP cs.LG eess.SP physics.data-an</categories><comments>13 pages, 3 figures, 3 tables</comments><journal-ref>Proceedings of the International Conference on Computational
  Science and Applications (ICCSA-2019), 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a classification model that predicts if an earthquake with the
magnitude above a threshold will take place at a given location in a time range
30-180 days from a given moment of time. A common approach is to use expert
forecasts based on features like Region-Time-Length (RTL) characteristics. The
proposed approach uses machine learning on top of multiple RTL features to take
into account effects at various scales and to improve prediction accuracy. For
historical data about Japan earthquakes 1992-2005 and predictions at locations
given in this database the best model has precision up to ~ 0.95 and recall up
to ~ 0.98.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10841</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10841</id><created>2019-05-26</created><updated>2020-01-13</updated><authors><author><keyname>Le</keyname><forenames>Han</forenames></author><author><keyname>Gupta</keyname><forenames>Rajarsi</forenames></author><author><keyname>Hou</keyname><forenames>Le</forenames></author><author><keyname>Abousamra</keyname><forenames>Shahira</forenames></author><author><keyname>Fassler</keyname><forenames>Danielle</forenames></author><author><keyname>Kurc</keyname><forenames>Tahsin</forenames></author><author><keyname>Samaras</keyname><forenames>Dimitris</forenames></author><author><keyname>Batiste</keyname><forenames>Rebecca</forenames></author><author><keyname>Zhao</keyname><forenames>Tianhao</forenames></author><author><keyname>Rao</keyname><forenames>Arvind</forenames></author><author><keyname>Van Dyke</keyname><forenames>Alison L.</forenames></author><author><keyname>Sharma</keyname><forenames>Ashish</forenames></author><author><keyname>Bremer</keyname><forenames>Erich</forenames></author><author><keyname>Almeida</keyname><forenames>Jonas S.</forenames></author><author><keyname>Saltz</keyname><forenames>Joel</forenames></author></authors><title>Utilizing Automated Breast Cancer Detection to Identify Spatial
  Distributions of Tumor Infiltrating Lymphocytes in Invasive Breast Cancer</title><categories>eess.IV cs.CV</categories><comments>The American Journal of Pathology</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Quantitative assessment of Tumor-TIL spatial relationships is increasingly
important in both basic science and clinical aspects of breast cancer research.
We have developed and evaluated convolutional neural network (CNN) analysis
pipelines to generate combined maps of cancer regions and tumor infiltrating
lymphocytes (TILs) in routine diagnostic breast cancer whole slide tissue
images (WSIs). We produce interactive whole slide maps that provide 1) insight
about the structural patterns and spatial distribution of lymphocytic
infiltrates and 2) facilitate improved quantification of TILs. We evaluated
both tumor and TIL analyses using three CNN networks - Resnet-34, VGG16 and
Inception v4, and demonstrated that the results compared favorably to those
obtained by what believe are the best published methods. We have produced
open-source tools and generated a public dataset consisting of tumor/TIL maps
for 1,015 TCGA breast cancer images. We also present a customized web-based
interface that enables easy visualization and interactive exploration of
high-resolution combined Tumor-TIL maps for 1,015TCGA invasive breast cancer
cases that can be downloaded for further downstream analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10846</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10846</id><created>2019-05-26</created><authors><author><keyname>Singh</keyname><forenames>Shashank</forenames></author><author><keyname>Namboodiri</keyname><forenames>Aryesh</forenames></author><author><keyname>Selvan</keyname><forenames>M. P.</forenames></author></authors><title>Simplified Algorithm for Dynamic Demand Response in Smart Homes Under
  Smart Grid Environment</title><categories>eess.SP</categories><comments>This paper was accepted and presented in 2019 IEEE PES GTD Grand
  International Conference and Exposition Asia (GTD Asia). Furthermore, the
  conference proceedings has been published in IEEE Xplore</comments><journal-ref>In Proc. 2019 IEEE PES GTD Grand International Conference and
  Exposition Asia (GTD Asia), Bangkok, Thailand, 2019, pp. 259-264</journal-ref><doi>10.1109/GTDAsia.2019.8715935</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under Smart Grid environment, the consumers may respond to incentive--based
smart energy tariffs for a particular consumption pattern. Demand Response (DR)
is a portfolio of signaling schemes from the utility to the consumers for load
shifting/shedding with a given deadline. The signaling schemes include
Time--of--Use (ToU) pricing, Maximum Demand Limit (MDL) signals etc. This paper
proposes a DR algorithm which schedules the operation of home appliances/loads
through a minimization problem. The category of loads and their operational
timings in a day have been considered as the operational parameters of the
system. These operational parameters determine the dynamic priority of a load,
which is an intermediate step of this algorithm. The ToU pricing, MDL signals,
and the dynamic priority of loads are the constraints in this formulated
minimization problem, which yields an optimal schedule of operation for each
participating load within the consumer provided duration. The objective is to
flatten the daily load curve of a smart home by distributing the operation of
its appliances in possible low--price intervals without violating the MDL
constraint. This proposed algorithm is simulated in MATLAB environment against
various test cases. The obtained results are plotted to depict significant
monetary savings and flattened load curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10890</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10890</id><created>2019-05-26</created><authors><author><keyname>Hu</keyname><forenames>Sha</forenames></author><author><keyname>Kapetanovic</keyname><forenames>Dzevdan</forenames></author><author><keyname>Wang</keyname><forenames>Neng</forenames></author><author><keyname>Hu</keyname><forenames>Wenquan</forenames></author></authors><title>Deep-Neural-Network based Fall-back Mechanism in Interference-Aware
  Receiver Design</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 7 figures, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider designing a fall-back mechanism in an
interference-aware receiver. Typically, there are two different manners of
dealing with interference, known as enhanced interference-rejection-combining
(eIRC) and symbol-level interference-cancellation (SLIC). Although SLIC
performs better than eIRC, it has higher complexity and requires the knowledge
of modulation-format (MF) of interference. Due to potential errors in MF
detection, SLIC can run with a wrong MF and render limited gains. Therefore,
designing a fall-back mechanism is of interest that only activates SLIC when
the detected MF is reliable. Otherwise, a fall-back happens and the receiver
turns to eIRC. Finding a closed-form expression of an optimal fall-back
mechanism seems difficult, and we utilize deep-neural-network (DNN) to design
it which is shown to be effective and performs better than a traditional
Bayes-risk based design in terms of reducing error-rate and saving
computational-cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10915</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10915</id><created>2019-05-26</created><updated>2019-11-19</updated><authors><author><keyname>Guan</keyname><forenames>Bochen</forenames></author><author><keyname>Zhang</keyname><forenames>Jinnian</forenames></author><author><keyname>Sethares</keyname><forenames>William A.</forenames></author><author><keyname>Kijowski</keyname><forenames>Richard</forenames></author><author><keyname>Liu</keyname><forenames>Fang</forenames></author></authors><title>SpecNet: Spectral Domain Convolutional Neural Network</title><categories>cs.CV cs.LG eess.IV</categories><comments>9 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The memory consumption of most Convolutional Neural Network (CNN)
architectures grows rapidly with increasing depth of the network, which is a
major constraint for efficient network training and inference on modern GPUs
with limited memory. Several studies show that the feature maps (as generated
after the convolutional layers) are the main bottleneck in this memory problem.
Often, these feature maps mimic natural photographs in the sense that their
energy is concentrated in the spectral domain. Although embedding CNN
architectures in the spectral domain is widely exploited to accelerate the
training process, we demonstrate that it is also possible to use the spectral
domain to reduce the memory footprint by proposing a Spectral Domain
Convolutional Neural Network (SpecNet) that performs both the convolution and
the activation operations in the spectral domain. SpecNet exploits a
configurable threshold to force small values in the feature maps to zero,
allowing the feature maps to be stored sparsely. SpecNet also employs a special
activation function that preserves the sparsity of the feature maps while
effectively encouraging the convergence of the network. The performance of
SpecNet is evaluated on three competitive object recognition benchmark tasks
(MNIST, CIFAR-10, and SVHN), and compared with four state-of-the-art
implementations (LeNet, AlexNet, VGG, and DenseNet). Overall, SpecNet is able
to reduce memory consumption by about 60% without significant loss of
performance for all tested network architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10920</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10920</id><created>2019-05-24</created><authors><author><keyname>Kerdegari</keyname><forenames>Hamideh</forenames></author><author><keyname>Razaak</keyname><forenames>Manzoor</forenames></author><author><keyname>Argyriou</keyname><forenames>Vasileios</forenames></author><author><keyname>Remagnino</keyname><forenames>Paolo</forenames></author></authors><title>Semi-supervised GAN for Classification of Multispectral Imagery Acquired
  by UAVs</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAV) are used in precision agriculture (PA) to
enable aerial monitoring of farmlands. Intelligent methods are required to
pinpoint weed infestations and make optimal choice of pesticide. UAV can fly a
multispectral camera and collect data. However, the classification of
multispectral images using supervised machine learning algorithms such as
convolutional neural networks (CNN) requires large amount of training data.
This is a common drawback in deep learning we try to circumvent making use of a
semi-supervised generative adversarial networks (GAN), providing a pixel-wise
classification for all the acquired multispectral images. Our algorithm
consists of a generator network that provides photo-realistic images as extra
training data to a multi-class classifier, acting as a discriminator and
trained on small amounts of labeled data. The performance of the proposed
method is evaluated on the weedNet dataset consisting of multispectral crop and
weed images collected by a micro aerial vehicle (MAV). The results by the
proposed semi-supervised GAN achieves high classification accuracy and
demonstrates the potential of GAN-based methods for the challenging task of
multispectral image classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10939</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10939</id><created>2019-05-26</created><authors><author><keyname>Kimura</keyname><forenames>Masanari</forenames></author></authors><title>PNUNet: Anomaly Detection using Positive-and-Negative Noise based on
  Self-Training Procedure</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the novel framework for anomaly detection in images. Our new
framework, PNUNet, is based on many normal data and few anomalous data. We
assume that some noises are added to the input images and learn to remove the
noise. In addition, the proposed method achieves significant performance
improvement by updating the noise assumed in the inputs using a self-training
framework. The experimental results for the benchmark datasets show the
usefulness of our new anomaly detection framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10940</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10940</id><created>2019-05-26</created><authors><author><keyname>Sangdeh</keyname><forenames>Pedram Kheirkhah</forenames></author><author><keyname>Pirayesh</keyname><forenames>Hossein</forenames></author><author><keyname>Quadri</keyname><forenames>Adnan</forenames></author><author><keyname>Zeng</keyname><forenames>Huacheng</forenames></author></authors><title>A Practical Spectrum Sharing Scheme for Cognitive Radio Networks: Design
  and Experiments</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum shortage is a fundamental problem in wireless networks and this
problem becomes increasingly acute with the rapid proliferation of wireless
devices. To address this problem, spectrum sharing in the context of cognitive
radio networks (CRNs) has been considered a promising solution. In this paper,
we propose a practical spectrum sharing scheme for a small CRN that comprises a
pair of primary users and a pair of secondary users by leveraging the
multiple-input and multiple-output (MIMO) technology. In our scheme, we assume
that the secondary users take full responsibility for cross-network
interference cancellation (IC). We also assume that the secondary users have no
knowledge about the primary network, including its signal waveform, frame
structure, and network protocol. The key components of our proposed scheme are
two MIMO-based interference management techniques: blind beamforming (BBF) and
blind interference cancellation (BIC). We have built a prototype of our scheme
on a wireless testbed and demonstrated that the prototyped secondary network
can coexist with commercial Wi-Fi devices (primary users). Experimental results
further show that, for a secondary device with two or three antennas, BBF and
BIC achieve an average of 25dB and 33dB IC capability in an office environment,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10959</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10959</id><created>2019-05-26</created><authors><author><keyname>Tian</keyname><forenames>Ye</forenames></author><author><keyname>Yang</keyname><forenames>Li</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>Tang</keyname><forenames>Qing</forenames></author><author><keyname>Ji</keyname><forenames>Mili</forenames></author><author><keyname>Yu</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Yu</forenames></author><author><keyname>Yang</keyname><forenames>Hong</forenames></author><author><keyname>Qian</keyname><forenames>Airong</forenames></author></authors><title>Computer-aided Detection of Squamous Carcinoma of the Cervix in Whole
  Slide Images</title><categories>cs.CV eess.IV</categories><comments>8 pages, 5figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goal: Squamous cell carcinoma of cervix is one of the most prevalent cancer
worldwide in females. Traditionally, the most indispensable diagnosis of cervix
squamous carcinoma is histopathological assessment which is achieved under
microscope by pathologist. However, human evaluation of pathology slide is
highly depending on the experience of pathologist, thus big inter- and
intra-observer variability exists. Digital pathology, in combination with deep
learning provides an opportunity to improve the objectivity and efficiency of
histopathologic slide analysis. Methods: In this study, we obtained 800
haematoxylin and eosin stained slides from 300 patients suffered from cervix
squamous carcinoma. Based on information from morphological heterogeneity in
the tumor and its adjacent area, we established deep learning models using
popular convolution neural network architectures (inception-v3,
InceptionResnet-v2 and Resnet50). Then random forest was introduced to feature
extractions and slide-based classification. Results: The overall performance of
our proposed models on slide-based tumor discrimination were outstanding with
an AUC scores &gt; 0.94. While, location identifications of lesions in whole slide
images were mediocre (FROC scores &gt; 0.52) duo to the extreme complexity of
tumor tissues. Conclusion: For the first time, our analysis workflow
highlighted a quantitative visual-based slide analysis of cervix squamous
carcinoma. Significance: This study demonstrates a pathway to assist
pathologist and accelerate the diagnosis of patients by utilizing new
computational approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10974</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10974</id><created>2019-05-27</created><authors><author><keyname>Miko&#x142;ajczyk</keyname><forenames>Agnieszka</forenames></author><author><keyname>Grochowski</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Style transfer-based image synthesis as an efficient regularization
  technique in deep learning</title><categories>cs.CV cs.LG eess.IV</categories><comments>6 pages, 4 figures, accepted to the 24th International Conference on
  Methods and Models in Automation and Robotics (MMAR 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These days deep learning is the fastest-growing area in the field of Machine
Learning. Convolutional Neural Networks are currently the main tool used for
image analysis and classification purposes. Although great achievements and
perspectives, deep neural networks and accompanying learning algorithms have
some relevant challenges to tackle. In this paper, we have focused on the most
frequently mentioned problem in the field of machine learning, that is
relatively poor generalization abilities. Partial remedies for this are
regularization techniques e.g. dropout, batch normalization, weight decay,
transfer learning, early stopping and data augmentation. In this paper, we have
focused on data augmentation. We propose to use a method based on a neural
style transfer, which allows generating new unlabeled images of a high
perceptual quality that combine the content of a base image with the appearance
of another one. In a proposed approach, the newly created images are described
with pseudo-labels, and then used as a training dataset. Real, labeled images
are divided into the validation and test set. We validated the proposed method
on a challenging skin lesion classification case study. Four representative
neural architectures are examined. Obtained results show the strong potential
of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10982</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.10982</id><created>2019-05-27</created><authors><author><keyname>Khan</keyname><forenames>Sulaiman</forenames></author><author><keyname>Ali</keyname><forenames>Hazrat</forenames></author><author><keyname>Ullah</keyname><forenames>Zia</forenames></author><author><keyname>Bulbul</keyname><forenames>Mohammad Farhad</forenames></author></authors><title>An Intelligent Monitoring System of Vehicles on Highway Traffic</title><categories>cs.CV cs.AI cs.LG eess.SP</categories><comments>5 pages</comments><journal-ref>2018 12th International Conference on Open Source Systems and
  Technologies (ICOSST), Lahore, Pakistan, 2018, pp. 71-75</journal-ref><doi>10.1109/ICOSST.2018.8632192</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Vehicle speed monitoring and management of highways is the critical problem
of the road in this modern age of growing technology and population. A poor
management results in frequent traffic jam, traffic rules violation and fatal
road accidents. Using traditional techniques of RADAR, LIDAR and LASAR to
address this problem is time-consuming, expensive and tedious. This paper
presents an efficient framework to produce a simple, cost efficient and
intelligent system for vehicle speed monitoring. The proposed method uses an HD
(High Definition) camera mounted on the road side either on a pole or on a
traffic signal for recording video frames. On the basis of these frames, a
vehicle can be tracked by using radius growing method, and its speed can be
calculated by calculating vehicle mask and its displacement in consecutive
frames. The method uses pattern recognition, digital image processing and
mathematical techniques for vehicle detection, tracking and speed calculation.
The validity of the proposed model is proved by testing it on different
highways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11003</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11003</id><created>2019-05-27</created><authors><author><keyname>Mei</keyname><forenames>Zhenning</forenames></author><author><keyname>Yu</keyname><forenames>Xilin</forenames></author><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>Ranking power spectra: a proof of concept</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Objective: To characterize the irregularity of the spectrum of a signal,
spectral entropy is a widely adopted measure. However, such a metric is
invariant under any permutation of the estimations of the powers of individual
frequency components on a predefined grid. This erases the order structure
inherent in the spectrum which is also an important aspect of irregularity of
the signal. To disentangle the order structure and extract meaningful
information from raw digital signal, novel analysis method is necessary.
Approach: A novel method to depict the order structure by simply ranking power
estimations on frequency grid of a evenly spaced signal is proposed. Two
descriptors mapping real- and vector-valued power spectrum estimation of a
signal into scalar value are defined in a heuristic manner. By definition, the
proposed descriptor is capable of distinguishing signals with identical
spectrum entropies. Main Results: The proposed descriptor showed its potential
in diverse problems. Significant (p&lt;0.001) differences were observed from brain
signals and surface electromyography of different pathological/physiological
states. Drastic change accompanied by the alteration of the underlying process
of signals enables it as candidate feature for seizure detection and endpoint
detection in speech signal. Significance: This letter explores the previously
ignored order structure in the spectrum of physiological signal. We take one
step forward along this direction by proposing two computationally efficient
descriptors with guaranteed information gain. As far as the authors are
concerned, this is the first work revealing the effectiveness of the order
structure in the spectrum in physiological signal processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11017</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11017</id><created>2019-05-27</created><authors><author><keyname>Sun</keyname><forenames>Chengjian</forenames></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames></author></authors><title>Learning to Optimize with Unsupervised Learning: Training Deep Neural
  Networks for URLLC</title><categories>cs.LG eess.SP stat.ML</categories><comments>7 pages, 1 figure, submitted to IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning the optimized solution as a function of environmental parameters is
effective in solving numerical optimization in real time for time-sensitive
applications. Existing works of learning to optimize train deep neural networks
(DNN) with labels, and the learnt solution are inaccurate, which cannot be
employed to ensure the stringent quality of service. In this paper, we propose
a framework to learn the latent function with unsupervised deep learning, where
the property that the optimal solution should satisfy is used as the
&quot;supervision signal&quot; implicitly. The framework is applicable to both functional
and variable optimization problems with constraints. We take a variable
optimization problem in ultra-reliable and low-latency communications as an
example, which demonstrates that the ultra-high reliability can be supported by
the DNN without supervision labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11022</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11022</id><created>2019-05-27</created><authors><author><keyname>Shytermeja</keyname><forenames>Enik</forenames><affiliation>ENAC</affiliation></author><author><keyname>Garcia-Pena</keyname><forenames>Axel</forenames><affiliation>ENAC</affiliation></author><author><keyname>Julien</keyname><forenames>Olivier</forenames><affiliation>ENAC</affiliation></author></authors><title>Performance Comparison of a proposed Vector Tracking architecture versus
  the Scalar configuration for a L1/E1 GPS/Galileo receiver</title><categories>eess.SP</categories><proxy>ccsd</proxy><journal-ref>ENC 2016, European Navigation Conference, May 2016, Helsinki,
  Finland. pp.ISBN : 9781479989164</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In urban environments, standalone GNSS receivers can be strongly affected to
the point of not being able to provide a position accuracy suitable for use in
vehicular applications. In this paper, a vector delay/frequency-locked loop
(VDFLL) architecture for a dual constellation L1/E1 GPS/Galileo receiver is
proposed. In this implementation, the individual DLLs and FLLs of each tracked
satellite are replaced with an Extended Kalman filter (EKF), responsible for
both estimating the user's position, velocity and clock bias and closing the
code/carrier updates for each GPS L1 and Galileo E1 tracking channels. In this
work, a detailed performance comparison between the scalar tracking and VDFLL
configuration is assessed under signal outages and significant power drops
conditions that are simulated in different satellite channels. Contrary to the
conventional tracking, the L1/E1 VDFLL loop is able to recover the frequency
and code-delay estimation at the end of the simulated outages without the
requirement of signal reacquisition process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11034</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11034</id><created>2019-05-27</created><updated>2019-11-20</updated><authors><author><keyname>Berg</keyname><forenames>Amanda</forenames></author><author><keyname>Ahlberg</keyname><forenames>J&#xf6;rgen</forenames></author><author><keyname>Felsberg</keyname><forenames>Michael</forenames></author></authors><title>Unsupervised Learning of Anomaly Detection from Contaminated Image Data
  using Simultaneous Encoder Training</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised learning of anomaly detection in high-dimensional data, such as
images, is a challenging problem recently subject to intense research. Through
careful modelling of the data distribution of normal samples, it is possible to
detect deviant samples, so called anomalies. Generative Adversarial Networks
(GANs) can model the highly complex, high-dimensional data distribution of
normal image samples, and have shown to be a suitable approach to the problem.
Previously published GAN-based anomaly detection methods often assume that
anomaly-free data is available for training. However, this assumption is not
valid in most real-life scenarios, a.k.a. in the wild. In this work, we
evaluate the effects of anomaly contaminations in the training data on
state-of-the-art GAN-based anomaly detection methods. As expected, detection
performance deteriorates. To address this performance drop, we propose to add
an additional encoder network already at training time and show that joint
generator-encoder training stratifies the latent space, mitigating the problem
with contaminated data. We show experimentally that the norm of a query image
in this stratified latent space becomes a highly significant cue to
discriminate anomalies from normal data. The proposed method achieves
state-of-the-art performance on CIFAR-10 as well as on a large, previously
untested dataset with cell images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11045</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11045</id><created>2019-05-27</created><authors><author><keyname>Xue</keyname><forenames>Yuyang</forenames></author><author><keyname>Su</keyname><forenames>Jiannan</forenames></author></authors><title>Attention Based Image Compression Post-Processing Convolutional Neural
  Network</title><categories>eess.IV cs.CV cs.LG</categories><comments>4 pages, 2 figures, CVPR Compression Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional image compressors, e.g., BPG and H.266, have achieved great
image and video compression quality. Recently, Convolutional Neural Network has
been used widely in image compression. We proposed an attention-based
convolutional neural network for low bit-rate compression to post-process the
output of traditional image compression decoder. Across the experimental
results on validation sets, the post-processing module trained by MAE and
MS-SSIM losses yields the highest PSNR of 32.10 on average at the bit-rate of
0.15.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11104</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11104</id><created>2019-05-27</created><authors><author><keyname>Tatarenko</keyname><forenames>Tatiana</forenames></author><author><keyname>Zimmermann</keyname><forenames>Jan</forenames></author><author><keyname>Adamy</keyname><forenames>Volker Willert andJ&#xfc;rgen</forenames></author></authors><title>Penalized Push-Sum Algorithm for Constrained Distributed Optimization
  with Application to Energy Management in Smart Grid</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study distributed convex constrained optimization on a time-varying
multi-agent network. Each agent has access to its own local cost function, its
local constraints, and its instant number of out-neighbors. The collective goal
is to minimize the sum of the cost functions over the set of all constraints.
We utilize the push-sum protocol to be able to solve this distributed
optimization problem. We adapt the push-sum optimization algorithm, which has
been studied in context of unconstrained optimization so far, to convex
constrained optimization by introducing an appropriate choice of penalty
functions and penalty parameters. Under some additional technical assumptions
on the gradients we prove convergence of the distributed penalty-based push-sum
algorithm to the optimal value of the global objective function. We apply the
proposed penalty-based push-sum algorithm to the problem of distributed energy
management in smart grid and discuss the advantages of this novel procedure in
comparison with existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11142</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11142</id><created>2019-05-27</created><authors><author><keyname>Tian</keyname><forenames>Guanzhong</forenames></author><author><keyname>Yuan</keyname><forenames>Yi</forenames></author><author><keyname>liu</keyname><forenames>Yong</forenames></author></authors><title>Audio2Face: Generating Speech/Face Animation from Single Audio with
  Attention-Based Bidirectional LSTM Networks</title><categories>cs.LG cs.CV cs.SD eess.AS eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an end to end deep learning approach for generating real-time
facial animation from just audio. Specifically, our deep architecture employs
deep bidirectional long short-term memory network and attention mechanism to
discover the latent representations of time-varying contextual information
within the speech and recognize the significance of different information
contributed to certain face status. Therefore, our model is able to drive
different levels of facial movements at inference and automatically keep up
with the corresponding pitch and latent speaking style in the input audio, with
no assumption or further human intervention. Evaluation results show that our
method could not only generate accurate lip movements from audio, but also
successfully regress the speaker's time-varying facial movements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11147</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11147</id><created>2019-05-27</created><authors><author><keyname>Yao</keyname><forenames>Jianping</forenames></author><author><keyname>Zhong</keyname><forenames>Canhui</forenames></author><author><keyname>Liu</keyname><forenames>Zhihan</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author></authors><title>3D Trajectory Optimization for Secure UAV Communication with CoMP
  Reception</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 5 figures, submitted to IEEE Conference for possible
  publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a secrecy unmanned aerial vehicle (UAV) communication
system with coordinated multi-point (CoMP) reception, in which one UAV sends
confidential messages to a set of distributed ground nodes (GNs) that can
cooperate in signal detection, in the presence of several colluding suspicious
eavesdroppers. Different from prior works considering the two-dimensional (2D)
horizontal trajectory design in the non-CoMP scenario, this paper additionally
exploits the UAV's vertical trajectory (or altitude) control for further
improving the secrecy communication performance with CoMP. In particular, we
jointly optimize the three dimensional (3D) trajectory and transmit power
allocation of the UAV to maximize the average secrecy rate at GNs over a
particular flight period, subject to the UAV's maximum flight speed and maximum
transmit power constraints. To solve the non-convex optimization problem, we
propose an alternating-optimization-based approach, which optimizes the
transmit power allocation and trajectory design in an alternating manner, by
convex optimization and successive convex approximation (SCA), respectively.
Numerical results show that in the scenario with CoMP reception, our proposed
3D trajectory optimization significantly outperforms the conventional 2D
horizontal trajectory design, by exploiting the additional degree of freedom in
vertical trajectory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11159</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11159</id><created>2019-05-27</created><authors><author><keyname>Byra</keyname><forenames>Michal</forenames></author><author><keyname>Andre</keyname><forenames>Michael</forenames></author></authors><title>Breast mass classification in ultrasound based on Kendall's shape
  manifold</title><categories>cs.CV eess.IV physics.med-ph</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Morphological features play an important role in breast mass classification
in sonography. While benign breast masses tend to have a well-defined
ellipsoidal contour, shape of malignant breast masses is commonly ill-defined
and highly variable. Various handcrafted morphological features have been
developed over the years to assess this phenomenon and help the radiologists
differentiate benign and malignant masses. In this paper we propose an
automatic approach to morphology analysis, we express shapes of breast masses
as points on the Kendall's shape manifold. Next, we use the full Procrustes
distance to develop support vector machine classifiers for breast mass
differentiation. The usefulness of our method is demonstrated using a dataset
of B-mode images collected from 163 breast masses. Our method achieved area
under the receiver operating characteristic curve of 0.81. The proposed method
can be used to assess shapes of breast masses in ultrasound without any feature
engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11172</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11172</id><created>2019-05-27</created><authors><author><keyname>Kim</keyname><forenames>Dong-Wook</forenames></author><author><keyname>Chung</keyname><forenames>Jae Ryun</forenames></author><author><keyname>Jung</keyname><forenames>Seung-Won</forenames></author></authors><title>GRDN:Grouped Residual Dense Network for Real Image Denoising and
  GAN-based Real-world Noise Modeling</title><categories>eess.IV cs.CV</categories><comments>To appear in CVPR 2019 workshop. The winners of the NTIRE2019
  Challenge on Image Denoising Challenge: Track 2 sRGB</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research on image denoising has progressed with the development of
deep learning architectures, especially convolutional neural networks. However,
real-world image denoising is still very challenging because it is not possible
to obtain ideal pairs of ground-truth images and real-world noisy images. Owing
to the recent release of benchmark datasets, the interest of the image
denoising community is now moving toward the real-world denoising problem. In
this paper, we propose a grouped residual dense network (GRDN), which is an
extended and generalized architecture of the state-of-the-art residual dense
network (RDN). The core part of RDN is defined as grouped residual dense block
(GRDB) and used as a building module of GRDN. We experimentally show that the
image denoising performance can be significantly improved by cascading GRDBs.
In addition to the network architecture design, we also develop a new
generative adversarial network-based real-world noise modeling method. We
demonstrate the superiority of the proposed methods by achieving the highest
score in terms of both the peak signal-to-noise ratio and the structural
similarity in the NTIRE2019 Real Image Denoising Challenge - Track 2:sRGB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11173</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11173</id><created>2019-05-27</created><updated>2019-09-10</updated><authors><author><keyname>Jia</keyname><forenames>Xiaoqi</forenames></author><author><keyname>Tai</keyname><forenames>Jianwei</forenames></author><author><keyname>Zhou</keyname><forenames>Hang</forenames></author><author><keyname>Li</keyname><forenames>Yakai</forenames></author><author><keyname>Zhang</keyname><forenames>Weijuan</forenames></author><author><keyname>Du</keyname><forenames>Haichao</forenames></author><author><keyname>Huang</keyname><forenames>Qingjia</forenames></author></authors><title>ET-GAN: Cross-Language Emotion Transfer Based on Cycle-Consistent
  Generative Adversarial Networks</title><categories>cs.SD cs.CL eess.AS</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the remarkable progress made for synthesizing emotional speech from
text, it is still challenging to provide emotion information to existing speech
segments. Previous methods mainly rely on parallel data which is difficult to
get. Moreover, few works have studied the generalization ability for one model
to transfer emotion information across different languages. To cope with such
problems, we propose an emotion transfer system named ET-GAN, for learning
language-independent emotion transfer from one emotion to another without
parallel training samples. Based on cycle-consistent generative adversarial
network, our method ensures the transfer of only emotion with novel simple loss
designs. Besides, we introduce an approach for migrating emotion information
across different languages by using domain adaption. The experiment results
show that our method can efficiently generate high-quality emotional speech for
any given emotion category, without aligned speech pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11217</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11217</id><created>2019-05-23</created><authors><author><keyname>Joseph</keyname><forenames>Jan Moritz</forenames></author><author><keyname>Bamberg</keyname><forenames>Lennart</forenames></author><author><keyname>Hajjar</keyname><forenames>Imad</forenames></author><author><keyname>Schmidt</keyname><forenames>Robert</forenames></author><author><keyname>Pionteck</keyname><forenames>Thilo</forenames></author><author><keyname>Garcia-Ortiz</keyname><forenames>Alberto</forenames></author></authors><title>Simulation Environment for Link Energy Estimation in Networks-on-Chip
  with Virtual Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network-on-chip (NoC) is the most promising design paradigm for the
interconnect architecture of a multiprocessor system-on-chip (MPSoC). On the
downside, a NoC has a significant impact on the overall energy consumption of
the system. NoC simulators are highly relevant for design space exploration
even at an early stage. Since links in NoC consume up to 50% of the energy, a
realistic energy consumption of links in NoC simulators is important. This work
presents a simulation environment which implements a technique to precisely
estimate the data dependent link energy consumption in NoCs with virtual
channels for the first time. Our model works at a high level of abstraction,
making it feasible to estimate the energy requirements at an early design
stage. Additionally, it enables the fast evaluation and early exploration of
low-power coding techniques. The presented model is applicable for 2D and 3D
NoCs. A case study for an image processing application shows that the current
link model leads to an underestimate of the link energy consumption by up to a
factor of four. In contrast, the technique presented in this paper estimates
the energy quantities precisely with an error below 1% compared to results
obtained by precise, but computational extensive, bit-level simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11218</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11218</id><created>2019-05-23</created><authors><author><keyname>Kuentzer</keyname><forenames>Felipe A.</forenames></author><author><keyname>Juracy</keyname><forenames>Leonardo R.</forenames></author><author><keyname>Moreira</keyname><forenames>Matheus T.</forenames></author><author><keyname>Amory</keyname><forenames>Alexandre M.</forenames></author></authors><title>Delay lines test method for the Blade Template</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for testing the delay lines of Blade
asynchronous timing resilience template. It consists of an offline test method,
with low area overhead, for measuring the internal propagation delay of the
delay lines with external testers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11219</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11219</id><created>2019-05-27</created><authors><author><keyname>Scheiner</keyname><forenames>Nicolas</forenames></author><author><keyname>Appenrodt</keyname><forenames>Nils</forenames></author><author><keyname>Dickmann</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Sick</keyname><forenames>Bernhard</forenames></author></authors><title>Automated Ground Truth Estimation of Vulnerable Road Users in Automotive
  Radar Data Using GNSS</title><categories>eess.SP cs.LG stat.ML</categories><comments>5 pages, 5 figures</comments><journal-ref>Published in Proceedings of IEEE MTT-S International Conference on
  Microwaves for Intelligent Mobility (ICMIM), Detroit, MI, USA, April 2019,
  pp. 5-9, ISBN: 978-1-7281-0775-2</journal-ref><doi>10.1109/ICMIM.2019.8726801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Annotating automotive radar data is a difficult task. This article presents
an automated way of acquiring data labels which uses a highly accurate and
portable global navigation satellite system (GNSS). The proposed system is
discussed besides a revision of other label acquisitions techniques and a
problem description of manual data annotation. The article concludes with a
systematic comparison of conventional hand labeling and automatic data
acquisition. The results show clear advantages of the proposed method without a
relevant loss in labeling accuracy. Minor changes can be observed in the
measured radar data, but the so introduced bias of the GNSS reference is
clearly outweighed by the indisputable time savings. Beside data annotation,
the proposed system can also provide a ground truth for validating object
tracking or other automated driving system applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11229</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11229</id><created>2019-05-27</created><updated>2019-05-30</updated><authors><author><keyname>Liu</keyname><forenames>Haoyan</forenames></author><author><keyname>Liu</keyname><forenames>Yanming</forenames></author><author><keyname>Yang</keyname><forenames>Ming</forenames></author><author><keyname>Li</keyname><forenames>Xiaoping</forenames></author></authors><title>A Novel Demodulation and Estimation Algorithm for Blackout
  Communication: Extract Principal Components with Deep Learning</title><categories>eess.SP cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For reentry or near space communication, owing to the influence of the
time-varying plasma sheath channel environment, the received IQ baseband
signals are severely rotated on the constellation. Researches have shown that
the frequency of electron density varies from 20kHz to 100 kHz which is on the
same order as the symbol rate of most TT\&amp;C communication systems and a mass of
bandwidth will be consumed to track the time-varying channel with traditional
estimation. In this paper, motivated by principal curve analysis, we propose a
deep learning (DL) algorithm which called symmetric manifold network (SMN) to
extract the curves on the constellation and classify the signals based on the
curves. The key advantage is that SMN can achieve joint optimization of
demodulation and channel estimation. From our simulation results, the new
algorithm significantly reduces the symbol error rate (SER) compared to
existing algorithms and enables accurate estimation of fading with extremely
high bandwith utilization rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11234</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11234</id><created>2019-05-23</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Johnson</keyname><forenames>Brian K.</forenames></author></authors><title>Tractable Approach to MmWaves Cellular Analysis with FSO Backhauling
  under Feedback Delay and Hardware Limitations</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1901.04249</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate the performance of a millimeter waves (mmWaves)
cellular system with free space optical (FSO) backhauling. MmWave channels are
subject to Nakagami-m fading while the optical links experience the Double
Generalized Gamma including atmospheric turbulence, path loss and the
misalignment between the transmitter and the receiver aperture (also known as
the pointing errors). The FSO model also takes into account the receiver
detection technique which could be either heterodyne or intensity modulation
and direct detection (IM/DD). Each user equipment (UE) has to be associated to
one serving base station (BS) based on the received signal strength (RSS) or
Channel State Information (CSI). We assume partial relay selection (PRS) with
CSI based on mmWaves channels to select the BS associated with the highest
received CSI. Each serving BS decodes the received signal for denoising,
converts it into modulated FSO signal, and then forwards it to the data center.
Thereby, each BS can be viewed as a decode-and-forward (DF) relay. In practice,
the relay hardware suffers from nonlinear high power amplification (HPA)
impairments which, substantially degrade the system performance. In this work,
we will discuss the impacts of three common HPA impairments named respectively,
soft envelope limiter (SEL), traveling wave tube amplifier (TWTA), and solid
state power amplifier (SSPA). Novel closed-forms and tight upper bounds of the
outage probability, the probability of error, and the achievable rate are
derived. Capitalizing on these performance, we derive the high SNR asymptotes
to get engineering insights into the system gain such as the diversity order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11235</identifier>
 <datestamp>2020-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11235</id><created>2019-05-27</created><updated>2020-02-12</updated><authors><author><keyname>Dong</keyname><forenames>Linhao</forenames></author><author><keyname>Xu</keyname><forenames>Bo</forenames></author></authors><title>CIF: Continuous Integrate-and-Fire for End-to-End Speech Recognition</title><categories>cs.CL cs.LG cs.NE cs.SD eess.AS</categories><comments>To appear at ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel soft and monotonic alignment mechanism used
for sequence transduction. It is inspired by the integrate-and-fire model in
spiking neural networks and employed in the encoder-decoder framework consists
of continuous functions, thus being named as: Continuous Integrate-and-Fire
(CIF). Applied to the ASR task, CIF not only shows a concise calculation, but
also supports online recognition and acoustic boundary positioning, thus
suitable for various ASR scenarios. Several support strategies are also
proposed to alleviate the unique problems of CIF-based model. With the joint
action of these methods, the CIF-based model shows competitive performance.
Notably, it achieves a word error rate (WER) of 2.86% on the test-clean of
Librispeech and creates new state-of-the-art result on Mandarin telephone ASR
benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11252</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11252</id><created>2019-05-24</created><updated>2019-12-03</updated><authors><author><keyname>Afisiadis</keyname><forenames>Orion</forenames></author><author><keyname>Cotting</keyname><forenames>Matthieu</forenames></author><author><keyname>Burg</keyname><forenames>Andreas</forenames></author><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author></authors><title>On the Error Rate of the LoRa Modulation with Interference</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Transactions on Wireless
  Communications, arXiv admin note: substantial text overlap with
  arXiv:1905.00439</comments><doi>10.1109/TWC.2019.2952584</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LoRa is a chirp spread-spectrum modulation developed for the Internet of
Things. In this work, we examine the performance of LoRa in the presence of
both additive white Gaussian noise and interference from another LoRa user. To
this end, we extend an existing interference model, which assumes perfect
alignment of the signal of interest and the interference, to the more realistic
case where the interfering user is neither chip- nor phase-aligned with the
signal of interest and we derive an expression for the error rate. We show that
the existing aligned interference model overestimates the effect of
interference on the error rate. Moreover, we prove two symmetries in the
interfering signal and we derive low-complexity approximate formulas that can
significantly reduce the complexity of computing the symbol and frame error
rates compared to the complete expression. Finally, we provide numerical
simulations to corroborate the theoretical analysis and to verify the accuracy
of our proposed approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11259</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11259</id><created>2019-05-27</created><authors><author><keyname>Chen</keyname><forenames>Lu</forenames></author><author><keyname>Chen</keyname><forenames>Zhi</forenames></author><author><keyname>Tan</keyname><forenames>Bowen</forenames></author><author><keyname>Long</keyname><forenames>Sishan</forenames></author><author><keyname>Gasic</keyname><forenames>Milica</forenames></author><author><keyname>Yu</keyname><forenames>Kai</forenames></author></authors><title>AgentGraph: Towards Universal Dialogue Management with Structured Deep
  Reinforcement Learning</title><categories>cs.CL cs.AI cs.LG eess.AS</categories><comments>14 pages, 8 figures; Accepted by IEEE/ACM TRANSACTIONS ON AUDIO,
  SPEECH, AND LANGUAGE PROCESSING</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dialogue policy plays an important role in task-oriented spoken dialogue
systems. It determines how to respond to users. The recently proposed deep
reinforcement learning (DRL) approaches have been used for policy optimization.
However, these deep models are still challenging for two reasons: 1) Many
DRL-based policies are not sample-efficient. 2) Most models don't have the
capability of policy transfer between different domains. In this paper, we
propose a universal framework, AgentGraph, to tackle these two problems. The
proposed AgentGraph is the combination of GNN-based architecture and DRL-based
algorithm. It can be regarded as one of the multi-agent reinforcement learning
approaches. Each agent corresponds to a node in a graph, which is defined
according to the dialogue domain ontology. When making a decision, each agent
can communicate with its neighbors on the graph. Under AgentGraph framework, we
further propose Dual GNN-based dialogue policy, which implicitly decomposes the
decision in each turn into a high-level global decision and a low-level local
decision. Experiments show that AgentGraph models significantly outperform
traditional reinforcement learning approaches on most of the 18 tasks of the
PyDial benchmark. Moreover, when transferred from the source task to a target
task, these models not only have acceptable initial performance but also
converge much faster on the target task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11276</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11276</id><created>2019-05-27</created><authors><author><keyname>Zaj&#xed;c</keyname><forenames>Zbyn&#x11b;k</forenames></author><author><keyname>Kune&#x161;ov&#xe1;</keyname><forenames>Marie</forenames></author><author><keyname>Hr&#xfa;z</keyname><forenames>Marek</forenames></author><author><keyname>Van&#x11b;k</keyname><forenames>Jan</forenames></author></authors><title>UWB-NTIS Speaker Diarization System for the DIHARD II 2019 Challenge</title><categories>eess.AS cs.SD</categories><comments>Submitted to Interspeech 2019</comments><journal-ref>INTERSPEECH 2019</journal-ref><doi>10.21437/Interspeech.2019-1385</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present our system developed by the team from the New
Technologies for the Information Society (NTIS) research center of the
University of West Bohemia in Pilsen, for the Second DIHARD Speech Diarization
Challenge. The base of our system follows the currently-standard approach of
segmentation, i/x-vector extraction, clustering, and resegmentation. The
hyperparameters for each of the subsystems were selected according to the
domain classifier trained on the development set of DIHARD II. We compared our
system with results from the Kaldi diarization (with i/x-vectors) and combined
these systems. At the time of writing of this abstract, our best submission
achieved a DER of 23.47% and a JER of 48.99% on the evaluation set (in Track 1
using reference SAD).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11297</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11297</id><created>2019-05-27</created><authors><author><keyname>Wirkert</keyname><forenames>Sebastian J.</forenames></author><author><keyname>Isensee</keyname><forenames>Fabian</forenames></author><author><keyname>Vemuri</keyname><forenames>Anant S.</forenames></author><author><keyname>Ayala</keyname><forenames>Leonardo A.</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Klaus H.</forenames></author><author><keyname>Fei</keyname><forenames>Baowei</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Lena</forenames></author></authors><title>Task-specific multispectral band selection</title><categories>physics.bio-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multispectral imaging provides valuable information on tissue composition
such as hemoglobin oxygen saturation. However, the real-time application of
this technique in interventional medicine can be challenging because the
acquisition time of large amount of hyperspectral data with hundreds of bands
can be long. This challenge can partially be addressed by choosing a
discriminative subset of bands. The band selection methods proposed to date are
mainly based on the availability of often hard to obtain reference
measurements. We address this bottleneck with a new approach to band selection
that leverages highly accurate Monte Carlo simulations. We hypothesize that a
so chosen small subset of bands can reproduce or even improve upon the results
of a quasi continuous spectral measurement. We further investigate whether
novel domain adaptation techniques can address the inevitable domain shift
stemming from the use of simulations. Initial results based on in silico and in
vivo experiments suggest that 10-20 bands are sufficient to closely reproduce
results from 101 band spectral measurement in the 500-700nm range, depending on
the experiment. The investigated domain adaptation technique, which only
requires unannotated in vivo measurements yielded better results than the pure
in silico band selection method. Overall, our method could guide development of
novel and fast multispectral imaging systems suited for interventional use
without relying on complex hardware setups or manually labeled data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11333</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11333</id><created>2019-05-27</created><updated>2019-08-24</updated><authors><author><keyname>Hong</keyname><forenames>Shenda</forenames></author><author><keyname>Xiao</keyname><forenames>Cao</forenames></author><author><keyname>Ma</keyname><forenames>Tengfei</forenames></author><author><keyname>Li</keyname><forenames>Hongyan</forenames></author><author><keyname>Sun</keyname><forenames>Jimeng</forenames></author></authors><title>MINA: Multilevel Knowledge-Guided Attention for Modeling
  Electrocardiography Signals</title><categories>eess.SP cs.LG</categories><comments>Published in IJCAI 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Electrocardiography (ECG) signals are commonly used to diagnose various
cardiac abnormalities. Recently, deep learning models showed initial success on
modeling ECG data, however they are mostly black-box, thus lack
interpretability needed for clinical usage. In this work, we propose MultIlevel
kNowledge-guided Attention networks (MINA) that predict heart diseases from ECG
signals with intuitive explanation aligned with medical knowledge. By
extracting multilevel (beat-, rhythm- and frequency-level) domain knowledge
features separately, MINA combines the medical knowledge and ECG data via a
multilevel attention model, making the learned models highly interpretable. Our
experiments showed MINA achieved PR-AUC 0.9436 (outperforming the best baseline
by 5.51%) in real world ECG dataset. Finally, MINA also demonstrated robust
performance and strong interpretability against signal distortion and noise
contamination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11387</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11387</id><created>2019-05-26</created><authors><author><keyname>Tirunagari</keyname><forenames>Santosh</forenames></author><author><keyname>Poh</keyname><forenames>Norman</forenames></author><author><keyname>Wells</keyname><forenames>Kevin</forenames></author><author><keyname>Bober</keyname><forenames>Miroslaw</forenames></author><author><keyname>Gorden</keyname><forenames>Isky</forenames></author><author><keyname>Windridge</keyname><forenames>David</forenames></author></authors><title>Automatic Delineation of Kidney Region in DCE-MRI</title><categories>eess.IV cs.CV</categories><comments>arXiv admin note: text overlap with arXiv:1905.10218</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delineation of the kidney region in dynamic contrast-enhanced magnetic
resonance Imaging (DCE-MRI) is required during post-acquisition analysis in
order to quantify various aspects of renal function, such as filtration and
perfusion or blood flow. However, this can be obfuscated by the Partial Volume
Effect (PVE), caused due to the mixing of any single voxel with two or more
signal intensities from adjacent regions such as liver region and other
tissues. To avoid this problem, firstly, a kidney region of interest (ROI)
needs to be defined for the analysis. A clinician may choose to select a region
avoiding edges where PV mixing is likely to be significant. However, this
approach is time-consuming and labour intensive. To address this issue, we
present Dynamic Mode Decomposition (DMD) coupled with thresholding and blob
analysis as a framework for automatic delineation of the kidney region. This
method is first validated on synthetically generated data with ground-truth
available and then applied to ten healthy volunteers' kidney DCE-MRI datasets.
We found that the result obtained from our proposed framework is comparable to
that of a human expert. For example, while our result gives an average Root
Mean Square Error (RMSE) of 0.0097, the baseline achieves an average RMSE of
0.1196 across the 10 datasets. As a result, we conclude automatic modelling via
DMD framework is a promising approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11442</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11442</id><created>2019-05-27</created><updated>2019-05-30</updated><authors><author><keyname>Ibrahim</keyname><forenames>Hazem</forenames></author><author><keyname>Tabassum</keyname><forenames>Hina</forenames></author><author><keyname>Nguyen</keyname><forenames>Uyen T.</forenames></author></authors><title>Meta Distribution of SIR in Dual-Hop Internet-of-Things (IoT) Networks</title><categories>eess.SP</categories><journal-ref>IEEE ICC 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper characterizes the meta distribution of the downlink
signal-to-interference ratio (SIR) attained at a typical Internet-of-Things
(IoT) device in a dual-hop IoT network. The IoT device associates with either a
serving macro base station (MBS) for direct transmissions or associates with a
decode and forward (DF) relay for dual-hop transmissions, depending on the
biased received signal power criterion. In contrast to the conventional success
probability, the meta distribution is the distribution of the conditional
success probability (CSP), which is conditioned on the locations of the
wireless transmitters. The meta distribution is a fine-grained performance
metric that captures important network performance metrics such as the coverage
probability and the mean local delay as its special cases. Specifically, we
derive the moments of the CSP in order to calculate analytic expressions for
the meta distribution. Further, we derive mathematical expressions for special
cases such as the mean local delay, variance of the CSP, and success
probability of a typical IoT device and typical relay with different offloading
biases. We take in consideration in our analysis the association probabilities
of IoT devices. Finally, we investigate the impact of increasing the relay
density on the mean local delay using numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11449</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11449</id><created>2019-05-27</created><updated>2019-05-29</updated><authors><author><keyname>Tjandra</keyname><forenames>Andros</forenames></author><author><keyname>Sisman</keyname><forenames>Berrak</forenames></author><author><keyname>Zhang</keyname><forenames>Mingyang</forenames></author><author><keyname>Sakti</keyname><forenames>Sakriani</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoshi</forenames></author></authors><title>VQVAE Unsupervised Unit Discovery and Multi-scale Code2Spec Inverter for
  Zerospeech Challenge 2019</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Submitted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe our submitted system for the ZeroSpeech Challenge 2019. The
current challenge theme addresses the difficulty of constructing a speech
synthesizer without any text or phonetic labels and requires a system that can
(1) discover subword units in an unsupervised way, and (2) synthesize the
speech with a target speaker's voice. Moreover, the system should also balance
the discrimination score ABX, the bit-rate compression rate, and the
naturalness and the intelligibility of the constructed voice. To tackle these
problems and achieve the best trade-off, we utilize a vector quantized
variational autoencoder (VQ-VAE) and a multi-scale codebook-to-spectrogram
(Code2Spec) inverter trained by mean square error and adversarial loss. The
VQ-VAE extracts the speech to a latent space, forces itself to map it into the
nearest codebook and produces compressed representation. Next, the inverter
generates a magnitude spectrogram to the target voice, given the codebook
vectors from VQ-VAE. In our experiments, we also investigated several other
clustering algorithms, including K-Means and GMM, and compared them with the
VQ-VAE result on ABX scores and bit rates. Our proposed approach significantly
improved the intelligibility (in CER), the MOS, and discrimination ABX scores
compared to the official ZeroSpeech 2019 baseline or even the topline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11450</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11450</id><created>2019-05-27</created><authors><author><keyname>Arfaoui</keyname><forenames>Mohamed Amine</forenames></author><author><keyname>Soltani</keyname><forenames>Mohammad Dehghani</forenames></author><author><keyname>Tavakkolnia</keyname><forenames>Iman</forenames></author><author><keyname>Ghrayeb</keyname><forenames>Ali</forenames></author><author><keyname>Assi</keyname><forenames>Chadi</forenames></author><author><keyname>Safari</keyname><forenames>Majid</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>Physical Layer Security for Visible Light Communication Systems: A
  Survey</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the dramatic increase in high data rate services and in order to meet
the demands of the fifth-generation (5G) networks, researchers from both
academia and industry are exploring advanced transmission techniques, new
network architectures and new frequency spectrum such as the visible light
spectra. Visible light communication (VLC) particularly is an emerging
technology that has been introduced as a promising solution for 5G and beyond.
Although VLC systems are more immune against interference and less susceptible
to security vulnerabilities since light does not penetrate through walls,
security issues arise naturally in VLC channels due to their open and
broadcasting nature, compared to fiber-optic systems. In addition, since VLC is
considered to be an enabling technology for 5G, and security is one of the 5G
fundamental requirements, security issues should be carefully addressed and
resolved in the VLC context. On the other hand, due to the success of physical
layer security (PLS) in improving the security of radio-frequency (RF) wireless
networks, extending such PLS techniques to VLC systems has been of great
interest. Only two survey papers on security in VLC have been published in the
literature. However, a comparative and unified survey on PLS for VLC from
information theoretic and signal processing point of views is still missing.
This paper covers almost all aspects of PLS for VLC, including different
channel models, input distributions, network configurations,
precoding/signaling strategies, and secrecy capacity and information rates.
Furthermore, we propose a number of timely and open research directions for
PLS-VLC systems, including the application of measurement-based indoor and
outdoor channel models, incorporating user mobility and device orientation into
the channel model, and combining VLC and RF systems to realize the potential of
such technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11451</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11451</id><created>2019-05-27</created><authors><author><keyname>Masoudi</keyname><forenames>Samira</forenames></author><author><keyname>Wright</keyname><forenames>Cameron H. G.</forenames></author><author><keyname>Gatlin</keyname><forenames>Jesse C.</forenames></author><author><keyname>Oakey</keyname><forenames>John. S.</forenames></author></authors><title>Microtubule Motility Analysis based on Time-Lapse Fluorescence
  Microscopy</title><categories>q-bio.SC eess.IV</categories><comments>11 pages, 3 figures, conference paper</comments><journal-ref>journal of Biomedical Sciences Instrumentation, vol 52, pages
  126--133, April 2016, published by ISAs</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper describes an investigation into part of the mechanical mechanisms
underlying the formation of mitotic spindle, the cellular machinery responsible
for chromosomal separation during cell division. In normal eukaryotic cells,
spindles are composed of microtubule filaments that radiate outward from two
centrosomes. In many transformed cells, however, centrosome number is
misregulated resulting in cells with more than two centrosomes. Addressing the
question of how these cells accommodate these additional structures by
coalescing supernumerary centrosomes to form normal spindles will provide a
powerful insight toward understanding the proliferation of cancer cells and
developing new therapeutics. The process of centrosome coalescence is thought
to involve motor proteins that function to slide microtubules relative to one
another. Here we use in vitro motility assays combined with fluorescence
microscopy to visualize, characterize and quantify microtubule-microtubule
interactions. After segmenting the microtubules, their speed and direction of
movement are the extracted features to cluster their interaction type. In order
to evaluate the potential of our processing algorithm, we created a simulated
dataset similar to the time-lapse series. Once our procedure has been optimized
using the simulated data, we will apply it to the real data. Results of our
analyses will provide a quantitative description of interaction among
microtubules. This is a potentially important step toward more thorough
understanding of cancer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11461</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11461</id><created>2019-05-27</created><authors><author><keyname>Escribano</keyname><forenames>Francisco J.</forenames></author><author><keyname>Wagemakers</keyname><forenames>Alexandre</forenames></author><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author><author><keyname>Evangelista</keyname><forenames>Joao V. C.</forenames></author></authors><title>Design and Performance Analysis of an Index Time Frequency Modulation
  Scheme for Optical Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, 10 figures. IEEE Journal of Selected Topics in Signal
  Processing, 2019</comments><doi>10.1109/JSTSP.2019.2918484</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose an index modulation system suitable for optical
communications, based on jointly driving the time and frequency of the signal:
an index-time frequency hopping (I-TFH) system. We analyze its performance from
the point of view of its efficiency in power and spectrum, and its behavior in
terms of error probability for the non-turbulent free-space optical (FSO)
channel. We compare I-TFH with already proposed index modulated systems of the
same nature, but where the amplitude or the number of transmitters are driven
instead of the signal frequency. We derive and compare approximations for the
average symbol and bit error probabilities of all these systems. The simulation
results show that said approximations are tight enough for a wide range of
signal-to-noise ratios and system parameters. Moreover, I-TFH shows to be
better performing in BER and/or power efficiency than the comparative
alternatives, and may offer interesting properties in a variety of contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11476</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11476</id><created>2019-05-27</created><authors><author><keyname>Artner</keyname><forenames>Gerald</forenames></author></authors><title>Channel Static Antennas for Mobile Devices</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel static antennas are considered for mobile devices. The antenna keeps
the wireless communication channel static by performing a counter-movement that
is opposed to movements of the device that might be caused by a user. The
feasibility of the concept is demonstrated for linear movement in an office
environment. Channel measurements are performed with quarter wavelength
monopole antennas in the 2.4GHz ISM frequency band. A channel model for the
wireless communication channel of mobile devices with channel static antennas
is proposed based on these measurement results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11484</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11484</id><created>2019-05-27</created><authors><author><keyname>Artner</keyname><forenames>Gerald</forenames></author></authors><title>Channel Static Antennas for Compensating the Movements of a Partner
  Antenna</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has recently been demonstrated that the channel changes caused by the
movements of an antenna can be compensated by a counter-movement of the
antenna, effectively keeping the wireless channel static. In this work, it is
considered that the moving antenna can not perform such a counter-movement and
that the channel is instead kept static by the partner antenna to which the
channel is formed. It is established that the channel can be kept static under
certain conditions by moving the partner antenna with the original antenna
along the same trajectory (with-movement, German: Mitbewegung). Experimental
results are presented for a platform moving in straight motion over a finite
distance. The experiment is conducted in an anechoic environment with
quarter-wavelength monopole antennas in the gigahertz range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11529</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11529</id><created>2019-05-27</created><authors><author><keyname>Almousa</keyname><forenames>Motab</forenames></author></authors><title>Grid Optimal Integration of Power Ships</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power-generating ships or Power Ships (PSs) are considered one of the largest
mobile energy resources. In this paper, a model is proposed to evaluate the
integration of PSs into power grid operations. The model optimally coordinates
the ships to enhance the grid objective; its solution provides optimal
generation resource scheduling, as well as optimal scheduling and routing of
the ships. IEEE 6-bus and IEEE 118-bus case studies were considered to model
the system and to validate the effectiveness of the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11559</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11559</id><created>2019-05-26</created><authors><author><keyname>Liu</keyname><forenames>Huafeng</forenames></author><author><keyname>Yao</keyname><forenames>Yazhou</forenames></author><author><keyname>Sun</keyname><forenames>Zeren</forenames></author><author><keyname>Li</keyname><forenames>Xiangrui</forenames></author><author><keyname>Jia</keyname><forenames>Ke</forenames></author><author><keyname>Tang</keyname><forenames>Zhenmin</forenames></author></authors><title>Road Segmentation with Image-LiDAR Data Fusion</title><categories>cs.CV eess.IV</categories><comments>Accepted by Multimedia Tools and Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust road segmentation is a key challenge in self-driving research. Though
many image-based methods have been studied and high performances in dataset
evaluations have been reported, developing robust and reliable road
segmentation is still a major challenge. Data fusion across different sensors
to improve the performance of road segmentation is widely considered an
important and irreplaceable solution. In this paper, we propose a novel
structure to fuse image and LiDAR point cloud in an end-to-end semantic
segmentation network, in which the fusion is performed at decoder stage instead
of at, more commonly, encoder stage. During fusion, we improve the multi-scale
LiDAR map generation to increase the precision of the multi-scale LiDAR map by
introducing pyramid projection method. Additionally, we adapted the multi-path
refinement network with our fusion strategy and improve the road prediction
compared with transpose convolution with skip layers. Our approach has been
tested on KITTI ROAD dataset and has competitive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11563</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11563</id><created>2019-05-27</created><updated>2019-06-20</updated><authors><author><keyname>Liu</keyname><forenames>Andy T.</forenames></author><author><keyname>Hsu</keyname><forenames>Po-chun</forenames></author><author><keyname>Lee</keyname><forenames>Hung-yi</forenames></author></authors><title>Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice
  Conversion</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted by Interspeech 2019, Graz, Austria</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an unsupervised end-to-end training scheme where we discover
discrete subword units from speech without using any labels. The discrete
subword units are learned under an ASR-TTS autoencoder reconstruction setting,
where an ASR-Encoder is trained to discover a set of common linguistic units
given a variety of speakers, and a TTS-Decoder trained to project the
discovered units back to the designated speech. We propose a discrete encoding
method, Multilabel-Binary Vectors (MBV), to make the ASR-TTS autoencoder
differentiable. We found that the proposed encoding method offers automatic
extraction of speech content from speaker style, and is sufficient to cover
full linguistic content in a given language. Therefore, the TTS-Decoder can
synthesize speech with the same content as the input of ASR-Encoder but with
different speaker characteristics, which achieves voice conversion (VC). We
further improve the quality of VC using adversarial training, where we train a
TTS-Patcher that augments the output of TTS-Decoder. Objective and subjective
evaluations show that the proposed approach offers strong VC results as it
eliminates speaker identity while preserving content within speech. In the
ZeroSpeech 2019 Challenge, we achieved outstanding performance in terms of low
bitrate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11567</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11567</id><created>2019-05-27</created><authors><author><keyname>Lao</keyname><forenames>Qicheng</forenames></author><author><keyname>Fevens</keyname><forenames>Thomas</forenames></author></authors><title>Case-Based Histopathological Malignancy Diagnosis using Convolutional
  Neural Networks</title><categories>cs.CV eess.IV</categories><journal-ref>British Machine Vision Conference (BMVC) 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In practice, histopathological diagnosis of tumor malignancy often requires a
human expert to scan through histopathological images at multiple magnification
levels, after which a final diagnosis can be accurately determined. However,
previous research on such classification tasks using convolutional neural
networks primarily determine a diagnosis for a single magnification level. In
this paper, we propose a case-based approach using deep residual neural
networks for histopathological malignancy diagnosis, where a case is defined as
a sequence of images from the patient at all available levels of magnification.
Effectively, through mimicking what a human expert would actually do, our
approach makes a diagnosis decision based on features learned in combination at
multiple magnification levels. Our results show that the case-based approach
achieves better performance than the state-of-the-art methods when evaluated on
BreaKHis, a histopathological image dataset for breast tumors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11570</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11570</id><created>2019-05-27</created><authors><author><keyname>Song</keyname><forenames>Xianxin</forenames></author><author><keyname>Qin</keyname><forenames>Xiaoqi</forenames></author><author><keyname>Tao</keyname><forenames>Yunzheng</forenames></author><author><keyname>Liu</keyname><forenames>Baoling</forenames></author><author><keyname>Zhang</keyname><forenames>Ping</forenames></author></authors><title>Age Based Task Scheduling and Computation Offloading in Mobile-Edge
  Computing Systems</title><categories>eess.SP cs.NI</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To support emerging real-time monitoring and control applications, the
timeliness of computation results is of critical importance to mobile-edge
computing (MEC) systems. We propose a performance metric called age of task
(AoT) based on the concept of age of information (AoI), to evaluate the
temporal value of computation tasks. In this paper, we consider a system
consisting of a single MEC server and one mobile device running several
applications. We study an age minimization problem by jointly considering task
scheduling, computation offloading and energy consumption. To solve the problem
efficiently, we propose a light-weight task scheduling and computation
offloading algorithm. Through performance evaluation, we show that our proposed
age-based solution is competitive when compared with traditional strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11586</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11586</id><created>2019-05-27</created><authors><author><keyname>Burnaev</keyname><forenames>Evgeny</forenames></author></authors><title>Rare Failure Prediction via Event Matching for Aerospace Applications</title><categories>cs.LG eess.SP stat.AP stat.ML</categories><comments>7 pages, 8 figures, 1 table</comments><journal-ref>3rd International Conference on Circuits, System and Simulation
  (ICCSS 2019), 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a problem of failure prediction in the context of
predictive maintenance applications. We present a new approach for rare
failures prediction, based on a general methodology, which takes into account
peculiar properties of technical systems. We illustrate the applicability of
the method on the real-world test cases from aircraft operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11595</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11595</id><created>2019-05-27</created><updated>2019-07-26</updated><authors><author><keyname>Chandran</keyname><forenames>Sreenithy</forenames></author><author><keyname>Jayasuriya</keyname><forenames>Suren</forenames></author></authors><title>Adaptive Lighting for Data-Driven Non-Line-of-Sight 3D Localization and
  Object Identification</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-line-of-sight (NLOS) imaging of objects not visible to either the camera
or illumination source is a challenging task with vital applications including
surveillance and robotics. Recent NLOS reconstruction advances have been
achieved using time-resolved measurements which requires expensive and
specialized detectors and laser sources. In contrast, we propose a data-driven
approach for NLOS 3D localization and object identification requiring only a
conventional camera and projector. To generalize to complex line-of-sight (LOS)
scenes with non-planar surfaces and occlusions, we introduce an adaptive
lighting algorithm. This algorithm, based on radiosity, identifies and
illuminates scene patches in the LOS which most contribute to the NLOS light
paths, and can factor in system power constraints. We achieve an average
identification of 87.1% object identification for four classes of objects, and
average localization of the NLOS object's centroid with a mean-squared error
(MSE) of 1.97 cm in the occluded region for real data taken from a hardware
prototype. These results demonstrate the advantage of combining the physics of
light transport with active illumination for data-driven NLOS imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11678</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11678</id><created>2019-05-28</created><updated>2019-05-31</updated><authors><author><keyname>Jang</keyname><forenames>Soobeom</forenames></author><author><keyname>Moon</keyname><forenames>Seong-Eun</forenames></author><author><keyname>Lee</keyname><forenames>Jong-Seok</forenames></author></authors><title>Brain Signal Classification via Learning Connectivity Structure</title><categories>cs.LG eess.SP stat.ML</categories><comments>14 pages (11 for article + 3 for supplementary), 5 figures (3 for
  article + 2 for supplementary)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectivity between different brain regions is one of the most important
properties for classification of brain signals including electroencephalography
(EEG). However, how to define the connectivity structure for a given task is
still an open problem, because there is no ground truth about how the
connectivity structure should be in order to maximize the performance. In this
paper, we propose an end-to-end neural network model for EEG classification,
which can extract an appropriate multi-layer graph structure and signal
features directly from a set of raw EEG signals and perform classification.
Experimental results demonstrate that our method yields improved performance in
comparison to the existing approaches where manually defined connectivity
structures and signal features are used. Furthermore, we show that the graph
structure extraction process is reliable in terms of consistency, and the
learned graph structures make much sense in the neuroscientific viewpoint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11679</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11679</id><created>2019-05-28</created><authors><author><keyname>Sheng</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xiaozhe</forenames></author></authors><title>Online Measurement-Based Estimation of Dynamic System State Matrix in
  Ambient Conditions</title><categories>eess.SP</categories><comments>11 pages, 13 figures</comments><journal-ref>IEEE Transaction on Smart Grid, Early Access, May 2019</journal-ref><doi>10.1109/TSG.2019.2917672</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a purely measurement-based method is proposed to estimate the
dynamic system state matrix by applying the regression theorem of the
multivariate Ornstein-Uhlenbeck process. The proposed method employs a
recursive algorithm to minimize the required computational effort, making it
applicable to the real-time environment. One main advantage of the proposed
method is model independence, i.e., it is independent of the network model and
the dynamic model of generators. Among various applications of the estimated
matrix, detecting and locating unexpected network topology change is
illustrated in details. Simulation studies have shown that the proposed
measurement-based method can provide an accurate and efficient estimation of
the dynamic system state matrix under the occurrence of unexpected topology
change. Besides, various implementation conditions are tested to show that the
proposed method can provide accurate approximation despite measurement noise,
missing PMUs, and the implementation of higher-order generator models with
control devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11689</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11689</id><created>2019-05-28</created><authors><author><keyname>Chen</keyname><forenames>Yu-Hua</forenames></author><author><keyname>Wang</keyname><forenames>Bryan</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Demonstration of PerformanceNet: A Convolutional Neural Network Model
  for Score-to-Audio Music Generation</title><categories>cs.SD eess.AS</categories><comments>3 pages, 2 figures, IJCAI Demo 2019 camera-ready version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper PerformacnceNet, a neural network model we proposed
recently to achieve score-to-audio music generation. The model learns to
convert a music piece from the symbolic domain to the audio domain, assigning
performance-level attributes such as changes in velocity automatically to the
music and then synthesizing the audio. The model is therefore not just a neural
audio synthesizer, but an AI performer that learns to interpret a musical score
in its own way. The code and sample outputs of the model can be found online at
https://github.com/bwang514/PerformanceNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11700</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11700</id><created>2019-05-28</created><authors><author><keyname>Sarfati</keyname><forenames>Marc</forenames></author><author><keyname>Hu</keyname><forenames>Anthony</forenames></author><author><keyname>Donier</keyname><forenames>Jonathan</forenames></author></authors><title>Ensemble-based cover song detection</title><categories>cs.SD eess.AS</categories><comments>7 pages, 4 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio-based cover song detection has received much attention in the MIR
community in the recent years. To date, the most popular formulation of the
problem has been to compare the audio signals of two tracks and to make a
binary decision based on this information only. However, leveraging additional
signals might be key if one wants to solve the problem at an industrial scale.
In this paper, we introduce an ensemble-based method that approaches the
problem from a many-to-many perspective. Instead of considering pairs of tracks
in isolation, we consider larger sets of potential versions for a given
composition, and create and exploit the graph of relationships between these
tracks. We show that this can result in a significant improvement in
performance, in particular when the number of existing versions of a given
composition is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11703</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11703</id><created>2019-05-28</created><authors><author><keyname>Scheiner</keyname><forenames>Nicolas</forenames></author><author><keyname>Appenrodt</keyname><forenames>Nils</forenames></author><author><keyname>Dickmann</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Sick</keyname><forenames>Bernhard</forenames></author></authors><title>Radar-based Road User Classification and Novelty Detection with
  Recurrent Neural Network Ensembles</title><categories>cs.LG cs.RO eess.SP stat.ML</categories><comments>8 pages, 9 figures, accepted paper for 2019 IEEE Intelligent Vehicles
  Symposium (IV), Paris, France, June 2019</comments><journal-ref>Published in Proceedings of IEEE Intelligent Vehicles Symposium
  (IV), Paris, France, June 2019</journal-ref><doi>10.1109/IVS.2019.8813773</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radar-based road user classification is an important yet still challenging
task towards autonomous driving applications. The resolution of conventional
automotive radar sensors results in a sparse data representation which is tough
to recover by subsequent signal processing. In this article, classifier
ensembles originating from a one-vs-one binarization paradigm are enriched by
one-vs-all correction classifiers. They are utilized to efficiently classify
individual traffic participants and also identify hidden object classes which
have not been presented to the classifiers during training. For each classifier
of the ensemble an individual feature set is determined from a total set of 98
features. Thereby, the overall classification performance can be improved when
compared to previous methods and, additionally, novel classes can be identified
much more accurately. Furthermore, the proposed structure allows to give new
insights in the importance of features for the recognition of individual
classes which is crucial for the development of new algorithms and sensor
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11760</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11760</id><created>2019-05-28</created><authors><author><keyname>Haunschmid</keyname><forenames>Verena</forenames></author><author><keyname>Chowdhury</keyname><forenames>Shreyan</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Two-level Explanations in Music Emotion Recognition</title><categories>cs.SD cs.LG eess.AS</categories><comments>ML4MD Workshop of the 36th International Conference on Machine
  Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current ML models for music emotion recognition, while generally working
quite well, do not give meaningful or intuitive explanations for their
predictions. In this work, we propose a 2-step procedure to arrive at
spectrogram-level explanations that connect certain aspects of the audio to
interpretable mid-level perceptual features, and these to the actual emotion
prediction. That makes it possible to focus on specific musical reasons for a
prediction (in terms of perceptual features), and to trace these back to
patterns in the audio that can be interpreted visually and acoustically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11773</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11773</id><created>2019-05-28</created><authors><author><keyname>Chettrit</keyname><forenames>David</forenames></author><author><keyname>Amitai</keyname><forenames>Orna Bregman</forenames></author><author><keyname>Tamir</keyname><forenames>Itamar</forenames></author><author><keyname>Bar</keyname><forenames>Amir</forenames></author><author><keyname>Elnekave</keyname><forenames>Eldad</forenames></author></authors><title>PHT-bot: Deep-Learning based system for automatic risk stratification of
  COPD patients based upon signs of Pulmonary Hypertension</title><categories>cs.CV eess.IV</categories><journal-ref>Proc. SPIE 10950, Medical Imaging 2019: Computer-Aided Diagnosis,
  109500O</journal-ref><doi>10.1117/12.2512469</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of morbidity
and mortality worldwide. Identifying those at highest risk of deterioration
would allow more effective distribution of preventative and surveillance
resources. Secondary pulmonary hypertension is a manifestation of advanced
COPD, which can be reliably diagnosed by the main Pulmonary Artery (PA) to
Ascending Aorta (Ao) ratio. In effect, a PA diameter to Ao diameter ratio of
greater than 1 has been demonstrated to be a reliable marker of increased
pulmonary arterial pressure. Although clinically valuable and readily
visualized, the manual assessment of the PA and the Ao diameters is time
consuming and under-reported. The present study describes a non invasive method
to measure the diameters of both the Ao and the PA from contrast-enhanced chest
Computed Tomography (CT). The solution applies deep learning techniques in
order to select the correct axial slice to measure, and to segment both
arteries. The system achieves test Pearson correlation coefficient scores of
93% for the Ao and 92% for the PA. To the best of our knowledge, it is the
first such fully automated solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11785</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11785</id><created>2019-05-28</created><updated>2019-05-31</updated><authors><author><keyname>Poorjam</keyname><forenames>Amir Hossein</forenames></author><author><keyname>Kavalekalam</keyname><forenames>Mathew Shaji</forenames></author><author><keyname>Shi</keyname><forenames>Liming</forenames></author><author><keyname>Raykov</keyname><forenames>Yordan P.</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper Rindom</forenames></author><author><keyname>Little</keyname><forenames>Max A.</forenames></author><author><keyname>Christensen</keyname><forenames>Mads Gr&#xe6;sb&#xf8;ll</forenames></author></authors><title>Automatic Quality Control and Enhancement for Voice-Based Remote
  Parkinson's Disease Detection</title><categories>eess.AS cs.SD</categories><comments>Preprint, 12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of voice-based Parkinson's disease (PD) detection systems
degrades when there is an acoustic mismatch between training and operating
conditions caused mainly by degradation in test signals. In this paper, we
address this mismatch by considering three types of degradation commonly
encountered in remote voice analysis, namely background noise, reverberation
and nonlinear distortion, and investigate how these degradations influence the
performance of a PD detection system. Given that the specific degradation is
known, we explore the effectiveness of a variety of enhancement algorithms in
compensating this mismatch and improving the PD detection accuracy. Then, we
propose two approaches to automatically control the quality of recordings by
identifying the presence and type of short-term and long-term degradations and
protocol violations in voice signals. Finally, we experiment with using the
proposed quality control methods to inform the choice of enhancement algorithm.
Experimental results using the voice recordings of the mPower mobile PD data
set under different degradation conditions show the effectiveness of the
quality control approaches in selecting an appropriate enhancement method and,
consequently, in improving the PD detection accuracy. This study is a step
towards the development of a remote PD detection system capable of operating in
unseen acoustic environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11796</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11796</id><created>2019-05-24</created><authors><author><keyname>Tagliasacchi</keyname><forenames>Marco</forenames></author><author><keyname>Gfeller</keyname><forenames>Beat</forenames></author><author><keyname>Quitry</keyname><forenames>F&#xe9;lix de Chaumont</forenames></author><author><keyname>Roblek</keyname><forenames>Dominik</forenames></author></authors><title>Self-supervised audio representation learning for mobile devices</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore self-supervised models that can be potentially deployed on mobile
devices to learn general purpose audio representations. Specifically, we
propose methods that exploit the temporal context in the spectrogram domain.
One method estimates the temporal gap between two short audio segments
extracted at random from the same audio clip. The other methods are inspired by
Word2Vec, a popular technique used to learn word embeddings, and aim at
reconstructing a temporal spectrogram slice from past and future slices or,
alternatively, at reconstructing the context of surrounding slices from the
current slice. We focus our evaluation on small encoder architectures, which
can be potentially run on mobile devices during both inference (re-using a
common learned representation across multiple downstream tasks) and training
(capturing the true data distribution without compromising users' privacy when
combined with federated learning). We evaluate the quality of the embeddings
produced by the self-supervised learning models, and show that they can be
re-used for a variety of downstream tasks, and for some tasks even approach the
performance of fully supervised models of similar size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11858</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11858</id><created>2019-05-28</created><authors><author><keyname>Widmaier</keyname><forenames>Mark</forenames></author><author><keyname>Arnold</keyname><forenames>Maximilian</forenames></author><author><keyname>D&#xf6;rner</keyname><forenames>Sebastian</forenames></author><author><keyname>Cammerer</keyname><forenames>Sebastian</forenames></author><author><keyname>Brink</keyname><forenames>Stephan ten</forenames></author></authors><title>Towards Practical Indoor Positioning Based on Massive MIMO Systems</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>Submitted to VTC2019 Fall</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We showcase the practicability of an indoor positioning system (IPS) solely
based on Neural Networks (NNs) and the channel state information (CSI) of a
(Massive) multiple-input multiple-output (MIMO) communication system, i.e.,
only build on the basis of data that is already existent in today's systems. As
such our IPS system promises both, a good accuracy without the need of any
additional protocol/signaling overhead for the user localization task. In
particular, we propose a tailored NN structure with an additional phase branch
as feature extractor and (compared to previous results) a significantly reduced
amount of trainable parameters, leading to a minimization of the amount of
required training data. We provide actual measurements for indoor scenarios
with up to 64 antennas covering a large area of 80m2. In the second part,
several robustness investigations for real-measurements are conducted, i.e.,
once trained, we analyze the recall accuracy over a time-period of several
days. Further, we analyze the impact of pedestrians walking in-between the
measurements and show that finetuning and pre-training of the NN helps to
mitigate effects of hardware drifts and alterations in the propagation
environment over time. This reduces the amount of required training samples at
equal precision and, thereby, decreases the effort of the costly training data
acquisition
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11883</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11883</id><created>2019-05-24</created><authors><author><keyname>Sundararajan</keyname><forenames>Aditya</forenames></author><author><keyname>Olowu</keyname><forenames>Temitayo O.</forenames></author><author><keyname>Wei</keyname><forenames>Longfei</forenames></author><author><keyname>Rahman</keyname><forenames>Shahinur</forenames></author><author><keyname>Sarwat</keyname><forenames>Arif I.</forenames></author></authors><title>A Case Study on the Effects of Partial Solar Eclipse on Distributed
  Photovoltaic Systems and Management Areas</title><categories>eess.SP</categories><comments>Accepted by IET Smart Grid journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photovoltaic (PV) systems depend on irradiance, ambient temperature and
module temperature. A solar eclipse causes significant changes in these
parameters, thereby impacting PV generation profile, performance, and power
quality of larger grid where they connect to. This paper presents a case study
to evaluate the impacts of the solar eclipse of August 21, 2017 on two
real-world grid-tied PV systems (1.4MW and 355kW) in Miami and Daytona,
Florida, the feeders they are connected to, and the management areas they
belong to. Four types of analyses are conducted to obtain a comprehensive
picture of the impacts using 1-minute PV generation data, hourly weather data,
real feeder parameters, and daily reliability data. These analyses include:
individual PV system performance measurement using power performance index;
power quality analysis at the point of interconnection; a study on the
operation of voltage regulating devices on the feeders during eclipse peak
using an IEEE 8500 test case distribution feeder; and reliability study
involving a multilayer perceptron framework for forecasting system reliability
of the management areas. Results from this study provide a unique insight into
how solar eclipses impact the behavior of PV systems and the grid, which would
be of concern to electric utilities in future high penetration scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11928</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11928</id><created>2019-05-28</created><updated>2019-05-29</updated><authors><author><keyname>Hawley</keyname><forenames>Scott H.</forenames></author><author><keyname>Colburn</keyname><forenames>Benjamin</forenames></author><author><keyname>Mimilakis</keyname><forenames>Stylianos I.</forenames></author></authors><title>SignalTrain: Profiling Audio Compressors with Deep Neural Networks</title><categories>eess.AS cs.LG cs.SD</categories><comments>9 pages, 10 figures. v2: typos &amp; references fixed</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present a data-driven approach for predicting the behavior of
(i.e., profiling) a given non-linear audio signal processing effect (henceforth
&quot;audio effect&quot;). Our objective is to learn a mapping function that maps the
unprocessed audio to the processed by the audio effect to be profiled, using
time-domain samples. To that aim, we employ a deep auto-encoder model that is
conditioned on both time-domain samples and the control parameters of the
target audio effect. As a test-case study, we focus on the offline profiling of
two dynamic range compression audio effects, one software-based and the other
analog. Compressors were chosen because they are a widely used and important
set of effects and because their parameterized nonlinear time-dependent nature
makes them a challenging problem for a system aiming to profile &quot;general&quot; audio
effects. Results from our experimental procedure show that the primary
functional and auditory characteristics of the compressors can be captured,
however there is still sufficient audible noise to merit further investigation
before such methods are applied to real-world audio processing workflows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11932</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11932</id><created>2019-05-28</created><authors><author><keyname>Siljak</keyname><forenames>Harun</forenames></author><author><keyname>Psara</keyname><forenames>Kyriaki</forenames></author><author><keyname>Philippou</keyname><forenames>Anna</forenames></author></authors><title>Distributed Antenna Selection for Massive MIMO using Reversing Petri
  Nets</title><categories>eess.SP cs.IT math.IT</categories><comments>Copyright 2019 IEEE, Wireless Communications Letters</comments><doi>10.1109/LWC.2019.2920128</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed antenna selection for Distributed Massive MIMO (Multiple Input
Multiple Output) communication systems reduces computational complexity
compared to centralised approaches, and provides high fault tolerance while
retaining diversity and spatial multiplexity. We propose a novel distributed
algorithm for antenna selection and show its advantage over existing
centralised and distributed solutions. The proposed algorithm is shown to
perform well with imperfect channel state information, and to execute a small
number of simple computational operations per node, converging fast to a steady
state. We base it on Reversing Petri Nets, a variant of Petri nets inspired by
reversible computation, capable of both forward and backward execution while
obeying conservation laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11933</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11933</id><created>2019-05-14</created><authors><author><keyname>Lau</keyname><forenames>Billy Pik Lik</forenames></author><author><keyname>Marakkalage</keyname><forenames>Sumudu Hasala</forenames></author><author><keyname>Zhou</keyname><forenames>Yuren</forenames></author><author><keyname>Hassan</keyname><forenames>Naveed Ul</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Zhang</keyname><forenames>Meng</forenames></author><author><keyname>Tan</keyname><forenames>U-Xuan</forenames></author></authors><title>A Survey of Data Fusion in Smart City Applications</title><categories>eess.SP</categories><comments>Accepted and To be published in Elsevier Information Fusion</comments><doi>10.1016/j.inffus.2019.05.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advancement of various research sectors such as Internet of Things (IoT),
Machine Learning, Data Mining, Big Data, and Communication Technology has shed
some light in transforming an urban city integrating the aforementioned
techniques to a commonly known term - Smart City. With the emergence of smart
city, plethora of data sources have been made available for wide variety of
applications. The common technique for handling multiple data sources is data
fusion, where it improves data output quality or extracts knowledge from the
raw data. In order to cater evergrowing highly complicated applications,
studies in smart city have to utilize data from various sources and evaluate
their performance based on multiple aspects. To this end, we introduce a
multi-perspectives classification of the data fusion to evaluate the smart city
applications. Moreover, we applied the proposed multi-perspectives
classification to evaluate selected applications in each domain of the smart
city. We conclude the paper by discussing potential future direction and
challenges of data fusion integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11934</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11934</id><created>2019-05-24</created><authors><author><keyname>Cherif</keyname><forenames>Nesrine</forenames></author><author><keyname>Alzenad</keyname><forenames>Mohamed</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author><author><keyname>Yongacoglu</keyname><forenames>Abbas</forenames></author></authors><title>Downlink Coverage and Rate Analysis of an Aerial User in Integrated
  Aerial and Terrestrial Networks</title><categories>eess.SP cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, the downlink coverage probability and average achievable rate
of an aerial user in a vertical HetNet (VHetNet) comprising aerial base
stations (aerial-BSs) and terrestrial-BSs are analyzed. The locations of
terrestrial-BSs are modeled as an infinite 2-D Poisson point process (PPP)
while the locations of aerial-BSs are modeled as a finite 3-D Binomial point
process (BPP) deployed at a particular height. We adopt cellular-to-air (C2A)
channel model that incorporates LoS and NLoS transmissions between the
terrestrial-BSs and the typical aerial user while we assume LoS transmissions
for the air-toair (A2A) channels separating the aerial user and aerial-BSs. For
tractability reasons, we simplify the expression of the LoS probability
provided by the International Telecommunications Union using curve fitting. We
assume that the aerial user is associated with the BS (either an aerial-BS or
terrestrial-BS) that provides the strongest average received power. Using tools
from stochastic geometry, we derive analytical expressions of the coverage
probability and achievable rate in terms of the Laplace transform of
interference power. To simplify the derived analytical expressions, we assume
that the C2A links are in LoS conditions. Although this approximation gives
pessimistic results compared to the exact performance, the analytical
approximations are easier to evaluate and quantify well the performance at high
heights of the aerial user. Our findings reveal that using directive
beamforming for the aerial-BSs improves the downlink performance substantially
since it alleviates the strong interference signals received from the
aerial-BSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11935</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11935</id><created>2019-05-21</created><authors><author><keyname>Leung</keyname><forenames>Vincent C. H.</forenames></author><author><keyname>Huang</keyname><forenames>Jun-Jie</forenames></author><author><keyname>Dragotti</keyname><forenames>Pier Luigi</forenames></author></authors><title>Reconstruction of FRI Signals using Deep Neural Networks</title><categories>eess.SP</categories><comments>2 pages, 3 figures, Signal Processing with Adaptive Sparse Structured
  Representations (SPARS 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite Rate of Innovation (FRI) theory considers sampling and reconstruction
of classes of non-bandlimited signals, such as streams of Diracs. Widely used
FRI reconstruction methods including Prony's method and matrix pencil method
involve Singular Value Decomposition (SVD). When samples are corrupted with
noise, they achieve an optimal performance given by the Cram\'{e}r-Rao bound
yet break down at a certain Signal-to-Noise Ratio (SNR) due to the so-called
subspace swap problem. In this paper, we investigate a deep neural network
approach for FRI signal reconstruction that directly learns a transformation
from signal samples to FRI parameters. Simulations show significant improvement
on the breakdown SNR over existing FRI methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11945</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11945</id><created>2019-05-28</created><authors><author><keyname>Cheeseman</keyname><forenames>Alison K.</forenames></author><author><keyname>Tizhoosh</keyname><forenames>Hamid</forenames></author><author><keyname>Vrscay</keyname><forenames>Edward R.</forenames></author></authors><title>A Compact Representation of Histopathology Images using Digital Stain
  Separation &amp; Frequency-Based Encoded Local Projections</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in the International Conference on Image
  Analysis and Recognition (ICIAR 2019)</comments><doi>10.1007/978-3-030-27272-2_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, histopathology images have been increasingly used as a
diagnostic tool in the medical field. The process of accurately diagnosing a
biopsy sample requires significant expertise in the field, and as such can be
time-consuming and is prone to uncertainty and error. With the advent of
digital pathology, using image recognition systems to highlight problem areas
or locate similar images can aid pathologists in making quick and accurate
diagnoses. In this paper, we specifically consider the encoded local
projections (ELP) algorithm, which has previously shown some success as a tool
for classification and recognition of histopathology images. We build on the
success of the ELP algorithm as a means for image classification and
recognition by proposing a modified algorithm which captures the local
frequency information of the image. The proposed algorithm estimates local
frequencies by quantifying the changes in multiple projections in local windows
of greyscale images. By doing so we remove the need to store the full
projections, thus significantly reducing the histogram size, and decreasing
computation time for image retrieval and classification tasks. Furthermore, we
investigate the effectiveness of applying our method to histopathology images
which have been digitally separated into their hematoxylin and eosin stain
components. The proposed algorithm is tested on the publicly available invasive
ductal carcinoma (IDC) data set. The histograms are used to train an SVM to
classify the data. The experiments showed that the proposed method outperforms
the original ELP algorithm in image retrieval tasks. On classification tasks,
the results are found to be comparable to state-of-the-art deep learning
methods and better than many handcrafted features from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11959</identifier>
 <datestamp>2019-05-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11959</id><created>2019-05-28</created><authors><author><keyname>Foleiss</keyname><forenames>Juliano H.</forenames></author><author><keyname>Tavares</keyname><forenames>Tiago F.</forenames></author></authors><title>Texture Selection for Automatic Music Genre Classification</title><categories>cs.SD cs.IR cs.LG eess.AS</categories><comments>Submitted to Pattern Recognition (may, 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music Genre Classification is the problem of associating genre-related labels
to digitized music tracks. It has applications in the organization of
commercial and personal music collections. Often, music tracks are described as
a set of timbre-inspired sound textures. In shallow-learning systems, the total
number of sound textures per track is usually too high, and texture
downsampling is necessary to make training tractable. Although previous work
has solved this by linear downsampling, no extensive work has been done to
evaluate how texture selection benefits genre classification in the context of
the bag of frames track descriptions. In this paper, we evaluate the impact of
frame selection on automatic music genre classification in a bag of frames
scenario. We also present a novel texture selector based on K-Means aimed to
identify diverse sound textures within each track. We evaluated texture
selection in diverse datasets, four different feature sets, as well as its
relationship to a univariate feature selection strategy. The results show that
frame selection leads to significant improvement over the single vector
baseline on datasets consisting of full-length tracks, regardless of the
feature set. Results also indicate that the K-Means texture selector achieves
significant improvements over the baseline, using fewer textures per track than
the commonly used linear downsampling. The results also suggest that texture
selection is complementary to the feature selection strategy evaluated. Our
qualitative analysis indicates that texture variety within classes benefits
model generalization. Our analysis shows that selecting specific audio excerpts
can improve classification performance, and it can be done automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.11987</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.11987</id><created>2019-05-28</created><updated>2019-06-03</updated><authors><author><keyname>Scheiner</keyname><forenames>Nicolas</forenames></author><author><keyname>Haag</keyname><forenames>Stefan</forenames></author><author><keyname>Appenrodt</keyname><forenames>Nils</forenames></author><author><keyname>Duraisamy</keyname><forenames>Bharanidhar</forenames></author><author><keyname>Dickmann</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Fritzsche</keyname><forenames>Martin</forenames></author><author><keyname>Sick</keyname><forenames>Bernhard</forenames></author></authors><title>Automated Ground Truth Estimation For Automotive Radar Tracking
  Applications With Portable GNSS And IMU Devices</title><categories>eess.SP cs.LG cs.RO</categories><comments>10 pages, 9 figures, accepted paper for 2019 20th International Radar
  Symposium (IRS), Ulm, Germany, June 2019. arXiv admin note: text overlap with
  arXiv:1905.11219</comments><journal-ref>Published in Proceedings of 20th International Radar Symposium
  (IRS), Ulm, Germany, June 2019</journal-ref><doi>10.23919/IRS.2019.8768169</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Baseline generation for tracking applications is a difficult task when
working with real world radar data. Data sparsity usually only allows an
indirect way of estimating the original tracks as most objects' centers are not
represented in the data. This article proposes an automated way of acquiring
reference trajectories by using a highly accurate hand-held global navigation
satellite system (GNSS). An embedded inertial measurement unit (IMU) is used
for estimating orientation and motion behavior. This article contains two major
contributions. A method for associating radar data to vulnerable road user
(VRU) tracks is described. It is evaluated how accurate the system performs
under different GNSS reception conditions and how carrying a reference system
alters radar measurements. Second, the system is used to track pedestrians and
cyclists over many measurement cycles in order to generate object centered
occupancy grid maps. The reference system allows to much more precisely
generate real world radar data distributions of VRUs than compared to
conventional methods. Hereby, an important step towards radar-based VRU
tracking is accomplished.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12002</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12002</id><created>2019-05-28</created><updated>2019-12-07</updated><authors><author><keyname>Ibrahim</keyname><forenames>Hazem</forenames></author><author><keyname>Tabassum</keyname><forenames>Hina</forenames></author><author><keyname>Nguyen</keyname><forenames>Uyen T.</forenames></author></authors><title>The Meta Distributions of the SIR/SNR and Data Rate in Coexisting
  Sub-6GHz and Millimeter-wave Cellular Networks</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meta distribution is a fine-grained unified performance metric that enables
us to evaluate the {reliability and latency} of next generation wireless
networks, in addition to the conventional coverage probability. In this paper,
using stochastic geometry tools, we develop a systematic framework to
characterize the meta distributions of the downlink
signal-to-interference-ratio (SIR)/signal-to-noise-ratio (SNR) and data rate of
a typical device in a cellular network with coexisting sub-6GHz and millimeter
wave (mm-wave) spectrums. Macro base-stations (MBSs) transmit on sub-6GHz
channels (which we term &quot;microwave&quot; channels), whereas small base-stations
(SBSs) communicate with devices on mm-wave channels. The SBSs are connected to
MBSs via a microwave ($\mu$wave) wireless backhaul. The $\mu$wave channels are
interference limited and mm-wave channels are noise limited; therefore, we have
the meta-distribution of SIR and SNR in $\mu$wave and mm-wave channels,
respectively. To model the line-of-sight (LOS) nature of mm-wave channels, we
use Nakagami-m fading model. To derive the meta-distribution of SIR/SNR, we
characterize the conditional success probability (CSP) (or equivalently
reliability) and its $b^{\mathrm{th}}$ moment for a typical device (a) when it
associates to a $\mu$wave MBS for {\em direct} transmission, and (b) when it
associates to a mm-wave SBS for {\em dual-hop} transmission (backhaul and
access transmission). Performance metrics such as the mean and variance of the
local delay (network jitter), mean of the CSP (coverage probability), and
variance of the CSP are derived. Numerical results validate the analytical
results. Insights are extracted related to the reliability, coverage
probability, and latency of the considered network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12005</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12005</id><created>2019-05-28</created><authors><author><keyname>de Matos</keyname><forenames>Jonathan</forenames></author><author><keyname>Britto</keyname><forenames>Alceu de S.</forenames><suffix>Jr.</suffix></author><author><keyname>de Oliveira</keyname><forenames>Luiz E. S.</forenames></author><author><keyname>Koerich</keyname><forenames>Alessandro L.</forenames></author></authors><title>Texture CNN for Histopathological Image Classification</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biopsies are the gold standard for breast cancer diagnosis. This task can be
improved by the use of Computer Aided Diagnosis (CAD) systems, reducing the
time of diagnosis and reducing the inter and intra-observer variability. The
advances in computing have brought this type of system closer to reality.
However, datasets of Histopathological Images (HI) from biopsies are quite
small and unbalanced what makes difficult to use modern machine learning
techniques such as deep learning. In this paper we propose a compact
architecture based on texture filters that has fewer parameters than
traditional deep models but is able to capture the difference between malignant
and benign tissues with relative accuracy. The experimental results on the
BreakHis dataset have show that the proposed texture CNN achieves almost 90% of
accuracy for classifying benign and malignant tissues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12120</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12120</id><created>2019-05-28</created><updated>2019-07-20</updated><authors><author><keyname>Hatamizadeh</keyname><forenames>Ali</forenames></author><author><keyname>Hosseini</keyname><forenames>Hamid</forenames></author><author><keyname>Liu</keyname><forenames>Zhengyuan</forenames></author><author><keyname>Schwartz</keyname><forenames>Steven D.</forenames></author><author><keyname>Terzopoulos</keyname><forenames>Demetri</forenames></author></authors><title>Deep Dilated Convolutional Nets for the Automatic Segmentation of
  Retinal Vessels</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reliable segmentation of retinal vasculature can provide the means to
diagnose and monitor the progression of a variety of diseases affecting the
blood vessel network, including diabetes and hypertension. We leverage the
power of convolutional neural networks to devise a reliable and fully automated
method that can accurately detect, segment, and analyze retinal vessels. In
particular, we propose a novel, fully convolutional deep neural network with an
encoder-decoder architecture that employs dilated spatial pyramid pooling with
multiple dilation rates to recover the lost content in the encoder and add
multiscale contextual information to the decoder. We also propose a simple yet
effective way of quantifying and tracking the widths of retinal vessels through
direct use of the segmentation predictions. Unlike previous deep-learning-based
approaches to retinal vessel segmentation that mainly rely on patch-wise
analysis, our proposed method leverages a whole-image approach during training
and inference, resulting in more efficient training and faster inference
through the access of global content in the image. We have tested our method on
two publicly available datasets, and our state-of-the-art results on both the
DRIVE and CHASE-DB1 datasets attest to the effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12156</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12156</id><created>2019-05-28</created><authors><author><keyname>Xu</keyname><forenames>Xiangyu</forenames></author><author><keyname>Ma</keyname><forenames>Yongrui</forenames></author><author><keyname>Sun</keyname><forenames>Wenxiu</forenames></author></authors><title>Towards Real Scene Super-Resolution with Raw Images</title><categories>eess.IV cs.CV</categories><comments>Accepted in CVPR 2019, project page:
  https://sites.google.com/view/xiangyuxu/rawsr_cvpr19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most existing super-resolution methods do not perform well in real scenarios
due to lack of realistic training data and information loss of the model input.
To solve the first problem, we propose a new pipeline to generate realistic
training data by simulating the imaging process of digital cameras. And to
remedy the information loss of the input, we develop a dual convolutional
neural network to exploit the originally captured radiance information in raw
images. In addition, we propose to learn a spatially-variant color
transformation which helps more effective color corrections. Extensive
experiments demonstrate that super-resolution with raw data helps recover fine
details and clear structures, and more importantly, the proposed network and
data generation pipeline achieve superior results for single image
super-resolution in real scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12164</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12164</id><created>2019-05-22</created><authors><author><keyname>Zhang</keyname><forenames>Tianye</forenames></author><author><keyname>Feng</keyname><forenames>Haozhe</forenames></author><author><keyname>Chen</keyname><forenames>Zexian</forenames></author><author><keyname>Wang</keyname><forenames>Can</forenames></author><author><keyname>Huang</keyname><forenames>Yanhao</forenames></author><author><keyname>Tang</keyname><forenames>Yong</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>An Interactive Insight Identification and Annotation Framework for Power
  Grid Pixel Maps using DenseU-Hierarchical VAE</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Insights in power grid pixel maps (PGPMs) refer to important facility
operating states and unexpected changes in the power grid. Identifying insights
helps analysts understand the collaboration of various parts of the grid so
that preventive and correct operations can be taken to avoid potential
accidents. Existing solutions for identifying insights in PGPMs are performed
manually, which may be laborious and expertise-dependent. In this paper, we
propose an interactive insight identification and annotation framework by
leveraging an enhanced variational autoencoder (VAE). In particular, a new
architecture, DenseU-Hierarchical VAE (DUHiV), is designed to learn
representations from large-sized PGPMs, which achieves a significantly tighter
evidence lower bound (ELBO) than existing Hierarchical VAEs with a Multilayer
Perceptron architecture. Our approach supports modulating the derived
representations in an interactive visual interface, discover potential insights
and create multi-label annotations. Evaluations using real-world PGPMs datasets
show that our framework outperforms the baseline models in identifying and
annotating insights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12176</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12176</id><created>2019-05-28</created><updated>2020-01-31</updated><authors><author><keyname>Su</keyname><forenames>Kun</forenames></author><author><keyname>Shlizerman</keyname><forenames>Eli</forenames></author></authors><title>Clustering and Recognition of Spatiotemporal Features through
  Interpretable Embedding of Sequence to Sequence Recurrent Neural Networks</title><categories>cs.LG eess.SP q-bio.NC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Encoder-decoder recurrent neural network models (RNN Seq2Seq) have achieved
great success in ubiquitous areas of computation and applications. It was shown
to be successful in modeling data with both temporal and spatial dependencies
for translation or prediction tasks. In this study, we propose an embedding
approach to visualize and interpret the representation of data by these models.
Furthermore, we show that the embedding is an effective method for unsupervised
learning and can be utilized to estimate the optimality of model training. In
particular, we demonstrate that embedding space projections of the decoder
states of RNN Seq2Seq model trained on sequences prediction are organized in
clusters capturing similarities and differences in the dynamics of these
sequences. Such performance corresponds to an unsupervised clustering of any
spatio-temporal features and can be employed for time-dependent problems such
as temporal segmentation, clustering of dynamic activity, self-supervised
classification, action recognition, failure prediction, etc. We test and
demonstrate the application of the embedding methodology to time-sequences of
3D human body poses. We show that the methodology provides a high-quality
unsupervised categorization of movements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12230</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12230</id><created>2019-05-29</created><updated>2019-06-26</updated><authors><author><keyname>Kanda</keyname><forenames>Naoyuki</forenames></author><author><keyname>Boeddeker</keyname><forenames>Christoph</forenames></author><author><keyname>Heitkaemper</keyname><forenames>Jens</forenames></author><author><keyname>Fujita</keyname><forenames>Yusuke</forenames></author><author><keyname>Horiguchi</keyname><forenames>Shota</forenames></author><author><keyname>Nagamatsu</keyname><forenames>Kenji</forenames></author><author><keyname>Haeb-Umbach</keyname><forenames>Reinhold</forenames></author></authors><title>Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn
  University Joint Investigation for Dinner Party ASR</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present Hitachi and Paderborn University's joint effort for
automatic speech recognition (ASR) in a dinner party scenario. The main
challenges of ASR systems for dinner party recordings obtained by multiple
microphone arrays are (1) heavy speech overlaps, (2) severe noise and
reverberation, (3) very natural conversational content, and possibly (4)
insufficient training data. As an example of a dinner party scenario, we have
chosen the data presented during the CHiME-5 speech recognition challenge,
where the baseline ASR had a 73.3% word error rate (WER), and even the best
performing system at the CHiME-5 challenge had a 46.1% WER. We extensively
investigated a combination of the guided source separation-based speech
enhancement technique and an already proposed strong ASR backend and found that
a tight combination of these techniques provided substantial accuracy
improvements. Our final system achieved WERs of 39.94% and 41.64% for the
development and evaluation data, respectively, both of which are the best
published results for the dataset. We also investigated with additional
training data on the official small data in the CHiME-5 corpus to assess the
intrinsic difficulty of this ASR task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12256</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12256</id><created>2019-05-29</created><updated>2020-02-07</updated><authors><author><keyname>Lee</keyname><forenames>Kyungeun</forenames></author><author><keyname>Rhee</keyname><forenames>Wonjong</forenames></author></authors><title>DDP-GCN: Multi-Graph Convolutional Network for Spatiotemporal Traffic
  Forecasting</title><categories>cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic speed forecasting is one of the core problems in Intelligent
Transportation Systems. For a more accurate prediction, recent studies started
using not only the temporal speed patterns but also the spatial information on
the road network through the graph convolutional networks. Even though the road
network is highly complex due to its non-Euclidean and directional
characteristics, previous approaches mainly focus on modeling the spatial
dependencies only with the distance. In this paper, we identify two essential
spatial dependencies in traffic forecasting in addition to distance, direction
and positional relationship, for designing basic graph elements as the smallest
building blocks. Using the building blocks, we suggest DDP-GCN (Distance,
Direction, and Positional relationship Graph Convolutional Network) to
incorporate the three spatial relationships into prediction network for traffic
forecasting. We evaluate the proposed model with two large-scale real-world
datasets, and find 7.40% average improvement for 1-hour forecasting in highly
complex urban networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12281</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12281</id><created>2019-05-29</created><authors><author><keyname>Valsesia</keyname><forenames>Diego</forenames></author><author><keyname>Fracastoro</keyname><forenames>Giulia</forenames></author><author><keyname>Magli</keyname><forenames>Enrico</forenames></author></authors><title>Image Denoising with Graph-Convolutional Neural Networks</title><categories>eess.IV cs.CV</categories><comments>IEEE International Conference on Image Processing (ICIP) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering an image from a noisy observation is a key problem in signal
processing. Recently, it has been shown that data-driven approaches employing
convolutional neural networks can outperform classical model-based techniques,
because they can capture more powerful and discriminative features. However,
since these methods are based on convolutional operations, they are only
capable of exploiting local similarities without taking into account non-local
self-similarities. In this paper we propose a convolutional neural network that
employs graph-convolutional layers in order to exploit both local and non-local
similarities. The graph-convolutional layers dynamically construct
neighborhoods in the feature space to detect latent correlations in the feature
maps produced by the hidden layers. The experimental results show that the
proposed architecture outperforms classical convolutional neural networks for
the denoising task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12324</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12324</id><created>2019-05-29</created><authors><author><keyname>Mu&#xf1;oz-Montoro</keyname><forenames>A. J.</forenames></author><author><keyname>Vera-Candeas</keyname><forenames>P.</forenames></author><author><keyname>Suarez-Dou</keyname><forenames>D.</forenames></author><author><keyname>Cortina</keyname><forenames>R.</forenames></author></authors><title>A new definition of the distortion matrix for an audio-to-score
  alignment system</title><categories>cs.SD eess.AS</categories><comments>CMMSE 2019</comments><journal-ref>Computational and Mathematical Methods, Wiley Online Library. 2019</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper we present a new definition of the distortion matrix for a
score following framework based on DTW. The proposal consists of arranging the
score information in a sequence of note combinations and learning a spectral
pattern for each combination using instrument models. Then, the distortion
matrix is computed using these spectral patterns and a novel decomposition of
the input signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12347</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12347</id><created>2019-05-29</created><updated>2019-06-10</updated><authors><author><keyname>Amiraz</keyname><forenames>Chen</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author><author><keyname>Nadler</keyname><forenames>Boaz</forenames></author></authors><title>Tight Recovery Guarantees for Orthogonal Matching Pursuit Under Gaussian
  Noise</title><categories>math.ST eess.SP math.OC stat.TH</categories><comments>23 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal Matching pursuit (OMP) is a popular algorithm to estimate an
unknown sparse vector from multiple linear measurements of it. Assuming exact
sparsity and that the measurements are corrupted by additive Gaussian noise,
the success of OMP is often formulated as exactly recovering the support of the
sparse vector. Several authors derived a sufficient condition for exact support
recovery by OMP with high probability depending on the signal-to-noise ratio,
defined as the magnitude of the smallest non-zero coefficient of the vector
divided by the noise level. We make two contributions. First, we derive a
slightly sharper sufficient condition for two variants of OMP, in which either
the sparsity level or the noise level is known. Next, we show that this sharper
sufficient condition is tight, in the following sense: for a wide range of
problem parameters, there exist a dictionary of linear measurements and a
sparse vector with a signal-to-noise ratio slightly below that of the
sufficient condition, for which with high probability OMP fails to recover its
support. Finally, we present simulations which illustrate that our condition is
tight for a much broader range of dictionaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12366</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12366</id><created>2019-04-18</created><authors><author><keyname>Sharma</keyname><forenames>Utkarsh</forenames></author><author><keyname>Umematsu</keyname><forenames>Terumi</forenames></author><author><keyname>Tsujikawa</keyname><forenames>Masanori</forenames></author><author><keyname>Onishi</keyname><forenames>Yoshifumi</forenames></author></authors><title>Adaptive Heart Rate Estimation from Face Videos</title><categories>eess.SP</categories><comments>2 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel heart rate (HR) estimation method from facial videos that
dynamically adapts the HR pulse extraction algorithm to separately deal with
noise from 'rigid' head motion and 'non-rigid' facial expression. We first
identify the noise type, based on which, we apply specific noise removal steps.
Experiments performed on popular database show that the proposed method reduces
HR estimation error by over 32%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12385</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12385</id><created>2019-05-29</created><updated>2019-05-30</updated><authors><author><keyname>Aubin</keyname><forenames>Benjamin</forenames></author><author><keyname>Loureiro</keyname><forenames>Bruno</forenames></author><author><keyname>Maillard</keyname><forenames>Antoine</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>The spiked matrix model with generative priors</title><categories>math.ST cs.LG eess.SP math.PR stat.ML stat.TH</categories><comments>12 + 56, 8 figures, v2 lighter jpeg figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a low-dimensional parametrization of signals is a generic and powerful
way to enhance performance in signal processing and statistical inference. A
very popular and widely explored type of dimensionality reduction is sparsity;
another type is generative modelling of signal distributions. Generative models
based on neural networks, such as GANs or variational auto-encoders, are
particularly performant and are gaining on applicability. In this paper we
study spiked matrix models, where a low-rank matrix is observed through a noisy
channel. This problem with sparse structure of the spikes has attracted broad
attention in the past literature. Here, we replace the sparsity assumption by
generative modelling, and investigate the consequences on statistical and
algorithmic properties. We analyze the Bayes-optimal performance under specific
generative models for the spike. In contrast with the sparsity assumption, we
do not observe regions of parameters where statistical performance is superior
to the best known algorithmic performance. We show that in the analyzed cases
the approximate message passing algorithm is able to reach optimal performance.
We also design enhanced spectral algorithms and analyze their performance and
thresholds using random matrix theory, showing their superiority to the
classical principal component analysis. We complement our theoretical results
by illustrating the performance of the spectral algorithms when the spikes come
from real datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12394</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12394</id><created>2019-05-02</created><authors><author><keyname>Mo</keyname><forenames>Xiaopeng</forenames></author><author><keyname>Huang</keyname><forenames>Yuwei</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author></authors><title>Radio-Map-Based Robust Positioning Optimization for UAV-Enabled Wireless
  Power Transfer</title><categories>eess.SP cs.IT math.IT</categories><comments>submiited for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter studies an unmanned aerial vehicle-enabled wireless power
transfer system within a radio-map-based robust positioning design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12396</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12396</id><created>2019-05-29</created><authors><author><keyname>Zhao</keyname><forenames>Hui</forenames></author><author><keyname>Yang</keyname><forenames>Liang</forenames></author><author><keyname>Pan</keyname><forenames>Gaofeng</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Secrecy Outage Analysis Over Fluctuating Two-Ray Fading Channels</title><categories>eess.SP</categories><comments>2 Figures, 2 Pages</comments><doi>10.1049/el.2019.1104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we analyze the secrecy outage probability (SOP) over
fluctuating two-ray fading channels but with a different definition from the
one adopted in [5]. Following the new defined SOP, we derive an analytical
closed-form expression for our proposed SOP, as well as an asymptotic formula
valid in the high signal-to-noise ratio region of the source to destination
link. In the numerical results section, we perform some Monte-Carlo simulations
to validate the accuracy of our derived expressions, and also present the
probability gap between our proposed SOP and the SOP in [5].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12424</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12424</id><created>2019-05-27</created><authors><author><keyname>Najafi</keyname><forenames>Marzieh</forenames></author><author><keyname>Ajam</keyname><forenames>Hedieh</forenames></author><author><keyname>Jamali</keyname><forenames>Vahid</forenames></author><author><keyname>Diamantoulakis</keyname><forenames>Panagiotis D.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Statistical Modeling of the FSO Fronthaul Channel for UAV-based Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper is submitted to the IEEE Transactions on Communications.
  arXiv admin note: text overlap with arXiv:1711.00120</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the statistics of free space optics (FSO)
communication channel between a hovering unmanned aerial vehicle (UAV) and a
central unit (CU). Two unique characteristics make UAV-based FSO systems
significantly different from conventional FSO systems with immobile
transceivers. First, for UAV-based FSO systems, the incident laser beam is not
always orthogonal to the photo detector (PD) plane. Second, both position and
orientation of the UAV fluctuate over time due to dynamic wind load, inherent
random air fluctuations in the atmosphere around the UAV, and internal
vibrations of the UAV. On the contrary, for conventional FSO systems, the laser
beam is always perpendicular to the PD plane and the relative movement of the
transceivers is limited. In this paper, we develop a novel channel model for
UAV-based FSO systems by quantifying the corresponding geometric and
misalignment losses (GML), while taking into account the non-orthogonality of
the laser beam and the random fluctuations of the position and orientation of
the UAV. In particular, for diverse weather conditions, we propose different
fluctuation models for the position and orientation of the UAV and derive
corresponding statistical models for the GML. We further analyze the
performance of a UAV-based FSO link in terms of outage probability and ergodic
rate and simplify the resulting analytical expressions for the high
signal-to-noise ratio (SNR) regime. Finally, simulations validate the accuracy
of the presented analysis and provide important insights for system design. For
instance, we show that for a given variance of fluctuations, the beam width can
be optimized to minimize the outage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12437</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12437</id><created>2019-05-28</created><authors><author><keyname>Zhou</keyname><forenames>Yu</forenames></author></authors><title>High-precision terahertz frequency modulated continuous wave imaging
  method using continuous wavelet transform</title><categories>eess.SP eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the extensive application of terahertz imaging technologies in
the field of aerospace, we exploit a terahertz frequency modulated continuous
wave imaging method with continuous wavelet transform algorithm to detect a
multilayer heat shield made of special materials. This method uses the
frequency modulation continuous wave system to catch the reflected terahertz
signal and then processing the image data by the continuous wavelet transform
with different basis functions. By calculating the sizes of the defects area in
the final images and then comparing the results with real samples, a novel and
practical high-precision terahertz imaging method are demonstrated. Our method
can be an effective tool for the terahertz nondestructive testing of
composites, drugs and some cultural heritages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12467</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12467</id><created>2019-05-14</created><updated>2019-06-25</updated><authors><author><keyname>Ragni</keyname><forenames>A.</forenames></author><author><keyname>Sciortino</keyname><forenames>G.</forenames></author><author><keyname>Sampietro</keyname><forenames>M.</forenames></author><author><keyname>Ferrari</keyname><forenames>G.</forenames></author><author><keyname>Crisafi</keyname><forenames>F.</forenames></author><author><keyname>Kumar</keyname><forenames>V.</forenames></author><author><keyname>Cerullo</keyname><forenames>G.</forenames></author><author><keyname>Polli</keyname><forenames>D.</forenames></author></authors><title>Multi-channel lock-in based differential front-end for broadband Raman
  spectroscopy</title><categories>eess.SP</categories><comments>Post review version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Broadband Stimulated Raman Spectroscopy, the intrinsic limit given by the
laser shot noise is seldom reached due to the electronic noise of the front-end
amplifier and the intensity fluctuations of the laser source. In this paper we
present a low-noise multi-channel acquisition system, with an
integration-oriented design, able to compensate the common-mode fluctuations of
the laser output power with the pseudo-differential structure and reach a
sensitivity better than 10 ppm thanks to the lock-in technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12513</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12513</id><created>2019-05-29</created><authors><author><keyname>Alam</keyname><forenames>Md Sahabul</forenames></author><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author><author><keyname>Agba</keyname><forenames>Basile L.</forenames></author></authors><title>A Novel Relay Selection Strategy of Cooperative Network Impaired by
  Bursty Impulsive Noise</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Best relay selection (BRS) is crucial in enhancing the performance of
cooperative networks. In contrast to most previous works, where the guidelines
for BRS are limited to Gaussian noise, in this article, we propose a novel
relay selection protocol for a decode-and-forward cooperative network taking
into account the bursty impulsive noise (IN). The proposed protocol chooses the
N'th best relay considering both the channel gains and the states of the IN of
the source-relay and relay-destination links. For this scheme, to obtain the
state of IN, we propose a state detection algorithm using maximum a posteriori
(MAP) detection. To analyze the performance of the proposed protocol, we first
derive closed-form expressions for the probability density function (PDF) of
the received signal-to-noise ratio assuming all the relays know the state of IN
perfectly (genie-condition). Then, these PDFs are used to derive closed-form
expressions for the bit error rate (BER) and the outage probability. Finally,
we also derive the asymptotic BER and outage expressions to quantify the
diversity benefits. We show that the proposed MAP-based N'th BRS protocol
attains the derived genie-aided analytical results and outperforms the
conventional relay selection protocol, optimized for the Gaussian case, and
which does not take into account the IN memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12514</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12514</id><created>2019-05-28</created><authors><author><keyname>Avila</keyname><forenames>Jorge R. Salas</forenames></author><author><keyname>How</keyname><forenames>Kin Yau</forenames></author><author><keyname>Lu</keyname><forenames>Mingyang</forenames></author><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author></authors><title>A Novel Dual Modality Sensor With Sensitivities to Permittivity,
  Conductivity, and Permeability</title><categories>eess.SP physics.ins-det</categories><doi>10.1109/JSEN.2017.2767380</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an electromagnetic sensor which can operate simultaneously in
capacitive and inductive modalities with sensitivities to permittivity,
conductivity, and permeability is developed, and a novel measurement strategy
is proposed accordingly. The sensor is composed of two planar spiral coils with
a track width of 4 mm, which promotes its capacitive mode. The capacitive
coupling is measured in common mode, while the inductive coupling is measured
in differential mode. In capacitive mode, the sensor is sensitive to changes in
permittivity, i.e., the dielectric material distribution; while in inductive
mode, it is sensitive to magnetically permeable material and electrically
conductive material. Furthermore, it is demonstrated that the sensor can
simultaneously measure dielectric and conductive materials. This novel sensing
element has been designed and implemented. Experimental results verified its
effectiveness in dual modality measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12515</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12515</id><created>2019-05-28</created><authors><author><keyname>Lu</keyname><forenames>Mingyang</forenames></author><author><keyname>Zhu</keyname><forenames>Wenqian</forenames></author><author><keyname>Yin</keyname><forenames>Liyuan</forenames></author><author><keyname>Peyton</keyname><forenames>Anthony J.</forenames></author><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author><author><keyname>Qu</keyname><forenames>Zhigang</forenames></author></authors><title>Reducing the Lift-Off Effect on Permeability Measurement for Magnetic
  Plates From Multifrequency Induction Data</title><categories>eess.SP</categories><doi>10.1109/TIM.2017.2728338</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Liftoff variation causes errors in eddy current measurement of nonmagnetic
plates as well as magnetic plates. For nonmagnetic plates, previous work has
been carried out to address the issue. In this paper, we follow a similar
strategy, but try to reduce the lift-off effect on another index, zerocrossing
frequency for magnetic plates. This modified index, termed as the compensated
zero-crossing frequency, can be obtained from the measured multifrequency
inductance spectral data using the algorithm we developed in this paper. Since
the zero-crossing frequency can be compensated, the permeability of magnetic
plates can finally be predicted by deriving the relation between the
permeability and zero-crossing frequency from Dodd and Deeds method. We have
derived the method through mathematical manipulation and verified it by both
simulation and experimental data. The permeability error caused by liftoff can
be reduced within 7.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12528</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12528</id><created>2019-05-29</created><updated>2019-07-15</updated><authors><author><keyname>Stein</keyname><forenames>Manuel S.</forenames></author></authors><title>Glancing Through Massive Binary Radio Lenses: Hardware-Aware
  Interferometry With 1-Bit Sensors</title><categories>astro-ph.IM cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy consumption and hardware cost of signal digitization together with the
management of the resulting data volume form serious issues for high-rate
measurement systems with multiple sensors. Switching to binary sensing
front-ends results in a resource-efficient layout but is commonly associated
with significant distortion due to the nonlinear signal acquisition. In
particular, for applications that require to solve high-resolution processing
tasks under extreme conditions, it is a widely held belief that low-complexity
$1$-bit analog-to-digital conversion leads to unacceptable performance
degradation. In the Big Science context of low-frequency radio astronomy, we
propose a telescope architecture based on simplistic binary sampling, precise
probabilistic modeling, and likelihood-oriented data processing. The main
principles, building blocks, and advantages of such a radio telescope system,
which we refer to as The Massive Binary Radio Lenses, are sketched. The open
engineering science questions which have to be answered before building a
prototype are outlined. We set sail for the academic technology study by
deriving a statistical algorithm for interferometric imaging from binary array
measurements. The method aims at extracting the full discriminative information
about the spatial power distribution embedded in a binary sensor data stream
without bias. Radio measurements obtained with LOFAR are used to test the
developed imaging technique and discuss visual and quantitative results. These
assessments shed light on the fact that binary radio telescopes are suited for
surveying the universe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12531</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12531</id><created>2019-05-29</created><authors><author><keyname>Keskin</keyname><forenames>Gokce</forenames></author><author><keyname>Lee</keyname><forenames>Tyler</forenames></author><author><keyname>Stephenson</keyname><forenames>Cory</forenames></author><author><keyname>Elibol</keyname><forenames>Oguz H.</forenames></author></authors><title>Measuring the Effectiveness of Voice Conversion on Speaker
  Identification and Automatic Speech Recognition Systems</title><categories>eess.AS</categories><comments>Accepted for publication at ICML 2019 Synthetic Realities: Workshop
  on Detecting Audio-Visual Fakes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper evaluates the effectiveness of a Cycle-GAN based voice converter
(VC) on four speaker identification (SID) systems and an automated speech
recognition (ASR) system for various purposes. Audio samples converted by the
VC model are classified by the SID systems as the intended target at up to 46%
top-1 accuracy among more than 250 speakers. This encouraging result in
imitating the target styles led us to investigate if converted (synthetic)
samples can be used to improve ASR training. Unfortunately, adding synthetic
data to the ASR training set only marginally improves word and character error
rates. Our results indicate that even though VC models can successfully mimic
the style of target speakers as measured by SID systems, improving ASR training
with synthetic data from VC systems needs further research to establish its
efficacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12547</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12547</id><created>2019-05-29</created><authors><author><keyname>Mukherjee</keyname><forenames>Saswata</forenames></author><author><keyname>Vijayakumar</keyname><forenames>A.</forenames></author><author><keyname>Rosen</keyname><forenames>Joseph</forenames></author></authors><title>SLM aided noninvasive imaging through thin scattering layers</title><categories>physics.optics eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and demonstrate a new imaging technique to noninvasively see
through scattering layers with the aid of a spatial light modulator (SLM). A
relay system projects the incoherent light pattern emitting from the scattering
layer onto the SLM. Two coded phase masks are displayed, one after another, on
the SLM to modulate the projected scattered field. Two corresponding intensity
patterns are recorded by a digital camera, and subtracted one from the other in
the computer to obtain a bipolar matrix. A modified phase retrieval algorithm
is used to retrieve the object information from this bipolar matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12563</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12563</id><created>2019-05-29</created><updated>2019-08-21</updated><authors><author><keyname>Maier</keyname><forenames>Philipp M.</forenames></author><author><keyname>Keller</keyname><forenames>Sina</forenames></author></authors><title>Application of Different Simulated Spectral Data and Machine Learning to
  Estimate the Chlorophyll a Concentration of Several Inland Waters</title><categories>eess.IV cs.CV</categories><comments>This contribution was accepted for the IEEE Whispers 2019 in
  Amsterdam</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Water quality is of great importance for humans and for the environment and
has to be monitored continuously. It is determinable through proxies such as
the chlorophyll a concentration, which can be monitored by remote sensing
techniques. This study focuses on the trade-off between the spatial and the
spectral resolution of six simulated satellite-based data sets when estimating
the chlorophyll a concentration with supervised machine learning models. The
initial dataset for the spectral simulation of the satellite missions contains
spectrometer data and measured chlorophyll a concentration of 13 different
inland waters. Focusing on the regression performance, it appears that the
machine learning models achieve almost as good results with the simulated
Sentinel data as with the simulated hyperspectral data. Regarding the
applicability, the Sentinel 2 mission is the best choice for small inland
waters due to its high spatial and temporal resolution in combination with a
suitable spectral resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12586</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12586</id><created>2019-05-22</created><authors><author><keyname>Raad</keyname><forenames>Omar</forenames><affiliation>American University of Kuwait</affiliation></author><author><keyname>Makdessi</keyname><forenames>Majd</forenames><affiliation>American University of Kuwait</affiliation></author><author><keyname>Mohamad</keyname><forenames>Yazan</forenames><affiliation>American University of Kuwait</affiliation></author><author><keyname>Damaj</keyname><forenames>Issam</forenames><affiliation>American University of Kuwait</affiliation></author></authors><title>SysMART Indoor Services: A System of Smart and Connected Supermarkets</title><categories>eess.SP</categories><comments>7 pages, 11 figure</comments><acm-class>B.4.1; H.4.3; K.8.1</acm-class><journal-ref>The 31st Canadian Conference on Electrical and Computer
  Engineering, IEEE, Quebec City, Quebec, Canada, (2018) 13-16</journal-ref><doi>10.1109/CCECE.2018.8447626</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart gadgets are being embedded almost in every aspect of our lives. From
smart cities to smart watches, modern industries are increasingly supporting
the Internet of Things (IoT). SysMART aims at making supermarkets smart,
productive, and with a touch of modern lifestyle. While similar implementations
to improve the shopping experience exists, they tend mainly to replace the
shopping activity at the store with online shopping. Although online shopping
reduces time and effort, it deprives customers from enjoying the experience.
SysMART relies on cutting-edge devices and technology to simplify and reduce
the time required during grocery shopping inside the supermarket. In addition,
the system monitors and maintains perishable products in good condition
suitable for human consumption. SysMART is built using state-of-the-art
technologies that support rapid prototyping and precision data acquisition. The
selected development environment is LabVIEW with its world-class interfacing
libraries. The paper comprises a detailed system description, development
strategy, interface design, software engineering, and a thorough analysis and
evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12596</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12596</id><created>2019-05-29</created><authors><author><keyname>Straat</keyname><forenames>Michiel</forenames></author><author><keyname>Oosterhof</keyname><forenames>Jorrit</forenames></author></authors><title>Segmentation of blood vessels in retinal fundus images</title><categories>eess.IV cs.CV cs.LG</categories><comments>Conference: SC@RUG 2017, 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, several automatic segmentation methods have been proposed
for blood vessels in retinal fundus images, ranging from using cheap and fast
trainable filters to complicated neural networks and even deep learning. One
example of a filted-based segmentation method is B-COSFIRE. In this approach
the image filter is trained with example prototype patterns, to which the
filter becomes selective by finding points in a Difference of Gaussian response
on circles around the center with large intensity variation. In this paper we
discuss and evaluate several of these vessel segmentation methods. We take a
closer look at B-COSFIRE and study the performance of B-COSFIRE on the recently
published IOSTAR dataset by experiments and we examine how the parameter values
affect the performance. In the experiment we manage to reach a segmentation
accuracy of 0.9419. Based on our findings we discuss when B-COSFIRE is the
preferred method to use and in which circumstances it could be beneficial to
use a more (computationally) complex segmentation method. We also shortly
discuss areas beyond blood vessel segmentation where these methods can be used
to segment elongated structures, such as rivers in satellite images or nerves
of a leaf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12602</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12602</id><created>2019-05-29</created><authors><author><keyname>Zhao</keyname><forenames>Liuhui</forenames></author><author><keyname>Malikopoulos</keyname><forenames>Andreas A.</forenames></author></authors><title>Enhanced Mobility with Connectivity and Automation: A Review of Shared
  Autonomous Vehicle Systems</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shared mobility can provide access to transportation on a custom basis
without vehicle ownership. The advent of connected and automated vehicle
technologies can further enhance the potential benefits of shared mobility
systems. Although the implications of a system with shared autonomous vehicles
have been investigated, the research reported in the literature has exhibited
contradictory outcomes. In this paper, we present a summary of the research
efforts in shared autonomous vehicle systems that have been reported in the
literature to date and discuss potential future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12603</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12603</id><created>2019-05-29</created><updated>2019-06-07</updated><authors><author><keyname>Znidi</keyname><forenames>Faycal</forenames></author><author><keyname>Davarikia</keyname><forenames>Hamzeh</forenames></author><author><keyname>Iqbal</keyname><forenames>Kamran</forenames></author><author><keyname>Barati</keyname><forenames>Masoud</forenames></author></authors><title>Multi-Layer Spectral Clustering Approach to Intentional Islanding In
  Bulk Power Systems</title><categories>eess.SP math.OC</categories><comments>Accepted in Journal of Modern Power System and Clean Energy on 28 Apr
  2019</comments><doi>10.1007/s40565-019-0554-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intentional controlled islanding (ICI) is a final resort for preventing a
cascading failure and catastrophic power system blackouts. This paper proposes
a controlled islanding algorithm that uses spectral clustering over multi-layer
graphs to find a suitable islanding solution. The multi-criteria objective
function used in this controlled islanding algorithm involves the correlation
coefficients between bus frequency components and minimal active and reactive
power flow disruption. Similar to the previous studies, the algorithm is
applied in two stages. In the first stage, groups of coherent buses are
identified with the help of modularity clustering using correlation
coefficients between bus frequency components. In the second stage, the ICI
solution with minimum active and reactive power flow disruption and satisfying
bus coherency is determined by grouping all nodes using spectral clustering on
the multi-layer graph. Simulation studies on the IEEE 39-bus test system
demonstrate the effectiveness of the method in determining an islanding
solution in real time while addressing the generator coherency problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12605</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12605</id><created>2019-05-29</created><authors><author><keyname>Michelsanti</keyname><forenames>Daniel</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Sigurdsson</keyname><forenames>Sigurdur</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>Deep-Learning-Based Audio-Visual Speech Enhancement in Presence of
  Lombard Effect</title><categories>eess.AS cs.LG</categories><doi>10.1016/j.specom.2019.10.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When speaking in presence of background noise, humans reflexively change
their way of speaking in order to improve the intelligibility of their speech.
This reflex is known as Lombard effect. Collecting speech in Lombard conditions
is usually hard and costly. For this reason, speech enhancement systems are
generally trained and evaluated on speech recorded in quiet to which noise is
artificially added. Since these systems are often used in situations where
Lombard speech occurs, in this work we perform an analysis of the impact that
Lombard effect has on audio, visual and audio-visual speech enhancement,
focusing on deep-learning-based systems, since they represent the current state
of the art in the field.
  We conduct several experiments using an audio-visual Lombard speech corpus
consisting of utterances spoken by 54 different talkers. The results show that
training deep-learning-based models with Lombard speech is beneficial in terms
of both estimated speech quality and estimated speech intelligibility at low
signal to noise ratios, where the visual modality can play an important role in
acoustically challenging situations. We also find that a performance difference
between genders exists due to the distinct Lombard speech exhibited by males
and females, and we analyse it in relation with acoustic and visual features.
Furthermore, listening tests conducted with audio-visual stimuli show that the
speech quality of the signals processed with systems trained using Lombard
speech is statistically significantly better than the one obtained using
systems trained with non-Lombard speech at a signal to noise ratio of -5 dB.
Regarding speech intelligibility, we find a general tendency of the benefit in
training the systems with Lombard speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12629</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12629</id><created>2019-05-29</created><authors><author><keyname>Paolizzo</keyname><forenames>Fabio</forenames></author><author><keyname>Pichierri</keyname><forenames>Natalia</forenames></author><author><keyname>Casali</keyname><forenames>Daniele</forenames></author><author><keyname>Giardino</keyname><forenames>Daniele</forenames></author><author><keyname>Matta</keyname><forenames>Marco</forenames></author><author><keyname>Costantini</keyname><forenames>Giovanni</forenames></author></authors><title>Multilabel Automated Recognition of Emotions Induced Through Music</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>4 figures, 3 tables, The research supported by the EU through the
  MUSICAL-MOODS project funded by the Marie Sklodowska-Curie Actions Individual
  Fellowships Global Fellowships (MSCA-IF-GF) of the Horizon 2020 Programme
  H2020/2014-2020, REA grant agreement n.659434</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achieving advancements in automatic recognition of emotions that music can
induce require considering multiplicity and simultaneity of emotions.
Comparison of different machine learning algorithms performing multilabel and
multiclass classification is the core of our work. The study analyzes the
implementation of the Geneva Emotional Music Scale 9 in the Emotify music
dataset and the data distribution. The research goal is the identification of
best methods towards the definition of the audio component of a new a new
multimodal dataset for music emotion recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12692</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12692</id><created>2019-05-29</created><updated>2019-11-18</updated><authors><author><keyname>Varma</keyname><forenames>Rohan</forenames></author><author><keyname>Lee</keyname><forenames>Harlin</forenames></author><author><keyname>Kova&#x10d;evi&#x107;</keyname><forenames>Jelena</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author></authors><title>Vector-Valued Graph Trend Filtering with Non-Convex Penalties</title><categories>eess.SP cs.LG stat.ML</categories><comments>The first two authors contributed equally</comments><journal-ref>IEEE Transactions on Signal and Information Processing over
  Networks, vol. 6, pp. 48-62, 2020</journal-ref><doi>10.1109/TSIPN.2019.2957717</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the denoising of piecewise smooth graph signals that
exhibit inhomogeneous levels of smoothness over a graph, where the value at
each node can be vector-valued. We extend the graph trend filtering framework
to denoising vector-valued graph signals with a family of non-convex
regularizers, which exhibit superior recovery performance over existing convex
regularizers. Using an oracle inequality, we establish the statistical error
rates of first-order stationary points of the proposed non-convex method for
generic graphs. Furthermore, we present an ADMM-based algorithm to solve the
proposed method and establish its convergence. Numerical experiments are
conducted on both synthetic and real-world data for denoising, support
recovery, event detection, and semi-supervised classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12708</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12708</id><created>2019-05-29</created><authors><author><keyname>Narayanan</keyname><forenames>Athma</forenames></author><author><keyname>Dwivedi</keyname><forenames>Isht</forenames></author><author><keyname>Dariush</keyname><forenames>Behzad</forenames></author></authors><title>Dynamic Traffic Scene Classification with Space-Time Coherence</title><categories>cs.CV eess.IV</categories><comments>accpeted in (International Conference on Robotics and Automation)ICRA
  2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper examines the problem of dynamic traffic scene classification under
space-time variations in viewpoint that arise from video captured on-board a
moving vehicle. Solutions to this problem are important for realization of
effective driving assistance technologies required to interpret or predict road
user behavior. Currently, dynamic traffic scene classification has not been
adequately addressed due to a lack of benchmark datasets that consider
spatiotemporal evolution of traffic scenes resulting from a vehicle's
ego-motion. This paper has three main contributions. First, an annotated
dataset is released to enable dynamic scene classification that includes 80
hours of diverse high quality driving video data clips collected in the San
Francisco Bay area. The dataset includes temporal annotations for road places,
road types, weather, and road surface conditions. Second, we introduce novel
and baseline algorithms that utilize semantic context and temporal nature of
the dataset for dynamic classification of road scenes. Finally, we showcase
algorithms and experimental results that highlight how extracted features from
scene classification serve as strong priors and help with tactical driver
behavior understanding. The results show significant improvement from
previously reported driving behavior detection baselines in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12748</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12748</id><created>2019-05-29</created><authors><author><keyname>Kihero</keyname><forenames>Abuu B.</forenames></author><author><keyname>Solaija</keyname><forenames>Muhammad Sohaib J.</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author></authors><title>Multi-Numerology Multiplexing and Inter-Numerology Interference Analysis
  for 5G</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifth generation (5G) radio access technology (RAT) is expected to flexibly
serve multiple services with extremely diverse requirements. One of the steps
taken toward fulfilling this vision of the 5G-RAT is an introduction of the
multi-numerology concept, where multiple frame structures with different
subcarrier spacings coexist in one frequency band. Though efficient in
providing the required flexibility, this approach introduces a new kind of
interference into the system known as inter numerology interference (INI). This
study is geared toward analyzing the INI problem considering a cyclic prefix
orthogonal frequency domain multiplexing (CP-OFDM) system and exposing the
factors contributing to it through mathematical analyses. In-depth discussion
of various critical issues concerning multi-numerology system such as frequency
domain multiplexing and time domain symbol alignment for mixed numerologies is
presented. Based on the findings of the conducted analyses, the paper
highlights some approaches for minimizing INI in the system. The developed
mathematical analysis is finally verified by Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12802</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12802</id><created>2019-05-29</created><authors><author><keyname>Cui</keyname><forenames>Simin Li Zhengze</forenames></author><author><keyname>Ye</keyname><forenames>Xingwei</forenames></author><author><keyname>Feng</keyname><forenames>Jing</forenames></author><author><keyname>Yang</keyname><forenames>Yue</forenames></author><author><keyname>He</keyname><forenames>Zhengqian</forenames></author><author><keyname>Cong</keyname><forenames>Rong</forenames></author><author><keyname>Zhu</keyname><forenames>Dan</forenames></author><author><keyname>Zhang</keyname><forenames>Fangzheng</forenames></author><author><keyname>Pan</keyname><forenames>Shilong</forenames></author></authors><title>Chip-based photonic radar for high-resolution imaging</title><categories>eess.SP physics.ins-det physics.optics</categories><comments>4 pages, 6figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radar is the only sensor that can realize target imaging at all time and all
weather, which would be a key technical enabler for future intelligent society.
Poor resolution and large size are two critical issues for radars to gain
ground in civil applications. Conventional electronic radars are difficult to
address both issues especially in the relatively low-frequency band. In this
work, we propose and experimentally demonstrate, for the first time to the best
of our knowledge, a chip-based photonic radar based on silicon photonic
platform, which can implement high resolution imaging with very small
footprint. Both the wideband signal generator and the de-chirp receiver are
integrated on the chip. A broadband photonic imaging radar occupying the full
Ku band is experimentally established. A high precision range measurement with
a resolution of 2.7 cm and an error of less than 2.75 mm is obtained. Inverse
synthetic aperture (ISAR) imaging of multiple targets with complex profiles are
also implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12804</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12804</id><created>2019-05-29</created><updated>2019-09-17</updated><authors><author><keyname>da Silva</keyname><forenames>Angelo C. Mendes</forenames></author><author><keyname>Nunes</keyname><forenames>Mauricio A.</forenames></author><author><keyname>Neto</keyname><forenames>Raul Fonseca</forenames></author></authors><title>A Music Classification Model based on Metric Learning and Feature
  Extraction from MP3 Audio Files</title><categories>cs.SD cs.IR cs.LG eess.AS stat.ML</categories><comments>In a review process, I found some errors and made some changes in
  methodology that improved my results. Once I finish the experiments, I will
  upload the new version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of models for learning music similarity and feature
extraction from audio media files is an increasingly important task for the
entertainment industry. This work proposes a novel music classification model
based on metric learning and feature extraction from MP3 audio files. The
metric learning process considers the learning of a set of parameterized
distances employing a structured prediction approach from a set of MP3 audio
files containing several music genres. The main objective of this work is to
make possible learning a personalized metric for each customer. To extract the
acoustic information we use the Mel-Frequency Cepstral Coefficient (MFCC) and
make a dimensionality reduction with the use of Principal Components Analysis.
We attest the model validity performing a set of experiments and comparing the
training and testing results with baseline algorithms, such as K-means and Soft
Margin Linear Support Vector Machine (SVM). Experiments show promising results
and encourage the future development of an online version of the learning
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12806</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12806</id><created>2019-05-29</created><authors><author><keyname>Seeb&#xf6;ck</keyname><forenames>Philipp</forenames></author><author><keyname>Orlando</keyname><forenames>Jos&#xe9; Ignacio</forenames></author><author><keyname>Schlegl</keyname><forenames>Thomas</forenames></author><author><keyname>Waldstein</keyname><forenames>Sebastian M.</forenames></author><author><keyname>Bogunovi&#x107;</keyname><forenames>Hrvoje</forenames></author><author><keyname>Klimscha</keyname><forenames>Sophie</forenames></author><author><keyname>Langs</keyname><forenames>Georg</forenames></author><author><keyname>Schmidt-Erfurth</keyname><forenames>Ursula</forenames></author></authors><title>Exploiting Epistemic Uncertainty of Anatomy Segmentation for Anomaly
  Detection in Retinal OCT</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Accepted for publication in IEEE Transactions on Medical Imaging,
  2019</comments><doi>10.1109/TMI.2019.2919951</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diagnosis and treatment guidance are aided by detecting relevant biomarkers
in medical images. Although supervised deep learning can perform accurate
segmentation of pathological areas, it is limited by requiring a-priori
definitions of these regions, large-scale annotations, and a representative
patient cohort in the training set. In contrast, anomaly detection is not
limited to specific definitions of pathologies and allows for training on
healthy samples without annotation. Anomalous regions can then serve as
candidates for biomarker discovery. Knowledge about normal anatomical structure
brings implicit information for detecting anomalies. We propose to take
advantage of this property using bayesian deep learning, based on the
assumption that epistemic uncertainties will correlate with anatomical
deviations from a normal training set. A Bayesian U-Net is trained on a
well-defined healthy environment using weak labels of healthy anatomy produced
by existing methods. At test time, we capture epistemic uncertainty estimates
of our model using Monte Carlo dropout. A novel post-processing technique is
then applied to exploit these estimates and transfer their layered appearance
to smooth blob-shaped segmentations of the anomalies. We experimentally
validated this approach in retinal optical coherence tomography (OCT) images,
using weak labels of retinal layers. Our method achieved a Dice index of 0.789
in an independent anomaly test set of age-related macular degeneration (AMD)
cases. The resulting segmentations allowed very high accuracy for separating
healthy and diseased cases with late wet AMD, dry geographic atrophy (GA),
diabetic macular edema (DME) and retinal vein occlusion (RVO). Finally, we
qualitatively observed that our approach can also detect other deviations in
normal scans such as cut edge artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12845</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12845</id><created>2019-05-30</created><updated>2019-08-19</updated><authors><author><keyname>Li</keyname><forenames>Xiang</forenames></author><author><keyname>Lu</keyname><forenames>Chan</forenames></author><author><keyname>Cheng</keyname><forenames>Danni</forenames></author><author><keyname>Li</keyname><forenames>Wei-Hong</forenames></author><author><keyname>Cao</keyname><forenames>Mei</forenames></author><author><keyname>Liu</keyname><forenames>Bo</forenames></author><author><keyname>Ma</keyname><forenames>Jiechao</forenames></author><author><keyname>Zheng</keyname><forenames>Wei-Shi</forenames></author></authors><title>Towards Photo-Realistic Visible Watermark Removal with Conditional
  Generative Adversarial Networks</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible watermark plays an important role in image copyright protection and
the robustness of a visible watermark to an attack is shown to be essential. To
evaluate and improve the effectiveness of watermark, watermark removal attracts
increasing attention and becomes a hot research top. Current methods cast the
watermark removal as an image-to-image translation problem where the
encode-decode architectures with pixel-wise loss are adopted to transfer the
transparent watermarked pixels into unmarked pixels. However, when a number of
realistic images are presented, the watermarks are more likely to be unknown
and diverse (i.e., the watermarks might be opaque or semi-transparent; the
category and pattern of watermarks are unknown). When applying existing methods
to the real-world scenarios, they mostly can not satisfactorily reconstruct the
hidden information obscured under the complex and various watermarks (i.e., the
residual watermark traces remain and the reconstructed images lack reality). To
address this difficulty, in this paper, we present a new watermark processing
framework using the conditional generative adversarial networks (cGANs) for
visible watermark removal in the real-world application. The proposed method
enables the watermark removal solution to be more closed to the photo-realistic
reconstruction using a patch-based discriminator conditioned on the watermarked
images, which is adversarially trained to differentiate the difference between
the recovered images and original watermark-free images. Extensive experimental
results on a large-scale visible watermark dataset demonstrate the
effectiveness of the proposed method and clearly indicate that our proposed
approach can produce more photo-realistic and convincing results compared with
the state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12915</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12915</id><created>2019-05-30</created><updated>2020-02-24</updated><authors><author><keyname>Sargun</keyname><forenames>Deniz</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author></authors><title>Separating an Outlier from a Change</title><categories>eess.SP cs.IT math.IT stat.AP</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the change detection problem with an unknown post-change
distribution. Under this constraint, the unknown change in the distribution of
observations may occur in many ways without much structure, whereas, before the
change point, an outlier (false alarm) is highly structured, following a
particular sample path. We first characterize these likely events for the
deviation of finite strings and propose a method to test the deviation,
relative to the most likely way for it to occur as an outlier. Our method works
along with other change detection schemes to substantially reduce the false
positive rates associated with the plain scheme used without the heavy
computation associated with the generalized likelihood ratio test. We benchmark
our method with finite moving average and generalized likelihood ratio tests
under 4 different performance criteria. Finally, we apply our method on
economic market indicators and climate data. Our method successfully captures
the regime shifts during times of historical significance and identifies the
current climate change phenomenon to be a highly likely regime shift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12931</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12931</id><created>2019-05-30</created><updated>2019-07-17</updated><authors><author><keyname>Pinchaud</keyname><forenames>Nicolas</forenames></author></authors><title>Weakly supervised training of pixel resolution segmentation models on
  whole slide images</title><categories>eess.IV cs.LG stat.ML</categories><comments>Performance update</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to train pixel resolution segmentation models on
whole slide images in a weakly supervised setup. The model is trained to
classify patches extracted from slides. This leads the training to be made
under noisy labeled data. We solve the problem with two complementary
strategies. First, the patches are sampled online using the model's knowledge
by focusing on regions where the model's confidence is higher. Second, we
propose an extension of the KL divergence that is robust to noisy labels. Our
preliminary experiment on CAMELYON 16 data set show promising results. The
model can successfully segment tumor areas with strong morphological
consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.12988</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.12988</id><created>2019-05-30</created><authors><author><keyname>Widya</keyname><forenames>Aji Resindra</forenames></author><author><keyname>Monno</keyname><forenames>Yusuke</forenames></author><author><keyname>Imahori</keyname><forenames>Kosuke</forenames></author><author><keyname>Okutomi</keyname><forenames>Masatoshi</forenames></author><author><keyname>Suzuki</keyname><forenames>Sho</forenames></author><author><keyname>Gotoda</keyname><forenames>Takuji</forenames></author><author><keyname>Miki</keyname><forenames>Kenji</forenames></author></authors><title>3D Reconstruction of Whole Stomach from Endoscope Video Using
  Structure-from-Motion</title><categories>cs.CV eess.IV</categories><comments>5 pages, 4 figures, accepted in EMBC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gastric endoscopy is a common clinical practice that enables medical doctors
to diagnose the stomach inside a body. In order to identify a gastric lesion's
location such as early gastric cancer within the stomach, this work addressed
to reconstruct the 3D shape of a whole stomach with color texture information
generated from a standard monocular endoscope video. Previous works have tried
to reconstruct the 3D structures of various organs from endoscope images.
However, they are mainly focused on a partial surface. In this work, we
investigated how to enable structure-from-motion (SfM) to reconstruct the whole
shape of a stomach from a standard endoscope video. We specifically
investigated the combined effect of chromo-endoscopy and color channel
selection on SfM. Our study found that 3D reconstruction of the whole stomach
can be achieved by using red channel images captured under chromo-endoscopy by
spreading indigo carmine (IC) dye on the stomach surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13014</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13014</id><created>2019-04-25</created><updated>2019-06-05</updated><authors><author><keyname>Sun</keyname><forenames>Chengjian</forenames></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames></author></authors><title>Unsupervised Deep Learning for Ultra-reliable and Low-latency
  Communications</title><categories>cs.NI eess.SP stat.ML</categories><comments>6 pages, 1 figure, submitted to IEEE for possible publication. arXiv
  admin note: text overlap with arXiv:1905.11017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study how to solve resource allocation problems in
ultra-reliable and low-latency communications by unsupervised deep learning,
which often yield functional optimization problems with quality-of-service
(QoS) constraints. We take a joint power and bandwidth allocation problem as an
example, which minimizes the total bandwidth required to guarantee the QoS of
each user in terms of the delay bound and overall packet loss probability. The
global optimal solution is found in a symmetric scenario. A neural network was
introduced to find an approximated optimal solution in general scenarios, where
the QoS is ensured by using the property that the optimal solution should
satisfy as the &quot;supervision signal&quot;. Simulation results show that the
learning-based solution performs the same as the optimal solution in the
symmetric scenario, and can save around 40% bandwidth with respect to the
state-of-the-art policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13052</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13052</id><created>2019-05-30</created><updated>2019-07-29</updated><authors><author><keyname>Hong</keyname><forenames>Tao</forenames></author><author><keyname>Yavneh</keyname><forenames>Irad</forenames></author><author><keyname>Zibulevsky</keyname><forenames>Michael</forenames></author></authors><title>Solving RED with Weighted Proximal Methods</title><categories>eess.IV eess.SP</categories><comments>3 figures 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  REgularization by Denoising (RED) is a recently introduced framework for
solving inverse problems by incorporating state-of-the-art denoising algorithms
as the priors. Accordingly, the main computational task of RED is repeated
denoising processes. A drawback of this promising approach is that the
computational complexity of denoisers is relatively high, which may result in
long overall solution times. In this paper, we apply a general framework called
weighted proximal methods (WPMs) to solve RED efficiently. We first show that
two recently introduced RED solvers (using the fixed point and accelerated
proximal gradient methods) are particular cases of WPMs. Then we show by
numerical experiments that slightly more sophisticated variants of WPM can lead
to reduced run times for RED by requiring a significantly smaller number of
calls to the denoiser.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13079</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13079</id><created>2019-05-28</created><authors><author><keyname>Lu</keyname><forenames>Mingyang</forenames></author><author><keyname>Huang</keyname><forenames>Ruochen</forenames></author><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author><author><keyname>Zhao</keyname><forenames>Qian</forenames></author><author><keyname>Peyton</keyname><forenames>Anthony</forenames></author></authors><title>Measurement of permeability for ferrous metallic plates using a novel
  lift-off compensation technique on phase signature</title><categories>eess.SP</categories><doi>10.1109/JSEN.2019.2916431</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lift-off of sensor affects the prediction of electromagnetic properties for
both ferrous and non-ferrous steel plates. In this paper, we developed a
strategy to address this issue for ferrous plates. With increased lift-off, the
phase of the measured impedance for steel plates reduces. Meanwhile, the
magnitude of the impedance signal decreases. Based on these facts, a phase
compensation algorithm is developed which corrects the phase change due to
lift-off considering the magnitude of the impedance signal. Further, a new
magnetic permeability prediction technique is presented, which has been
validated by analytical and measured results. With this new technique, the
error in permeability prediction is less than 2% within the range of lift-offs
tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13080</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13080</id><created>2019-05-28</created><authors><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author><author><keyname>Tang</keyname><forenames>Jiawei</forenames></author><author><keyname>Lu</keyname><forenames>Mingyang</forenames></author><author><keyname>Xu</keyname><forenames>Hanyang</forenames></author><author><keyname>Huang</keyname><forenames>Ruochen</forenames></author><author><keyname>Zhao</keyname><forenames>Qian</forenames></author><author><keyname>Zhang</keyname><forenames>Zhijie</forenames></author><author><keyname>Peyton</keyname><forenames>Anthony</forenames></author></authors><title>An equivalent-effect phenomenon in eddy current non-destructive testing
  of thin structures</title><categories>eess.SP</categories><doi>10.1109/ACCESS.2019.2916980</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The inductance/impedance due to thin metallic structures in non-destructive
testing (NDT) is difficult to evaluate. In particular, in Finite Element Method
(FEM) eddy current simulation, an extremely fine mesh is required to accurately
simulate skin effects especially at high frequencies, and this could cause an
extremely large total mesh for the whole problem, i.e. including, for example,
other surrounding structures and excitation sources like coils. Consequently,
intensive computation requirements are needed. In this paper, an
equivalent-effect phenomenon is found, which has revealed that alternative
structures can produce the same effect on the sensor response, i.e. mutual
impedance/inductance of coupled coils if a relationship (reciprocal
relationship) between the electrical conductivity and the thickness of the
structure is observed. By using this relationship, the mutual
inductance/impedance can be calculated from the equivalent structures with much
fewer mesh elements, which can significantly save the computation time. In eddy
current NDT, coils inductance/impedance is normally used as a critical
parameter for various industrial applications, such as flaw detection, coating
and microstructure sensing. Theoretical derivation, measurements and
simulations have been presented to verify the feasibility of the proposed
phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13081</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13081</id><created>2019-05-28</created><authors><author><keyname>Lu</keyname><forenames>Mingyang</forenames></author><author><keyname>Xie</keyname><forenames>Yuedong</forenames></author><author><keyname>Zhu</keyname><forenames>Wenqian</forenames></author><author><keyname>Peyton</keyname><forenames>Anthony</forenames></author><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author></authors><title>Determination of the magnetic permeability, electrical conductivity, and
  thickness of ferrite metallic plates using a multi-frequency electromagnetic
  sensing system</title><categories>eess.SP</categories><doi>10.1109/TII.2018.2885406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an inverse method was developed which can, in principle,
reconstruct arbitrary permeability, conductivity, thickness, and lift-off with
a multi-frequency electromagnetic sensor from inductance spectroscopic
measurements. The system fives the error of &quot;Bad character(s) in field
Abstract&quot; for no reason. Please refer to manuscript for the full abstract.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13090</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13090</id><created>2019-05-30</created><updated>2019-06-16</updated><authors><author><keyname>Pandey</keyname><forenames>Amritanshu</forenames></author><author><keyname>Agarwal</keyname><forenames>Aayushya</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Nwachuku</keyname><forenames>Tochi</forenames></author><author><keyname>Rawn</keyname><forenames>Barry G.</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Improving Voltage Profile of the Nigerian Power Grid</title><categories>eess.SP</categories><comments>IEEE PowerAfrica 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extreme voltages at the system nodes are one of the primary causes for total
and partial collapse of the Nigerian grid. In this paper, we develop a
framework to re-dispatch the voltage set-points of committed generators in the
grid to improve the voltage profile of the system nodes thus lowering the
likelihood of a grid collapse. This framework is an extension of
circuit-theoretic formulation that can robustly solve general-purpose grid
optimization problems. In the results section, we re-dispatch the voltage
setpoints for committed generators in real-life Nigerian grid operation and
planning test cases to improve the overall voltage profile of the grid. We
further demonstrate that the re-dispatched grid is more resilient and secure
than the base case through running contingency analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13145</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13145</id><created>2019-05-30</created><authors><author><keyname>Yoo</keyname><forenames>Sunghwan</forenames></author><author><keyname>Gujrathi</keyname><forenames>Isha</forenames></author><author><keyname>Haider</keyname><forenames>Masoom A.</forenames></author><author><keyname>Khalvati</keyname><forenames>Farzad</forenames></author></authors><title>Prostate Cancer Detection using Deep Convolutional Neural Networks</title><categories>cs.CV eess.IV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prostate cancer is one of the most common forms of cancer and the third
leading cause of cancer death in North America. As an integrated part of
computer-aided detection (CAD) tools, diffusion-weighted magnetic resonance
imaging (DWI) has been intensively studied for accurate detection of prostate
cancer. With deep convolutional neural networks (CNNs) significant success in
computer vision tasks such as object detection and segmentation, different CNNs
architectures are increasingly investigated in medical imaging research
community as promising solutions for designing more accurate CAD tools for
cancer detection. In this work, we developed and implemented an automated
CNNs-based pipeline for detection of clinically significant prostate cancer
(PCa) for a given axial DWI image and for each patient. DWI images of 427
patients were used as the dataset, which contained 175 patients with PCa and
252 healthy patients. To measure the performance of the proposed pipeline, a
test set of 108 (out of 427) patients were set aside and not used in the
training phase. The proposed pipeline achieved area under the receiver
operating characteristic curve (AUC) of 0.87 (95% Confidence Interval (CI):
0.84-0.90) and 0.84 (95% CI: 0.76-0.91) at slice level and patient level,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13150</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13150</id><created>2019-05-30</created><updated>2019-07-13</updated><authors><author><keyname>Fainberg</keyname><forenames>Joachim</forenames></author><author><keyname>Klejch</keyname><forenames>Ond&#x159;ej</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author><author><keyname>Bell</keyname><forenames>Peter</forenames></author></authors><title>Lattice-based lightly-supervised acoustic model training</title><categories>cs.CL cs.SD eess.AS</categories><comments>Proc. INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the broadcast domain there is an abundance of related text data and
partial transcriptions, such as closed captions and subtitles. This text data
can be used for lightly supervised training, in which text matching the audio
is selected using an existing speech recognition model. Current approaches to
light supervision typically filter the data based on matching error rates
between the transcriptions and biased decoding hypotheses. In contrast,
semi-supervised training does not require matching text data, instead
generating a hypothesis using a background language model. State-of-the-art
semi-supervised training uses lattice-based supervision with the lattice-free
MMI (LF-MMI) objective function. We propose a technique to combine inaccurate
transcriptions with the lattices generated for semi-supervised training, thus
preserving uncertainty in the lattice where appropriate. We demonstrate that
this combined approach reduces the expected error rates over the lattices, and
reduces the word error rate (WER) on a broadcast task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13161</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13161</id><created>2019-05-30</created><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Xu</keyname><forenames>Guanghua</forenames></author><author><keyname>Ravi</keyname><forenames>Aravind</forenames></author><author><keyname>Pearce</keyname><forenames>Sarah</forenames></author><author><keyname>Jiang</keyname><forenames>Ning</forenames></author></authors><title>Simultaneous induction of SSMVEP and SMR Using a Gaiting video stimulus:
  a novel hybrid brain-computer interface</title><categories>eess.SP cs.HC</categories><comments>22 pages, 7 figures and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed a novel visual stimulus for brain-computer interface. The
stimulus is in the form gaiting sequence of a human. The hypothesis is that
observing such a visual stimulus would simultaneously induce 1) steady-state
motion visual evoked potential (SSMVEP) in the occipital area, similarly to an
SSVEP stimulus; and 2) sensorimotor rhythm (SMR) in the primary sensorimotor
area, because such action observation (AO) could activate the mirror neuron
system. Canonical correlation analysis (CCA) was used to detect SSMVEP from
occipital EEG, and event-related spectral perturbations (ERSP) were used to
identify SMR in the EEG from the sensorimotor area. The results showed that the
proposed visual gaiting stimulus-induced SSMVEP, with classification accuracies
of 88.9 $\pm$ 12.0% in a four-class scenario. More importantly, it induced
clear and sustained event-related desynchronization/synchronization (ERD/ERS)
in the EEG from the sensorimotor area, while no ERD/ERS in the sensorimotor
area could be observed when the other two SSVEP stimuli were used. Further, for
participants with sufficiently clear SSMVEP pattern (classification accuracy &gt;
85%), the ERD index values in mu-beta band induced by the proposed gaiting
stimulus were statistically different from that of the other two types of
stimulus. Therefore, a novel BCI based on the proposed stimulus has potential
in neurorehabilitation applications because it simultaneously has the high
accuracy of an SSMVEP (~90% accuracy in a four-class setup) and the ability to
activate sensorimotor cortex. And such potential will be further explored in
future studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13172</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13172</id><created>2019-05-30</created><authors><author><keyname>Smith</keyname><forenames>Phillip</forenames></author><author><keyname>Luong</keyname><forenames>Anh</forenames></author><author><keyname>Sarkar</keyname><forenames>Shamik</forenames></author><author><keyname>Singh</keyname><forenames>Harsimran</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>Kasera</keyname><forenames>Sneha</forenames></author><author><keyname>Derr</keyname><forenames>Kurt</forenames></author><author><keyname>Ramirez</keyname><forenames>Samuel</forenames></author></authors><title>Sitara: Spectrum Measurement Goes Mobile Through Crowd-sourcing</title><categories>cs.NI cs.HC eess.SP</categories><comments>13 pages, 13 figures, 3 tables; For additional documentation and
  source code refer to https://github.com/SPAN-UofU</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software-defined radios (SDRs) are often used in the experimental evaluation
of next-generation wireless technologies. While crowd-sourced spectrum
monitoring is an important component of future spectrum-agile technologies,
there is no clear way to test it in the real world, i.e., with hundreds of
users each with an SDR in their pocket participating in RF experiments
controlled by, and data uploaded to, the cloud. Current fully functional SDRs
are bulky, with components connected via wires, and last at most hours on a
single battery charge. To address the needs of such experiments, we design and
develop a compact, portable, untethered, and inexpensive SDR we call Sitara.
Our SDR interfaces with a mobile device over Bluetooth 5 and can function
standalone or as a client to a central command and control server. The Sitara
offers true portability: it operates up to one week on battery power, requires
no external wired connections and occupies a footprint smaller than a credit
card. It transmits and receives common waveforms, uploads IQ samples or
processed receiver data through a mobile device to a server for remote
processing and performs spectrum sensing functions. Multiple Sitaras form a
distributed system capable of conducting experiments in wireless networking and
communication in addition to RF monitoring and sensing activities. In this
paper, we describe our design, evaluate our solution, present experimental
results from multi-sensor deployments and discuss the value of this system in
future experimentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13181</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13181</id><created>2019-05-30</created><authors><author><keyname>Fosson</keyname><forenames>Sophie M.</forenames></author><author><keyname>Abuabiah</keyname><forenames>Mohammad</forenames></author></authors><title>Recovery of binary sparse signals from compressed linear measurements
  via polynomial optimization</title><categories>math.OC cs.LG eess.SP</categories><doi>10.1109/LSP.2019.2919943</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The recovery of signals with finite-valued components from few linear
measurements is a problem with widespread applications and interesting
mathematical characteristics. In the compressed sensing framework, tailored
methods have been recently proposed to deal with the case of finite-valued
sparse signals. In this work, we focus on binary sparse signals and we propose
a novel formulation, based on polynomial optimization. This approach is
analyzed and compared to the state-of-the-art binary compressed sensing
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13187</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13187</id><created>2019-05-30</created><authors><author><keyname>Churchill</keyname><forenames>Victor</forenames></author></authors><title>Use of convexity in contour detection</title><categories>eess.IV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formulate a simple algorithm that detects contours around a
region of interest in an image. After an initial smoothing, the method is based
on viewing an image as a topographic surface and finding convex and/or concave
regions using simple calculus-based testing. The algorithm can achieve
multi-scale contour detection by altering the initial smoothing. We show that
the method has promise by comparing results on several images with the
watershed transform performed on the gradient images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13208</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13208</id><created>2019-05-30</created><authors><author><keyname>Li</keyname><forenames>Jiayun</forenames></author><author><keyname>Li</keyname><forenames>Wenyuan</forenames></author><author><keyname>Gertych</keyname><forenames>Arkadiusz</forenames></author><author><keyname>Knudsen</keyname><forenames>Beatrice S.</forenames></author><author><keyname>Speier</keyname><forenames>William</forenames></author><author><keyname>Arnold</keyname><forenames>Corey W.</forenames></author></authors><title>An attention-based multi-resolution model for prostate whole slide
  imageclassification and localization</title><categories>cs.CV eess.IV</categories><comments>8 pages, 4 figures, CVPR 2019 Towards Causal, Explainable and
  Universal Medical Visual Diagnosis (MVD) Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histology review is often used as the `gold standard' for disease diagnosis.
Computer aided diagnosis tools can potentially help improve current pathology
workflows by reducing examination time and interobserver variability. Previous
work in cancer grading has focused mainly on classifying pre-defined regions of
interest (ROIs), or relied on large amounts of fine-grained labels. In this
paper, we propose a two-stage attention-based multiple instance learning model
for slide-level cancer grading and weakly-supervised ROI detection and
demonstrate its use in prostate cancer. Compared with existing Gleason
classification models, our model goes a step further by utilizing visualized
saliency maps to select informative tiles for fine-grained grade
classification. The model was primarily developed on a large-scale whole slide
dataset consisting of 3,521 prostate biopsy slides with only slide-level labels
from 718 patients. The model achieved state-of-the-art performance for prostate
cancer grading with an accuracy of 85.11\% for classifying benign, low-grade
(Gleason grade 3+3 or 3+4), and high-grade (Gleason grade 4+3 or higher) slides
on an independent test set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13212</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13212</id><created>2019-05-30</created><authors><author><keyname>Li</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Alkhateeb</keyname><forenames>Ahmed</forenames></author></authors><title>Deep Learning for Direct Hybrid Precoding in Millimeter Wave Massive
  MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>The results are generated using the DeepMIMO dataset. The code files
  will be available soon at http://deepmimo.net/DeepMIMO_applications.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel neural network architecture, that we call an
auto-precoder, and a deep-learning based approach that jointly senses the
millimeter wave (mmWave) channel and designs the hybrid precoding matrices with
only a few training pilots. More specifically, the proposed machine learning
model leverages the prior observations of the channel to achieve two
objectives. First, it optimizes the compressive channel sensing vectors based
on the surrounding environment in an unsupervised manner to focus the sensing
power on the most promising spatial directions. This is enabled by a novel
neural network architecture that accounts for the constraints on the RF chains
and models the transmitter/receiver measurement matrices as two complex-valued
convolutional layers. Second, the proposed model learns how to construct the RF
beamforming vectors of the hybrid architectures directly from the projected
channel vector (the received sensing vector). The auto-precoder neural network
that incorporates both the channel sensing and beam prediction is trained
end-to-end as a multi-task classification problem. Thanks to this design
methodology that leverages the prior channel observations and the implicit
awareness about the surrounding environment/user distributions, the proposed
approach significantly reduces the training overhead compared to classical
(non-machine learning) solutions. For example, for a system of 64 transmit and
64 receive antennas, with 3 RF chains at both sides, the proposed solution
needs only 8 or 16 channel training pilots to directly predict the RF
beamforming/combining vectors of the hybrid architectures and achieve
near-optimal achievable rates. This highlights a promising solution for the
channel estimation and hybrid precoding design problem in mmWave and massive
MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13221</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13221</id><created>2019-05-30</created><authors><author><keyname>Antipa</keyname><forenames>Nick</forenames></author><author><keyname>Oare</keyname><forenames>Patrick</forenames></author><author><keyname>Bostan</keyname><forenames>Emrah</forenames></author><author><keyname>Ng</keyname><forenames>Ren</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author></authors><title>Video from Stills: Lensless Imaging with Rolling Shutter</title><categories>eess.IV cs.CV eess.SP</categories><comments>8 pages, 7 figures, IEEE International Conference on Computational
  Photography 2019, Tokyo</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because image sensor chips have a finite bandwidth with which to read out
pixels, recording video typically requires a trade-off between frame rate and
pixel count. Compressed sensing techniques can circumvent this trade-off by
assuming that the image is compressible. Here, we propose using multiplexing
optics to spatially compress the scene, enabling information about the whole
scene to be sampled from a row of sensor pixels, which can be read off quickly
via a rolling shutter CMOS sensor. Conveniently, such multiplexing can be
achieved with a simple lensless, diffuser-based imaging system. Using sparse
recovery methods, we are able to recover 140 video frames at over 4,500 frames
per second, all from a single captured image with a rolling shutter sensor. Our
proof-of-concept system uses easily-fabricated diffusers paired with an
off-the-shelf sensor. The resulting prototype enables compressive encoding of
high frame rate video into a single rolling shutter exposure, and exceeds the
sampling-limited performance of an equivalent global shutter system for
sufficiently sparse objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13252</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13252</id><created>2019-05-30</created><authors><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Michetti</keyname><forenames>Giuseppe</forenames></author><author><keyname>Pirro</keyname><forenames>Michele</forenames></author><author><keyname>Kord</keyname><forenames>Ahmed</forenames></author><author><keyname>Sounas</keyname><forenames>Dimitrios</forenames></author><author><keyname>Xiao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Cassella</keyname><forenames>Cristian</forenames></author><author><keyname>Alu</keyname><forenames>Andrea</forenames></author><author><keyname>Rinaldi</keyname><forenames>Matteo</forenames></author></authors><title>Radio Frequency Magnet-free Circulators Based on Spatiotemporal
  Modulation of Surface Acoustic Wave Filters</title><categories>eess.SP</categories><doi>10.1109/TMTT.2019.2943291</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new generation of magnet-free circulators with high
performance is proposed. Circulators are crucial devices in modern
communication systems due to their ability to enable full-duplexing and double
the spectral efficiency directly in the physical layer of the radio-frequency
(RF) front-end. Traditionally, Lorentz reciprocity is broken by applying
magnetic bias to ferrite materials, therefore conventional circulators are
bulky and expensive. In this paper, this problem is addressed by replacing the
magnetic bias with periodic spatiotemporal modulation. Compared to previous
works, the proposed circulator is constructed using surface acoustic wave (SAW)
filters instead of transmission lines (TL), which reduces the modulation
frequency by at least a factor of 20 and ensures ultra-low power consumption
and high linearity. The miniaturized high quality (Q) factor SAW filters also
lead to a low-loss non-reciprocal band with strong isolation (IX) and broad
bandwidth (BW) on a chip scale, therefore addressing such limitations in
previous magnet-free demonstrations. Furthermore, compared to the conventional
differential circuit configuration, a novel quad configuration is developed,
which doubles the intermodulation-free bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13300</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13300</id><created>2019-05-23</created><authors><author><keyname>Chen</keyname><forenames>Lin</forenames></author><author><keyname>Yang</keyname><forenames>Haizhao</forenames></author></authors><title>Generative Imaging and Image Processing via Generative Encoder</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel generative encoder (GE) model for generative
imaging and image processing with applications in compressed sensing and
imaging, image compression, denoising, inpainting, deblurring, and
super-resolution. The GE model consists of a pre-training phase and a solving
phase. In the pre-training phase, we separately train two deep neural networks:
a generative adversarial network (GAN) with a generator $\G$ that captures the
data distribution of a given image set, and an auto-encoder (AE) network with
an encoder $\EN$ that compresses images following the estimated distribution by
GAN. In the solving phase, given a noisy image $x=\mathcal{P}(x^*)$, where
$x^*$ is the target unknown image, $\mathcal{P}$ is an operator adding an
addictive, or multiplicative, or convolutional noise, or equivalently given
such an image $x$ in the compressed domain, i.e., given $m=\EN(x)$, we solve
the optimization problem
  \[
  z^*=\underset{z}{\mathrm{argmin}} \|\EN(\G(z))-m\|_2^2+\lambda\|z\|_2^2
  \] to recover the image $x^*$ in a generative way via
$\hat{x}:=\G(z^*)\approx x^*$, where $\lambda&gt;0$ is a hyperparameter. The GE
model unifies the generative capacity of GANs and the stability of AEs in an
optimization framework above instead of stacking GANs and AEs into a single
network or combining their loss functions into one as in existing literature.
Numerical experiments show that the proposed model outperforms several
state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13306</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13306</id><created>2019-05-23</created><authors><author><keyname>Lehman</keyname><forenames>Charles</forenames></author><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Implicit Background Estimation for Semantic Segmentation</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene understanding and semantic segmentation are at the core of many
computer vision tasks, many of which, involve interacting with humans in
potentially dangerous ways. It is therefore paramount that techniques for
principled design of robust models be developed. In this paper, we provide
analytic and empirical evidence that correcting potentially errant non-distinct
mappings that result from the softmax function can result in improving
robustness characteristics on a state-of-the-art semantic segmentation model
with minimal impact to performance and minimal changes to the code base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13312</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13312</id><created>2019-05-23</created><authors><author><keyname>Wang</keyname><forenames>Li</forenames></author><author><keyname>Wang</keyname><forenames>Lihui</forenames></author><author><keyname>Chen</keyname><forenames>Qijian</forenames></author><author><keyname>Sun</keyname><forenames>Caixia</forenames></author><author><keyname>Cheng</keyname><forenames>Xinyu</forenames></author><author><keyname>Zhu</keyname><forenames>Yuemin</forenames></author></authors><title>Convolutional Restricted Boltzmann Machine Based-Radiomics for
  Prediction of Pathological Complete Response to Neoadjuvant Chemotherapy in
  Breast Cancer</title><categories>eess.IV cs.CV</categories><comments>8 pages, 6 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed a novel convolutional restricted Boltzmann machine CRBM-based
radiomic method for predicting pathologic complete response (pCR) to
neoadjuvant chemotherapy treatment (NACT) in breast cancer. The method consists
of extracting semantic features from CRBM network, and pCR prediction. It was
evaluated on the dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI)
data of 57 patients and using the area under the receiver operating
characteristic curve (AUC). Traditional radiomics features and the semantic
features learned from CRBM network were extracted from the images acquired
before and after the administration of NACT. After the feature selection, the
support vector machine (SVM), logistic regression (LR) and random forest (RF)
were trained to predict the pCR status. Compared to traditional radiomic
methods, the proposed CRBM-based radiomic method yielded an AUC of 0.92 for the
prediction with the images acquired before and after NACT, and an AUC of 0.87
for the pretreatment prediction, which was increased by about 38%. The results
showed that the CRBM-based radiomic method provided a potential means for
accurately predicting the pCR to NACT in breast cancer before the treatment,
which is very useful for making more appropriate and personalized treatment
regimens.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13321</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13321</id><created>2019-05-30</created><authors><author><keyname>Rice</keyname><forenames>William</forenames></author></authors><title>Applying Generative Adversarial Networks to Intelligent Subsurface
  Imaging and Identification</title><categories>eess.IV cs.LG</categories><comments>Master's thesis, Networked Intelligence lab in the University of
  Tennessee at Chattanooga&#xc3;&#x83;&#xc2;&#xa2;&#xc3;&#x82;&#xc2;&#x80;&#xc3;&#x82;&#xc2;&#x99;s Sim Center (2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To augment training data for machine learning models in Ground Penetrating
Radar (GPR) data classification and identification, this thesis focuses on the
generation of realistic GPR data using Generative Adversarial Networks. An
innovative GAN architecture is proposed for generating GPR B-scans, which is,
to the author's knowledge, the first successful application of GAN to GPR
B-scans. As one of the major contributions, a novel loss function is formulated
by merging frequency domain with time domain features. To test the efficacy of
generated B-scans, a real time object classifier is proposed to measure the
performance gain derived from augmented B-Scan images. The numerical experiment
illustrated that, based on the augmented training data, the proposed GAN
architecture demonstrated a significant increase (from 82% to 98%) in the
accuracy of the object classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13378</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13378</id><created>2019-05-30</created><authors><author><keyname>Lee</keyname><forenames>Hoon</forenames></author><author><keyname>Lee</keyname><forenames>Sang Hyun</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author></authors><title>Deep Learning for Distributed Optimization: Applications to Wireless
  Resource Management</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>to appear in IEEE J. Sel. Areas Commun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a deep learning (DL) framework to solve distributed
non-convex constrained optimizations in wireless networks where multiple
computing nodes, interconnected via backhaul links, desire to determine an
efficient assignment of their states based on local observations. Two different
configurations are considered: First, an infinite-capacity backhaul enables
nodes to communicate in a lossless way, thereby obtaining the solution by
centralized computations. Second, a practical finite-capacity backhaul leads to
the deployment of distributed solvers equipped along with quantizers for
communication through capacity-limited backhaul. The distributed nature and the
nonconvexity of the optimizations render the identification of the solution
unwieldy. To handle them, deep neural networks (DNNs) are introduced to
approximate an unknown computation for the solution accurately. In consequence,
the original problems are transformed to training tasks of the DNNs subject to
non-convex constraints where existing DL libraries fail to extend
straightforwardly. A constrained training strategy is developed based on the
primal-dual method. For distributed implementation, a novel binarization
technique at the output layer is developed for quantization at each node. Our
proposed distributed DL framework is examined in various network configurations
of wireless resource management. Numerical results verify the effectiveness of
our proposed approach over existing optimization techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13388</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13388</id><created>2019-05-30</created><authors><author><keyname>Wang</keyname><forenames>Haonan</forenames></author><author><keyname>Lin</keyname><forenames>Jun</forenames></author><author><keyname>Wang</keyname><forenames>Zhongfeng</forenames></author></authors><title>Design Light-weight 3D Convolutional Networks for Video Recognition
  Temporal Residual, Fully Separable Block, and Fast Algorithm</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep 3-dimensional (3D) Convolutional Network (ConvNet) has shown promising
performance on video recognition tasks because of its powerful spatio-temporal
information fusion ability. However, the extremely intensive requirements on
memory access and computing power prohibit it from being used in
resource-constrained scenarios, such as portable and edge devices. So in this
paper, we first propose a two-stage Fully Separable Block (FSB) to
significantly compress the model sizes of 3D ConvNets. Then a feature
enhancement approach named Temporal Residual Gradient (TRG) is developed to
improve the performance of compressed model on video tasks, which provides
higher accuracy, faster convergency and better robustness. Moreover, in order
to further decrease the computing workload, we propose a hybrid Fast Algorithm
(hFA) to drastically reduce the computation complexity of convolutions. These
methods are effectively combined to design a light-weight and efficient ConvNet
for video recognition tasks. Experiments on the popular dataset report 2.3x
compression rate, 3.6x workload reduction, and 6.3% top-1 accuracy gain, over
the state-of-the-art SlowFast model, which is already a highly compact model.
The proposed methods also show good adaptability on traditional 3D ConvNet,
demonstrating 7.4x more compact model, 11.0x less workload, and 3.0% higher
accuracy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13394</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13394</id><created>2019-05-26</created><authors><author><keyname>Liu</keyname><forenames>Huafeng</forenames></author><author><keyname>Han</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Li</keyname><forenames>Xiangrui</forenames></author><author><keyname>Yao</keyname><forenames>Yazhou</forenames></author><author><keyname>Huang</keyname><forenames>Pu</forenames></author><author><keyname>Tang</keyname><forenames>Zhenming</forenames></author></authors><title>Deep Representation Learning for Road Detection through Siamese Network</title><categories>cs.CV eess.IV</categories><comments>Accepted by Multimedia Tools and Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust road detection is a key challenge in safe autonomous driving.
Recently, with the rapid development of 3D sensors, more and more researchers
are trying to fuse information across different sensors to improve the
performance of road detection. Although many successful works have been
achieved in this field, methods for data fusion under deep learning framework
is still an open problem. In this paper, we propose a Siamese deep neural
network based on FCN-8s to detect road region. Our method uses data collected
from a monocular color camera and a Velodyne-64 LiDAR sensor. We project the
LiDAR point clouds onto the image plane to generate LiDAR images and feed them
into one of the branches of the network. The RGB images are fed into another
branch of our proposed network. The feature maps that these two branches
extract in multiple scales are fused before each pooling layer, via padding
additional fusion layers. Extensive experimental results on public dataset
KITTI ROAD demonstrate the effectiveness of our proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13399</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13399</id><created>2019-05-30</created><updated>2019-06-22</updated><authors><author><keyname>Gong</keyname><forenames>Yuan</forenames></author><author><keyname>Li</keyname><forenames>Boyang</forenames></author><author><keyname>Poellabauer</keyname><forenames>Christian</forenames></author><author><keyname>Shi</keyname><forenames>Yiyu</forenames></author></authors><title>Real-Time Adversarial Attacks</title><categories>cs.CR cs.LG cs.SD eess.AS</categories><comments>To Appear in the Proceedings of the 28th International Joint
  Conference on Artificial Intelligence (IJCAI 2019). Code:
  https://github.com/YuanGongND/realtime-adversarial-attack</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, many efforts have demonstrated that modern machine learning
algorithms are vulnerable to adversarial attacks, where small, but carefully
crafted, perturbations on the input can make them fail. While these attack
methods are very effective, they only focus on scenarios where the target model
takes static input, i.e., an attacker can observe the entire original sample
and then add a perturbation at any point of the sample. These attack approaches
are not applicable to situations where the target model takes streaming input,
i.e., an attacker is only able to observe past data points and add
perturbations to the remaining (unobserved) data points of the input. In this
paper, we propose a real-time adversarial attack scheme for machine learning
models with streaming inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13406</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13406</id><created>2019-05-31</created><authors><author><keyname>Chowdhury</keyname><forenames>Md Moin Uddin</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>RSS-Based Q-Learning for Indoor UAV Navigation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the potential use of unmanned aerial vehicles
(UAVs) for search and rescue (SAR) missions in GPS-denied indoor environments.
We consider the problem of navigating a UAV to a wireless signal source, e.g.,
a smartphone or watch owned by a victim. We assume that the source periodically
transmits RF signals to nearby wireless access points. Received signal strength
(RSS) at the UAV, which is a function of the UAV and source positions, is fed
to a Q-learning algorithm and the UAV is navigated to the vicinity of the
source. Unlike the traditional location-based Q-learning approach that uses the
GPS coordinates of the agent, our method uses the RSS to define the states and
rewards of the algorithm. It does not require any a priori information about
the environment. These, in turn, make it possible to use the UAVs in indoor SAR
operations. Two indoor scenarios with different dimensions are created using a
ray tracing software. Then, the corresponding heat maps that show the RSS at
each possible UAV location are extracted for more realistic analysis.
Performance of the RSS-based Q-learning algorithm is compared with the baseline
(location-based) Q-learning algorithm in terms of convergence speed, average
number of steps per episode, and the total length of the final trajectory. Our
results show that the RSS-based Q-learning provides competitive performance
with the location-based Q-learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13408</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13408</id><created>2019-05-31</created><updated>2019-11-24</updated><authors><author><keyname>Luo</keyname><forenames>Zhenwei</forenames></author></authors><title>Improving the resolution of CryoEM single particle analysis</title><categories>eess.IV math.OC stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We presented a new 3D refinement method for CryoEM single particle analysis
which can improve the resolution of final electron density map in this paper.
We proposed to enforce both sparsity and smoothness to improve the regularity
of electron density map in the refinement process. To achieve this goal, we
designed a novel type of real space penalty function and incorporated it into
the refinement process. We bridged the backprojection step with local kernel
regression, thus enable us to embed the 3D model in reproducing kernel Hilbert
space using specific kernels. We also proposed a first order method to solve
the resulting optimization problem and implemented it efficiently with CUDA. We
compared the performance of our new method with respect to the traditional
method on real datasets using a set of widely used metrics for CryoEM model
validation. We demonstrated that our method outperforms the traditional method
in terms of those metrics. The implementation of our method can be found at
https://github.com/alncat/cryoem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13412</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13412</id><created>2019-05-31</created><authors><author><keyname>Alfarraj</keyname><forenames>Motaz</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Semi-supervised Learning for Acoustic Impedance Inversion</title><categories>eess.IV eess.SP physics.geo-ph</categories><comments>An extended abstract publish in SEG2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent applications of deep learning in the seismic domain have shown great
potential in different areas such as inversion and interpretation. Deep
learning algorithms, in general, require tremendous amounts of labeled data to
train properly. To overcome this issue, we propose a semi-supervised framework
for acoustic impedance inversion based on convolutional and recurrent neural
networks. Specifically, seismic traces and acoustic impedance traces are
modeled as time series. Then, a neural-network-based inversion model comprising
convolutional and recurrent neural layers is used to invert seismic data for
acoustic impedance. The proposed workflow uses well log data to guide the
inversion. In addition, it utilizes a learned seismic forward model to
regularize the training and to serve as a geophysical constraint for the
inversion. The proposed workflow achieves an average correlation of 98% between
the estimated and target elastic impedance using 20 AI traces for training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13448</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13448</id><created>2019-05-31</created><authors><author><keyname>Xu</keyname><forenames>Xuenan</forenames></author><author><keyname>Dinkel</keyname><forenames>Heinrich</forenames></author><author><keyname>Wu</keyname><forenames>Mengyue</forenames></author><author><keyname>Yu</keyname><forenames>Kai</forenames></author></authors><title>What does a Car-ssette tape tell?</title><categories>cs.SD cs.CL eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Captioning has attracted much attention in image and video understanding
while little work examines audio captioning. This paper contributes a
manually-annotated dataset on car scene, in extension to a previously published
hospital audio captioning dataset. An encoder-decoder model with pretrained
word embeddings and additional sentence loss is proposed. This current model
can accelerate the training process and generate semantically correct but
unseen unique sentences. We test the model on the current car dataset, previous
Hospital Dataset and the Joint Dataset, indicating its generalization
capability across different scenes. Further, we make an effort to provide a
better objective evaluation metric, namely the BERT similarity score. It
compares the semantic-level similarity and compensates for drawbacks of N-gram
based metrics like BLEU, namely high scores for word-similar sentences. This
new metric demonstrates higher correlation with human evaluation. However,
though detailed audio captions can now be automatically generated, human
annotations still outperform model captions in many aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13456</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13456</id><created>2019-05-31</created><updated>2019-10-09</updated><authors><author><keyname>Han</keyname><forenames>Changhee</forenames></author><author><keyname>Rundo</keyname><forenames>Leonardo</forenames></author><author><keyname>Araki</keyname><forenames>Ryosuke</forenames></author><author><keyname>Nagano</keyname><forenames>Yudai</forenames></author><author><keyname>Furukawa</keyname><forenames>Yujiro</forenames></author><author><keyname>Mauri</keyname><forenames>Giancarlo</forenames></author><author><keyname>Nakayama</keyname><forenames>Hideki</forenames></author><author><keyname>Hayashi</keyname><forenames>Hideaki</forenames></author></authors><title>Combining Noise-to-Image and Image-to-Image GANs: Brain MR Image
  Augmentation for Tumor Detection</title><categories>eess.IV cs.AI cs.CV</categories><comments>12 pages, 7 figures, accepted to IEEE ACCESS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNNs) achieve excellent computer-assisted
diagnosis with sufficient annotated training data. However, most medical
imaging datasets are small and fragmented. In this context, Generative
Adversarial Networks (GANs) can synthesize realistic/diverse additional
training images to fill the data lack in the real image distribution;
researchers have improved classification by augmenting data with noise-to-image
(e.g., random noise samples to diverse pathological images) or image-to-image
GANs (e.g., a benign image to a malignant one). Yet, no research has reported
results combining noise-to-image and image-to-image GANs for further
performance boost. Therefore, to maximize the DA effect with the GAN
combinations, we propose a two-step GAN-based DA that generates and refines
brain Magnetic Resonance (MR) images with/without tumors separately: (i)
Progressive Growing of GANs (PGGANs), multi-stage noise-to-image GAN for
high-resolution MR image generation, first generates realistic/diverse 256 X
256 images; (ii) Multimodal UNsupervised Image-to-image Translation (MUNIT)
that combines GANs/Variational AutoEncoders or SimGAN that uses a DA-focused
GAN loss, further refines the texture/shape of the PGGAN-generated images
similarly to the real ones. We thoroughly investigate CNN-based tumor
classification results, also considering the influence of pre-training on
ImageNet and discarding weird-looking GAN-generated images. The results show
that, when combined with classic DA, our two-step GAN-based DA can
significantly outperform the classic DA alone, in tumor detection (i.e.,
boosting sensitivity 93.67% to 97.48%) and also in other medical imaging tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13510</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13510</id><created>2019-05-31</created><authors><author><keyname>Qin</keyname><forenames>Zhijin</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author><author><keyname>McCann</keyname><forenames>Julie A.</forenames></author></authors><title>Performance Analysis of Clustered LoRa Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper has been accepted by IEEE Trans. Vehicular Technology
  (TVT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the uplink transmission performance of
low-power wide-area (LPWA) networks with regards to coexisting radio modules.
We adopt long range (LoRa) radio technique as an example of the network of
focus even though our analysis can be easily extended to other situations. We
exploit a new topology to model the network, where the node locations of LoRa
follow a Poisson cluster process (PCP) while other coexisting radio modules
follow a Poisson point process (PPP). Unlike most of the performance analysis
based on stochastic geometry, we take noise into consideration. More
specifically, two models, with a fixed and a random number of active LoRa nodes
in each cluster, respectively, are considered. To obtain insights, both the
exact and simple approximated expressions for coverage probability are derived.
Based on them, area spectral efficiency and energy efficiency are obtained.
From our analysis, we show how the performance of LPWA networks can be enhanced
through adjusting the density of LoRa nodes around each LoRa receiver.
Moreover, the simulation results unveil that the optimal number of active LoRa
nodes in each cluster exists to maximize the area spectral efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13533</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13533</id><created>2019-05-28</created><authors><author><keyname>Lu</keyname><forenames>Yantao</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Autonomous Human Activity Classification from Ego-vision Camera and
  Accelerometer Data</title><categories>cs.CV eess.IV</categories><comments>Accepted for presentation at EPIC@CVPR2019 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been significant amount of research work on human activity
classification relying either on Inertial Measurement Unit (IMU) data or data
from static cameras providing a third-person view. Using only IMU data limits
the variety and complexity of the activities that can be detected. For
instance, the sitting activity can be detected by IMU data, but it cannot be
determined whether the subject has sat on a chair or a sofa, or where the
subject is. To perform fine-grained activity classification from egocentric
videos, and to distinguish between activities that cannot be differentiated by
only IMU data, we present an autonomous and robust method using data from both
ego-vision cameras and IMUs. In contrast to convolutional neural network-based
approaches, we propose to employ capsule networks to obtain features from
egocentric video data. Moreover, Convolutional Long Short Term Memory framework
is employed both on egocentric videos and IMU data to capture temporal aspect
of actions. We also propose a genetic algorithm-based approach to autonomously
and systematically set various network parameters, rather than using manual
settings. Experiments have been performed to perform 9- and 26-label activity
classification, and the proposed method, using autonomously set network
parameters, has provided very promising results, achieving overall accuracies
of 86.6\% and 77.2\%, respectively. The proposed approach combining both
modalities also provides increased accuracy compared to using only egovision
data and only IMU data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13536</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13536</id><created>2019-05-24</created><authors><author><keyname>Canel</keyname><forenames>Christopher</forenames></author><author><keyname>Kim</keyname><forenames>Thomas</forenames></author><author><keyname>Zhou</keyname><forenames>Giulio</forenames></author><author><keyname>Li</keyname><forenames>Conglong</forenames></author><author><keyname>Lim</keyname><forenames>Hyeontaek</forenames></author><author><keyname>Andersen</keyname><forenames>David G.</forenames></author><author><keyname>Kaminsky</keyname><forenames>Michael</forenames></author><author><keyname>Dulloor</keyname><forenames>Subramanya R.</forenames></author></authors><title>Scaling Video Analytics on Constrained Edge Nodes</title><categories>cs.CV cs.LG cs.PF eess.IV stat.ML</categories><comments>This paper is an extended version of a paper with the same title
  published in the 2nd SysML Conference, SysML '19 (Canel et. al., 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As video camera deployments continue to grow, the need to process large
volumes of real-time data strains wide area network infrastructure. When
per-camera bandwidth is limited, it is infeasible for applications such as
traffic monitoring and pedestrian tracking to offload high-quality video
streams to a datacenter. This paper presents FilterForward, a new edge-to-cloud
system that enables datacenter-based applications to process content from
thousands of cameras by installing lightweight edge filters that backhaul only
relevant video frames. FilterForward introduces fast and expressive
per-application microclassifiers that share computation to simultaneously
detect dozens of events on computationally constrained edge nodes. Only
matching events are transmitted to the cloud. Evaluation on two real-world
camera feed datasets shows that FilterForward reduces bandwidth use by an order
of magnitude while improving computational efficiency and event detection
accuracy for challenging video content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13544</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13544</id><created>2019-05-28</created><authors><author><keyname>Lu</keyname><forenames>Mingyang</forenames></author><author><keyname>Yin</keyname><forenames>Liyuan</forenames></author><author><keyname>Peyton</keyname><forenames>Anthony J.</forenames></author><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author></authors><title>A Novel Compensation Algorithm for Thickness Measurement Immune to
  Lift-Off Variations Using Eddy Current Method</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1905.12515</comments><doi>10.1109/TIM.2016.2600918</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lift-off variation causes errors in the eddy current thickness measurements
of metallic plates. In this paper, we have developed an algorithm that can
compensate for this variation and produce an index that is linked to the
thickness, but is virtually independent of lift-off. This index, termed as the
compensated peak frequency, can be obtained from the measured multifrequency
inductance spectral data using the algorithm we developed in this paper. This
method has been derived through mathematical manipulation and verified by both
the simulation and experimental data. Accuracy in the thickness measurements at
different lift-offs proved to be within 2%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13546</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13546</id><created>2019-05-28</created><authors><author><keyname>Struckmeier</keyname><forenames>Oliver</forenames></author></authors><title>LeagueAI: Improving object detector performance and flexibility through
  automatically generated training data and domain randomization</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this technical report I present my method for automatic synthetic dataset
generation for object detection and demonstrate it on the video game League of
Legends. This report furthermore serves as a handbook on how to automatically
generate datasets and as an introduction on the dataset generation part of the
LeagueAI framework. The LeagueAI framework is a software framework that
provides detailed information about the game League of Legends based on the
same input a human player would have, namely vision. The framework allows
researchers and enthusiasts to develop their own intelligent agents or to
extract detailed information about the state of the game. A big problem of
machine vision applications usually is the laborious work of gathering large
amounts of hand labeled data. Thus, a crucial part of the vision pipeline of
the LeagueAI framework, the dataset generation, is presented in this report.
The method involves extracting image raw data from the game's 3D models and
combining them with the game background to create game-like synthetic images
and to generate the corresponding labels automatically. In an experiment I
compared a model trained on synthetic data to a model trained on hand labeled
data and a model trained on a combined dataset. The model trained on the
synthetic data showed higher detection precision on more classes and more
reliable tracking performance of the player character. The model trained on the
combined dataset did not perform better because of the different formats of the
older hand labeled dataset and the synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13550</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13550</id><created>2019-05-30</created><authors><author><keyname>Du</keyname><forenames>Pei</forenames></author><author><keyname>Wang</keyname><forenames>Jianzhou</forenames></author><author><keyname>Hao</keyname><forenames>Yan</forenames></author><author><keyname>Niu</keyname><forenames>Tong</forenames></author><author><keyname>Yang</keyname><forenames>Wendong</forenames></author></authors><title>A novel hybrid model based on multi-objective Harris hawks optimization
  algorithm for daily PM2.5 and PM10 forecasting</title><categories>cs.LG eess.SP stat.AP stat.ML</categories><comments>24 pages, 4 figures</comments><msc-class>68U20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High levels of air pollution may seriously affect people's living environment
and even endanger their lives. In order to reduce air pollution concentrations,
and warn the public before the occurrence of hazardous air pollutants, it is
urgent to design an accurate and reliable air pollutant forecasting model.
However, most previous research have many deficiencies, such as ignoring the
importance of predictive stability, and poor initial parameters and so on,
which have significantly effect on the performance of air pollution prediction.
Therefore, to address these issues, a novel hybrid model is proposed in this
study. Specifically, a powerful data preprocessing techniques is applied to
decompose the original time series into different modes from low- frequency to
high- frequency. Next, a new multi-objective algorithm called MOHHO is first
developed in this study, which are introduced to tune the parameters of ELM
model with high forecasting accuracy and stability for air pollution series
prediction, simultaneously. And the optimized ELM model is used to perform the
time series prediction. Finally, a scientific and robust evaluation system
including several error criteria, benchmark models, and several experiments
using six air pollutant concentrations time series from three cities in China
is designed to perform a compressive assessment for the presented hybrid
forecasting model. Experimental results indicate that the proposed hybrid model
can guarantee a more stable and higher predictive performance compared to
others, whose superior prediction ability may help to develop effective plans
for air pollutant emissions and prevent health problems caused by air
pollution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13553</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13553</id><created>2019-05-30</created><updated>2020-02-20</updated><authors><author><keyname>Yang</keyname><forenames>Honglei</forenames></author><author><keyname>Wang</keyname><forenames>Haifeng</forenames></author><author><keyname>Yi</keyname><forenames>Hang</forenames></author><author><keyname>Wang</keyname><forenames>Xueyun</forenames></author><author><keyname>Wang</keyname><forenames>Hongbo</forenames></author><author><keyname>Zhang</keyname><forenames>Shengkang</forenames></author></authors><title>Picosecond-precision optical time transfer in free space using flexible
  binary offset carrier modulation</title><categories>eess.SP physics.ins-det</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free-space optical time transfer that features high precision and flexibility
will act a crucial role in near-future ground-to-satellite/inter-satellite
clock networks and outdoor timing services. Here we propose a free-space
optical flexible-binary-offset-carrier-modulated (FlexBOC-modulated) time
transfer method. The utilized FlexBOC modulation could yield a comparative
precision, although its occupied bandwidth is tremendously reduced by at least
97.5% compared to optical binary phase modulation. Meanwhile, the adoption of
optical techniques eliminates the multi-path effect that is major limit in the
current microwave satellite time transfer system. What's more, the time
interval measurement avoids a continuous link that may be routinely broken by
physical obstructions. For verification, a time transfer experiment with our
home-built system between two sites separated by a 30-m free-space path outside
the laboratory was conducted. Over a 15 h period, the time deviation is 2.3 ps
in a 1-s averaging time, and averages down to 1.0 ps until ~60 s. The
fractional frequency instability exhibits 4.0E-12 at a gate time of 1 s, and
approaches to 2.6E10-15 at 10000 s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13561</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13561</id><created>2019-05-29</created><authors><author><keyname>Fang</keyname><forenames>Fuming</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Echizen</keyname><forenames>Isao</forenames></author><author><keyname>Todisco</keyname><forenames>Massimiliano</forenames></author><author><keyname>Evans</keyname><forenames>Nicholas</forenames></author><author><keyname>Bonastre</keyname><forenames>Jean-Francois</forenames></author></authors><title>Speaker Anonymization Using X-vector and Neural Waveform Models</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Submitted to the 10th ISCA Speech Synthesis Workshop (SSW10)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The social media revolution has produced a plethora of web services to which
users can easily upload and share multimedia documents. Despite the popularity
and convenience of such services, the sharing of such inherently personal data,
including speech data, raises obvious security and privacy concerns. In
particular, a user's speech data may be acquired and used with speech synthesis
systems to produce high-quality speech utterances which reflect the same user's
speaker identity. These utterances may then be used to attack speaker
verification systems. One solution to mitigate these concerns involves the
concealing of speaker identities before the sharing of speech data. For this
purpose, we present a new approach to speaker anonymization. The idea is to
extract linguistic and speaker identity features from an utterance and then to
use these with neural acoustic and waveform models to synthesize anonymized
speech. The original speaker identity, in the form of timbre, is suppressed and
replaced with that of an anonymous pseudo identity. The approach exploits
state-of-the-art x-vector speaker representations. These are used to derive
anonymized pseudo speaker identities through the combination of multiple,
random speaker x-vectors. Experimental results show that the proposed approach
is effective in concealing speaker identities. It increases the equal error
rate of a speaker verification system while maintaining high quality,
anonymized speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13567</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13567</id><created>2019-05-30</created><authors><author><keyname>Hung</keyname><forenames>Yun-Ning</forenames></author><author><keyname>Chiang</keyname><forenames>I-Tung</forenames></author><author><keyname>Chen</keyname><forenames>Yi-An</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Musical Composition Style Transfer via Disentangled Timbre
  Representations</title><categories>eess.AS cs.SD</categories><comments>Accepted by the 28th International Joint Conference on Artificial
  Intelligence. arXiv admin note: text overlap with arXiv:1811.03271</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Music creation involves not only composing the different parts (e.g., melody,
chords) of a musical work but also arranging/selecting the instruments to play
the different parts. While the former has received increasing attention, the
latter has not been much investigated. This paper presents, to the best of our
knowledge, the first deep learning models for rearranging music of arbitrary
genres. Specifically, we build encoders and decoders that take a piece of
polyphonic musical audio as input and predict as output its musical score. We
investigate disentanglement techniques such as adversarial training to separate
latent factors that are related to the musical content (pitch) of different
parts of the piece, and that are related to the instrumentation (timbre) of the
parts per short-time segment. By disentangling pitch and timbre, our models
have an idea of how each piece was composed and arranged. Moreover, the models
can realize &quot;composition style transfer&quot; by rearranging a musical piece without
much affecting its pitch content. We validate the effectiveness of the models
by experiments on instrument activity detection and composition style transfer.
To facilitate follow-up research, we open source our code at
https://github.com/biboamy/instrument-disentangle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13573</identifier>
 <datestamp>2019-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13573</id><created>2019-05-30</created><updated>2019-12-11</updated><authors><author><keyname>Liu</keyname><forenames>Yi-Wen</forenames></author><author><keyname>Kao</keyname><forenames>Sheng-Lun</forenames></author><author><keyname>Wu</keyname><forenames>Hau-Tieng</forenames></author><author><keyname>Liu</keyname><forenames>Tzu-Chi</forenames></author><author><keyname>Fang</keyname><forenames>Te-Yung</forenames></author><author><keyname>Wang</keyname><forenames>Pa-Chun</forenames></author></authors><title>Transient-evoked otoacoustic emission signals predicting outcomes of
  acute sensorineural hearing loss in patients with Meniere's Disease</title><categories>eess.SP cs.LG stat.ML</categories><comments>This is a journal version accepted by Acta Oto-Laryngologica on
  December 6, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Fluctuating hearing loss is characteristic of Meniere's Disease
(MD) during acute episodes. However, no reliable audiometric hallmarks are
available for counselling the hearing recovery possibility. Aims/Objectives: To
find parameters for predicting MD hearing outcomes. Material and Methods: We
applied machine learning techniques to analyse transient-evoked otoacoustic
emission (TEOAE) signals recorded from patients with MD. Thirty unilateral MD
patients were recruited prospectively after onset of acute cochleo-vestibular
symptoms. Serial TEOAE and pure-tone audiogram (PTA) data were recorded
longitudinally. Denoised TEOAE signals were projected onto the three most
prominent principal directions through a linear transformation. Binary
classification was performed using a support vector machine (SVM). TEOAE signal
parameters, including signal energy and group delay, were compared between
improved and nonimproved groups using Welchs t-test. Results: Signal energy did
not differ (p = 0.64) but a significant difference in 1-kHz (p = 0.045) group
delay was recorded between improved and nonimproved groups. The SVM achieved a
cross-validated accuracy of &gt;80% in predicting hearing outcomes. Conclusions
and Significance: This study revealed that baseline TEOAE parameters obtained
during acute MD episodes, when processed through machine learning technology,
may provide information on outer hair cell function to predict hearing
recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13575</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13575</id><created>2019-05-31</created><authors><author><keyname>Armstrong</keyname><forenames>John A.</forenames></author><author><keyname>Fletcher</keyname><forenames>Lyndsay</forenames></author></authors><title>Fast Solar Image Classification Using Deep Learning and its Importance
  for Automation in Solar Physics</title><categories>astro-ph.SR astro-ph.IM cs.CV eess.IV</categories><comments>19 pages, 9 figures, accepted for publication in Solar Physics</comments><doi>10.1007/s11207-019-1473-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The volume of data being collected in solar physics has exponentially
increased over the past decade and with the introduction of the $\textit{Daniel
K. Inouye Solar Telescope}$ (DKIST) we will be entering the age of petabyte
solar data. Automated feature detection will be an invaluable tool for
post-processing of solar images to create catalogues of data ready for
researchers to use. We propose a deep learning model to accomplish this; a deep
convolutional neural network is adept at feature extraction and processing
images quickly. We train our network using data from $\textit{Hinode/Solar
Optical Telescope}$ (SOT) H$\alpha$ images of a small subset of solar features
with different geometries: filaments, prominences, flare ribbons, sunspots and
the quiet Sun ($\textit{i.e.}$ the absence of any of the other four features).
We achieve near perfect performance on classifying unseen images from SOT
($\approx$99.9\%) in 4.66 seconds. We also for the first time explore transfer
learning in a solar context. Transfer learning uses pre-trained deep neural
networks to help train new deep learning models $\textit{i.e.}$ it teaches a
new model. We show that our network is robust to changes in resolution by
degrading images from SOT resolution ($\approx$0.33$^{\prime \prime}$ at
$\lambda$=6563\AA{}) to $\textit{Solar Dynamics Observatory/Atmospheric Imaging
Assembly}$ (SDO/AIA) resolution ($\approx$1.2$^{\prime \prime}$) without a
change in performance of our network. However, we also observe where the
network fails to generalise to sunspots from SDO/AIA bands 1600/1700\AA{} due
to small-scale brightenings around the sunspots and prominences in SDO/AIA
304\AA{} due to coronal emission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13594</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13594</id><created>2019-05-31</created><authors><author><keyname>Jiao</keyname><forenames>Shuming</forenames></author><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Lei</keyname><forenames>Ting</forenames></author><author><keyname>Xie</keyname><forenames>Zhenwei</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaocong</forenames></author></authors><title>Known-plaintext attack and ciphertext-only attack for encrypted
  single-pixel imaging</title><categories>eess.IV cs.CR cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many previous works, a single-pixel imaging (SPI) system is constructed as
an optical image encryption system. Unauthorized users are not able to
reconstruct the plaintext image from the ciphertext intensity sequence without
knowing the illumination pattern key. However, little cryptanalysis about
encrypted SPI has been investigated in the past. In this work, we propose a
known-plaintext attack scheme and a ciphertext-only attack scheme to an
encrypted SPI system for the first time. The known-plaintext attack is
implemented by interchanging the roles of illumination patterns and object
images in the SPI model. The ciphertext-only attack is implemented based on the
statistical features of single-pixel intensity values. The two schemes can
crack encrypted SPI systems and successfully recover the key containing correct
illumination patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13598</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13598</id><created>2019-05-29</created><authors><author><keyname>Familua</keyname><forenames>Ayokunle Damilola</forenames></author></authors><title>A Block Diagonal Markov Model for Indoor Software-Defined Power Line
  Communication</title><categories>eess.SP cs.LG stat.AP stat.ML</categories><comments>Conference Paper with 9 pages, 6 figures, 3 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Semi-Hidden Markov Model (SHMM) for bursty error channels is defined by a
state transition probability matrix $A$, a prior probability vector $\Pi$, and
the state dependent output symbol error probability matrix $B$. Several
processes are utilized for estimating $A$, $\Pi$ and $B$ from a given
empirically obtained or simulated error sequence. However, despite placing some
restrictions on the underlying Markov model structure, we still have a
computationally intensive estimation procedure, especially given a large error
sequence containing long burst of identical symbols. Thus, in this paper, we
utilize under some moderate assumptions, a Markov model with random state
transition matrix $A$ equivalent to a unique Block Diagonal Markov model with
state transition matrix $\Lambda$ to model an indoor software-defined power
line communication system. A computationally efficient modified Baum-Welch
algorithm for estimation of $\Lambda$ given an experimentally obtained error
sequence from the indoor PLC channel is utilized. Resulting Equivalent Block
Diagonal Markov models assist designers to accelerate and facilitate the
procedure of novel PLC systems design and evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13667</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13667</id><created>2019-05-31</created><updated>2020-02-14</updated><authors><author><keyname>Ede</keyname><forenames>Jeffrey M.</forenames></author><author><keyname>Beanland</keyname><forenames>Richard</forenames></author></authors><title>Partial Scanning Transmission Electron Microscopy with Deep Learning</title><categories>eess.IV cs.CV cs.LG</categories><comments>20 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Compressed sensing algorithms are used to decrease electron microscope scan
time and electron beam exposure with minimal information loss. Following
successful applications of deep learning to compressed sensing, we have
developed a two-stage multiscale generative adversarial neural network to
complete realistic 512$\times$512 scanning transmission electron micrographs
from spiral, jittered gridlike, and other partial scans. For spiral scans and
mean squared error based pre-training, this enables electron beam coverage to
be decreased by 17.9$\times$ with a 3.8\% test set root mean squared intensity
error, and by 87.0$\times$ with a 6.2\% error. Our generator networks are
trained on partial scans created from a new dataset of 16227 scanning
transmission electron micrographs. High performance is achieved with adaptive
learning rate clipping of loss spikes and an auxiliary trainer network. Our
source code, new dataset, and pre-trained models have been made publicly
available at https://github.com/Jeffrey-Ede/partial-STEM
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13689</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13689</id><created>2019-05-31</created><authors><author><keyname>Sch&#xe4;ufele</keyname><forenames>Daniel</forenames></author><author><keyname>Cavalcante</keyname><forenames>Renato L. G.</forenames></author><author><keyname>Stanczak</keyname><forenames>Slawomir</forenames></author></authors><title>Tensor Completion for Radio Map Reconstruction using Low Rank and
  Smoothness</title><categories>eess.SP</categories><doi>10.1109/SPAWC.2019.8815495</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio maps are important enablers for many applications in wireless networks,
ranging from network planning and optimization to fingerprint based
localization. Sampling the complete map is prohibitively expensive in practice,
so methods for reconstructing the complete map from a subset of measurements
are increasingly gaining attention in the literature. In this paper, we propose
two algorithms for this purpose, which build on existing approaches that aim at
minimizing the tensor rank while additionally enforcing smoothness of the radio
map. Experimental results with synthetic measurements derived via ray tracing
show that our algorithms outperform state of the art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13743</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13743</id><created>2019-05-31</created><authors><author><keyname>Soysal</keyname><forenames>Alkan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Age of Information in G/G/1/1 Systems: Age Expressions, Bounds, Special
  Cases, and Optimization</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Submitted for publication, May 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the age of information in G/G/1/1 systems under two service
discipline models. In the first model, if a new update arrives when the service
is busy, it is blocked; in the second model, a new update preempts the current
update in service. For the blocking model, we first derive an exact age
expression, then we propose two simple to calculate upper bounds for the
average age. The first upper bound assumes the interarrival times to have
log-concave distribution. The second upper bound assumes both the interarrivals
and service times to have log-concave distribution. Both upper bounds are tight
in the case of M/M/1/1 systems. We show that deterministic interarrivals and
service times are optimum for the blocking service model. In addition, using
the age expression for G/G/1/1 systems, we calculate average age expressions
for special cases, i.e., M/G/1/1 and G/M/1/1 systems. Next, for the preemption
in service model, we first derive an exact average age expression for G/G/1/1
systems. Then, we propose a simple to calculate upper bound for the average
age. In addition, similar to blocking discipline, using the age expression for
G/G/1/1 systems, we calculate average age expressions for special cases, i.e.,
M/G/1/1 and G/M/1/1 systems. Average age for G/M/1/1 can be written as a
summation of two terms, the first of which depends only on the first and second
moments of interarrival times and the second of which depends only on the
service rate. In other words, interarrival and service times are decoupled. We
show that deterministic interarrivals are optimum for G/M/1/1 systems. On the
other hand, we observe for non-exponential service times that the optimal
distribution of interarrival times depends on the relative values of the mean
interarrival time and the mean service time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.13749</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1905.13749</id><created>2019-05-28</created><authors><author><keyname>Liu</keyname><forenames>Juan</forenames></author><author><keyname>Koch</keyname><forenames>Kevin M.</forenames></author></authors><title>Deep Quantitative Susceptibility Mapping for Background Field Removal
  and Total Field Inversion</title><categories>physics.med-ph eess.IV</categories><comments>10 figures. arXiv admin note: substantial text overlap with
  arXiv:1904.07105</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Quantitative susceptibility mapping (QSM) utilizes MRI signal phase to
estimate local tissue susceptibility, which has been shown useful to provide
novel image contrast and as biomarkers of abnormal tissue. QSM requires
addressing a challenging post-processing problem: filtering of image phase
estimates and inversion of the phase to susceptibility relationship. A wide
variety of quantification errors, robustness limitations, and artifacts
constraints QSM clinical translation. To overcome these limitations, a robust
deep-learning-based QSM reconstruction approach is proposed to perform
background field removal and susceptibility inversion simultaneously from input
MRI phase images. Synthetic training data based on in-vivo data sources and
physics simulations were used for training. The network was quantitatively
tested using gold-standard in-silico labeled dataset against established
background field removal and QSM inversion approaches. In addition, the
algorithm was applied to a QSM challenge data and clinical
susceptibility-weighted imaging (SWI) data. When quantitatively compared
against gold-standard in-silico labels, the proposed algorithm outperformed the
existing comparable background field removal approaches and QSM reconstruction
algorithms. The QSM challenge data and clinical SWI data demonstrated that the
proposed approach was able to robustly generate high quality local field and
QSM with improved accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00053</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00053</id><created>2019-05-31</created><authors><author><keyname>Mirhosseini</keyname><forenames>Fahime Sadat</forenames></author><author><keyname>Pizzo</keyname><forenames>Andrea</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Tadaion</keyname><forenames>Aliakbar</forenames></author></authors><title>Spectral Efficiency Analysis in Dense Massive MIMO Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 5 figures, to be presented at SPAWC2019, Cannes, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the uplink of a Massive MIMO network wherein the base
stations (BSs) are randomly deployed according to a homogenous Poisson point
process of intensity $\lambda$. Each BS is equipped with $M$ antennas and
serves $K$ user equipments. A rigorous stochastic geometry framework with a
multi-slope path loss model and pilot-based channel estimation is used to
analyze the impact of $\lambda$ on channel estimation accuracy and spectral
efficiency. Both maximum ratio and zero-forcing combiners are considered.
Interesting analytical insights are provided into the interplay of network
parameters such as $\lambda$, antenna-UE ratio $M/K$, and pilot reuse factor.
The relative strength of pilot contamination and (inter- and intra-cell)
interference is analytically and numerically evaluated, as a function of
$\lambda$. It turns out that pilot contamination becomes relevant only for
impractical values of $M/K\ge 100$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00056</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00056</id><created>2019-05-31</created><authors><author><keyname>Chang</keyname><forenames>Huibin</forenames></author><author><keyname>Enfedaque</keyname><forenames>Pablo</forenames></author><author><keyname>Marchesini</keyname><forenames>Stefano</forenames></author></authors><title>Iterative chemical mapping for x-ray spectroscopic ptychography with
  (incomplete) dictionary</title><categories>eess.IV math.OC</categories><comments>13 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectroscopic ptychography is a powerful technique to determine the chemical
composition of a sample with high spatial resolution. In spectro-ptychography a
sample is rastered through a focused beam of x-rays with varying photon energy
and a series of phaseless diffraction data is recorded. Each chemical component
in the material under investigation has a characteristic absorption or phase
contrast as a function of photon energy. Using a reference dictionary formed by
the set of contrast functions of photon energy of the chemical components, it
is possible to obtain the chemical composition of the material from high
resolution multi-spectral images. Here we investigate the use of a known or an
incomplete dictionary (partially known) in spectroscopic blind-phase retrieval
ptychography. We establish a nonlinear spectroscopic ptychography model (SP)
model based on Poisson maximum likelihood, and develop fast iterative
operator-splitting based algorithms. We show that accurate chemical maps can be
recovered even when the scanning stepsizes (2$\times$FWHM of the probe) are
quite large in the case of Poisson noised measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00078</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00078</id><created>2019-05-31</created><authors><author><keyname>Wang</keyname><forenames>Dali</forenames></author><author><keyname>Lu</keyname><forenames>Zheng</forenames></author><author><keyname>Bao</keyname><forenames>Zhirong</forenames></author></authors><title>Augmenting C. elegans Microscopic Dataset for Accelerated Pattern
  Recognition</title><categories>eess.IV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detection of cell shape changes in 3D time-lapse images of complex
tissues is an important task. However, it is a challenging and tedious task to
establish a comprehensive dataset to improve the performance of deep learning
models. In the paper, we present a deep learning approach to augment 3D live
images of the Caenorhabditis elegans embryo, so that we can further speed up
the specific structural pattern recognition. We use an unsupervised training
over unlabeled images to generate supplementary datasets for further pattern
recognition. Technically, we used Alex-style neural networks in a generative
adversarial network framework to generate new datasets that have common
features of the C. elegans membrane structure. We also made the dataset
available for a broad scientific community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00101</identifier>
 <datestamp>2020-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00101</id><created>2019-05-31</created><updated>2020-01-07</updated><authors><author><keyname>LeBlanc</keyname><forenames>Joel W.</forenames></author><author><keyname>Thelen</keyname><forenames>Brian J.</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames></author></authors><title>Testing that a Local Optimum of the Likelihood is Globally Optimum using
  Reparameterized Embeddings</title><categories>eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many mathematical imaging problems are posed as non-convex optimization
problems. When numerically tractable global optimization procedures are not
available, one is often interested in testing ex post facto whether or not a
locally convergent algorithm has found the globally optimal solution. When the
problem is formulated in terms of maximizing the likelihood function of using a
statistical model, a local test of global optimality can be constructed. In
this paper, we develop such a test, based on a global maximum validation
function proposed by Biernacki, under the assumption that the statistical
distribution is in the generalized location family, a condition often satisfied
in inverse problems. In addition, a new reparameterization and embedding is
presented that exploits knowledge about the forward operator to improve the
global maximum validation function. It is shown that the reparameterized
embedding can be gainfully applied to a physically-motivated joint-inverse
problem arising in camera-blur estimation. Improved accuracy and reduced
computation are demonstrated for the proposed global maximum testing method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00165</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00165</id><created>2019-06-01</created><updated>2020-01-07</updated><authors><author><keyname>Zheng</keyname><forenames>Xuehang</forenames></author><author><keyname>Ravishankar</keyname><forenames>Saiprasad</forenames></author><author><keyname>Long</keyname><forenames>Yong</forenames></author><author><keyname>Klasky</keyname><forenames>Marc Louis</forenames></author><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author></authors><title>Two-layer Residual Sparsifying Transform Learning for Image
  Reconstruction</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted to IEEE ISBI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal models based on sparsity, low-rank and other properties have been
exploited for image reconstruction from limited and corrupted data in medical
imaging and other computational imaging applications. In particular,
sparsifying transform models have shown promise in various applications, and
offer numerous advantages such as efficiencies in sparse coding and learning.
This work investigates pre-learning a two-layer extension of the transform
model for image reconstruction, wherein the transform domain or filtering
residuals of the image are further sparsified in the second layer. The proposed
block coordinate descent optimization algorithms involve highly efficient
updates. Preliminary numerical experiments demonstrate the usefulness of a
two-layer model over the previous related schemes for CT image reconstruction
from low-dose measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00183</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00183</id><created>2019-06-01</created><authors><author><keyname>Eltayeb</keyname><forenames>Mohammed E.</forenames></author></authors><title>Relay-Aided Channel Estimation for mmWave Systems with Imperfect Antenna
  Arrays</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in IEEE ICC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Sensing (CS) based channel estimation techniques have recently
emerged as an effective way to acquire the channel of millimeter-wave (mmWave)
systems with a small number of measurements. These techniques, however, are
based on prior knowledge of transmit and receive array manifolds, and assume
perfect antenna arrays at both the transmitter and the receiver. In the
presence of antenna imperfections, the geometry and response of the arrays are
modified. This distorts the CS measurement matrix and results in channel
estimation errors. This paper studies the effects of both transmit and receive
antenna imperfections on the mmWave channel estimate. A relay-aided solution
which corrects for errors caused by faulty transmit arrays is then proposed.
Simulation results demonstrate the effectiveness of the proposed solution and
show that comparable channel estimates can be obtained when compared to systems
with perfect antennas without the need for additional training overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00204</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00204</id><created>2019-06-01</created><authors><author><keyname>Fezza</keyname><forenames>Sid Ahmed</forenames></author><author><keyname>Bakhti</keyname><forenames>Yassine</forenames></author><author><keyname>Hamidouche</keyname><forenames>Wassim</forenames></author><author><keyname>D&#xe9;forges</keyname><forenames>Olivier</forenames></author></authors><title>Perceptual Evaluation of Adversarial Attacks for CNN-based Image
  Classification</title><categories>cs.LG cs.CR cs.CV eess.IV stat.ML</categories><comments>Eleventh International Conference on Quality of Multimedia Experience
  (QoMEX 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNNs) have recently achieved state-of-the-art
performance and provide significant progress in many machine learning tasks,
such as image classification, speech processing, natural language processing,
etc. However, recent studies have shown that DNNs are vulnerable to adversarial
attacks. For instance, in the image classification domain, adding small
imperceptible perturbations to the input image is sufficient to fool the DNN
and to cause misclassification. The perturbed image, called \textit{adversarial
example}, should be visually as close as possible to the original image.
However, all the works proposed in the literature for generating adversarial
examples have used the $L_{p}$ norms ($L_{0}$, $L_{2}$ and $L_{\infty}$) as
distance metrics to quantify the similarity between the original image and the
adversarial example. Nonetheless, the $L_{p}$ norms do not correlate with human
judgment, making them not suitable to reliably assess the perceptual
similarity/fidelity of adversarial examples. In this paper, we present a
database for visual fidelity assessment of adversarial examples. We describe
the creation of the database and evaluate the performance of fifteen
state-of-the-art full-reference (FR) image fidelity assessment metrics that
could substitute $L_{p}$ norms. The database as well as subjective scores are
publicly available to help designing new metrics for adversarial examples and
to facilitate future research works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00220</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00220</id><created>2019-06-01</created><updated>2019-11-25</updated><authors><author><keyname>Mei</keyname><forenames>Weidong</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Cooperative Downlink Interference Transmission and Cancellation for
  Cellular-Connected UAV: A Divide-and-Conquer Approach</title><categories>cs.IT eess.SP math.IT</categories><comments>14 pages, 9 figures, accepted by IEEE Transactions on Communications</comments><doi>10.1109/TCOMM.2019.2955953</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The line-of-sight dominant air-ground channels have posed critical
interference issues in cellular-connected unmanned aerial vehicle (UAV)
communications. In this paper, we propose a new base station (BS) cooperative
beamforming (CB) technique for the cellular downlink to mitigate the strong
interference caused by the co-channel terrestrial transmissions to the UAV.
Besides the conventional CB by cooperatively transmitting the UAV's message,
the serving BSs of the UAVs exploit a novel interference transmission scheme to
effectively suppress the terrestrial interference to the UAV. Specifically, the
co-channel terrestrial users' messages are shared with the UAV's serving BSs
and transmitted via CB to cancel their resultant interference at the UAV. To
balance between the CB gains for UAV signal enhancement and interference
cancellation, we aim to maximize the UAV's receive
signal-to-interference-plus-noise ratio by jointly optimizing the power
allocations at all of its serving BSs for transmitting the UAV's and co-channel
terrestrial users' messages. First, we derive the closed-form optimal solution
to this problem in a special case and draw useful insights. Then, we propose an
algorithm to solve the problem optimally in the general case. As the optimal
solution requires centralized implementation with exorbitant message/channel
information exchanges among the BSs, we further propose a distributed algorithm
that is amenable to practical implementation, based on a new divide-and-conquer
approach, whereby each co-channel BS divides its perceived interference to the
UAV into multiple portions, each to be canceled by a different serving BS of
the UAV with its best effort. Numerical results show that the proposed
centralized and distributed CB schemes with interference transmission and
cancellation (ITC) can both significantly outperform the conventional CB
without applying ITC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00225</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00225</id><created>2019-06-01</created><updated>2019-12-11</updated><authors><author><keyname>Fan</keyname><forenames>Fanda</forenames></author><author><keyname>Huang</keyname><forenames>Yunyou</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Xiong</keyname><forenames>Xingwang</forenames></author><author><keyname>Jiang</keyname><forenames>Zihan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhifei</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author></authors><title>A Semantic-based Medical Image Fusion Approach</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is necessary for clinicians to comprehensively analyze patient information
from different sources. Medical image fusion is a promising approach to
providing overall information from medical images of different modalities.
However, existing medical image fusion approaches ignore the semantics of
images, making the fused image difficult to understand. In this work, we
propose a new evaluation index to measure the semantic loss of fused image, and
put forward a Fusion W-Net (FW-Net) for multimodal medical image fusion. The
experimental results are promising: the fused image generated by our approach
greatly reduces the semantic information loss, and has better visual effects in
contrast to five state-of-art approaches. Our approach and tool have great
potential to be applied in the clinical setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00240</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00240</id><created>2019-06-01</created><authors><author><keyname>Causey</keyname><forenames>Jason L.</forenames></author><author><keyname>Guan</keyname><forenames>Yuanfang</forenames></author><author><keyname>Dong</keyname><forenames>Wei</forenames></author><author><keyname>Walker</keyname><forenames>Karl</forenames></author><author><keyname>Qualls</keyname><forenames>Jake A.</forenames></author><author><keyname>Prior</keyname><forenames>Fred</forenames></author><author><keyname>Huang</keyname><forenames>Xiuzhen</forenames></author></authors><title>Lung cancer screening with low-dose CT scans using a deep learning
  approach</title><categories>eess.IV cs.CV</categories><comments>6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lung cancer is the leading cause of cancer deaths. Early detection through
low-dose computed tomography (CT) screening has been shown to significantly
reduce mortality but suffers from a high false positive rate that leads to
unnecessary diagnostic procedures. Quantitative image analysis coupled to deep
learning techniques has the potential to reduce this false positive rate. We
conducted a computational analysis of 1449 low-dose CT studies drawn from the
National Lung Screening Trial (NLST) cohort. We applied to this cohort our
newly developed algorithm, DeepScreener, which is based on a novel deep
learning approach. The algorithm, after the training process using about 3000
CT studies, does not require lung nodule annotations to conduct cancer
prediction. The algorithm uses consecutive slices and multi-task features to
determine whether a nodule is likely to be cancer, and a spatial pyramid to
detect nodules at different scales. We find that the algorithm can predict a
patient's cancer status from a volumetric lung CT image with high accuracy
(78.2%, with area under the Receiver Operating Characteristic curve (AUC) of
0.858). Our preliminary framework ranked 16th of 1972 teams (top 1%) in the
Data Science Bowl 2017 (DSB2017) competition, based on the challenge datasets.
We report here the application of DeepScreener on an independent NLST test set.
This study indicates that the deep learning approach has the potential to
significantly reduce the false positive rate in lung cancer screening with
low-dose CT scans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00252</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00252</id><created>2019-06-01</created><updated>2019-07-27</updated><authors><author><keyname>Borchardt</keyname><forenames>John J.</forenames></author><author><keyname>LaPointe</keyname><forenames>Tyler C.</forenames></author></authors><title>U-Slot Patch Principle and Design Methodology Using Characteristic Mode
  Analysis and Coupled Mode Theory</title><categories>physics.app-ph eess.SP</categories><comments>10 pages, 17 figures</comments><report-no>SAND2019-6034J</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patch antennas incorporating a U-shaped slot are well-known to have
relatively large (about 30%) impedance bandwidths. This work uses
Characteristic Mode Analysis to explain the impedance behavior of a classic
U-slot patch geometry in terms of Coupled Mode Theory and shows the relevant
modes are in-phase and anti-phase coupled modes whose resonant frequencies are
governed by Coupled Mode Theory. Additional analysis shows that one uncoupled
resonator is the conventional TM01 patch mode and the other is a lumped LC
resonator involving the slot and the probe. An equivalent circuit model for the
antenna is given wherein element values are extracted from Characteristic Mode
Analysis data and which explicitly demonstrates coupling between these two
resonators. The circuit model approximately reproduces the impedance locus of
the driven simulation. A design methodology based on Coupled Mode Theory and
guided by Characteristic Mode Analysis is presented that allows wideband U-slot
patch geometries to be designed quickly and efficiently. The methodology is
illustrated through example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00254</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00254</id><created>2019-06-01</created><authors><author><keyname>Kiskin</keyname><forenames>Ivan</forenames></author><author><keyname>Meepegama</keyname><forenames>Udeepa</forenames></author><author><keyname>Roberts</keyname><forenames>Steven</forenames></author></authors><title>Super-resolution of Time-series Labels for Bootstrapped Event Detection</title><categories>cs.LG cs.CV cs.SD eess.AS stat.ML</categories><comments>Accepted at the Time-series workshop at ICML 2019, Long Beach</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving real-world problems, particularly with deep learning, relies on the
availability of abundant, quality data. In this paper we develop a novel
framework that maximises the utility of time-series datasets that contain only
small quantities of expertly-labelled data, larger quantities of weakly (or
coarsely) labelled data and a large volume of unlabelled data. This represents
scenarios commonly encountered in the real world, such as in crowd-sourcing
applications. In our work, we use a nested loop using a Kernel Density
Estimator (KDE) to super-resolve the abundant low-quality data labels, thereby
enabling effective training of a Convolutional Neural Network (CNN). We
demonstrate two key results: a) The KDE is able to super-resolve labels more
accurately, and with better calibrated probabilities, than well-established
classifiers acting as baselines; b) Our CNN, trained on super-resolved labels
from the KDE, achieves an improvement in F1 score of 22.1% over the next best
baseline system in our candidate problem domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00267</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00267</id><created>2019-06-01</created><updated>2020-01-14</updated><authors><author><keyname>Borchardt</keyname><forenames>John J.</forenames></author></authors><title>Loop Antennas for Use On/Off Metal Ground Planes</title><categories>physics.app-ph eess.SP</categories><comments>5 pages, 10 figures</comments><report-no>SAND2020-0357J</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Antenna detuning due to changes in the surrounding environment can cause
significant degradation in radio link range due to increased mismatch loss at
the antenna feed. This paper presents an electrically small loop antenna at 433
MHz that passively maintains its free-space tune and match when located a
certain distance away from a large conducting ground plane. An equivalent
circuit model is developed that explains this behavior and shows that the
geometry balances inductive and capacitive parasitics introduced by the ground
plane such that the loop reactance and thus resonant frequency do not change. A
design law that guides the design of similar loop antennas is then derived.
Finally, experimental data showing the design substantially eliminates ground
plane detuning in practice is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00270</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00270</id><created>2019-06-01</created><authors><author><keyname>Brummer</keyname><forenames>Benoit</forenames></author><author><keyname>De Vleeschouwer</keyname><forenames>Christophe</forenames></author></authors><title>Natural Image Noise Dataset</title><categories>eess.IV cs.CV</categories><comments>NTIRE at CVPR 2019</comments><acm-class>I.4.4</acm-class><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Convolutional neural networks have been the focus of research aiming to solve
image denoising problems, but their performance remains unsatisfactory for most
applications. These networks are trained with synthetic noise distributions
that do not accurately reflect the noise captured by image sensors. Some
datasets of clean-noisy image pairs have been introduced but they are usually
meant for benchmarking or specific applications. We introduce the Natural Image
Noise Dataset (NIND), a dataset of DSLR-like images with varying levels of ISO
noise which is large enough to train models for blind denoising over a wide
range of noise. We demonstrate a denoising model trained with the NIND and show
that it significantly outperforms BM3D on ISO noise from unseen images, even
when generalizing to images from a different type of camera. The Natural Image
Noise Dataset is published on Wikimedia Commons such that it remains open for
curation and contributions. We expect that this dataset will prove useful for
future image denoising applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00287</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00287</id><created>2019-06-01</created><authors><author><keyname>Challita</keyname><forenames>Ursula</forenames></author><author><keyname>Hiltunen</keyname><forenames>Kimmo</forenames></author><author><keyname>Tercero</keyname><forenames>Miurel</forenames></author></authors><title>Performance Evaluation for the Co-existence of eMBB and URLLC Networks:
  Synchronized versus Unsynchronized TDD</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To ensure the high level of automation required in today's industrial
applications, next-generation wireless networks must enable real-time control
and automation of dynamic processes with the requirements of extreme
low-latency and ultra-reliable communications. In this paper, we provide a
performance assessment for the co-existence of a macro (eMBB) and a local
factory (URLLC) network and evaluate the network conditions under which the
latency and reliability requirements of factory automation applications are
met. In particular, we evaluate the co-existence of the eMBB and URLLC networks
under two scenarios: (i) synchronized TDD, in which both networks follow the
same TDD pattern, and (ii) unsynchronized TDD, in which the eMBB and URLLC
networks follow different TDD patterns. Simulation results show that the high
downlink interference from the macro base stations towards the factory results
in a reduction of the downlink URLLC capacity and service availability in case
of synchronized TDD and a reduction of the uplink URLLC capacity and service
availability in case of unsynchronized TDD. Finally, it is shown that a
promising case for co-existence is the adjacent channel allocation, for both
synchronized and unsynchronized TDD deployments. Here, the required isolation
to protect the URLLC network in the worst-case scenario where the factory is
located next to a macro site can be handled via the factory wall penetration
loss (e.g., considering high concrete or metal-coated building walls) along
with other solutions such as filters, larger separation distance, and band
pairing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00309</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00309</id><created>2019-06-01</created><authors><author><keyname>Dai</keyname><forenames>Jisheng</forenames></author><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>So</keyname><forenames>Hing Cheung</forenames></author></authors><title>Sparse Bayesian Learning Approach for Discrete Signal Reconstruction</title><categories>eess.SP cs.IR</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study addresses the problem of discrete signal reconstruction from the
perspective of sparse Bayesian learning (SBL). Generally, it is intractable to
perform the Bayesian inference with the ideal discretization prior under the
SBL framework. To overcome this challenge, we introduce a novel discretization
enforcing prior to exploit the knowledge of the discrete nature of the
signal-of-interest. By integrating the discretization enforcing prior into the
SBL framework and applying the variational Bayesian inference (VBI)
methodology, we devise an alternating update algorithm to jointly characterize
the finite alphabet feature and reconstruct the unknown signal. When the
measurement matrix is i.i.d. Gaussian per component, we further embed the
generalized approximate message passing (GAMP) into the VBI-based method, so as
to directly adopt the ideal prior and significantly reduce the computational
burden. Simulation results demonstrate substantial performance improvement of
the two proposed methods over existing schemes. Moreover, the GAMP-based
variant outperforms the VBI-based method with an i.i.d. Gaussian measurement
matrix but it fails to work for non i.i.d. Gaussian matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00319</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00319</id><created>2019-06-01</created><authors><author><keyname>Stein</keyname><forenames>Lewin</forenames></author><author><keyname>Sesterhenn</keyname><forenames>Joern</forenames></author></authors><title>An acoustic model of a Helmholtz resonator under a grazing turbulent
  boundary layer</title><categories>physics.flu-dyn cs.SD eess.AS physics.comp-ph</categories><comments>22 pages, 12 figures</comments><msc-class>76F65, 76F10, 76F40, 76G25</msc-class><journal-ref>J. Acta Mech (2019) 230: 2013</journal-ref><doi>10.1007/s00707-018-2354-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic models of resonant duct systems with turbulent flow depend on fitted
constants based on expensive experimental test series. We introduce a new model
of a resonant cavity, flush mounted in a duct or flat plate, under grazing
turbulent flow. Based on previous work by Goody, Howe and Golliard, we present
a more universal model where the constants are replaced by physically
significant parameters. This enables the user to understand and to trace back
how a modification of design parameters (geometry, fluid condition) will affect
acoustic properties. The derivation of the model is supported by a detailed
three-dimensional direct numerical simulation as well as an experimental test
series. We show that the model is valid for low Mach number flows (M =
0.01-0.14) and for low frequencies (below higher transverse cavity modes).
Hence, within this range, no expensive simulation or experiment is needed any
longer to predict the sound spectrum. In principle, the model is applicable to
arbitrary geometries: Just the provided definitions need to be applied to
update the significant parameters. Utilizing the lumped-element method, the
model consists of exchangeable elements and guarantees a flexible use. Even
though the model is linear, resonance conditions between acoustic cavity modes
and fluid dynamic unstable modes are correctly predicted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00387</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00387</id><created>2019-06-02</created><authors><author><keyname>Bushnaq</keyname><forenames>Osama M.</forenames></author><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>Sensor Placement and Resource Allocation for Energy Harvesting IoT
  Networks</title><categories>eess.SP</categories><comments>Submitted to Elsevier DSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies optimal sensor selection for source estimation in energy
harvesting Internet of Things (IoT) networks. Specifically, the focus is on the
selection of the sensor locations which minimizes the estimation error at a
fusion center, and to optimally allocate power and bandwidth for each selected
sensor subject to a prescribed spectral and energy budget. To do so,
measurement accuracy, communication link quality, and the amount of energy
harvested are all taken into account. The sensor selection is studied under
both analog and digital transmission schemes from the selected sensors to the
fusion center. In the digital transmission case, an information theoretic
approach is used to model the transmission rate, observation quantization, and
encoding. We numerically prove that with a sufficient system bandwidth, the
digital system outperforms the analog system with a possibly different sensor
selection. Two source models are studied in this paper: static source
estimation for a vector of correlated sources and dynamic state estimation for
a scalar source. The design problem of interest is a Boolean non convex
optimization problem, which is solved by relaxing the Boolean constraints. We
propose a randomized rounding algorithm which generalizes the existing
algorithm. The proposed randomized rounding algorithm takes the joint sensor
location, power and bandwidth selection into account to efficiently round the
obtained relaxed solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00397</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00397</id><created>2019-06-02</created><authors><author><keyname>Genes</keyname><forenames>Cristian</forenames></author><author><keyname>Esnaola</keyname><forenames>I&#xf1;aki</forenames></author><author><keyname>Perlaza</keyname><forenames>Samir</forenames></author><author><keyname>Coca</keyname><forenames>Daniel</forenames></author></authors><title>Recovery of Missing Data in Correlated Smart Grid Datasets</title><categories>eess.SP</categories><comments>Extended version of submission to IEEE Data Science Workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the recovery of missing data from multiple smart grid datasets
within a matrix completion framework. The datasets contain the electrical
magnitudes required for monitoring and control of the electricity distribution
system. Each dataset is described by a low rank matrix. Different datasets are
correlated as a result of containing measurements of different physical
magnitudes generated by the same distribution system. To assess the validity of
matrix completion techniques in the recovery of missing data, we characterize
the fundamental limits when two correlated datasets are jointly recovered. We
then proceed to evaluate the performance of Singular Value Thresholding (SVT)
and Bayesian SVT (BSVT) in this setting. We show that BSVT outperforms SVT by
simulating the recovery for different correlated datasets. The performance of
BSVT displays the tradeoff behaviour described by the fundamental limit, which
suggests that BSVT exploits the correlation between the datasets in an
efficient manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00400</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00400</id><created>2019-06-02</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Mobile Edge Intelligence and Computing for the Internet of Vehicles</title><categories>cs.NI eess.SP</categories><comments>18 pages, 6 figures, submitted to Proceedings of the IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Vehicles (IoV) is an emerging paradigm, driven by recent
advancements in vehicular communications and networking. Advances in research
can now provide reliable communication links between vehicles, via
vehicle-to-vehicle communications, and between vehicles and roadside
infrastructures, via vehicle-to-infrastructure communications. Meanwhile, the
capability and intelligence of vehicles are being rapidly enhanced, and this
will have the potential of supporting a plethora of new exciting applications,
which will integrate fully autonomous vehicles, the Internet of Things (IoT),
and the environment. These trends will bring about an era of intelligent IoV,
which will heavily depend upon communications, computing, and data analytics
technologies. To store and process the massive amount of data generated by
intelligent IoV, onboard processing and Cloud computing will not be sufficient,
due to resource/power constraints and communication overhead/latency,
respectively. By deploying storage and computing resources at the wireless
network edge, e.g., radio access points, the edge information system (EIS),
including edge caching, edge computing, and edge AI, will play a key role in
the future intelligent IoV. Such system will provide not only low-latency
content delivery and computation services, but also localized data acquisition,
aggregation and processing. This article surveys the latest development in EIS
for intelligent IoV. Key design issues, methodologies and hardware platforms
are introduced. In particular, typical use cases for intelligent vehicles are
illustrated, including edge-assisted perception, mapping, and localization. In
addition, various open research problems are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00425</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00425</id><created>2019-06-02</created><updated>2019-12-02</updated><authors><author><keyname>Basri</keyname><forenames>Ronen</forenames></author><author><keyname>Jacobs</keyname><forenames>David</forenames></author><author><keyname>Kasten</keyname><forenames>Yoni</forenames></author><author><keyname>Kritchman</keyname><forenames>Shira</forenames></author></authors><title>The Convergence Rate of Neural Networks for Learned Functions of
  Different Frequencies</title><categories>cs.LG eess.SP stat.ML</categories><journal-ref>in Advances in Neural Information Processing Systems 32 (NIPS
  2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the relationship between the frequency of a function and the speed
at which a neural network learns it. We build on recent results that show that
the dynamics of overparameterized neural networks trained with gradient descent
can be well approximated by a linear system. When normalized training data is
uniformly distributed on a hypersphere, the eigenfunctions of this linear
system are spherical harmonic functions. We derive the corresponding
eigenvalues for each frequency after introducing a bias term in the model. This
bias term had been omitted from the linear network model without significantly
affecting previous theoretical results. However, we show theoretically and
experimentally that a shallow neural network without bias cannot represent or
learn simple, low frequency functions with odd frequencies. Our results lead to
specific predictions of the time it will take a network to learn functions of
varying frequency. These predictions match the empirical behavior of both
shallow and deep networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00437</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00437</id><created>2019-06-02</created><authors><author><keyname>Alavi</keyname><forenames>Seyed Amir</forenames></author><author><keyname>Javadipour</keyname><forenames>Mehrnaz</forenames></author><author><keyname>Mehran</keyname><forenames>Kamyar</forenames></author></authors><title>State Monitoring for Situational Awareness in Rural Microgrids Using the
  IoT Infrastructure</title><categories>eess.SP cs.NI cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an event-triggered estimation strategy and a data
collection architecture for situational awareness (SA) in microgrids. An
estimation agent structure based on the event-triggered Kalman filter is
proposed and implemented for state estimation layer of the SA using long range
wide area network (LoRAWAN) protocol. A setup has been developed which can
provide enormous data collection capabilities from smart meters, in order to
realise an adequate SA level in microgrids. Thingsboard Internet of things
(IoT) platform is used for the SA visualisation with a customised dashboard. It
is shown by using the developed estimation strategy, an adequate level of SA
can be achieved with a minimum installation and communication cost to have an
accurate average state estimation of the microgrid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00511</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00511</id><created>2019-06-02</created><updated>2019-06-06</updated><authors><author><keyname>Meisel</keyname><forenames>Christian</forenames></author><author><keyname>Atrache</keyname><forenames>Rima El</forenames></author><author><keyname>Jackson</keyname><forenames>Michele</forenames></author><author><keyname>Schubach</keyname><forenames>Sarah</forenames></author><author><keyname>Ufongene</keyname><forenames>Claire</forenames></author><author><keyname>Loddenkemper</keyname><forenames>Tobias</forenames></author></authors><title>Deep learning from wristband sensor data: towards wearable, non-invasive
  seizure forecasting</title><categories>q-bio.NC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seizure forecasting may provide patients with timely warnings to adapt their
daily activities and help clinicians deliver more objective, personalized
treatments. While recent work has convincingly demonstrated that seizure risk
assessment is possible, these early approaches relied largely on complex, often
invasive setups including intracranial electrocorticography, implanted devices
and multi-channel EEG, which limits translation of these methods to broad
clinical application. To facilitate broader adaptation of seizure forecasting
in clinical practice, non-invasive, easily applicable techniques that reliably
assess seizure risk, in combination with clinical information, are crucial.
Wristbands that continuously record physiological parameters, including
electrodermal activity, body temperature, blood volume pressure and actigraphy,
may afford monitoring of autonomous nervous system function and movement
relevant for such a task, hence minimizing potential complications associated
with invasive monitoring, and avoiding stigma associated with bulky external
monitoring devices on the head. Here, we use deep learning to analyze
long-term, multi-modal wristband sensor data from 50 patients with epilepsy
(total duration $&gt;$1400 hours) to assess its capability to distinguish preictal
from interictal states. Prediction performance is assessed using area under the
receiver operating charateristic (AUC) and improvement over chance (IoC) based
on F1 scores. Using one- and two-dimensional convolutional neural networks, we
identified better-than-chance predictability in out-of-sample test data in 60\%
of the patients in leave-one-out and 43\% of patients in pseudo-prospective
approaches. These results provide a step towards developing easier to apply,
non-invasive methods for seizure risk assessments in patients with epilepsy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00518</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00518</id><created>2019-06-02</created><authors><author><keyname>Moeller</keyname><forenames>Lothar</forenames></author></authors><title>Stokes Vector Spectroscopy of Nonlinear Depolarized Light</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experimental Stokes vector spectroscopy characterizes polarization state
noise in nonlinear fiber transmission. Noise bandwidths of a few MHz are
observed from XPM-blurred receive SOPs using a polarization scrambling
interferometer. This method can detect data pattern correlations among WDM
channels that contribute to performance degradations in signalling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00543</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00543</id><created>2019-06-02</created><updated>2019-06-04</updated><authors><author><keyname>Li</keyname><forenames>Hongyu</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Qian</forenames></author></authors><title>Hybrid beamforming with dynamic subarrays and low-resolution PSs for
  mmWave MU-MISO systems</title><categories>eess.SP</categories><comments>30 pages, 10 figures, 1 table, submitted to Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog/digital hybrid beamforming architectures with large-scale antenna
arrays have been widely considered in millimeter wave (mmWave) communication
systems because they can address the tradeoff between performance and hardware
efficiency compared with traditional fully-digital beamforming. Most of the
prior work on hybrid beamforming focused on fullyconnected architecture or
partially-connected scheme with fixedsubarrays, in which the analog beamformers
are usually realized by infinite-resolution phase shifters (PSs). In this
paper, we introduce a novel hybrid beamforming architecture with dynamic
subarrays and hardware-efficient low-resolution PSs for mmWave multiuser
multiple-input single-output (MU-MISO) systems. By dynamically connecting each
RF chain to a non-overlap subarray via a switch network and PSs, we can exploit
multiple-antenna and multiuser diversities to mitigate the performance loss due
to the use of practical low-resolution PSs. An iterative hybrid beamformer
design algorithm is first proposed based on fractional programming (FP), aiming
at maximizing the sum-rate performance of the MU-MISO system. In an effort to
reduce the complexity, we also present a simple heuristic hybrid beamformer
design algorithm for the dynamic subarray scheme. Extensive simulation results
demonstrate the advantages of the proposed hybrid beamforming architecture with
dynamic subarrays and low-resolution PSs compared to existing fixed-subarray
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00560</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00560</id><created>2019-06-03</created><authors><author><keyname>Zhou</keyname><forenames>Xian</forenames></author><author><keyname>Shen</keyname><forenames>Yanyan</forenames></author><author><keyname>Huang</keyname><forenames>Linpeng</forenames></author></authors><title>Revisiting Flow Information for Traffic Prediction</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic prediction is a fundamental task in many real applications, which
aims to predict the future traffic volume in any region of a city. In essence,
traffic volume in a region is the aggregation of traffic flows from/to the
region. However, existing traffic prediction methods focus on modeling complex
spatiotemporal traffic correlations and seldomly study the influence of the
original traffic flows among regions. In this paper, we revisit the traffic
flow information and exploit the direct flow correlations among regions towards
more accurate traffic prediction. We introduce a novel flow-aware graph
convolution to model dynamic flow correlations among regions. We further
introduce an integrated Gated Recurrent Unit network to incorporate flow
correlations with spatiotemporal modeling. The experimental results on
real-world traffic datasets validate the effectiveness of the proposed method,
especially on the traffic conditions with a great change on flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00566</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00566</id><created>2019-06-03</created><updated>2019-07-08</updated><authors><author><keyname>McLeod</keyname><forenames>Andrew</forenames></author></authors><title>Evaluating Non-aligned Musical Score Transcriptions with MV2H</title><categories>eess.AS cs.IR cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The original MV2H metric was designed to evaluate systems which transcribe
from an input audio (or MIDI) piece to a complete musical score. However, it
requires both the transcribed score and the ground truth score to be
time-aligned with the input. Some recent work has begun to transcribe directly
from an audio signal into a musical score, skipping the alignment step. This
paper introduces an automatic alignment method based on dynamic time warp which
allows for MV2H to be used to evaluate such non-aligned transcriptions. This
has the additional benefit of allowing non-aligned musical scores---which are
significantly more widely available than aligned ones---to be used as ground
truth. The code for the improved MV2H, which now also includes a MusicXML
parser, and allows for key and time signature changes, is available at
www.github.com/apmcleod/MV2H.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00571</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00571</id><created>2019-06-03</created><authors><author><keyname>Luis</keyname><forenames>Juan Jose Garau</forenames></author><author><keyname>Guerster</keyname><forenames>Markus</forenames></author><author><keyname>del Portillo</keyname><forenames>Inigo</forenames></author><author><keyname>Crawley</keyname><forenames>Edward</forenames></author><author><keyname>Cameron</keyname><forenames>Bruce</forenames></author></authors><title>Deep Reinforcement Learning Architecture for Continuous Power Allocation
  in High Throughput Satellites</title><categories>eess.SP cs.LG stat.ML</categories><comments>8 pages, 5 figures, workshop</comments><doi>10.13140/RG.2.2.15014.98882</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In the coming years, the satellite broadband market will experience
significant increases in the service demand, especially for the mobility
sector, where demand is burstier. Many of the next generation of satellites
will be equipped with numerous degrees of freedom in power and bandwidth
allocation capabilities, making manual resource allocation impractical and
inefficient. Therefore, it is desirable to automate the operation of these
highly flexible satellites. This paper presents a novel power allocation
approach based on Deep Reinforcement Learning (DRL) that represents the problem
as continuous state and action spaces. We make use of the Proximal Policy
Optimization (PPO) algorithm to optimize the allocation policy for minimum
Unmet System Demand (USD) and power consumption. The performance of the
algorithm is analyzed through simulations of a multibeam satellite system,
which show promising results for DRL to be used as a dynamic resource
allocation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00576</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00576</id><created>2019-06-03</created><authors><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Wen</keyname><forenames>Chao-kai</forenames></author><author><keyname>Tong</keyname><forenames>Jun</forenames></author><author><keyname>Xu</keyname><forenames>Chongbin</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author></authors><title>Gridless Variational Bayesian Channel Estimation for Antenna Array
  Systems with Low Resolution ADCs</title><categories>eess.SP cs.IT math.IT</categories><comments>25 pages in a single column</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Employing low-resolution analog-to-digital converters (ADCs) coupled with
large antenna arrays at the receivers has drawn considerable interests in the
millimeter wave (mm-wave) system. Since mm-wave channels are sparse in angular
dimensions, exploiting the structure could reduce the number of measurements
while achieve acceptable performance at the same time. Motivated by the
variational Bayesian line spectral estimation (VALSE) algorithm which treats
the angles as random parameters, in contrast with previous works which confine
the estimate to the set of grid angle points and induce grid mismatch, this
paper proposes the grid-less quantized variational Bayesian channel estimation
(GL-QVBCE) algorithm for antenna array systems with low resolution ADCs.
Compared to the traditional least squares (LS) approach, numerical results show
that GL-QVBCE performs significantly better and asymptotically approaches the
Cram\`{e}r Rao bound (CRB).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00579</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00579</id><created>2019-06-03</created><updated>2019-11-14</updated><authors><author><keyname>Effendi</keyname><forenames>Johanes</forenames></author><author><keyname>Tjandra</keyname><forenames>Andros</forenames></author><author><keyname>Sakti</keyname><forenames>Sakriani</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoshi</forenames></author></authors><title>Listening while Speaking and Visualizing: Improving ASR through
  Multimodal Chain</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted in IEEE ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previously, a machine speech chain, which is based on sequence-to-sequence
deep learning, was proposed to mimic speech perception and production behavior.
Such chains separately processed listening and speaking by automatic speech
recognition (ASR) and text-to-speech synthesis (TTS) and simultaneously enabled
them to teach each other in semi-supervised learning when they received
unpaired data. Unfortunately, this speech chain study is limited to speech and
textual modalities. In fact, natural communication is actually multimodal and
involves both auditory and visual sensory systems. Although the said speech
chain reduces the requirement of having a full amount of paired data, in this
case we still need a large amount of unpaired data. In this research, we take a
further step and construct a multimodal chain and design a closely knit chain
architecture that combines ASR, TTS, image captioning, and image production
models into a single framework. The framework allows the training of each
component without requiring a large number of parallel multimodal data. Our
experimental results also show that an ASR can be further trained without
speech and text data and cross-modal data augmentation remains possible through
our proposed chain, which improves the ASR performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00594</identifier>
 <datestamp>2020-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00594</id><created>2019-06-03</created><authors><author><keyname>Gomes</keyname><forenames>Douglas P. S.</forenames></author><author><keyname>Ozansoy</keyname><forenames>Cagil</forenames></author><author><keyname>Ulhaq</keyname><forenames>Anwaar</forenames></author></authors><title>Vegetation High-Impedance Faults' High-Frequency Signatures via Sparse
  Coding</title><categories>eess.SP</categories><doi>10.1109/TIM.2019.2950822</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The behavior of High-Impedance Faults (HIFs) in power distribution systems
depends on multiple factors, making it a challenging disturbance to model. If
enough data from real staged faults is provided, signal processing techniques
can help reveal patterns from a specific type of fault. Such a task is
implemented herein by employing the Shift-Invariant Sparse Coding (SISC)
technique on a data set of staged vegetation high-impedance faults. The
technique facilitates the uncoupling of shifted and convoluted patterns present
in the recorded signals from fault tests. The deconvolution of these patterns
was then individually studied to identify the possible repeating fault
signatures. The work is primarily focused on the investigation of the
under-discussed high-frequency faults signals, especially regarding voltage
disturbances created by the fault currents. Therefore, the main contribution
from this paper is the resulted evidence of consistent behavior from real
vegetation HIFs at higher frequencies. These results can enhance phenomena
awareness and support future methodologies dealing with these disturbances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00614</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00614</id><created>2019-06-03</created><authors><author><keyname>Moy</keyname><forenames>Christophe</forenames><affiliation>IETR</affiliation></author><author><keyname>Besson</keyname><forenames>Lilian</forenames><affiliation>IETR, SEQUEL</affiliation></author></authors><title>Decentralized Spectrum Learning for IoT Wireless Networks Collision
  Mitigation</title><categories>cs.NI eess.SP</categories><proxy>ccsd</proxy><journal-ref>ISIoT workshop, May 2019, Santorin, Greece</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the principles and implementation results of
reinforcement learning algorithms on IoT devices for radio collision mitigation
in ISM unlicensed bands. Learning is here used to improve both the IoT network
capability to support a larger number of objects as well as the autonomy of IoT
devices. We first illustrate the efficiency of the proposed approach in a
proof-of-concept based on USRP software radio platforms operating on real radio
signals. It shows how collisions with other RF signals present in the ISM band
are diminished for a given IoT device. Then we describe the first
implementation of learning algorithms on LoRa devices operating in a real
LoRaWAN network, that we named IoTligent. The proposed solution adds neither
processing overhead so that it can be ran in the IoT devices, nor network
overhead so that no change is required to LoRaWAN. Real life experiments have
been done in a realistic LoRa network and they show that IoTligent device
battery life can be extended by a factor 2 in the scenarios we faced during our
experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00617</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00617</id><created>2019-06-03</created><authors><author><keyname>Lahiani</keyname><forenames>Amal</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Albarqouni</keyname><forenames>Shadi</forenames></author><author><keyname>Klaiman</keyname><forenames>Eldad</forenames></author></authors><title>Perceptual Embedding Consistency for Seamless Reconstruction of Tilewise
  Style Transfer</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Style transfer is a field with growing interest and use cases in deep
learning. Recent work has shown Generative Adversarial Networks(GANs) can be
used to create realistic images of virtually stained slide images in digital
pathology with clinically validated interpretability. Digital pathology images
are typically of extremely high resolution, making tilewise analysis necessary
for deep learning applications. It has been shown that image generators with
instance normalization can cause a tiling artifact when a large image is
reconstructed from the tilewise analysis. We introduce a novel perceptual
embedding consistency loss significantly reducing the tiling artifact created
in the reconstructed whole slide image (WSI). We validate our results by
comparing virtually stained slide images with consecutive real stained tissue
slide images. We also demonstrate that our model is more robust to contrast,
color and brightness perturbations by running comparative sensitivity analysis
tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00625</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00625</id><created>2019-06-03</created><authors><author><keyname>Chen</keyname><forenames>Xianfu</forenames></author><author><keyname>Wu</keyname><forenames>Celimuge</forenames></author><author><keyname>Zhang</keyname><forenames>Honggang</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Vuojala</keyname><forenames>Heli</forenames></author></authors><title>Decentralized Deep Reinforcement Learning for Delay-Power Tradeoff in
  Vehicular Communications</title><categories>eess.SP cs.LG</categories><comments>Accepted to Proc. IEEE ICC, Shanghai, China, May 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper targets at the problem of radio resource management for expected
long-term delay-power tradeoff in vehicular communications. At each decision
epoch, the road side unit observes the global network state, allocates channels
and schedules data packets for all vehicle user equipment-pairs (VUE-pairs).
The decision-making procedure is modelled as a discrete-time Markov decision
process (MDP). The technical challenges in solving an optimal control policy
originate from highly spatial mobility of vehicles and temporal variations in
data traffic. To simplify the decision-making process, we first decompose the
MDP into a series of per-VUE-pair MDPs. We then propose an online long
short-term memory based deep reinforcement learning algorithm to break the
curse of high dimensionality in state space faced by each per-VUE-pair MDP.
With the proposed algorithm, the optimal channel allocation and packet
scheduling decision at each epoch can be made in a decentralized way in
accordance with the partial observations of the global network state at the
VUE-pairs. Numerical simulations validate the theoretical analysis and show the
effectiveness of the proposed online learning algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00650</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00650</id><created>2019-06-03</created><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Van Nieuwenhove</keyname><forenames>Vincent</forenames></author><author><keyname>Soons</keyname><forenames>Joris</forenames></author><author><keyname>De Beenhouwer</keyname><forenames>Jan</forenames></author><author><keyname>Sijbers</keyname><forenames>Jan</forenames></author></authors><title>Deep Neural Network Assisted Iterative Reconstruction Method for Low
  Dose CT</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low Dose Computed Tomography suffers from a high amount of noise and/or
undersampling artefacts in the reconstructed image. In the current article, a
Deep Learning technique is exploited as a regularization term for the iterative
reconstruction method SIRT. While SIRT minimizes the error in the sinogram
space, the proposed regularization model additionally steers intermediate SIRT
reconstructions towards the desired output. Extensive evaluations demonstrate
the superior outcomes of the proposed method compared to the state of the art
techniques. Comparing the forward projection of the reconstructed image with
the original signal shows a higher fidelity to the sinogram space for the
current approach amongst other learning based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00651</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00651</id><created>2019-06-03</created><updated>2019-06-04</updated><authors><author><keyname>Krull</keyname><forenames>Alexander</forenames></author><author><keyname>Vicar</keyname><forenames>Tomas</forenames></author><author><keyname>Jug</keyname><forenames>Florian</forenames></author></authors><title>Probabilistic Noise2Void: Unsupervised Content-Aware Denoising</title><categories>eess.IV cs.CV</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, Convolutional Neural Networks (CNNs) are the leading method for image
denoising. They are traditionally trained on pairs of images, which are often
hard to obtain for practical applications. This motivates self-supervised
training methods such as Noise2Void~(N2V) that operate on single noisy images.
Self-supervised methods are, unfortunately, not competitive with models trained
on image pairs. Here, we present 'Probabilistic Noise2Void' (PN2V), a method to
train CNNs to predict per-pixel intensity distributions. Combining these with a
suitable description of the noise, we obtain a complete probabilistic model for
the noisy observations and true signal in every pixel. We evaluate PN2V on
publicly available microscopy datasets, under a broad range of noise regimes,
and achieve competitive results with respect to supervised state-of-the-art
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00654</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00654</id><created>2019-06-03</created><authors><author><keyname>Wang</keyname><forenames>Zhepei</forenames></author><author><keyname>Subakan</keyname><forenames>Cem</forenames></author><author><keyname>Tzinis</keyname><forenames>Efthymios</forenames></author><author><keyname>Smaragdis</keyname><forenames>Paris</forenames></author><author><keyname>Charlin</keyname><forenames>Laurent</forenames></author></authors><title>Continual Learning of New Sound Classes using Generative Replay</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continual learning consists in incrementally training a model on a sequence
of datasets and testing on the union of all datasets. In this paper, we examine
continual learning for the problem of sound classification, in which we wish to
refine already trained models to learn new sound classes. In practice one does
not want to maintain all past training data and retrain from scratch, but
naively updating a model with new data(sets) results in a degradation of
already learned tasks, which is referred to as &quot;catastrophic forgetting.&quot; We
develop a generative replay procedure for generating training audio spectrogram
data, in place of keeping older training datasets. We show that by
incrementally refining a classifier with generative replay a generator that is
4% of the size of all previous training data matches the performance of
refining the classifier keeping 20% of all previous training data. We thus
conclude that we can extend a trained sound classifier to learn new classes
without having to keep previously used datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00662</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00662</id><created>2019-06-03</created><authors><author><keyname>Schreiber</keyname><forenames>Jens</forenames></author><author><keyname>Jessulat</keyname><forenames>Maik</forenames></author><author><keyname>Sick</keyname><forenames>Bernhard</forenames></author></authors><title>Generative Adversarial Networks for Operational Scenario Planning of
  Renewable Energy Farms: A Study on Wind and Photovoltaic</title><categories>cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the integration of renewable energy sources, power grid operators need
realistic information about the effects of energy production and consumption to
assess grid stability.
  Recently, research in scenario planning benefits from utilizing generative
adversarial networks (GANs) as generative models for operational scenario
planning.
  In these scenarios, operators examine temporal as well as spatial influences
of different energy sources on the grid.
  The analysis of how renewable energy resources affect the grid enables the
operators to evaluate the stability and to identify potential weak points such
as a limiting transformer.
  However, due to their novelty, there are limited studies on how well GANs
model the underlying power distribution.
  This analysis is essential because, e.g., especially extreme situations with
low or high power generation are required to evaluate grid stability.
  We conduct a comparative study of the Wasserstein distance,
binary-cross-entropy loss, and a Gaussian copula as the baseline applied on two
wind and two solar datasets with limited data compared to previous studies.
  Both GANs achieve good results considering the limited amount of data, but
the Wasserstein GAN is superior in modeling temporal and spatial relations, and
the power distribution.
  Besides evaluating the generated power distribution over all farms, it is
essential to assess terrain specific distributions for wind scenarios.
  These terrain specific power distributions affect the grid by their
differences in their generating power magnitude.
  Therefore, in a second study, we show that even when simultaneously learning
distributions from wind parks with terrain specific patterns, GANs are capable
of modeling these individualities also when faced with limited data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00668</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00668</id><created>2019-06-03</created><updated>2019-08-13</updated><authors><author><keyname>Lu</keyname><forenames>Ming</forenames></author><author><keyname>Zhao</keyname><forenames>Hao</forenames></author><author><keyname>Yao</keyname><forenames>Anbang</forenames></author><author><keyname>Chen</keyname><forenames>Yurong</forenames></author><author><keyname>Xu</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>A Closed-form Solution to Universal Style Transfer</title><categories>cs.CV eess.IV</categories><comments>Accepted to ICCV 2019. Code is available at
  https://github.com/lu-m13/OptimalStyleTransfer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universal style transfer tries to explicitly minimize the losses in feature
space, thus it does not require training on any pre-defined styles. It usually
uses different layers of VGG network as the encoders and trains several
decoders to invert the features into images. Therefore, the effect of style
transfer is achieved by feature transform. Although plenty of methods have been
proposed, a theoretical analysis of feature transform is still missing. In this
paper, we first propose a novel interpretation by treating it as the optimal
transport problem. Then, we demonstrate the relations of our formulation with
former works like Adaptive Instance Normalization (AdaIN) and Whitening and
Coloring Transform (WCT). Finally, we derive a closed-form solution named
Optimal Style Transfer (OST) under our formulation by additionally considering
the content loss of Gatys. Comparatively, our solution can preserve better
structure and achieve visually pleasing results. It is simple yet effective and
we demonstrate its advantages both quantitatively and qualitatively. Besides,
we hope our theoretical analysis can inspire future works in neural style
transfer. Code is available at https://github.com/lu-m13/OptimalStyleTransfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00672</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00672</id><created>2019-06-03</created><updated>2019-08-06</updated><authors><author><keyname>He</keyname><forenames>Mutian</forenames></author><author><keyname>Deng</keyname><forenames>Yan</forenames></author><author><keyname>He</keyname><forenames>Lei</forenames></author></authors><title>Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic
  Attention for Neural TTS</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted by Interspeech 2019, Graz, Austria; v3: typo fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural TTS has demonstrated strong capabilities to generate human-like speech
with high quality and naturalness, while its generalization to out-of-domain
texts is still a challenging task, with regard to the design of attention-based
sequence-to-sequence acoustic modeling. Various errors occur in those inputs
with unseen context, including attention collapse, skipping, repeating, etc.,
which limits the broader applications. In this paper, we propose a novel
stepwise monotonic attention method in sequence-to-sequence acoustic modeling
to improve the robustness on out-of-domain inputs. The method utilizes the
strict monotonic property in TTS with constraints on monotonic hard attention
that the alignments between inputs and outputs sequence must be not only
monotonic but allowing no skipping on inputs. Soft attention could be used to
evade mismatch between training and inference. The experimental results show
that the proposed method could achieve significant improvements in robustness
on out-of-domain scenarios for phoneme-based models, without any regression on
the in-domain naturalness test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00709</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00709</id><created>2019-06-03</created><authors><author><keyname>Sagong</keyname><forenames>Min-Cheol</forenames></author><author><keyname>Shin</keyname><forenames>Yong-Goo</forenames></author><author><keyname>Yeo</keyname><forenames>Yoon-Jae</forenames></author><author><keyname>Park</keyname><forenames>Seung</forenames></author><author><keyname>Ko</keyname><forenames>Sung-Jea</forenames></author></authors><title>cGANs with Conditional Convolution Layer</title><categories>cs.CV cs.LG eess.IV</categories><comments>Submitted to International Journal of Computer Vision (IJCV)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional generative adversarial networks (cGANs) have been widely
researched to generate class conditional images using a single generator.
However, in the conventional cGANs techniques, it is still challenging for the
generator to learn condition-specific features, since a standard convolutional
layer with the same weights is used regardless of the condition. In this paper,
we propose a novel convolution layer, called the conditional convolution layer,
which directly generates different feature maps by employing the weights which
are adjusted depending on the conditions. More specifically, in each
conditional convolution layer, the weights are conditioned in a simple but
effective way through filter-wise scaling and channel-wise shifting operations.
In contrast to the conventional methods, the proposed method with a single
generator can effectively handle condition-specific characteristics. The
experimental results on CIFAR, LSUN and ImageNet datasets show that the
generator with the proposed conditional convolution layer achieves a higher
quality of conditional image generation than that with the standard convolution
layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00732</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00732</id><created>2019-05-17</created><authors><author><keyname>Rasouli</keyname><forenames>Mohammad</forenames></author><author><keyname>Pache</keyname><forenames>Camille</forenames></author><author><keyname>Panciatici</keyname><forenames>Patrick</forenames></author><author><keyname>Maeght</keyname><forenames>Jean</forenames></author><author><keyname>Johari</keyname><forenames>Ramesh</forenames></author><author><keyname>Rajagopal</keyname><forenames>Ram</forenames></author></authors><title>Cloud Storage for Multi-Service Battery Operation (Extended Version)</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrical batteries are able to provide a wide range of services to the
electricity system. However, the main barrier to their development is the cost,
which can be overcome by the provision of multiple services. This paper
proposes a multi-service framework where large-scale batteries are shared
between different users and use cases by defining operational metrics such as
multiplexing gain and probability of blocking. We apply this framework to the
specific case of sharing a battery between two services: grid congestion
management and Cloud Storage for households. The proposed Cloud Storage service
allows end users to have access to virtual storage capacities, while taking
advantage of the flexibility of cloud services. An empirical analysis of this
model based on a large set of household consumption data in California and a
real grid use case from the French Transmission System Operator (RTE) evaluates
the economic value of multi-service batteries providing Cloud Storage and grid
congestion management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00733</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00733</id><created>2019-06-03</created><updated>2019-09-22</updated><authors><author><keyname>&#xc1;lvarez</keyname><forenames>David</forenames></author><author><keyname>Pascual</keyname><forenames>Santiago</forenames></author><author><keyname>Bonafonte</keyname><forenames>Antonio</forenames></author></authors><title>Problem-Agnostic Speech Embeddings for Multi-Speaker Text-to-Speech with
  SampleRNN</title><categories>cs.SD eess.AS</categories><comments>Published at 10th ISCA Speech Synthesis Workshop</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Text-to-speech (TTS) acoustic models map linguistic features into an acoustic
representation out of which an audible waveform is generated. The latest and
most natural TTS systems build a direct mapping between linguistic and waveform
domains, like SampleRNN. This way, possible signal naturalness losses are
avoided as intermediate acoustic representations are discarded. Another
important dimension of study apart from naturalness is their adaptability to
generate voice from new speakers that were unseen during training. In this
paper we first propose the use of problem-agnostic speech embeddings in a
multi-speaker acoustic model for TTS based on SampleRNN. This way we feed the
acoustic model with speaker acoustically dependent representations that enrich
the waveform generation more than discrete embeddings unrelated to these
factors. Our first results suggest that the proposed embeddings lead to better
quality voices than those obtained with discrete embeddings. Furthermore, as we
can use any speech segment as an encoded representation during inference, the
model is capable to generalize to new speaker identities without retraining the
network. We finally show that, with a small increase of speech duration in the
embedding extractor, we dramatically reduce the spectral distortion to close
the gap towards the target identities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00768</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00768</id><created>2019-06-03</created><authors><author><keyname>Gozes</keyname><forenames>Ophir</forenames></author><author><keyname>Greenspan</keyname><forenames>Hayit</forenames></author></authors><title>Deep Feature Learning from a Hospital-Scale Chest X-ray Dataset with
  Application to TB Detection on a Small-Scale Dataset</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of ImageNet pre-trained networks is becoming widespread in the
medical imaging community. It enables training on small datasets, commonly
available in medical imaging tasks. The recent emergence of a large Chest X-ray
dataset opened the possibility for learning features that are specific to the
X-ray analysis task. In this work, we demonstrate that the features learned
allow for better classification results for the problem of Tuberculosis
detection and enable generalization to an unseen dataset. To accomplish the
task of feature learning, we train a DenseNet-121 CNN on 112K images from the
ChestXray14 dataset which includes labels of 14 common thoracic pathologies. In
addition to the pathology labels, we incorporate metadata which is available in
the dataset: Patient Positioning, Gender and Patient Age. We term this
architecture MetaChexNet. As a by-product of the feature learning, we
demonstrate state of the art performance on the task of patient Age \&amp; Gender
estimation using CNN's. Finally, we show the features learned using ChestXray14
allow for better transfer learning on small-scale datasets for Tuberculosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00776</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00776</id><created>2019-05-29</created><authors><author><keyname>Shi</keyname><forenames>Weisen</forenames><affiliation>Sherman</affiliation></author><author><keyname>Li</keyname><forenames>Junling</forenames><affiliation>Sherman</affiliation></author><author><keyname>Cheng</keyname><forenames>Nan</forenames><affiliation>Sherman</affiliation></author><author><keyname>Lyu</keyname><forenames>Feng</forenames><affiliation>Sherman</affiliation></author><author><keyname>Dai</keyname><forenames>Yanpeng</forenames><affiliation>Sherman</affiliation></author><author><keyname>Zhou</keyname><forenames>Haibo</forenames><affiliation>Sherman</affiliation></author><author><keyname>Xuemin</keyname><affiliation>Sherman</affiliation></author><author><keyname>Shen</keyname></author></authors><title>3D Multi-Drone-Cell Trajectory Design for Efficient IoT Data Collection</title><categories>cs.NI eess.SP</categories><comments>Accepted by IEEE ICC'19</comments><journal-ref>ICC 2019 - 2019 IEEE International Conference on Communications
  (ICC)</journal-ref><doi>10.1109/ICC.2019.8761719</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drone cell (DC) is an emerging technique to offer flexible and cost-effective
wireless connections to collect Internet-of-things (IoT) data in uncovered
areas of terrestrial networks. The flying trajectory of DC significantly
impacts the data collection performance. However, designing the trajectory is a
challenging issue due to the complicated 3D mobility of DC, unique DC-to-ground
(D2G) channel features, limited DC-to-BS (D2B) backhaul link quality, etc. In
this paper, we propose a 3D DC trajectory design for the DC-assisted IoT data
collection where multiple DCs periodically fly over IoT devices and relay the
IoT data to the base stations (BSs). The trajectory design is formulated as a
mixed integer non-linear programming (MINLP) problem to minimize the average
user-to-DC (U2D) pathloss, considering the state-of-the-art practical D2G
channel model. We decouple the MINLP problem into multiple quasi-convex or
integer linear programming (ILP) sub-problems, which optimizes the user
association, user scheduling, horizontal trajectories and DC flying altitudes
of DCs, respectively. Then, a 3D multi-DC trajectory design algorithm is
developed to solve the MINLP problem, in which the sub-problems are optimized
iteratively through the block coordinate descent (BCD) method. Compared with
the static DC deployment, the proposed trajectory design can lower the average
U2D pathloss by 10-15 dB, and reduce the standard deviation of U2D pathloss by
56%, which indicates the improvements in both link quality and user fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00777</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00777</id><created>2019-05-29</created><updated>2019-10-22</updated><authors><author><keyname>Shi</keyname><forenames>Weisen</forenames></author><author><keyname>Li</keyname><forenames>Junlng</forenames></author><author><keyname>Cheng</keyname><forenames>Nan</forenames></author><author><keyname>Lyu</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Shan</forenames></author><author><keyname>Zhou</keyname><forenames>Haibo</forenames></author><author><keyname>Shen</keyname><forenames>Xuemin</forenames></author></authors><title>Multi-Drone 3D Trajectory Planning and Scheduling in Drone Assisted
  Radio Access Networks</title><categories>cs.NI eess.SP</categories><comments>Published on IEEE TVT</comments><journal-ref>IEEE Transactions on Vehicular Technology, vol. 68, no. 8, pp.
  8145-8158, Aug. 2019</journal-ref><doi>10.1109/TVT.2019.2925629</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drone base station (DBS) is a promising technique to extend wireless
connections for uncovered users of terrestrial radio access networks (RAN). To
improve user fairness and network performance, in this paper, we design 3D
trajectories of multiple DBSs in the drone assisted radio access networks
(DA-RAN) where DBSs fly over associated areas of interests (AoIs) and relay
communications between the base station (BS) and users in AoIs. We formulate
the multi-DBS 3D trajectory planning and scheduling as a mixed integer
non-linear programming (MINLP) problem with the objective of minimizing the
average DBS-to-user (D2U) pathloss. The 3D trajectory variations in both
horizontal and vertical directions, as well as the state-of-the-art DBS-related
channel models are considered in the formulation. To address the non-convexity
and NP-hardness of the MINLP problem, we first decouple it into multiple
integer linear programming (ILP) and quasi-convex sub-problems in which AoI
association, D2U communication scheduling, horizontal trajectories and flying
heights of DBSs are respectively optimized. Then, we design a multi-DBS 3D
trajectory planning and scheduling algorithm to solve the sub-problems
iteratively based on the block coordinate descent (BCD) method. A k-means-based
initial trajectory generation and a search-based start slot scheduling are
considered in the proposed algorithm to improve trajectory design performance
and ensure inter-DBS distance constraint, respectively. Extensive simulations
are conducted to investigate the impacts of DBS quantity, horizontal speed and
initial trajectory on the trajectory planning results. Compared with the static
DBS deployment, the proposed trajectory planning can achieve 10-15 dB reduction
on average D2U pathloss, and reduce the D2U pathloss standard deviation by 68%,
which indicate the improvements of network performance and user fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00778</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00778</id><created>2019-05-30</created><updated>2019-12-08</updated><authors><author><keyname>Saito</keyname><forenames>Yuji</forenames></author><author><keyname>Nonomura</keyname><forenames>Taku</forenames></author><author><keyname>Nankai</keyname><forenames>Koki</forenames></author><author><keyname>Yamada</keyname><forenames>Keigo</forenames></author><author><keyname>Asai</keyname><forenames>Keisuke</forenames></author><author><keyname>Sasaki</keyname><forenames>Yasuo</forenames></author><author><keyname>Tsubakino</keyname><forenames>Daisuke</forenames></author></authors><title>Data-driven Vector-measurement-sensor Selection based on Greedy
  Algorithm</title><categories>eess.SP physics.data-an physics.flu-dyn</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vector-measurement-sensor problem for the least square estimation is
considered, by extending the previous novel approach in this paper. Previous
studies show that the sparse-sensor-placement algorithm in which the state of
the flowfield can be obtained by the limited number of sensors for the
flowfield that can be represented by the limited POD mode. The extension of the
vector-measurement-sensor selection of the greedy algorithm is proposed and is
applied to test and PIV (particle image velocimetry) data to reconstruct the
full state based on the information given by the sparse vector-measurement
sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00782</identifier>
 <datestamp>2019-12-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00782</id><created>2019-05-30</created><authors><author><keyname>de Pedro-Carracedo</keyname><forenames>J.</forenames><affiliation>University of Alcala</affiliation></author><author><keyname>Ugena</keyname><forenames>A. M.</forenames><affiliation>Technical University of Madrid</affiliation></author><author><keyname>Gonzalez-Marcos</keyname><forenames>A. P.</forenames><affiliation>Technical University of Madrid</affiliation></author></authors><title>Dynamical analysis of biological signals with the 0-1 test</title><categories>eess.SP nlin.CD</categories><comments>8 pages, 3 figures with 40 subfigures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 0-1 test distinguishes between regular and chaotic dynamics for a
deterministic system using a time series. Here is presented how to use the test
with biological signals. Between all the biological signals obtained as a times
series, we present the results of applying the test and study with more details
the photoplethysmogram (PPG) from different subjects; different biological
signals of one subject are analyzed also with the test. PPG signal contains
extensive physiological dynamics information; mainly used to heart rate
monitoring and blood oxygen saturation. Based on its understandable statistics,
several indices have been proposed and may apply to some clinical needs.
However, continuous real-time monitoring, of the non-stationary biological
signals, is frequently used on the modern intensive care unit. A deep
understanding of the PPG signal will allow finding algorithms to evaluate other
possible indices that give information about the dynamical system that
constitutes the human body. We demonstrate that the PPG signal, as a time
series, on a healthy individual, is a quasi-periodic signal. The parameters
calculated for the analysis give some ideas of what the quasi-periodic
properties mean. Results are on PPG signals from different healthy young
people. The dynamical analysis of the PPG signal applying the 0-1 test allows
distinguishing a regular dynamic, periodic o quasi-periodic, from a chaotic
dynamics operating directly over the time series. The result obtained is
compared with the results from well known time series that are random, chaotic,
aperiodic, periodic, and quasi-periodic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00789</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00789</id><created>2019-06-03</created><authors><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina</forenames></author><author><keyname>Griffiths</keyname><forenames>Hugh</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Joint Radar and Communication Design: Applications, State-of-the-art,
  and the Road Ahead</title><categories>eess.SP</categories><comments>24 pages, 12 figures, submitted to IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we firstly overview the application scenarios and the research
progress in the area of communication and radar spectrum sharing (CRSS). We
then propose a novel transceiver architecture and frame structure for a
dual-functional radar-communication (DFRC) base station (BS) operating in the
millimeter wave (mmWave) band, using the hybrid analog-digital (HAD)
beamforming technique. We assume that the BS is serving a multi-antenna aided
user equipment (UE) operating in a mmWave channel, which in the meantime
actively detects multiple targets. Note that part of the targets also play the
role of scatterers for the communication signal. Given this framework, we
propose a novel scheme for joint target search and communication channel
estimation relying on the omni-directional pilot signals generated by the HAD
structure. Given a fully-digital communication precoder and a desired radar
transmit beampattern, we propose to design the analog and digital precoders
under non-convex constant-modulus (CM) and power constraints, such that the BS
can formulate narrow beams towards all the targets, while pre-equalizing the
impact of the communication channel. Furthermore, we design an HAD receiver
that can simultaneously process signals from the UE and echo waves from the
targets. By tracking the angular variation of the targets, we show that it is
possible to recover the target echoes and mitigate the potential interference
imposed on the UE signals by invoking the successive interference cancellation
(SIC) technique, even when the radar and communication signals share the
equivalent signal-to-noise ratio (SNR). The feasibility and the efficiency of
the proposed approaches in realizing DFRC are verified via numerical
simulations. Finally, our discussions are summarized by overviewing the open
problems in the research field of CRSS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00794</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00794</id><created>2019-06-03</created><updated>2019-09-05</updated><authors><author><keyname>Serr&#xe0;</keyname><forenames>Joan</forenames></author><author><keyname>Pascual</keyname><forenames>Santiago</forenames></author><author><keyname>Segura</keyname><forenames>Carlos</forenames></author></authors><title>Blow: a single-scale hyperconditioned flow for non-parallel raw-audio
  voice conversion</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Includes appendix. Accepted for NeurIPS2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end models for raw audio generation are a challenge, specially if they
have to work with non-parallel data, which is a desirable setup in many
situations. Voice conversion, in which a model has to impersonate a speaker in
a recording, is one of those situations. In this paper, we propose Blow, a
single-scale normalizing flow using hypernetwork conditioning to perform
many-to-many voice conversion between raw audio. Blow is trained end-to-end,
with non-parallel data, on a frame-by-frame basis using a single speaker
identifier. We show that Blow compares favorably to existing flow-based
architectures and other competitive baselines, obtaining equal or better
performance in both objective and subjective evaluations. We further assess the
impact of its main components with an ablation study, and quantify a number of
properties such as the necessary amount of training data or the preference for
source or target speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00797</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00797</id><created>2019-05-31</created><updated>2019-12-23</updated><authors><author><keyname>Oberguggenberger</keyname><forenames>Michael</forenames></author><author><keyname>Schwarz</keyname><forenames>Martin</forenames></author></authors><title>Deterministic and stochastic damage detection via dynamic response
  analysis</title><categories>eess.SP math.ST stat.TH</categories><msc-class>74J25 (primary) 35C05, 62P30 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a method of damage detection in elastic materials, which
is based on analyzing the time-dependent (dynamic) response of the material
excited by an acoustic signal. A case study is presented consisting of
experimental measurements and their mathematical analysis. The decisive
parameters (wave speed and damping coefficient) of a mathematical model of the
acoustic wave are calibrated by comparing the measurement data with the
numerically evaluated exact solution predicted by the mathematical model. The
calibration is done both deterministically by minimizing the square error over
time and stochastically by a Bayesian approach, implemented through the
Metropolis-Hastings algorithm. The resulting posterior distribution of the
parameters can be used to construct a Bayesian test for damage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00823</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00823</id><created>2019-06-03</created><updated>2019-10-27</updated><authors><author><keyname>Izacard</keyname><forenames>Gautier</forenames></author><author><keyname>Mohan</keyname><forenames>Sreyas</forenames></author><author><keyname>Fernandez-Granda</keyname><forenames>Carlos</forenames></author></authors><title>Data-driven Estimation of Sinusoid Frequencies</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency estimation is a fundamental problem in signal processing, with
applications in radar imaging, underwater acoustics, seismic imaging, and
spectroscopy. The goal is to estimate the frequency of each component in a
multisinusoidal signal from a finite number of noisy samples. A recent
machine-learning approach uses a neural network to output a learned
representation with local maxima at the position of the frequency estimates. In
this work, we propose a novel neural-network architecture that produces a
significantly more accurate representation, and combine it with an additional
neural-network module trained to detect the number of frequencies. This yields
a fast, fully-automatic method for frequency estimation that achieves
state-of-the-art results. In particular, it outperforms existing techniques by
a substantial margin at medium-to-high noise levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00850</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00850</id><created>2019-05-15</created><authors><author><keyname>Mohammed</keyname><forenames>Ihab</forenames></author><author><keyname>Tabatabai</keyname><forenames>Shadha</forenames></author><author><keyname>Al-Fuqaha</keyname><forenames>Ala</forenames></author><author><keyname>Qadir</keyname><forenames>Junaid</forenames></author></authors><title>Opportunistic Data Ferrying in Areas with Limited Information and
  Communications Infrastructure</title><categories>cs.DC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interest in smart cities is rapidly rising due to the global rise in
urbanization and the wide-scale instrumentation of modern cities. Due to the
considerable infrastructural cost of setting up smart cities and smart
communities, researchers are exploring the use of existing vehicles on the
roads as &quot;message ferries&quot; for the transport data for smart community
applications to avoid the cost of installing new communication infrastructure.
In this paper, we propose an opportunistic data ferry selection algorithm that
strives to select vehicles that can minimize the overall delay for data
delivery from a source to a given destination. Our proposed opportunistic
algorithm utilizes an ensemble of online hiring algorithms, which are run
together in passive mode, to select the online hiring algorithm that has
performed the best in recent history. The proposed ensemble based algorithm is
evaluated empirically using real-world traces from taxies plying routes in
Shanghai, China, and its performance is compared against a baseline of four
state-of-the-art online hiring algorithms. A number of experiments are
conducted and our results indicate that the proposed algorithm can reduce the
overall delay compared to the baseline by an impressive 13% to 258%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00884</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00884</id><created>2019-06-03</created><updated>2019-09-28</updated><authors><author><keyname>Dong</keyname><forenames>Haoye</forenames></author><author><keyname>Liang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Zhang</keyname><forenames>Yixuan</forenames></author><author><keyname>Zhang</keyname><forenames>Xujie</forenames></author><author><keyname>Xie</keyname><forenames>Zhenyu</forenames></author><author><keyname>Wu</keyname><forenames>Bowen</forenames></author><author><keyname>Zhang</keyname><forenames>Ziqi</forenames></author><author><keyname>Shen</keyname><forenames>Xiaohui</forenames></author><author><keyname>Yin</keyname><forenames>Jian</forenames></author></authors><title>Fashion Editing with Adversarial Parsing Learning</title><categories>cs.CV eess.IV</categories><comments>22 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactive fashion image manipulation, which enables users to edit images
with sketches and color strokes, is an interesting research problem with great
application value. Existing works often treat it as a general inpainting task
and do not fully leverage the semantic structural information in fashion
images. Moreover, they directly utilize conventional convolution and
normalization layers to restore the incomplete image, which tends to wash away
the sketch and color information. In this paper, we propose a novel Fashion
Editing Generative Adversarial Network (FE-GAN), which is capable of
manipulating fashion images by free-form sketches and sparse color strokes.
FE-GAN consists of two modules: 1) a free-form parsing network that learns to
control the human parsing generation by manipulating sketch and color; 2) a
parsing-aware inpainting network that renders detailed textures with semantic
guidance from the human parsing map. A new attention normalization layer is
further applied at multiple scales in the decoder of the inpainting network to
enhance the quality of the synthesized image. Extensive experiments on
high-resolution fashion image datasets demonstrate that the proposed method
significantly outperforms the state-of-the-art methods on image manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00891</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00891</id><created>2019-06-03</created><updated>2019-06-19</updated><authors><author><keyname>Fan</keyname><forenames>Zhun</forenames></author><author><keyname>Lu</keyname><forenames>Jiewei</forenames></author><author><keyname>Qiu</keyname><forenames>Benzhang</forenames></author><author><keyname>Jiang</keyname><forenames>Tao</forenames></author><author><keyname>An</keyname><forenames>Kang</forenames></author><author><keyname>Josephraj</keyname><forenames>Alex Noel</forenames></author><author><keyname>Wei</keyname><forenames>Chuliang</forenames></author></authors><title>Automated Steel Bar Counting and Center Localization with Convolutional
  Neural Networks</title><categories>cs.CV cs.SY eess.SY</categories><comments>Ready to submit IEEE Transactions on Industrial Informatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated steel bar counting and center localization plays an important role
in the factory automation of steel bars. Traditional methods only focus on
steel bar counting and their performances are often limited by complex
industrial environments. Convolutional neural network (CNN), which has great
capability to deal with complex tasks in challenging environments, is applied
in this work. A framework called CNN-DC is proposed to achieve automated steel
bar counting and center localization simultaneously. The proposed framework
CNN-DC first detects the candidate center points with a deep CNN. Then an
effective clustering algorithm named as Distance Clustering(DC) is proposed to
cluster the candidate center points and locate the true centers of steel bars.
The proposed CNN-DC can achieve 99.26% accuracy for steel bar counting and 4.1%
center offset for center localization on the established steel bar dataset,
which demonstrates that the proposed CNN-DC can perform well on automated steel
bar counting and center localization. Code is made publicly available at:
https://github.com/BenzhangQiu/Steel-bar-Detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00903</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00903</id><created>2019-06-03</created><authors><author><keyname>Wang</keyname><forenames>Chuan</forenames></author><author><keyname>Nguyen</keyname><forenames>Hung D.</forenames></author></authors><title>Steady-state Voltage Profile and Long-term Voltage Stability of
  Electrified Road with Wireless Dynamic Charging</title><categories>eess.SP math.DS</categories><comments>6 pages, 8 figures, accepted to present at eenergy19, ACM19, Phoenix,
  AZ, USA, June 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless dynamic charging technologies are becoming a promising alternative
solution to plug-in ones as they allow on-the-move charging for electric
vehicles. From a power network point of view, this type of charging makes
electric vehicles a new type of loads--the moving loads. Such moving loads are
different from the traditional loads as they may change their locations
constantly in the grids. To study the effect of these moving loads on power
distribution grids, this work focuses on the steady-state analysis of
electrified roads equipped with wireless dynamic charging. In particular, the
voltage profile and the long-term voltage stability of the electrified roads
are considered. Unusual shapes of the voltage profile are observed such as the
half-leaf veins for a one-way road and the harp-like shape for a two-way road.
Voltage swings are also detected while the vehicles move in the two-way road
configuration. As for the long-term voltage stability, continuation power flow
is used to characterize the maximum length of a road as well as the maximum
number of vehicles that the road can accommodate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00905</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00905</id><created>2019-06-03</created><updated>2019-09-18</updated><authors><author><keyname>Nakahira</keyname><forenames>Yorie</forenames></author><author><keyname>Liu</keyname><forenames>Quanying</forenames></author><author><keyname>Sejnowski</keyname><forenames>Terrence J.</forenames></author><author><keyname>Doyle</keyname><forenames>John C.</forenames></author></authors><title>Fitts' Law for speed-accuracy trade-off describes a diversity-enabled
  sweet spot in sensorimotor control</title><categories>eess.SP q-bio.NC</categories><comments>23 pages, 4 figures, Supplementary Material</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Human sensorimotor control exhibits remarkable speed and accuracy, and the
tradeoff between them is encapsulated in Fitts' Law for reaching and pointing.
While Fitts related this to Shannon's channel capacity theorem, despite
widespread study of Fitts' Law, a theory that connects implementation of
sensorimotor control at the system and hardware level has not emerged. Here we
describe a theory that connects hardware (neurons and muscles with inherent
severe speed-accuracy tradeoffs) with system level control to explain Fitts'
Law for reaching and related laws. The results supporting the theory show that
diversity between hardware components is exploited to achieve both fast and
accurate control performance despite slow or inaccurate hardware. Such
&quot;diversity-enabled sweet spots&quot; (DESSs) are ubiquitous in biology and
technology, and explain why large heterogeneities exist in biological and
technical components and how both engineers and natural selection routinely
evolve fast and accurate systems using imperfect hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00939</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00939</id><created>2019-06-03</created><authors><author><keyname>Azari</keyname><forenames>Amin</forenames></author><author><keyname>Papapetrou</keyname><forenames>Panagiotis</forenames></author><author><keyname>Denic</keyname><forenames>Stojan</forenames></author><author><keyname>Peters</keyname><forenames>Gunnar</forenames></author></authors><title>Cellular Traffic Prediction and Classification: a comparative evaluation
  of LSTM and ARIMA</title><categories>cs.NI cs.LG eess.SP stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:1906.00951</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction of user traffic in cellular networks has attracted profound
attention for improving resource utilization. In this paper, we study the
problem of network traffic traffic prediction and classification by employing
standard machine learning and statistical learning time series prediction
methods, including long short-term memory (LSTM) and autoregressive integrated
moving average (ARIMA), respectively. We present an extensive experimental
evaluation of the designed tools over a real network traffic dataset. Within
this analysis, we explore the impact of different parameters to the
effectiveness of the predictions. We further extend our analysis to the problem
of network traffic classification and prediction of traffic bursts. The
results, on the one hand, demonstrate superior performance of LSTM over ARIMA
in general, especially when the length of the training time series is high
enough, and it is augmented by a wisely-selected set of features. On the other
hand, the results shed light on the circumstances in which, ARIMA performs
close to the optimal with lower complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.00944</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.00944</id><created>2019-06-03</created><updated>2019-09-18</updated><authors><author><keyname>Hasnain</keyname><forenames>Aqib</forenames></author><author><keyname>Boddupalli</keyname><forenames>Nibodh</forenames></author><author><keyname>Yeung</keyname><forenames>Enoch</forenames></author></authors><title>Optimal reporter placement in sparsely measured genetic networks using
  the Koopman operator</title><categories>q-bio.MN cs.SY eess.SY math.DS math.OC</categories><comments>6 pages, 3 figures, to appear in 2019 IEEE Conference on Decision and
  Control (CDC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal sensor placement is an important yet unsolved problem in control
theory. In biological organisms, genetic activity is often highly nonlinear,
making it difficult to design libraries of promoters to act as reporters of the
cell state. We make use of the Koopman observability gramian to develop an
algorithm for optimal sensor (or reporter) placement for discrete time
nonlinear dynamical systems to ease the difficulty of design of the promoter
library. This ease is enabled due to the fact that the Koopman operator
represents the evolution of a nonlinear system linearly by lifting the states
to an infinite-dimensional space of observables. The Koopman framework ideally
demands high temporal resolution, but data in biology are often sampled
sparsely in time. Therefore we compute what we call the temporally fine-grained
Koopman operator from the temporally coarse-grained Koopman operator, the
latter of which is identified from the sparse data. The optimal placement of
sensors then corresponds to maximizing the observability of the fine-grained
system. We demonstrate the algorithm on a simulation example of a circadian
oscillator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01040</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01040</id><created>2019-06-03</created><updated>2019-08-19</updated><authors><author><keyname>Guan</keyname><forenames>Melody Y.</forenames></author><author><keyname>Valiant</keyname><forenames>Gregory</forenames></author></authors><title>A Surprising Density of Illusionable Natural Speech</title><categories>cs.SD cs.CL cs.LG eess.AS stat.ML</categories><comments>CogSci 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work on adversarial examples has demonstrated that most natural inputs
can be perturbed to fool even state-of-the-art machine learning systems. But
does this happen for humans as well? In this work, we investigate: what
fraction of natural instances of speech can be turned into &quot;illusions&quot; which
either alter humans' perception or result in different people having
significantly different perceptions? We first consider the McGurk effect, the
phenomenon by which adding a carefully chosen video clip to the audio channel
affects the viewer's perception of what is said (McGurk and MacDonald, 1976).
We obtain empirical estimates that a significant fraction of both words and
sentences occurring in natural speech have some susceptibility to this effect.
We also learn models for predicting McGurk illusionability. Finally we
demonstrate that the Yanny or Laurel auditory illusion (Pressnitzer et al.,
2018) is not an isolated occurrence by generating several very different new
instances. We believe that the surprising density of illusionable natural
speech warrants further investigation, from the perspectives of both security
and cognitive science. Supplementary videos are available at:
https://www.youtube.com/playlist?list=PLaX7t1K-e_fF2iaenoKznCatm0RC37B_k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01054</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01054</id><created>2019-05-04</created><authors><author><keyname>Mishra</keyname><forenames>Sumita</forenames></author><author><keyname>Chaudhary</keyname><forenames>Naresh Kumar</forenames></author><author><keyname>Asthana</keyname><forenames>Pallavi</forenames></author><author><keyname>Kumar</keyname><forenames>Anil</forenames></author></authors><title>Deep 3D Convolutional Neural Network for Automated Lung Cancer Diagnosis</title><categories>eess.IV cs.CV</categories><comments>Initial draft of PAPER Presented at IRSCNS 2018 , Goa , India final
  version available at Mishra S., Chaudhary N.K., Asthana P., Kumar A. (2019)
  Deep 3D Convolutional Neural Network for Automated Lung Cancer Diagnosis. In:
  Peng SL., Dey N., Bundele M. (eds) Computing and Network Sustainability.
  Lecture Notes in Networks and Systems, vol 75. Springer, Singapore</comments><doi>10.1007/978-981-13-7150-9_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer Aided Diagnosis has emerged as an indispensible technique for
validating the opinion of radiologists in CT interpretation. This paper
presents a deep 3D Convolutional Neural Network (CNN) architecture for
automated CT scan-based lung cancer detection system. It utilizes three
dimensional spatial information to learn highly discriminative 3 dimensional
features instead of 2D features like texture or geometric shape whick need to
be generated manually. The proposed deep learning method automatically extracts
the 3D features on the basis of spatio-temporal statistics.The developed model
is end-to-end and is able to predict malignancy of each voxel for given input
scan. Simulation results demonstrate the effectiveness of proposed 3D CNN
network for classification of lung nodule in-spite of limited computational
capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01061</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01061</id><created>2019-06-03</created><authors><author><keyname>Reid</keyname><forenames>Tyler G. R.</forenames></author><author><keyname>Houts</keyname><forenames>Sarah E.</forenames></author><author><keyname>Cammarata</keyname><forenames>Robert</forenames></author><author><keyname>Mills</keyname><forenames>Graham</forenames></author><author><keyname>Agarwal</keyname><forenames>Siddharth</forenames></author><author><keyname>Vora</keyname><forenames>Ankit</forenames></author><author><keyname>Pandey</keyname><forenames>Gaurav</forenames></author></authors><title>Localization Requirements for Autonomous Vehicles</title><categories>cs.RO cs.SY eess.SP</categories><comments>Under review with the SAE Journal of Connected and Automated Vehicles</comments><journal-ref>SAE Intl. J CAV 2(3):2019</journal-ref><doi>10.4271/12-02-03-0012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous vehicles require precise knowledge of their position and
orientation in all weather and traffic conditions for path planning,
perception, control, and general safe operation. Here we derive these
requirements for autonomous vehicles based on first principles. We begin with
the safety integrity level, defining the allowable probability of failure per
hour of operation based on desired improvements on road safety today. This
draws comparisons with the localization integrity levels required in aviation
and rail where similar numbers are derived at 10^-8 probability of failure per
hour of operation. We then define the geometry of the problem, where the aim is
to maintain knowledge that the vehicle is within its lane and to determine what
road level it is on. Longitudinal, lateral, and vertical localization error
bounds (alert limits) and 95% accuracy requirements are derived based on US
road geometry standards (lane width, curvature, and vertical clearance) and
allowable vehicle dimensions. For passenger vehicles operating on freeway
roads, the result is a required lateral error bound of 0.57 m (0.20 m, 95%), a
longitudinal bound of 1.40 m (0.48 m, 95%), a vertical bound of 1.30 m (0.43 m,
95%), and an attitude bound in each direction of 1.50 deg (0.51 deg, 95%). On
local streets, the road geometry makes requirements more stringent where
lateral and longitudinal error bounds of 0.29 m (0.10 m, 95%) are needed with
an orientation requirement of 0.50 deg (0.17 deg, 95%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01062</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01062</id><created>2019-06-03</created><authors><author><keyname>Ahmadzadeh</keyname><forenames>Azim</forenames></author><author><keyname>Kempton</keyname><forenames>Dustin J.</forenames></author><author><keyname>Angryk</keyname><forenames>Rafal A.</forenames></author></authors><title>A Curated Image Parameter Dataset from Solar Dynamics Observatory
  Mission</title><categories>astro-ph.SR astro-ph.IM cs.CV eess.IV</categories><comments>Accepted to The Astrophysical Journal Supplement Series, 2019, 29
  pages</comments><doi>10.3847/1538-4365/ab253a</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a large image parameter dataset extracted from the Solar Dynamics
Observatory (SDO) mission's AIA instrument, for the period of January 2011
through the current date, with the cadence of six minutes, for nine wavelength
channels. The volume of the dataset for each year is just short of 1 TiB.
Towards achieving better results in the region classification of active regions
and coronal holes, we improve upon the performance of a set of ten image
parameters, through an in depth evaluation of various assumptions that are
necessary for calculation of these image parameters. Then, where possible, a
method for finding an appropriate settings for the parameter calculations was
devised, as well as a validation task to show our improved results. In
addition, we include comparisons of JP2 and FITS image formats using supervised
classification models, by tuning the parameters specific to the format of the
images from which they are extracted, and specific to each wavelength. The
results of these comparisons show that utilizing JP2 images, which are
significantly smaller files, is not detrimental to the region classification
task that these parameters were originally intended for. Finally, we compute
the tuned parameters on the AIA images and provide a public API
(http://dmlab.cs.gsu.edu/dmlabapi) to access the dataset. This dataset can be
used in a range of studies on AIA images, such as content-based image retrieval
or tracking of solar events, where dimensionality reduction on the images is
necessary for feasibility of the tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01075</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01075</id><created>2019-05-30</created><updated>2019-06-23</updated><authors><author><keyname>Shylendra</keyname><forenames>Ahish</forenames></author><author><keyname>Bhunia</keyname><forenames>Swarup</forenames></author><author><keyname>Trivedi</keyname><forenames>Amit Ranjan</forenames></author></authors><title>Using your ADC and Backend Capacitors to Authenticate for Free:
  (Virtually) Free from Database, Enrollment, and Excessive Area/Power Overhead</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of counterfeit chips has emerged as a crucial concern.
Physically-unclonable-function (PUF)-based techniques are widely used for
authentication, however, require dedicated hardware and large signature
database. In this work, we show intrinsic &amp; database-free authentication using
back-end capacitors. The discussed technique simplifies authentication setup
and reduces the test cost. We show that an analog-to-digital converter (ADC)
can be modified for back-end capacitor-based authentication in addition to its
regular functionality; hence, a dedicated authentication module is not
necessary. Moreover, since back-end capacitors are quite insensitive to
temperature and aging-induced variations than transistors, the discussed
technique result in a more reliable authentication than transistor PUF-based
authentication. The modifications to conventional ADC incur 3.2% power overhead
and 75% active-area overhead; however, arguably, the advantages of the
discussed intrinsic &amp; database-free authentication outweigh the overheads. Full
version of this article is published at IEEE TVLSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01078</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01078</id><created>2019-05-31</created><updated>2019-07-31</updated><authors><author><keyname>Wu</keyname><forenames>Jyun-Yi</forenames></author><author><keyname>Yu</keyname><forenames>Cheng</forenames></author><author><keyname>Fu</keyname><forenames>Szu-Wei</forenames></author><author><keyname>Liu</keyname><forenames>Chih-Ting</forenames></author><author><keyname>Chien</keyname><forenames>Shao-Yi</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author></authors><title>Increasing Compactness Of Deep Learning Based Speech Enhancement Models
  With Parameter Pruning And Quantization Techniques</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>4pages, 6 figures</comments><doi>10.1109/LSP.2019.2951950</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most recent studies on deep learning based speech enhancement (SE) focused on
improving denoising performance. However, successful SE applications require
striking a desirable balance between denoising performance and computational
cost in real scenarios. In this study, we propose a novel parameter pruning
(PP) technique, which removes redundant channels in a neural network. In
addition, a parameter quantization (PQ) technique was applied to reduce the
size of a neural network by representing weights with fewer cluster centroids.
Because the techniques are derived based on different concepts, the PP and PQ
can be integrated to provide even more compact SE models. The experimental
results show that the PP and PQ techniques produce a compacted SE model with a
size of only 10.03% compared to that of the original model, resulting in minor
performance losses of 1.43% (from 0.70 to 0.69) for STOI and 3.24% (from 1.85
to 1.79) for PESQ. The promising results suggest that the PP and PQ techniques
can be used in a SE system in devices with limited storage and computation
resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01082</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01082</id><created>2019-05-31</created><updated>2019-10-12</updated><authors><author><keyname>Gao</keyname><forenames>Tingran</forenames></author><author><keyname>Fan</keyname><forenames>Yifeng</forenames></author><author><keyname>Zhao</keyname><forenames>Zhizhen</forenames></author></authors><title>Representation Theoretic Patterns in Multi-Frequency Class Averaging for
  Three-Dimensional Cryo-Electron Microscopy</title><categories>eess.IV cs.CV math.FA</categories><comments>31 pages, 10 figures</comments><msc-class>20G05, 33C45, 33C55, 55R25</msc-class><acm-class>I.4.5; I.4.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop in this paper a novel intrinsic classification algorithm --
multi-frequency class averaging (MFCA) -- for clustering noisy projection
images obtained from three-dimensional cryo-electron microscopy (cryo-EM) by
the similarity among their viewing directions. This new algorithm leverages
multiple irreducible representations of the unitary group to introduce
additional redundancy into the representation of the transport data, extending
and outperforming the previous class averaging algorithm of Hadani and Singer
[Foundations of Computational Mathematics, 11 (5), pp. 589--616 (2011)] that
uses only a single representation. The formal algebraic model and
representation theoretic patterns of the proposed MFCA algorithm extend the
framework of Hadani and Singer to arbitrary irreducible representations of the
unitary group. We conceptually establish the consistency and stability of MFCA
by inspecting the spectral properties of a generalized localized parallel
transport operator on the two-dimensional unit sphere through the lens of
Wigner matrices. We demonstrate the efficacy of the proposed algorithm with
numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01083</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01083</id><created>2019-06-04</created><authors><author><keyname>Vasquez</keyname><forenames>Sean</forenames></author><author><keyname>Lewis</keyname><forenames>Mike</forenames></author></authors><title>MelNet: A Generative Model for Audio in the Frequency Domain</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capturing high-level structure in audio waveforms is challenging because a
single second of audio spans tens of thousands of timesteps. While long-range
dependencies are difficult to model directly in the time domain, we show that
they can be more tractably modelled in two-dimensional time-frequency
representations such as spectrograms. By leveraging this representational
advantage, in conjunction with a highly expressive probabilistic model and a
multiscale generation procedure, we design a model capable of generating
high-fidelity audio samples which capture structure at timescales that
time-domain models have yet to achieve. We apply our model to a variety of
audio generation tasks, including unconditional speech generation, music
generation, and text-to-speech synthesis---showing improvements over previous
approaches in both density estimates and human judgments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01087</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01087</id><created>2019-06-03</created><updated>2019-10-16</updated><authors><author><keyname>Wang</keyname><forenames>Fen</forenames></author><author><keyname>Wang</keyname><forenames>Yongchao</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Yang</keyname><forenames>Cheng</forenames></author></authors><title>Graph Sampling for Matrix Completion Using Recurrent Gershgorin Disc
  Shift</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix completion algorithms fill missing entries in a large matrix given a
subset of observed samples. However, how to best pre-select informative matrix
entries given a sampling budget is largely unaddressed. In this paper, we
propose a fast sample selection strategy for matrix completion from a graph
signal processing perspective. Specifically, we first regularize the matrix
reconstruction objective using a dual graph signal smoothness prior, resulting
in a system of linear equations for solution. We then select appropriate
samples to maximize the smallest eigenvalue $\lambda_{\min}$ of the coefficient
matrix, thus maximizing the stability of the linear system. To efficiently
solve this combinatorial problem, we derive a greedy sampling strategy,
leveraging on Gershgorin circle theorem, that iteratively selects one sample
(equivalent to shifting one Gershgorin disc) at a time corresponding to the
largest magnitude entry in the first eigenvector of a modified graph Laplacian
matrix. Our algorithm benefits computationally from warm start as the first
eigenvectors of incremented Laplacian matrices are computed recurrently for
more samples. To achieve computation scalability when sampling large matrices,
we further rewrite the coefficient matrix as a sum of two separate components,
each of which exhibits block-diagonal structure that we exploit for alternating
block-wise sampling. Extensive experiments on both synthetic and real-world
datasets show that our graph sampling algorithm substantially outperforms
existing sampling schemes for matrix completion and reduces the completion
error, when combined with a range of modern matrix completion algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01095</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01095</id><created>2019-06-03</created><authors><author><keyname>Lin</keyname><forenames>Ming</forenames></author><author><keyname>Song</keyname><forenames>Xiaomin</forenames></author><author><keyname>Qian</keyname><forenames>Qi</forenames></author><author><keyname>Li</keyname><forenames>Hao</forenames></author><author><keyname>Sun</keyname><forenames>Liang</forenames></author><author><keyname>Zhu</keyname><forenames>Shenghuo</forenames></author><author><keyname>Jin</keyname><forenames>Rong</forenames></author></authors><title>Robust Gaussian Process Regression for Real-Time High Precision GPS
  Signal Enhancement</title><categories>stat.ML cs.LG eess.SP</categories><comments>accepted by SIGKDD 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Satellite-based positioning system such as GPS often suffers from large
amount of noise that degrades the positioning accuracy dramatically especially
in real-time applications. In this work, we consider a data-mining approach to
enhance the GPS signal. We build a large-scale high precision GPS receiver grid
system to collect real-time GPS signals for training. The Gaussian Process (GP)
regression is chosen to model the vertical Total Electron Content (vTEC)
distribution of the ionosphere of the Earth. Our experiments show that the
noise in the real-time GPS signals often exceeds the breakdown point of the
conventional robust regression methods resulting in sub-optimal system
performance. We propose a three-step approach to address this challenge. In the
first step we perform a set of signal validity tests to separate the signals
into clean and dirty groups. In the second step, we train an initial model on
the clean signals and then reweigting the dirty signals based on the residual
error. A final model is retrained on both the clean signals and the reweighted
dirty signals. In the theoretical analysis, we prove that the proposed
three-step approach is able to tolerate much higher noise level than the
vanilla robust regression methods if two reweighting rules are followed. We
validate the superiority of the proposed method in our real-time high precision
positioning system against several popular state-of-the-art robust regression
methods. Our method achieves centimeter positioning accuracy in the benchmark
region with probability $78.4\%$ , outperforming the second best baseline
method by a margin of $8.3\%$. The benchmark takes 6 hours on 20,000 CPU cores
or 14 years on a single CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01123</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01123</id><created>2019-06-03</created><authors><author><keyname>Kozlovtsev</keyname><forenames>Konstantin</forenames></author><author><keyname>Kitov</keyname><forenames>Victor</forenames></author></authors><title>Depth-Preserving Real-Time Arbitrary Style Transfer</title><categories>cs.CV eess.IV</categories><msc-class>68T45</msc-class><acm-class>I.4.9; I.4.10</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Style transfer is the process of rendering one image with some content in the
style of another image, representing the style. Recent studies of Liu et al.
(2017) have shown significant improvement of style transfer rendering quality
by adjusting traditional methods of Gatys et al. (2016) and Johnson et al.
(2016) with regularizer, forcing preservation of the depth map of the content
image. However these traditional methods are either computationally inefficient
or require training a separate neural network for new style. AdaIN method of
Huang et al. (2017) allows efficient transferring of arbitrary style without
training a separate model but is not able to reproduce the depth map of the
content image. We propose an extension to this method, allowing depth map
preservation. Qualitative analysis and results of user evaluation study
indicate that the proposed method provides better stylizations, compared to the
original style transfer methods of Gatys et al. (2016) and Huang et al. (2017).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01155</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01155</id><created>2019-06-03</created><updated>2019-06-10</updated><authors><author><keyname>Nezami</keyname><forenames>Omid Mohamad</forenames></author><author><keyname>Lou</keyname><forenames>Paria Jamshid</forenames></author><author><keyname>Karami</keyname><forenames>Mansoureh</forenames></author></authors><title>ShEMO -- A Large-Scale Validated Database for Persian Speech Emotion
  Detection</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a large-scale, validated database for Persian called
Sharif Emotional Speech Database (ShEMO). The database includes 3000
semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data
extracted from online radio plays. The ShEMO covers speech samples of 87
native-Persian speakers for five basic emotions including anger, fear,
happiness, sadness and surprise, as well as neutral state. Twelve annotators
label the underlying emotional state of utterances and majority voting is used
to decide on the final labels. According to the kappa measure, the
inter-annotator agreement is 64% which is interpreted as &quot;substantial
agreement&quot;. We also present benchmark results based on common classification
methods in speech emotion detection task. According to the experiments, support
vector machine achieves the best results for both gender-independent (58.2%)
and gender-dependent models (female=59.4%, male=57.6%). The ShEMO is available
for academic purposes free of charge to provide a baseline for further research
on Persian emotional speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01157</identifier>
 <datestamp>2019-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01157</id><created>2019-06-03</created><updated>2019-11-04</updated><authors><author><keyname>Voleti</keyname><forenames>Rohit</forenames></author><author><keyname>Liss</keyname><forenames>Julie M.</forenames></author><author><keyname>Berisha</keyname><forenames>Visar</forenames></author></authors><title>A Review of Automated Speech and Language Features for Assessment of
  Cognitive and Thought Disorders</title><categories>cs.CL cs.SD eess.AS eess.SP</categories><comments>\c{opyright} 2019 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</comments><report-no>J-STSP-AAHD-00183-2019</report-no><doi>10.1109/JSTSP.2019.2952087</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is widely accepted that information derived from analyzing speech (the
acoustic signal) and language production (words and sentences) serves as a
useful window into the health of an individual's cognitive ability. In fact,
most neuropsychological testing batteries have a component related to speech
and language where clinicians elicit speech from patients for subjective
evaluation across a broad set of dimensions. With advances in speech signal
processing and natural language processing, there has been recent interest in
developing tools to detect more subtle changes in cognitive-linguistic
function. This work relies on extracting a set of features from recorded and
transcribed speech for objective assessments of speech and language, early
diagnosis of neurological disease, and tracking of disease after diagnosis.
With an emphasis on cognitive and thought disorders, in this paper we provide a
review of existing speech and language features used in this domain, discuss
their clinical application, and highlight their advantages and disadvantages.
Broadly speaking, the review is split into two categories: language features
based on natural language processing and speech features based on speech signal
processing. Within each category, we consider features that aim to measure
complementary dimensions of cognitive-linguistics, including language
diversity, syntactic complexity, semantic coherence, and timing. We conclude
the review with a proposal of new research directions to further advance the
field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01168</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01168</id><created>2019-06-03</created><authors><author><keyname>Schreiber</keyname><forenames>Jens</forenames></author></authors><title>Transfer Learning in the Field of Renewable Energies -- A Transfer
  Learning Framework Providing Power Forecasts Throughout the Lifecycle of Wind
  Farms After Initial Connection to the Electrical Grid</title><categories>cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, transfer learning gained particular interest in the field of
vision and natural language processing. In the research field of vision, e.g.,
deep neural networks and transfer learning techniques achieve almost perfect
classification scores within minutes. Nonetheless, these techniques are not yet
widely applied in other domains. Therefore, this article identifies critical
challenges and shows potential solutions for power forecasts in the field of
renewable energies. It proposes a framework utilizing transfer learning
techniques in wind power forecasts with limited or no historical data. On the
one hand, this allows evaluating the applicability of transfer learning in the
field of renewable energy. On the other hand, by developing automatic
procedures, we assure that the proposed methods provide a framework that
applies to domains in organic computing as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01199</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01199</id><created>2019-06-04</created><authors><author><keyname>Salesky</keyname><forenames>Elizabeth</forenames></author><author><keyname>Sperber</keyname><forenames>Matthias</forenames></author><author><keyname>Black</keyname><forenames>Alan W</forenames></author></authors><title>Exploring Phoneme-Level Speech Representations for End-to-End Speech
  Translation</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to ACL 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work on end-to-end translation from speech has primarily used
frame-level features as speech representations, which creates longer, sparser
sequences than text. We show that a naive method to create compressed
phoneme-like speech representations is far more effective and efficient for
translation than traditional frame-level speech features. Specifically, we
generate phoneme labels for speech frames and average consecutive frames with
the same label to create shorter, higher-level source sequences for
translation. We see improvements of up to 5 BLEU on both our high and low
resource language pairs, with a reduction in training time of 60%. Our
improvements hold across multiple data sizes and two language pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01203</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01203</id><created>2019-06-04</created><authors><author><keyname>Liu</keyname><forenames>Jen-Yu</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Dilated Convolution with Dilated GRU for Music Source Separation</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stacked dilated convolutions used in Wavenet have been shown effective for
generating high-quality audios. By replacing pooling/striding with dilation in
convolution layers, they can preserve high-resolution information and still
reach distant locations. Producing high-resolution predictions is also crucial
in music source separation, whose goal is to separate different sound sources
while maintaining the quality of the separated sounds. Therefore, this paper
investigates using stacked dilated convolutions as the backbone for music
source separation. However, while stacked dilated convolutions can reach wider
context than standard convolutions, their effective receptive fields are still
fixed and may not be wide enough for complex music audio signals. To reach
information at remote locations, we propose to combine dilated convolution with
a modified version of gated recurrent units (GRU) called the `Dilated GRU' to
form a block. A Dilated GRU unit receives information from k steps before
instead of the previous step for a fixed k. This modification allows a GRU unit
to reach a location with fewer recurrent steps and run faster because it can
execute partially in parallel. We show that the proposed model with a stack of
such blocks performs equally well or better than the state-of-the-art models
for separating vocals and accompaniments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01223</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01223</id><created>2019-06-04</created><updated>2019-06-05</updated><authors><author><keyname>Campos</keyname><forenames>Joaquim</forenames></author><author><keyname>Meierhans</keyname><forenames>Simon</forenames></author><author><keyname>Djelouah</keyname><forenames>Abdelaziz</forenames></author><author><keyname>Schroers</keyname><forenames>Christopher</forenames></author></authors><title>Content Adaptive Optimization for Neural Image Compression</title><categories>cs.CV eess.IV</categories><comments>CVPR Workshop and Challenge on Learned Image Compression (2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of neural image compression has witnessed exciting progress as
recently proposed architectures already surpass the established transform
coding based approaches. While, so far, research has mainly focused on
architecture and model improvements, in this work we explore content adaptive
optimization. To this end, we introduce an iterative procedure which adapts the
latent representation to the specific content we wish to compress while keeping
the parameters of the network and the predictive model fixed. Our experiments
show that this allows for an overall increase in rate-distortion performance,
independently of the specific architecture used. Furthermore, we also evaluate
this strategy in the context of adapting a pretrained network to other content
that is different in visual appearance or resolution. Here, our experiments
show that our adaptation strategy can largely close the gap as compared to
models specifically trained for the given content while having the benefit that
no additional data in the form of model parameter updates has to be
transmitted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01259</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01259</id><created>2019-06-04</created><authors><author><keyname>Hou</keyname><forenames>Xianxu</forenames></author><author><keyname>Luo</keyname><forenames>Hongming</forenames></author><author><keyname>Liu</keyname><forenames>Jingxin</forenames></author><author><keyname>Xu</keyname><forenames>Bolei</forenames></author><author><keyname>Sun</keyname><forenames>Ke</forenames></author><author><keyname>Gong</keyname><forenames>Yuanhao</forenames></author><author><keyname>Liu</keyname><forenames>Bozhi</forenames></author><author><keyname>Qiu</keyname><forenames>Guoping</forenames></author></authors><title>Learning Deep Image Priors for Blind Image Denoising</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image denoising is the process of removing noise from noisy images, which is
an image domain transferring task, i.e., from a single or several noise level
domains to a photo-realistic domain. In this paper, we propose an effective
image denoising method by learning two image priors from the perspective of
domain alignment. We tackle the domain alignment on two levels. 1) the
feature-level prior is to learn domain-invariant features for corrupted images
with different level noise; 2) the pixel-level prior is used to push the
denoised images to the natural image manifold. The two image priors are based
on $\mathcal{H}$-divergence theory and implemented by learning classifiers in
adversarial training manners. We evaluate our approach on multiple datasets.
The results demonstrate the effectiveness of our approach for robust image
denoising on both synthetic and real-world noisy images. Furthermore, we show
that the feature-level prior is capable of alleviating the discrepancy between
different level noise. It can be used to improve the blind denoising
performance in terms of distortion measures (PSNR and SSIM), while pixel-level
prior can effectively improve the perceptual quality to ensure the realistic
outputs, which is further validated by subjective evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01272</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01272</id><created>2019-06-04</created><authors><author><keyname>Rogers</keyname><forenames>Thomas W.</forenames></author><author><keyname>Jaccard</keyname><forenames>Nicolas</forenames></author><author><keyname>Carbonaro</keyname><forenames>Francis</forenames></author><author><keyname>Lemij</keyname><forenames>Hans G.</forenames></author><author><keyname>Vermeer</keyname><forenames>Koenraad A.</forenames></author><author><keyname>Reus</keyname><forenames>Nicolaas J.</forenames></author><author><keyname>Trikha</keyname><forenames>Sameer</forenames></author></authors><title>Evaluation of an AI system for the automated detection of glaucoma from
  stereoscopic optic disc photographs: the European Optic Disc Assessment Study</title><categories>cs.CV eess.IV</categories><comments>24 pages, 3 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objectives: To evaluate the performance of a deep learning based Artificial
Intelligence (AI) software for detection of glaucoma from stereoscopic optic
disc photographs, and to compare this performance to the performance of a large
cohort of ophthalmologists and optometrists.
  Methods: A retrospective study evaluating the diagnostic performance of an AI
software (Pegasus v1.0, Visulytix Ltd., London UK) and comparing it to that of
243 European ophthalmologists and 208 British optometrists, as determined in
previous studies, for the detection of glaucomatous optic neuropathy from 94
scanned stereoscopic photographic slides scanned into digital format.
  Results: Pegasus was able to detect glaucomatous optic neuropathy with an
accuracy of 83.4% (95% CI: 77.5-89.2). This is comparable to an average
ophthalmologist accuracy of 80.5% (95% CI: 67.2-93.8) and average optometrist
accuracy of 80% (95% CI: 67-88) on the same images. In addition, the AI system
had an intra-observer agreement (Cohen's Kappa, $\kappa$) of 0.74 (95% CI:
0.63-0.85), compared to 0.70 (range: -0.13-1.00; 95% CI: 0.67-0.73) and 0.71
(range: 0.08-1.00) for ophthalmologists and optometrists, respectively. There
was no statistically significant difference between the performance of the deep
learning system and ophthalmologists or optometrists. There was no
statistically significant difference between the performance of the deep
learning system and ophthalmologists or optometrists.
  Conclusion: The AI system obtained a diagnostic performance and repeatability
comparable to that of the ophthalmologists and optometrists. We conclude that
deep learning based AI systems, such as Pegasus, demonstrate significant
promise in the assisted detection of glaucomatous optic neuropathy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01299</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01299</id><created>2019-06-04</created><authors><author><keyname>Anand</keyname><forenames>Ashwary</forenames></author><author><keyname>Agrawal</keyname><forenames>Shubh</forenames></author><author><keyname>Agrawal</keyname><forenames>Shivang</forenames></author><author><keyname>Chandra</keyname><forenames>Aman</forenames></author><author><keyname>Deshmukh</keyname><forenames>Krishnakant</forenames></author></authors><title>Grid-based Localization Stack for Inspection Drones towards Automation
  of Large Scale Warehouse Systems</title><categories>cs.RO eess.IV</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SLAM based techniques are often adopted for solving the navigation problem
for the drones in GPS denied environment. Despite the widespread success of
these approaches, they have not yet been fully exploited for automation in a
warehouse system due to expensive sensors and setup requirements. This paper
focuses on the use of low-cost monocular camera-equipped drones for performing
warehouse management tasks like inventory scanning and position update. The
methods introduced are at par with the existing state of warehouse environment
present today, that is, the existence of a grid network for the ground
vehicles, hence eliminating any additional infrastructure requirement for drone
deployment. As we lack scale information, that in itself forbids us to use any
3D techniques, we focus more towards optimizing standard image processing
algorithms like the thick line detection and further developing it into a fast
and robust grid localization framework. In this paper, we show different line
detection algorithms, their significance in grid localization and their
limitations. We further extend our proposed implementation towards a real-time
navigation stack for an actual warehouse inspection case scenario. Our line
detection method using skeletonization and centroid strategy works considerably
even with varying light conditions, line thicknesses, colors, orientations, and
partial occlusions. A simple yet effective Kalman Filter has been used for
smoothening the {\rho} and {\theta} outputs of the two different line detection
methods for better drone control while grid following. A generic strategy that
handles the navigation of the drone on a grid for completion of the allotted
task is also developed. Based on the simulation and real-life experiments, the
final developments on the drone localization and navigation in a structured
environment are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01379</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01379</id><created>2019-06-04</created><authors><author><keyname>Huang</keyname><forenames>Zhongling</forenames></author><author><keyname>Pan</keyname><forenames>Zongxu</forenames></author><author><keyname>Lei</keyname><forenames>Bin</forenames></author></authors><title>What, Where and How to Transfer in SAR Target Recognition Based on Deep
  CNNs</title><categories>eess.SP cs.CV</categories><journal-ref>IEEE Transactions on Geoscience and Remote Sensing 2019</journal-ref><doi>10.1109/TGRS.2019.2947634</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep convolutional neural networks (DCNNs) have attracted much attention in
remote sensing recently. Compared with the large-scale annotated dataset in
natural images, the lack of labeled data in remote sensing becomes an obstacle
to train a deep network very well, especially in SAR image interpretation.
Transfer learning provides an effective way to solve this problem by borrowing
the knowledge from the source task to the target task. In optical remote
sensing application, a prevalent mechanism is to fine-tune on an existing model
pre-trained with a large-scale natural image dataset, such as ImageNet.
However, this scheme does not achieve satisfactory performance for SAR
application because of the prominent discrepancy between SAR and optical
images. In this paper, we attempt to discuss three issues that are seldom
studied before in detail: (1) what network and source tasks are better to
transfer to SAR targets, (2) in which layer are transferred features more
generic to SAR targets and (3) how to transfer effectively to SAR targets
recognition. Based on the analysis, a transitive transfer method via
multi-source data with domain adaptation is proposed in this paper to decrease
the discrepancy between the source data and SAR targets. Several experiments
are conducted on OpenSARShip. The results indicate that the universal
conclusions about transfer learning in natural images cannot be completely
applied to SAR targets, and the analysis of what and where to transfer in SAR
target recognition is helpful to decide how to transfer more effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01453</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01453</id><created>2019-06-03</created><authors><author><keyname>Nardelli</keyname><forenames>Marco Buongiorno</forenames></author></authors><title>MUSICNTWRK: data tools for music theory, analysis and composition</title><categories>cs.SD eess.AS</categories><comments>arXiv admin note: substantial text overlap with arXiv:1905.01842</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the API for MUSICNTWRK, a python library for pitch class set and
rhythmic sequences classification and manipulation, the generation of networks
in generalized music and sound spaces, deep learning algorithms for timbre
recognition, and the sonification of arbitrary data. The software is freely
available under GPL 3.0 and can be downloaded at www.musicntwrk.com.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01454</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01454</id><created>2019-06-03</created><updated>2019-11-04</updated><authors><author><keyname>Vestman</keyname><forenames>Ville</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author><author><keyname>Hautam&#xe4;ki</keyname><forenames>Rosa Gonz&#xe1;lez</forenames></author><author><keyname>Sahidullah</keyname><forenames>Md</forenames></author></authors><title>Voice Mimicry Attacks Assisted by Automatic Speaker Verification</title><categories>eess.AS cs.CR cs.LG cs.SD</categories><comments>Published in Computer Speech and Language. arXiv admin note: text
  overlap with arXiv:1811.03790</comments><doi>10.1016/j.csl.2019.05.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we simulate a scenario, where a publicly available ASV system
is used to enhance mimicry attacks against another closed source ASV system. In
specific, ASV technology is used to perform a similarity search between the
voices of recruited attackers (6) and potential target speakers (7,365) from
VoxCeleb corpora to find the closest targets for each of the attackers. In
addition, we consider 'median', 'furthest', and 'common' targets to serve as a
reference points. Our goal is to gain insights how well similarity rankings
transfer from the attacker's ASV system to the attacked ASV system, whether the
attackers are able to improve their attacks by mimicking, and how the
properties of the voices of attackers change due to mimicking. We address these
questions through ASV experiments, listening tests, and prosodic and formant
analyses. For the ASV experiments, we use i-vector technology in the attacker
side, and x-vectors in the attacked side. For the listening tests, we recruit
listeners through crowdsourcing. The results of the ASV experiments indicate
that the speaker similarity scores transfer well from one ASV system to
another. Both the ASV experiments and the listening tests reveal that the
mimicry attempts do not, in general, help in bringing attacker's scores closer
to the target's. A detailed analysis shows that mimicking does not improve
attacks, when the natural voices of attackers and targets are similar to each
other. The analysis of prosody and formants suggests that the attackers were
able to considerably change their speaking rates when mimicking, but the
changes in F0 and formants were modest. Overall, the results suggest that
untrained impersonators do not pose a high threat towards ASV systems, but the
use of ASV systems to attack other ASV systems is a potential threat.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01456</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01456</id><created>2019-06-03</created><authors><author><keyname>Nikitin</keyname><forenames>Alexei V.</forenames></author><author><keyname>Davidchack</keyname><forenames>Ruslan L.</forenames></author></authors><title>Complementary Intermittently Nonlinear Filtering for Mitigation of
  Hidden Outlier Interference</title><categories>eess.SP</categories><comments>9 pages, 14 figures. arXiv admin note: substantial text overlap with
  arXiv:1905.10476</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When interference affecting various communication and sensor systems contains
clearly identifiable outliers (e.g. an impulsive component), it can be
efficiently mitigated in real time by intermittently nonlinear filters
developed in our earlier work, achieving improvements in the signal quality
otherwise unattainable. However, apparent amplitude outliers in the
interference can disappear and reappear due to various filtering effects,
including fading and multipass, as the signal propagates through media and/or
the signal processing chain. In addition, the outlier structure of the
interference can be obscured by strong non-outlier interfering signals, such as
thermal noise and/or adjacent channel interference, or by the signal of
interest itself. In this paper, we first outline the overall approach to using
intermittently nonlinear filters for in-band, real-time mitigation of such
interference with hidden outlier components in practical complex interference
scenarios. We then introduce Complementary Intermittently Nonlinear Filters
(CINFs) and focus on the particular task of mitigating the outlier noise
obscured by the signal of interest itself. We describe practical
implementations of such nonlinear filtering arrangements for mitigation of
hidden outlier interference, in the process of analog-to-digital conversion,
for wide ranges of interference powers and the rates of outlier generating
events. To emphasize the effectiveness and versatility of this approach, in our
examples we use particularly challenging waveforms that severely obscure
low-amplitude outlier noise, such as broadband chirp signals (e.g. used in
radar, sonar, and spread-spectrum communications) and ``bursty,&quot; high crest
factor signals (e.g. OFDM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01503</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01503</id><created>2019-06-04</created><authors><author><keyname>Cisotto</keyname><forenames>Giulia</forenames></author><author><keyname>Casarin</keyname><forenames>Edoardo</forenames></author><author><keyname>Tomasin</keyname><forenames>Stefano</forenames></author></authors><title>Performance Requirements of Advanced Healthcare Services over Future
  Cellular Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fifth generation (5G) of communication systems has ambitious targets of
data rate, end-to-end latency, and connection availability, while the
deployment of a new flexible network architecture will spur new applications.
E-health and mobile health (m-health) solutions will meet the increasing demand
of new, sustainable, and more accessible services beneficial to both
practitioners and the rapidly aging population. This paper aims at defining the
technical requirements of future cellular networks to support a variety of
advanced healthcare services (e.g., smart hospital, telesurgery, connected
ambulances, and monitoring). While 5G will be able to satisfy these
requirements, it will also pave the way for future e- and m-health in the
sixth-generation (6G) cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01513</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01513</id><created>2019-05-30</created><authors><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author><author><keyname>Lu</keyname><forenames>Mingyang</forenames></author><author><keyname>Tang</keyname><forenames>Jiawei</forenames></author><author><keyname>Zhao</keyname><forenames>Qian</forenames></author><author><keyname>Zhang</keyname><forenames>Zhijie</forenames></author><author><keyname>Li</keyname><forenames>Kai</forenames></author><author><keyname>Han</keyname><forenames>Yan</forenames></author><author><keyname>Peyton</keyname><forenames>Anthony</forenames></author></authors><title>Custom Edge-Element FEM Solver and its Application to Eddy-Current
  Simulation of Realistic 2M-Element Human Brain Phantom</title><categories>physics.med-ph eess.SP physics.bio-ph physics.comp-ph q-bio.QM</categories><doi>10.1002/bem.22148</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extensive research papers of three-dimensional computational techniques are
widely used for the investigation of human brain pathophysiology. Eddy current
analyzing could provide an indication of conductivity change within a
biological body. A significant obstacle to current trend analyses is the
development of a numerically stable and efficiency-finite element scheme that
performs well at low frequency and does not require a large number of degrees
of freedom. Here, a custom finite element method (FEM) solver based on edge
elements is proposed using the weakly coupled theory, which separates the
solution into two steps. First, the background field (the magnetic vector
potential on each edge) is calculated and stored. Then, the electric scalar
potential on each node is obtained by FEM based on Galerkin formulations.
Consequently, the electric field and eddy current distribution in the object
can be obtained. This solver is more efficient than typical commercial solvers
since it reduces the vector eddy current equation to a scalar one, and reduces
the meshing domain to just the eddy current region. It can therefore tackle
complex eddy current calculations for models with much larger numbers of
elements, such as those encountered in eddy current computation in biological
tissues. An example is presented with a realistic human brain mesh of 2 million
elements. In addition, with this solver, the equivalent magnetic field induced
from the excitation coil is applied, and therefore there is no need to mesh the
excitation coil. In combination, these significantly increase the efficiency of
the solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01516</identifier>
 <datestamp>2019-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01516</id><created>2019-06-04</created><updated>2019-12-12</updated><authors><author><keyname>Tian</keyname><forenames>Chang</forenames></author><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Khalilsarai</keyname><forenames>Mahdi Barzegar</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Luo</keyname><forenames>Wu</forenames></author><author><keyname>Zhao</keyname><forenames>Minjian</forenames></author></authors><title>Randomized Channel Sparsifying Hybrid Precoding for FDD Massive MIMO
  Systems</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel randomized channel sparsifying hybrid precoding (RCSHP)
design to reduce the signaling overhead of channel estimation and the hardware
cost and power consumption at the base station (BS), in order to fully harvest
benefits of frequency division duplex (FDD) massive multiple-input
multiple-output (MIMO) systems. RCSHP allows time-sharing among multiple analog
precoders, each serving a compatible user group. The analog precoder is adapted
to the channel statistics to properly sparsify the channel for the associated
user group, such that the resulting effective channel (product of channel and
analog precoder) not only has enough spatial degrees of freedom (DoF) to serve
this group of users, but also can be accurately estimated under the limited
pilot budget. The digital precoder is adapted to the effective channel based on
the duality theory to facilitate the power allocation and exploit the spatial
multiplexing gain. We formulate the joint optimization of the time-sharing
factors and the associated sets of analog precoders and power allocations as a
general utility optimization problem, which considers the impact of effective
channel estimation error on the system performance. Then we propose an
efficient stochastic successive convex approximation algorithm to provably
obtain Karush-Kuhn-Tucker (KKT) points of this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01595</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01595</id><created>2019-06-04</created><authors><author><keyname>Shamsi</keyname><forenames>Mahdi</forenames></author><author><keyname>Ghandi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>A Nonlinear Acceleration Method for Iterative Algorithms</title><categories>eess.SP cs.LG cs.NA eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative methods have led to better understanding and solving problems such
as missing sampling, deconvolution, inverse systems, impulsive and Salt and
Pepper noise removal problems. However, the challenges such as the speed of
convergence and or the accuracy of the answer still remain. In order to improve
the existing iterative algorithms, a non-linear method is discussed in this
paper. The mentioned method is analyzed from different aspects, including its
convergence and its ability to accelerate recursive algorithms. We show that
this method is capable of improving Iterative Method (IM) as a non-uniform
sampling reconstruction algorithm and some iterative sparse recovery algorithms
such as Iterative Reweighted Least Squares (IRLS), Iterative Method with
Adaptive Thresholding (IMAT), Smoothed l0 (SL0) and Alternating Direction
Method of Multipliers (ADMM) for solving LASSO problems family (including Lasso
itself, Lasso-LSQR and group-Lasso). It is also capable of both accelerating
and stabilizing the well-known Chebyshev Acceleration (CA) method. Furthermore,
the proposed algorithm can extend the stability range by reducing the
sensitivity of iterative algorithms to the changes of adaptation rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01626</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01626</id><created>2019-06-04</created><authors><author><keyname>Shah</keyname><forenames>Viraj</forenames></author><author><keyname>Joshi</keyname><forenames>Ameya</forenames></author><author><keyname>Ghosal</keyname><forenames>Sambuddha</forenames></author><author><keyname>Pokuri</keyname><forenames>Balaji</forenames></author><author><keyname>Sarkar</keyname><forenames>Soumik</forenames></author><author><keyname>Ganapathysubramanian</keyname><forenames>Baskar</forenames></author><author><keyname>Hegde</keyname><forenames>Chinmay</forenames></author></authors><title>Encoding Invariances in Deep Generative Models</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable training of generative adversarial networks (GANs) typically require
massive datasets in order to model complicated distributions. However, in
several applications, training samples obey invariances that are \textit{a
priori} known; for example, in complex physics simulations, the training data
obey universal laws encoded as well-defined mathematical equations. In this
paper, we propose a new generative modeling approach, InvNet, that can
efficiently model data spaces with known invariances. We devise an adversarial
training algorithm to encode them into data distribution. We validate our
framework in three experimental settings: generating images with fixed motifs;
solving nonlinear partial differential equations (PDEs); and reconstructing
two-phase microstructures with desired statistical properties. We complement
our experiments with several theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01671</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01671</id><created>2019-06-04</created><authors><author><keyname>Kakkavas</keyname><forenames>Anastasios</forenames></author><author><keyname>Seco-Granados</keyname><forenames>Gonzalo</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Garc&#xed;a</keyname><forenames>Mario H. Casta&#xf1;eda</forenames></author><author><keyname>Stirling-Gallacher</keyname><forenames>Richard A.</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>5G Downlink Multi-Beam Signal Design for LOS Positioning</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted to IEEE GLOBECOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study optimal transmit strategies for minimizing the
positioning error bound in a line-of-sight scenario, under different levels of
prior knowledge of the channel parameters. For the case of perfect prior
knowledge, we prove that two beams are optimal, and determine their beam
directions and optimal power allocation. For the imperfect prior knowledge
case, we compute the optimal power allocation among the beams of a codebook for
two different robustness-related objectives, namely average or maximum squared
position error bound minimization. Our numerical results show that our
low-complexity approach can outperform existing methods that entail higher
signaling and computational overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01704</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01704</id><created>2019-05-10</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Zheng</keyname><forenames>Wenming</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Zong</keyname><forenames>Yuan</forenames></author><author><keyname>Qi</keyname><forenames>Lei</forenames></author><author><keyname>Cui</keyname><forenames>Zhen</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author><author><keyname>Song</keyname><forenames>Tengfei</forenames></author></authors><title>A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition</title><categories>q-bio.NC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The neuroscience study has revealed the discrepancy of emotion expression
between left and right hemispheres of human brain. Inspired by this study, in
this paper, we propose a novel bi-hemispheric discrepancy model (BiHDM) to
learn the asymmetric differences between two hemispheres for
electroencephalograph (EEG) emotion recognition. Concretely, we first employ
four directed recurrent neural networks (RNNs) based on two spatial
orientations to traverse electrode signals on two separate brain regions, which
enables the model to obtain the deep representations of all the EEG electrodes'
signals while keeping the intrinsic spatial dependence. Then we design a
pairwise subnetwork to capture the discrepancy information between two
hemispheres and extract higher-level features for final classification.
Besides, in order to reduce the domain shift between training and testing data,
we use a domain discriminator that adversarially induces the overall feature
learning module to generate emotion-related but domain-invariant feature, which
can further promote EEG emotion recognition. We conduct experiments on three
public EEG emotional datasets, and the experiments show that the new
state-of-the-art results can be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01719</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01719</id><created>2019-06-04</created><updated>2019-06-18</updated><authors><author><keyname>Tiwari</keyname><forenames>Krishan K.</forenames></author><author><keyname>Grass</keyname><forenames>Eckhard</forenames></author><author><keyname>Thompson</keyname><forenames>John S.</forenames></author><author><keyname>Kraemer</keyname><forenames>Rolf</forenames></author></authors><title>Memory-assisted Statistically-ranked RF Beam Training Algorithm for
  Sparse MIMO</title><categories>cs.IT eess.SP math.IT</categories><comments>Under peer-review for IEEE Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel radio frequency (RF) beam training algorithm for
sparse multiple input multiple output (MIMO) channels using unitary RF
beamforming codebooks at transmitter (Tx) and receiver (Rx). The algorithm
leverages statistical knowledge from past beam data for expedited beam search
with statistically-minimal training overheads. Beams are tested in the order of
their ranks based on their probabilities for providing a communication link.
For low beam entropy scenarios, statistically-ranked beam search performs
excellent in reducing the average number of beam tests per Tx-Rx beam pair
identification for a communication link. For high beam entropy cases, a hybrid
algorithm involving both memory-assisted statistically-ranked (MarS) beam
search and multi-level (ML) beam search is also proposed. Savings in training
overheads increase with decrease in beam entropy and increase in MIMO channel
dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01722</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01722</id><created>2019-06-04</created><authors><author><keyname>Tiwari</keyname><forenames>Krishan Kumar</forenames></author><author><keyname>Sark</keyname><forenames>Vladica</forenames></author><author><keyname>Grass</keyname><forenames>Eckhard</forenames></author><author><keyname>Kraemer</keyname><forenames>Rolf</forenames></author></authors><title>Monopulse-based THz Beam Tracking for Indoor Virtual Reality
  Applications</title><categories>eess.SP cs.IT math.IT</categories><comments>24th ITG Fachtagung Mobilkommunikation Technologien und Anwendungen
  Osnabruck, Germany, May 2019, pp. 10-13</comments><report-no>VDE Vertrag ISBN 978-3-8007-4962-1 (E-Book) copyright 2019 ISBN
  978-3-8007-4961-4 (Print) 9 Bismarckstrasse 33, 10625 Berlin
  www.vde-verlag.de</report-no><journal-ref>Proc. of 24th ITG Fachtagung Mobilkommunikation Technologien und
  Anwendungen Osnabruck, Germany, May 2019, pp. 10-13</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Terahertz spectrum is being researched upon to provide ultra-high throughput
radio links for indoor applications, e.g., virtual reality (VR), etc. as well
as outdoor applications, e.g., backhaul links, etc. This paper investigates a
monopulse-based beam tracking approach for limited mobility users relying on
sparse massive multiple input multiple output (MIMO) wireless channels. Owing
to the sparsity, beamforming is realized using digitally-controlled radio
frequency (RF) / intermediate-frequency (IF) phase shifters with constant
amplitude constraint for transmit power compliance. A monopulse-based beam
tracking technique, using received signal strength indi-cation (RSSI) is
adopted to avoid feedback overheads for obvious reasons of efficacy and
resource savings. The Matlab implementation of the beam tracking algorithm is
also reported. This Matlab implementation has been kept as general purpose as
possible using functions wherein the channel, beamforming codebooks, monopulse
comparator, etc. can easily be updated for specific requirements and with
minimum code amendments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01748</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01748</id><created>2019-06-04</created><authors><author><keyname>M&#xd6;ckl</keyname><forenames>Leonhard</forenames></author><author><keyname>Petrov</keyname><forenames>Petar N.</forenames></author><author><keyname>Moerner</keyname><forenames>W. E.</forenames></author></authors><title>Accurate phase retrieval of complex point spread functions with deep
  residual neural networks</title><categories>eess.IV physics.optics</categories><comments>8 pages, 4 figures</comments><doi>10.1063/1.5125252</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Phase retrieval, i.e. the reconstruction of phase information from intensity
information, is a central problem in many optical systems. Here, we demonstrate
that a deep residual neural net is able to quickly and accurately perform this
task for arbitrary point spread functions (PSFs) formed by Zernike-type phase
modulations. Five slices of the 3D PSF at different focal positions within a
two micron range around the focus are sufficient to retrieve the first six
orders of Zernike coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01765</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01765</id><created>2019-06-04</created><authors><author><keyname>Yang</keyname><forenames>Yansong</forenames></author><author><keyname>Lu</keyname><forenames>Ruochen</forenames></author><author><keyname>Gao</keyname><forenames>Liuqing</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>4.5 GHz Lithium Niobate MEMS Filters with 10% Fractional Bandwidth for
  5G Front-ends</title><categories>eess.SP</categories><comments>3 pages, 7 figures</comments><journal-ref>Journal of Microelectromechanical Systems, vol. 28, no. 4, pp.
  575-577, Aug. 2019</journal-ref><doi>10.1109/JMEMS.2019.2922935</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new class of micro-electro-mechanical system (MEMS)
C-band filters for 5G front-ends. The filter is comprised of resonators based
on the first-order asymmetric Lamb wave (A1) mode in thin film lithium niobate.
Two filters have been demonstrated at 4.5 GHz with sharp roll-off, flat in-band
group delay, and spurious-free response over a wide frequency range. The first
design shows a fractional bandwidth (FBW) of 10%, an insertion loss (IL) of 1.7
dB, an out-of-band (OoB) rejection of -13 dB, and a compact footprint of 0.36
mm2, while the second design shows an FBW of 8.5%, an IL of 2.7 dB, an OoB
rejection of -25 dB, and a footprint of 0.9 mm^2. The demonstrations herein
mark the largest fractional bandwidth (FBW) achieved for acoustic-only filters
at 5G frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01796</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01796</id><created>2019-06-04</created><updated>2020-02-07</updated><authors><author><keyname>Zhou</keyname><forenames>Chenhong</forenames></author><author><keyname>Ding</keyname><forenames>Changxing</forenames></author><author><keyname>Wang</keyname><forenames>Xinchao</forenames></author><author><keyname>Lu</keyname><forenames>Zhentai</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author></authors><title>One-pass Multi-task Networks with Cross-task Guided Attention for Brain
  Tumor Segmentation</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><comments>14 pages, 7 figures, To appear in IEEE Transactions on Image
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Class imbalance has emerged as one of the major challenges for medical image
segmentation. The model cascade (MC) strategy significantly alleviates the
class imbalance issue via running a set of individual deep models for
coarse-to-fine segmentation. Despite its outstanding performance, however, this
method leads to undesired system complexity and also ignores the correlation
among the models. To handle these flaws, we propose a light-weight deep model,
i.e., the One-pass Multi-task Network (OM-Net) to solve class imbalance better
than MC does, while requiring only one-pass computation. First, OM-Net
integrates the separate segmentation tasks into one deep model, which consists
of shared parameters to learn joint features, as well as task-specific
parameters to learn discriminative features. Second, to more effectively
optimize OM-Net, we take advantage of the correlation among tasks to design
both an online training data transfer strategy and a curriculum learning-based
training strategy. Third, we further propose sharing prediction results between
tasks and design a cross-task guided attention (CGA) module which can
adaptively recalibrate channel-wise feature responses based on the
category-specific statistics. Finally, a simple yet effective post-processing
method is introduced to refine the segmentation results. Extensive experiments
are conducted to demonstrate the effectiveness of the proposed techniques. Most
impressively, we achieve state-of-the-art performance on the BraTS 2015 testing
set and BraTS 2017 online validation set. Using these proposed approaches, we
also won joint third place in the BraTS 2018 challenge among 64 participating
teams. The code is publicly available at
https://github.com/chenhong-zhou/OM-Net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01806</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01806</id><created>2019-06-04</created><updated>2019-11-27</updated><authors><author><keyname>Liao</keyname><forenames>Haofu</forenames></author><author><keyname>Lin</keyname><forenames>Wei-An</forenames></author><author><keyname>Yuan</keyname><forenames>Jianbo</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author><author><keyname>Luo</keyname><forenames>Jiebo</forenames></author></authors><title>Artifact Disentanglement Network for Unsupervised Metal Artifact
  Reduction</title><categories>eess.IV cs.CV</categories><comments>This work is accepted to MICCAI 2019. An extended version can be
  found at arXiv:1908.01104</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Current deep neural network based approaches to computed tomography (CT)
metal artifact reduction (MAR) are supervised methods which rely heavily on
synthesized data for training. However, as synthesized data may not perfectly
simulate the underlying physical mechanisms of CT imaging, the supervised
methods often generalize poorly to clinical applications. To address this
problem, we propose, to the best of our knowledge, the first unsupervised
learning approach to MAR. Specifically, we introduce a novel artifact
disentanglement network that enables different forms of generations and
regularizations between the artifact-affected and artifact-free image domains
to support unsupervised learning. Extensive experiments show that our method
significantly outperforms the existing unsupervised models for image-to-image
translation problems, and achieves comparable performance to existing
supervised models on a synthesized dataset. When applied to clinical datasets,
our method achieves considerable improvements over the supervised models. The
source code of this paper is publicly available at
https://github.com/liaohaofu/adn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01810</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01810</id><created>2019-06-04</created><authors><author><keyname>Hu</keyname><forenames>Long</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Yang</keyname><forenames>Jun</forenames></author><author><keyname>Fortino</keyname><forenames>Giancarlo</forenames></author><author><keyname>Chen</keyname><forenames>Min</forenames></author></authors><title>A Sustainable Multi-modal Multi-layer Emotion-aware Service at the Edge</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Limited by the computational capabilities and battery energy of terminal
devices and network bandwidth, emotion recognition tasks fail to achieve good
interactive experience for users. The intolerable latency for users also
seriously restricts the popularization of emotion recognition applications in
the edge environments such as fatigue detection in auto-driving. The
development of edge computing provides a more sustainable solution for this
problem. Based on edge computing, this article proposes a multi-modal
multi-layer emotion-aware service (MULTI-EASE) architecture that considers
user's facial expression and voice as a multi-modal data source of emotion
recognition, and employs the intelligent terminal, edge server and cloud as
multi-layer execution environment. By analyzing the average delay of each task
and the average energy consumption at the mobile device, we formulate a
delay-constrained energy minimization problem and perform a task scheduling
policy between multiple layers to reduce the end-to-end delay and energy
consumption by using an edge-based approach, further to improve the users'
emotion interactive experience and achieve energy saving in edge computing.
Finally, a prototype system is also implemented to validate the architecture of
MULTI-EASE, the experimental results show that MULTI-EASE is a sustainable and
efficient platform for emotion analysis applications, and also provide a
valuable reference for dynamic task scheduling under MULTI-EASE architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01818</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01818</id><created>2019-06-05</created><updated>2020-02-20</updated><authors><author><keyname>Choi</keyname><forenames>Jinho</forenames></author></authors><title>Opportunistic NOMA for Uplink Short-Message Delivery with a Delay
  Constraint</title><categories>eess.SP cs.IT math.IT</categories><comments>11 pages, 9 figures, IEEE Trans. Wireless Communications (to be
  published)</comments><msc-class>94Axx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the application of opportunistic non-orthogonal
multiple access (NOMA) mode to short-message transmissions with user's power
control under a finite power budget. It is shown that opportunistic NOMA mode,
which can transmit multiple packets per slot, can dramatically lower the
session error probability when W packets are to be transmitted within a session
consisting of Ws slots, where Ws &gt;= W and the slot length is equivalent to the
packet length, compared to orthogonal multiple access (OMA) where at most one
packet can be transmitted in each slot. From this, opportunistic NOMA mode can
be seen as an attractive approach for uplink transmissions. We derive an
upper-bound on the session error probability as a closed-form expression and
also obtain a closed-form for the NOMA factor that shows the minimum possible
ratio of the session error probability of opportunistic NOMA to that of OMA.
Simulation results also confirm that opportunistic NOMA mode has a much lower
session error probability than OMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01821</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01821</id><created>2019-06-05</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Martens</keyname><forenames>Alaina</forenames></author><author><keyname>Zimmerman</keyname><forenames>Emily</forenames></author><author><keyname>Ostadabbas</keyname><forenames>Sarah</forenames></author></authors><title>Infant Contact-less Non-Nutritive Sucking Pattern Quantification via
  Facial Gesture Analysis</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-nutritive sucking (NNS) is defined as the sucking action that occurs when
a finger, pacifier, or other object is placed in the baby's mouth, but there is
no nutrient delivered. In addition to providing a sense of safety, NNS even can
be regarded as an indicator of infant's central nervous system development. The
rich data, such as sucking frequency, the number of cycles, and their amplitude
during baby's non-nutritive sucking is important clue for judging the brain
development of infants or preterm infants. Nowadays most researchers are
collecting NNS data by using some contact devices such as pressure transducers.
However, such invasive contact will have a direct impact on the baby's natural
sucking behavior, resulting in significant distortion in the collected data.
Therefore, we propose a novel contact-less NNS data acquisition and
quantification scheme, which leverages the facial landmarks tracking technology
to extract the movement signals of baby's jaw from recorded baby's sucking
video. Since completion of the sucking action requires a large amount of
synchronous coordination and neural integration of the facial muscles and the
cranial nerves, the facial muscle movement signals accompanying baby's sucking
pacifier can indirectly replace the NNS signal. We have evaluated our method on
videos collected from several infants during their NNS behaviors and we have
achieved the quantified NNS patterns closely comparable to results from visual
inspection as well as contact-based sensor readings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01862</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01862</id><created>2019-06-05</created><authors><author><keyname>Coup&#xe9;</keyname><forenames>Pierrick</forenames></author><author><keyname>Mansencal</keyname><forenames>Boris</forenames></author><author><keyname>Cl&#xe9;ment</keyname><forenames>Micha&#xeb;l</forenames></author><author><keyname>Giraud</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>de Senneville</keyname><forenames>Baudouin Denis</forenames></author><author><keyname>Ta</keyname><forenames>Vinh-Thong</forenames></author><author><keyname>Lepetit</keyname><forenames>Vincent</forenames></author><author><keyname>Manjon</keyname><forenames>Jos&#xe9; V.</forenames></author></authors><title>AssemblyNet: A Novel Deep Decision-Making Process for Whole Brain MRI
  Segmentation</title><categories>eess.IV cs.CV cs.LG q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whole brain segmentation using deep learning (DL) is a very challenging task
since the number of anatomical labels is very high compared to the number of
available training images. To address this problem, previous DL methods
proposed to use a global convolution neural network (CNN) or few independent
CNNs. In this paper, we present a novel ensemble method based on a large number
of CNNs processing different overlapping brain areas. Inspired by parliamentary
decision-making systems, we propose a framework called AssemblyNet, made of two
&quot;assemblies&quot; of U-Nets. Such a parliamentary system is capable of dealing with
complex decisions and reaching a consensus quickly. AssemblyNet introduces
sharing of knowledge among neighboring U-Nets, an &quot;amendment&quot; procedure made by
the second assembly at higher-resolution to refine the decision taken by the
first one, and a final decision obtained by majority voting. When using the
same 45 training images, AssemblyNet outperforms global U-Net by 28% in terms
of the Dice metric, patch-based joint label fusion by 15% and SLANT-27 by 10%.
Finally, AssemblyNet demonstrates high capacity to deal with limited training
data to achieve whole brain segmentation in practical training and testing
times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01864</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01864</id><created>2019-06-05</created><authors><author><keyname>Zhang</keyname><forenames>Xingzhou</forenames></author><author><keyname>Wang</keyname><forenames>Yifan</forenames></author><author><keyname>Lu</keyname><forenames>Sidi</forenames></author><author><keyname>Liu</keyname><forenames>Liangkai</forenames></author><author><keyname>Xu</keyname><forenames>Lanyu</forenames></author><author><keyname>Shi</keyname><forenames>Weisong</forenames></author></authors><title>OpenEI: An Open Framework for Edge Intelligence</title><categories>cs.AI cs.DC eess.SP</categories><comments>12 pages, 6 figures, ICDCS 2019 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last five years, edge computing has attracted tremendous attention
from industry and academia due to its promise to reduce latency, save
bandwidth, improve availability, and protect data privacy to keep data secure.
At the same time, we have witnessed the proliferation of AI algorithms and
models which accelerate the successful deployment of intelligence mainly in
cloud services. These two trends, combined together, have created a new
horizon: Edge Intelligence (EI). The development of EI requires much attention
from both the computer systems research community and the AI community to meet
these demands. However, existing computing techniques used in the cloud are not
applicable to edge computing directly due to the diversity of computing sources
and the distribution of data sources. We envision that there missing a
framework that can be rapidly deployed on edge and enable edge AI capabilities.
To address this challenge, in this paper we first present the definition and a
systematic review of EI. Then, we introduce an Open Framework for Edge
Intelligence (OpenEI), which is a lightweight software platform to equip edges
with intelligent processing and data sharing capability. We analyze four
fundamental EI techniques which are used to build OpenEI and identify several
open problems based on potential research directions. Finally, four typical
application scenarios enabled by OpenEI are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01875</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01875</id><created>2019-06-05</created><authors><author><keyname>Pham</keyname><forenames>Minh</forenames></author><author><keyname>Rana</keyname><forenames>Arjun</forenames></author><author><keyname>Miao</keyname><forenames>Jianwei</forenames></author><author><keyname>Osher</keyname><forenames>Stanley</forenames></author></authors><title>A semi-implicit relaxed Douglas-Rachford algorithm (sir-DR) for
  Ptychograhpy</title><categories>eess.IV math.OC</categories><doi>10.1364/OE.27.031246</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alternating projection based methods, such as ePIE and rPIE, have been used
widely in ptychography. However, they only work well if there are adequate
measurements (diffraction patterns); in the case of sparse data (i.e. fewer
measurements) alternating projection underperforms and might not even converge.
In this paper, we propose semi-implicit relaxed Douglas Rachford (sir-DR), an
accelerated iterative method, to solve the classical ptychography problem.
Using both simulated and experimental data, we show that sir-DR improves the
convergence speed and the reconstruction quality relative to ePIE and rPIE.
Furthermore, in certain cases when sparsity is high, sir-DR converges while
ePIE and rPIE fail. To facilitate others to use the algorithm, we post the
Matlab source code of sir-DR on a public website
(www.physics.ucla.edu/research/imaging/sir-DR). We anticipate that this
algorithm can be generally applied to the ptychographic reconstruction of a
wide range of samples in the physical and biological sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01882</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01882</id><created>2019-06-05</created><authors><author><keyname>de Loynes</keyname><forenames>Basile</forenames></author><author><keyname>Navarro</keyname><forenames>Fabien</forenames></author><author><keyname>Olivier</keyname><forenames>Baptiste</forenames></author></authors><title>Data-driven Thresholding in Denoising with Spectral Graph Wavelet
  Transform</title><categories>eess.SP stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to adaptive signal denoising in the context of Graph
Signal Processing (GSP) using Spectral Graph Wavelet Transform (SGWT). This
issue is addressed \emph{via} a data-driven thresholding process in the
transformed domain by optimizing the parameters in the sense of the Mean Square
Error (MSE) using the Stein's Unbiased Risk Estimator (SURE). The SGWT
considered is built upon a partition of unity making the transform
semi-orthogonal so that the optimization can be performed in the transformed
domain. However, since the SGWT is over-complete, the SURE needs to be adapted
to the context of correlated noise. Two thresholding strategies called
coordinatewise and block thresholding process are investigated. For each of
them, the SURE is derived for a whole family of elementary thresholding
functions among which the soft threshold and the James-Stein threshold. To
provide a fully data-driven method, a noise variance estimator derived from the
Von Neumann estimator in the Gaussian model is adapted to the graph setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01885</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01885</id><created>2019-06-05</created><authors><author><keyname>Sarker</keyname><forenames>Mohammad Ibrahim</forenames></author><author><keyname>Kim</keyname><forenames>Hyongsuk</forenames></author></authors><title>Farm land weed detection with region-based deep convolutional neural
  networks</title><categories>cs.CV eess.IV</categories><comments>7 Pages, Published in ICROS 2017 32nd Control Robot System Society
  Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning has become a major field of research in order to handle more
and more complex image detection problems. Among the existing state-of-the-art
CNN models, in this paper a region-based, fully convolutional network, for fast
and accurate object detection has been proposed based on the experimental
results. Among the region based networks, ResNet is regarded as the most recent
CNN architecture which has obtained the best results at ImageNet Large-Scale
Visual Recognition Challenge (ILSVRC) in 2015. Deep residual networks (ResNets)
can make the training process faster and attain more accuracy compared to their
equivalent conventional neural networks. Being motivated with such unique
attributes of ResNet, this paper evaluates the performance of fine-tuned ResNet
for object classification of our weeds dataset. The dataset of farm land weeds
detection is insufficient to train such deep CNN models. To overcome this
shortcoming, we perform dropout techniques along with deep residual network for
reducing over-fitting problem as well as applying data augmentation with the
proposed ResNet to achieve a significant outperforming result from our weeds
dataset. We achieved better object detection performance with Region-based
Fully Convolutional Networks (R-FCN) technique which is latched with our
proposed ResNet-101.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01894</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01894</id><created>2019-06-05</created><authors><author><keyname>Fan</keyname><forenames>Rui</forenames></author><author><keyname>Wang</keyname><forenames>Lujia</forenames></author><author><keyname>Liu</keyname><forenames>Ming</forenames></author><author><keyname>Pitas</keyname><forenames>Ioannis</forenames></author></authors><title>A Robust Roll Angle Estimation Algorithm Based on Gradient Descent</title><categories>cs.RO cs.CV eess.IV</categories><comments>5 pages, six figures, 2019 EUSIPCO</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a robust roll angle estimation algorithm, which is
developed from our previously published work, where the roll angle was
estimated from a dense disparity map by minimizing a global energy using golden
section search algorithm. In this paper, to achieve greater computational
efficiency, we utilize gradient descent to optimize the aforementioned global
energy. The experimental results illustrate that the proposed roll angle
estimation algorithm takes fewer iterations to achieve the same precision as
the previous method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01895</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01895</id><created>2019-06-05</created><authors><author><keyname>Chen</keyname><forenames>Min</forenames></author><author><keyname>Zhou</keyname><forenames>Ping</forenames></author><author><keyname>Wu</keyname><forenames>Di</forenames></author><author><keyname>Hu</keyname><forenames>Long</forenames></author><author><keyname>Hassan</keyname><forenames>Mohammad Mehedi</forenames></author><author><keyname>Alamri</keyname><forenames>Atif</forenames></author></authors><title>AI-Skin : Skin Disease Recognition based on Self-learning and Wide Data
  Collection through a Closed Loop Framework</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are a lot of hidden dangers in the change of human skin conditions,
such as the sunburn caused by long-time exposure to ultraviolet radiation,
which not only has aesthetic impact causing psychological depression and lack
of self-confidence, but also may even be life-threatening due to skin
canceration. Current skin disease researches adopt the auto-classification
system for improving the accuracy rate of skin disease classification. However,
the excessive dependence on the image sample database is unable to provide
individualized diagnosis service for different population groups. To overcome
this problem, a medical AI framework based on data width evolution and
self-learning is put forward in this paper to provide skin disease medical
service meeting the requirement of real time, extendibility and
individualization. First, the wide collection of data in the close-loop
information flow of user and remote medical data center is discussed. Next, a
data set filter algorithm based on information entropy is given, to lighten the
load of edge node and meanwhile improve the learning ability of remote cloud
analysis model. In addition, the framework provides an external algorithm load
module, which can be compatible with the application requirements according to
the model selected. Three kinds of deep learning model, i.e. LeNet-5, AlexNet
and VGG16, are loaded and compared, which have verified the universality of the
algorithm load module. The experiment platform for the proposed real-time,
individualized and extensible skin disease recognition system is built. And the
system's computation and communication delay under the interaction scenario
between tester and remote data center are analyzed. It is demonstrated that the
system we put forward is reliable and effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.01921</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.01921</id><created>2019-06-05</created><updated>2019-12-08</updated><authors><author><keyname>Wang</keyname><forenames>Hanqing</forenames></author><author><keyname>Kosasih</keyname><forenames>Alva</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Hardjawana</keyname><forenames>Wibowo</forenames></author></authors><title>Expectation Propagation Detector for Extra-Large Scale Massive MIMO</title><categories>eess.SP cs.IT math.IT</categories><comments>15 pages, 16 figures, accepted by IEEE Transactions on Wireless
  Communications for publication</comments><doi>10.1109/TWC.2019.2961892</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The order-of-magnitude increase in the dimension of antenna arrays, which
forms extra-large-scale massive multiple-input-multiple-output (MIMO) systems,
enables substantial improvement in spectral efficiency, energy efficiency, and
spatial resolution. However, practical challenges, such as excessive
computational complexity and excess of baseband data to be transferred and
processed, prohibit the use of centralized processing. A promising solution is
to distribute baseband data from disjoint subsets of antennas into parallel
processing procedures coordinated by a central processing unit. This solution
is called subarray-based architecture. In this work, we extend the application
of expectation propagation (EP) principle, which effectively balances
performance and practical feasibility in conventional centralized MIMO detector
design, to fit the subarray-based architecture. Analytical results confirm the
convergence of the proposed iterative procedure and that the proposed detector
asymptotically approximates Bayesian optimal performance under certain
conditions. The proposed subarray-based EP detector is reduced to centralized
EP detector when only one subarray exists. In addition, we propose additional
strategies for further reducing the complexity and overhead of the information
exchange between parallel subarrays and the central processing unit to
facilitate the practical implementation of the proposed detector. Simulation
results demonstrate that the proposed detector achieves numerical stability
within few iterations and outperforms its counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02031</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02031</id><created>2019-06-05</created><updated>2019-08-22</updated><authors><author><keyname>Chen</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Jiawei</forenames></author><author><keyname>Wei</keyname><forenames>Dong</forenames></author><author><keyname>Li</keyname><forenames>Yuexiang</forenames></author><author><keyname>Zheng</keyname><forenames>Yefeng</forenames></author></authors><title>OctopusNet: A Deep Learning Segmentation Network for Multi-modal Medical
  Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models, such as the fully convolutional network (FCN), have
been widely used in 3D biomedical segmentation and achieved state-of-the-art
performance. Multiple modalities are often used for disease diagnosis and
quantification. Two approaches are widely used in the literature to fuse
multiple modalities in the segmentation networks: early-fusion (which stacks
multiple modalities as different input channels) and late-fusion (which fuses
the segmentation results from different modalities at the very end). These
fusion methods easily suffer from the cross-modal interference caused by the
input modalities which have wide variations. To address the problem, we propose
a novel deep learning architecture, namely OctopusNet, to better leverage and
fuse the information contained in multi-modalities. The proposed framework
employs a separate encoder for each modality for feature extraction and
exploits a hyper-fusion decoder to fuse the extracted features while avoiding
feature explosion. We evaluate the proposed OctopusNet on two publicly
available datasets, i.e. ISLES-2018 and MRBrainS-2013. The experimental results
show that our framework outperforms the commonly-used feature fusion approaches
and yields the state-of-the-art segmentation accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02070</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02070</id><created>2019-06-05</created><authors><author><keyname>Sherafat</keyname><forenames>Behnam</forenames></author><author><keyname>Rashidi</keyname><forenames>Abbas</forenames></author><author><keyname>Lee</keyname><forenames>Yong-Cheol</forenames></author><author><keyname>Ahn</keyname><forenames>Changbum R.</forenames></author></authors><title>Automated Activity Recognition of Construction Equipment Using a Data
  Fusion Approach</title><categories>eess.SP cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated monitoring of construction operations, especially operations of
equipment and machines, is an essential step toward cost-estimating, and
planning of construction projects. In recent years, a number of methods were
suggested for recognizing activities of construction equipment. These methods
are based on processing single types of data (audio, visual, or kinematic
data). Considering the complexity of construction jobsites, using one source of
data is not reliable enough to cover all conditions and scenarios. To address
the issue, we utilized a data fusion approach: This approach is based on
collecting audio and kinematic data, and includes the following steps: 1)
recording audio and kinematic data generated by machines, 2) preprocessing
data, 3) extracting time- and frequency-domain-features, 4) feature-fusion, and
5) categorizing activities using a machine-learning algorithm. The proposed
approach was implemented on multiple machines and the experiments show that it
is possible to get up to 25% more-accurate results compared to cases of using
single-data-sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02076</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02076</id><created>2019-06-05</created><updated>2019-09-06</updated><authors><author><keyname>Calhas</keyname><forenames>David</forenames></author><author><keyname>Romero</keyname><forenames>Enrique</forenames></author><author><keyname>Henriques</keyname><forenames>Rui</forenames></author></authors><title>On the use of Pairwise Distance Learning for Brain Signal Classification
  with Limited Observations</title><categories>cs.LG cs.CV cs.NE eess.SP q-bio.NC stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The increasing access to brain signal data using electroencephalography
creates new opportunities to study electrophysiological brain activity and
perform ambulatory diagnoses of neuronal diseases. This work proposes a
pairwise distance learning approach for Schizophrenia classification relying on
the spectral properties of the signal. Given the limited number of observations
(i.e. the case and/or control individuals) in clinical trials, we propose a
Siamese neural network architecture to learn a discriminative feature space
from pairwise combinations of observations per channel. In this way, the
multivariate order of the signal is used as a form of data augmentation,
further supporting the network generalization ability. Convolutional layers
with parameters learned under a cosine contrastive loss are proposed to
adequately explore spectral images derived from the brain signal. Results on a
case-control population show that the features extracted using the proposed
neural network lead to an improved Schizophrenia diagnosis (+10pp in accuracy
and sensitivity) against spectral features, thus suggesting the existence of
non-trivial, discriminative electrophysiological brain patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02112</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02112</id><created>2019-06-05</created><updated>2019-07-09</updated><authors><author><keyname>Ma</keyname><forenames>Pingchuan</forenames></author><author><keyname>Petridis</keyname><forenames>Stavros</forenames></author><author><keyname>Pantic</keyname><forenames>Maja</forenames></author></authors><title>Investigating the Lombard Effect Influence on End-to-End Audio-Visual
  Speech Recognition</title><categories>eess.AS cs.CV eess.IV</categories><comments>Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several audio-visual speech recognition models have been recently proposed
which aim to improve the robustness over audio-only models in the presence of
noise. However, almost all of them ignore the impact of the Lombard effect,
i.e., the change in speaking style in noisy environments which aims to make
speech more intelligible and affects both the acoustic characteristics of
speech and the lip movements. In this paper, we investigate the impact of the
Lombard effect in audio-visual speech recognition. To the best of our
knowledge, this is the first work which does so using end-to-end deep
architectures and presents results on unseen speakers. Our results show that
properly modelling Lombard speech is always beneficial. Even if a relatively
small amount of Lombard speech is added to the training set then the
performance in a real scenario, where noisy Lombard speech is present, can be
significantly improved. We also show that the standard approach followed in the
literature, where a model is trained and tested on noisy plain speech, provides
a correct estimate of the video-only performance and slightly underestimates
the audio-visual performance. In case of audio-only approaches, performance is
overestimated for SNRs higher than -3dB and underestimated for lower SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02125</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02125</id><created>2019-05-14</created><authors><author><keyname>Liang</keyname><forenames>Paul Pu</forenames></author><author><keyname>Lim</keyname><forenames>Yao Chong</forenames></author><author><keyname>Tsai</keyname><forenames>Yao-Hung Hubert</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan</forenames></author><author><keyname>Morency</keyname><forenames>Louis-Philippe</forenames></author></authors><title>Strong and Simple Baselines for Multimodal Utterance Embeddings</title><categories>cs.CL cs.AI cs.LG cs.SD eess.AS stat.ML</categories><comments>NAACL 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human language is a rich multimodal signal consisting of spoken words, facial
expressions, body gestures, and vocal intonations. Learning representations for
these spoken utterances is a complex research problem due to the presence of
multiple heterogeneous sources of information. Recent advances in multimodal
learning have followed the general trend of building more complex models that
utilize various attention, memory and recurrent components. In this paper, we
propose two simple but strong baselines to learn embeddings of multimodal
utterances. The first baseline assumes a conditional factorization of the
utterance into unimodal factors. Each unimodal factor is modeled using the
simple form of a likelihood function obtained via a linear transformation of
the embedding. We show that the optimal embedding can be derived in closed form
by taking a weighted average of the unimodal features. In order to capture
richer representations, our second baseline extends the first by factorizing
into unimodal, bimodal, and trimodal factors, while retaining simplicity and
efficiency during learning and inference. From a set of experiments across two
tasks, we show strong performance on both supervised and semi-supervised
multimodal prediction, as well as significant (10 times) speedups over neural
models during inference. Overall, we believe that our strong baseline models
offer new benchmarking options for future research in multimodal learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02169</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02169</id><created>2019-06-05</created><authors><author><keyname>Rodriguez-Fernandez</keyname><forenames>Javier</forenames></author><author><keyname>Gonzalez-Prelcic</keyname><forenames>Nuria</forenames></author></authors><title>Joint Synchronization, Phase Noise and Compressive Channel Estimation in
  Hybrid Frequency-Selective mmWave MIMO Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The large beamforming gain used to operate at millimeter wave (mmWave)
frequencies requires obtaining channel information to configure hybrid antenna
arrays. Previously proposed wideband channel estimation strategies, however,
assume perfect time-frequency synchronization and neglect phase noise, making
these approaches impractical. Consequently, achieving time-frequency
synchronization between transmitter and receiver and correcting for phase noise
(PN) as the channel is estimated, is the greatest challenge yet to be solved in
order to configure hybrid precoders and combiners in practical settings. In
this paper, building upon our prior work, we find the Maximum A Posteriori
(MAP) solution to the joint problem of timing offset (TO), carrier frequency
offset (CFO), PN and compressive channel estimation for broadband mmWave MIMO
systems with hybrid architectures. Simulation results show that, using
significantly less training symbols than in the beam training protocol in the
5G New Radio communications standard, joint synchronization and channel
estimation at the low SNR regime can be achieved, and near-optimum data rates
can be attained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02191</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02191</id><created>2019-06-05</created><updated>2020-02-08</updated><authors><author><keyname>Soberanis-Mukul</keyname><forenames>Roger D.</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Albarqouni</keyname><forenames>Shadi</forenames></author></authors><title>Uncertainty-based graph convolutional networks for organ segmentation
  refinement</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Organ segmentation is an important pre-processing step in many computer
assisted intervention and diagnosis methods. In recent years, CNNs have
dominated the state of the art in this task. Organ segmentation scenarios
present a challenging environment for these methods due to high variability in
shape and similarity with background. This leads to the generation of false
negative and false positive regions in the output segmentation. In this
context, the uncertainty analysis of the model can provide us with useful
information about potentially misclassified elements. In this work we propose a
method based on uncertainty analysis and graph convolutional networks as a
post-processing step for segmentation. For this, we employ the uncertainty
levels of the CNN to formulate a semi-supervised graph learning problem that is
solved by training a GCN on the low uncertainty elements. Finally, we evaluate
the full graph on the trained GCN to get the refined segmentation. We test our
framework in refining the output of pancreas and spleen segmentation models. We
show that the framework can increase the average dice score in 1% and 2%
respectively for these problems. Finally, we discuss the results and current
limitations of the model that lead to future work in this research direction
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02241</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02241</id><created>2019-06-05</created><authors><author><keyname>Zhao</keyname><forenames>Yun</forenames></author><author><keyname>Guzman</keyname><forenames>Elmer</forenames></author><author><keyname>Audouard</keyname><forenames>Morgane</forenames></author><author><keyname>Cheng</keyname><forenames>Zhuowei</forenames></author><author><keyname>Hansma</keyname><forenames>PaulK.</forenames></author><author><keyname>Kosik</keyname><forenames>Kenneth S.</forenames></author><author><keyname>Petzold</keyname><forenames>Linda</forenames></author></authors><title>A Deep Learning Framework for Classification of in vitro Multi-Electrode
  Array Recordings</title><categories>q-bio.NC cs.LG eess.SP</categories><comments>14 pages, in ICDM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-Electrode Arrays (MEAs) have been widely used to record neuronal
activities, which could be used in the diagnosis of gene defects and drug
effects. In this paper, we address the problem of classifying in vitro MEA
recordings of mouse and human neuronal cultures from different genotypes, where
there is no easy way to directly utilize raw sequences as inputs to train an
end-to-end classification model. While carefully extracting some features by
hand could partially solve the problem, this approach suffers from obvious
drawbacks such as difficulty of generalizing. We propose a deep learning
framework to address this challenge. Our approach correctly classifies neuronal
culture data prepared from two different genotypes -- a mouse Knockout of the
delta-catenin gene and human induced Pluripotent Stem Cell-derived neurons from
Williams syndrome. By splitting the long recordings into short slices for
training, and applying Consensus Prediction during testing, our deep learning
approach improves the prediction accuracy by 16.69% compared with feature based
Logistic Regression for mouse MEA recordings. We further achieve an accuracy of
95.91% using Consensus Prediction in one subset of mouse MEA recording data,
which were all recorded at six days in vitro. As high-density MEA recordings
become more widely available, this approach could be generalized for
classification of neurons carrying different mutations and classification of
drug responses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02246</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02246</id><created>2019-06-05</created><authors><author><keyname>Shafran</keyname><forenames>Izhak</forenames></author><author><keyname>Bagby</keyname><forenames>Tom</forenames></author><author><keyname>Skerry-Ryan</keyname><forenames>R. J.</forenames></author></authors><title>Complex Evolution Recurrent Neural Networks (ceRNNs)</title><categories>cs.LG cs.CL cs.SD eess.AS eess.SP</categories><journal-ref>Proc. International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), pages 5854-5858, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unitary Evolution Recurrent Neural Networks (uRNNs) have three attractive
properties: (a) the unitary property, (b) the complex-valued nature, and (c)
their efficient linear operators. The literature so far does not address -- how
critical is the unitary property of the model? Furthermore, uRNNs have not been
evaluated on large tasks. To study these shortcomings, we propose the complex
evolution Recurrent Neural Networks (ceRNNs), which is similar to uRNNs but
drops the unitary property selectively. On a simple multivariate linear
regression task, we illustrate that dropping the constraints improves the
learning trajectory. In copy memory task, ceRNNs and uRNNs perform identically,
demonstrating that their superior performance over LSTMs is due to
complex-valued nature and their linear operators. In a large scale real-world
speech recognition, we find that pre-pending a uRNN degrades the performance of
our baseline LSTM acoustic models, while pre-pending a ceRNN improves the
performance over the baseline by 0.8% absolute WER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02252</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02252</id><created>2019-06-05</created><authors><author><keyname>Liu</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Li</forenames></author><author><keyname>Lou</keyname><forenames>Yifei</forenames></author><author><keyname>Li</keyname><forenames>Rencang</forenames></author><author><keyname>Purdon</keyname><forenames>Patrick</forenames></author></authors><title>Probabilistic Structure Learning for EEG/MEG Source Imaging with
  Hierarchical Graph Prior</title><categories>stat.AP cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain source imaging is an important method for noninvasively characterizing
brain activity using Electroencephalogram (EEG) or Magnetoencephalography (MEG)
recordings. Traditional EEG/MEG Source Imaging (ESI) methods usually assume
that either source activity at different time points is unrelated, or that
similar spatiotemporal patterns exist across an entire study period. The former
assumption makes ESI analyses sensitive to noise, while the latter renders ESI
analyses unable to account for time-varying patterns of activity. To
effectively deal with noise while maintaining flexibility and continuity among
brain activation patterns, we propose a novel probabilistic ESI model based on
a hierarchical graph prior. Under our method, a spanning tree constraint
ensures that activity patterns have spatiotemporal continuity. An efficient
algorithm based on alternating convex search is presented to solve the proposed
model and is provably convergent. Comprehensive numerical studies using
synthetic data on a real brain model are conducted under different levels of
signal-to-noise ratio (SNR) from both sensor and source spaces. We also examine
the EEG/MEG data in a real application, in which our ESI reconstructions are
neurologically plausible. All the results demonstrate significant improvements
of the proposed algorithm over the benchmark methods in terms of source
localization performance, especially at high noise levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02281</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02281</id><created>2019-06-05</created><authors><author><keyname>Balsiger</keyname><forenames>Fabian</forenames></author><author><keyname>Soom</keyname><forenames>Yannick</forenames></author><author><keyname>Scheidegger</keyname><forenames>Olivier</forenames></author><author><keyname>Reyes</keyname><forenames>Mauricio</forenames></author></authors><title>Learning Shape Representation on Sparse Point Clouds for Volumetric
  Image Segmentation</title><categories>cs.CV eess.IV</categories><comments>Accepted at MICCAI 2019</comments><doi>10.1007/978-3-030-32245-8_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Volumetric image segmentation with convolutional neural networks (CNNs)
encounters several challenges, which are specific to medical images. Among
these challenges are large volumes of interest, high class imbalances, and
difficulties in learning shape representations. To tackle these challenges, we
propose to improve over traditional CNN-based volumetric image segmentation
through point-wise classification of point clouds. The sparsity of point clouds
allows processing of entire image volumes, balancing highly imbalanced
segmentation problems, and explicitly learning an anatomical shape. We build
upon PointCNN, a neural network proposed to process point clouds, and propose
here to jointly encode shape and volumetric information within the point cloud
in a compact and computationally effective manner. We demonstrate how this
approach can then be used to refine CNN-based segmentation, which yields
significantly improved results in our experiments on the difficult task of
peripheral nerve segmentation from magnetic resonance neurography images. By
synthetic experiments, we further show the capability of our approach in
learning an explicit anatomical shape representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02283</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02283</id><created>2019-06-05</created><authors><author><keyname>Zlocha</keyname><forenames>Martin</forenames></author><author><keyname>Dou</keyname><forenames>Qi</forenames></author><author><keyname>Glocker</keyname><forenames>Ben</forenames></author></authors><title>Improving RetinaNet for CT Lesion Detection with Dense Masks from Weak
  RECIST Labels</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate, automated lesion detection in Computed Tomography (CT) is an
important yet challenging task due to the large variation of lesion types,
sizes, locations and appearances. Recent work on CT lesion detection employs
two-stage region proposal based methods trained with centroid or bounding-box
annotations. We propose a highly accurate and efficient one-stage lesion
detector, by re-designing a RetinaNet to meet the particular challenges in
medical imaging. Specifically, we optimize the anchor configurations using a
differential evolution search algorithm. For training, we leverage the response
evaluation criteria in solid tumors (RECIST) annotation which are measured in
clinical routine. We incorporate dense masks from weak RECIST labels, obtained
automatically using GrabCut, into the training objective, which in combination
with other advancements yields new state-of-the-art performance. We evaluate
our method on the public DeepLesion benchmark, consisting of 32,735 lesions
across the body. Our one-stage detector achieves a sensitivity of 90.77% at 4
false positives per image, significantly outperforming the best reported
methods by over 5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02292</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02292</id><created>2019-06-05</created><authors><author><keyname>Ye</keyname><forenames>Cong</forenames></author><author><keyname>Slavakis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Patil</keyname><forenames>Pratik V.</forenames></author><author><keyname>Muldoon</keyname><forenames>Sarah F.</forenames></author><author><keyname>Medaglia</keyname><forenames>John</forenames></author></authors><title>Brain-Network Clustering via Kernel-ARMA Modeling and the Grassmannian</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in neuroscience and in the technology of functional magnetic
resonance imaging (fMRI) and electro-encephalography (EEG) have propelled a
growing interest in brain-network clustering via time-series analysis.
Notwithstanding, most of the brain-network clustering methods revolve around
state clustering and/or node clustering (a.k.a. community detection or topology
inference) within states. This work answers first the need of capturing
non-linear nodal dependencies by bringing forth a novel feature-extraction
mechanism via kernel autoregressive-moving-average modeling. The extracted
features are mapped to the Grassmann manifold (Grassmannian), which consists of
all linear subspaces of a fixed rank. By virtue of the Riemannian geometry of
the Grassmannian, a unifying clustering framework is offered to tackle all
possible clustering problems in a network: Cluster multiple states, detect
communities within states, and even identify/track subnetwork state sequences.
The effectiveness of the proposed approach is underlined by extensive numerical
tests on synthetic and real fMRI/EEG data which demonstrate that the advocated
learning method compares favorably versus several state-of-the-art clustering
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02311</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02311</id><created>2019-06-05</created><authors><author><keyname>Leibovich</keyname><forenames>Matan</forenames></author><author><keyname>Papanicolaou</keyname><forenames>George</forenames></author><author><keyname>Tsogka</keyname><forenames>Chrysoula</forenames></author></authors><title>Low rank plus sparse decomposition of synthetic aperture radar data for
  target imaging and tracking</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze synthetic aperture radar (SAR) imaging of complex ground scenes
that contain both stationary and moving targets. In the usual SAR acquisition
scheme, we consider ways to preprocess the data so as to separate the
contributions of the moving targets from those due to stationary background
reflectors. Both components of the data, that is, reflections from stationary
and moving targets, are considered as signal that is needed for target imaging
and tracking, respectively. The approach we use is to decompose the data matrix
into a low rank and a sparse part. This decomposition enables us to capture the
reflections from moving targets into the sparse part and those from stationary
targets into the low rank part of the data. The computational tool for this is
robust principal component analysis (RPCA) applied to the SAR data matrix. We
also introduce a lossless baseband transformation of the data, which simplifies
the analysis and improves the performance of the RPCA algorithm. Our main
contribution is a theoretical analysis that determines an optimal choice of
parameters for the RPCA algorithm so as to have an effective and stable
separation of SAR data coming from moving and stationary targets. This analysis
gives also a lower bound for detectable target velocities. We show in
particular that the rank of the sparse matrix is proportional to the square
root of the target's speed in the direction that connects the SAR platform
trajectory to the imaging region. The robustness of the approach is illustrated
with numerical simulations in the X-band SAR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02327</identifier>
 <datestamp>2020-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02327</id><created>2019-06-05</created><updated>2020-02-04</updated><authors><author><keyname>Lim</keyname><forenames>Hongki</forenames></author><author><keyname>Chun</keyname><forenames>Il Yong</forenames></author><author><keyname>Dewaraja</keyname><forenames>Yuni K.</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>Improved low-count quantitative PET reconstruction with an iterative
  neural network</title><categories>eess.IV cs.LG physics.med-ph stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Image reconstruction in low-count PET is particularly challenging because
gammas from natural radioactivity in Lu-based crystals cause high random
fractions that lower the measurement signal-to-noise-ratio (SNR). In
model-based image reconstruction (MBIR), using more iterations of an
unregularized method may increase the noise, so incorporating regularization
into the image reconstruction is desirable to control the noise. New
regularization methods based on learned convolutional operators are emerging in
MBIR. We modify the architecture of an iterative neural network, BCD-Net, for
PET MBIR, and demonstrate the efficacy of the trained BCD-Net using XCAT
phantom data that simulates the low true coincidence count-rates with high
random fractions typical for Y-90 PET patient imaging after Y-90 microsphere
radioembolization. Numerical results show that the proposed BCD-Net
significantly improves PET reconstruction performance compared to MBIR methods
using non-trained regularizers, total variation (TV) and non-local means (NLM).
BCD-Net significantly improved CNR and RMSE compared to TV (NLM) regularized
MBIR. Moreover, BCD-Net successfully generalizes to data that differs from
training data. Improvements were also demonstrated for the clinically relevant
phantom measurement data where we used training and testing datasets having
very different activity distributions and count-levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02343</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02343</id><created>2019-06-05</created><authors><author><keyname>Larrazabal</keyname><forenames>Agostina J.</forenames></author><author><keyname>Martinez</keyname><forenames>Cesar</forenames></author><author><keyname>Ferrante</keyname><forenames>Enzo</forenames></author></authors><title>Anatomical Priors for Image Segmentation via Post-Processing with
  Denoising Autoencoders</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted for publication in MICCAI 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Deep convolutional neural networks (CNN) proved to be highly accurate to
perform anatomical segmentation of medical images. However, some of the most
popular CNN architectures for image segmentation still rely on post-processing
strategies (e.g. Conditional Random Fields) to incorporate connectivity
constraints into the resulting masks. These post-processing steps are based on
the assumption that objects are usually continuous and therefore nearby pixels
should be assigned the same object label. Even if it is a valid assumption in
general, these methods do not offer a straightforward way to incorporate more
complex priors like convexity or arbitrary shape restrictions. In this work we
propose Post-DAE, a post-processing method based on denoising autoencoders
(DAE) trained using only segmentation masks. We learn a low-dimensional space
of anatomically plausible segmentations, and use it as a post-processing step
to impose shape constraints on the resulting masks obtained with arbitrary
segmentation methods. Our approach is independent of image modality and
intensity information since it employs only segmentation masks for training.
This enables the use of anatomical segmentations that do not need to be paired
with intensity images, making the approach very flexible. Our experimental
results on anatomical segmentation of X-ray images show that Post-DAE can
improve the quality of noisy and incorrect segmentation masks obtained with a
variety of standard methods, by bringing them back to a feasible space, with
almost no extra computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02360</identifier>
 <datestamp>2019-12-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02360</id><created>2019-06-05</created><updated>2019-12-13</updated><authors><author><keyname>Nadeem</keyname><forenames>Qurrat-Ul-Ain</forenames></author><author><keyname>Kammoun</keyname><forenames>Abla</forenames></author><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Intelligent Reflecting Surface Assisted Wireless Communication: Modeling
  and Channel Estimation</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently completed 5G new radio standard is a result of several
cutting-edge technologies, including massive multiple-input multiple-output
(MIMO), millimeter (mm)-Wave communication and network densification. However,
these technologies face two main practical limitations 1) the lack of control
over the wireless channel, and 2) the high power consumption of the wireless
interface. To address the need for green and sustainable future cellular
networks, the concept of reconfiguring wireless propagation environments using
Intelligent Reflecting Surfaces (IRS)s has emerged. An IRS comprises of a large
number of low-cost passive antennas that can smartly reflect the impinging
electromagnetic waves for performance enhancement. This paper looks at the
evolution of the reflective radio concept towards IRSs, outlines the
IRS-assisted multi-user multiple-input single-output (MISO) communication model
and discusses how it differentiates from the conventional multi-antenna
communication models. We propose a minimum mean squared error (MMSE) based
channel estimation protocol for the design and analysis of IRS-assisted
systems. Performance evaluation results at 2.5 GHz operating frequency are
provided to illustrate the efficiency of the proposed system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02392</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02392</id><created>2019-06-05</created><authors><author><keyname>Song</keyname><forenames>Tao</forenames></author></authors><title>Generative Model-Based Ischemic Stroke Lesion Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CT perfusion (CTP) has been used to triage ischemic stroke patients in the
early stage, because of its speed, availability, and lack of contraindications.
Perfusion parameters including cerebral blood volume (CBV), cerebral blood flow
(CBF), mean transit time (MTT) and time of peak (Tmax) could also be computed
from CTP data. However, CTP data or the perfusion parameters, are ambiguous to
locate the infarct core or tissue at risk (penumbra), which is normally
confirmed by the follow-up Diffusion Weighted Imaging (DWI) or perfusion
diffusion mismatch. In this paper, we propose a novel generative modelbased
segmentation framework composed of an extractor, a generator and a segmentor
for ischemic stroke lesion segmentation. First, an extractor is used to
directly extract the representative feature images from the CTP feature images.
Second, a generator is used to generate the clinical relevant DWI images using
the output from the extractor and perfusion parameters. Finally, the segmentor
is used to precisely segment the ischemic stroke lesion using the generated DWI
from the generator. Meanwhile, a novel pixel-region loss function, generalized
dice combined with weighted cross entropy, is used to handle data unbalance
problem which is commonly encountered in medical image segmentation. All
networks are trained end-to-end from scratch using the 2018 Ischemic Stroke
Lesion Segmentation Challenge (ISLES) dataset and our method won the first
place in the 2018 ischemic stroke lesions segmentation challenge in the test
stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02426</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02426</id><created>2019-06-06</created><authors><author><keyname>Wu</keyname><forenames>Cho-Ying</forenames></author><author><keyname>Neumann</keyname><forenames>Ulrich</forenames></author></authors><title>Salient Building Outline Enhancement and Extraction Using Iterative L0
  Smoothing and Line Enhancing</title><categories>eess.IV cs.CV cs.GR</categories><comments>Accepted to ICIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, our goal is salient building outline enhancement and
extraction from images taken from consumer cameras using L0 smoothing. We
address weak outlines and over-smoothing problem. Weak outlines are often
undetected by edge extractors or easily smoothed out. We propose an iterative
method, including the smoothing cell and sharpening cell. In the smoothing
cell, we iteratively enlarge the smoothing level of the L0 smoothing. In the
sharpening cell, we use Hough Transform to extract lines, based on the
assumption that salient outlines for buildings are usually straight, and
enhance those extracted lines. Our goal is to enhance line structures and do
the L0 smoothing simultaneously. Also, we propose to create building masks from
semantic segmentation using an encoder-decoder network. The masks filter out
irrelevant edges. We also provide an evaluation dataset on this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02429</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02429</id><created>2019-06-06</created><authors><author><keyname>Wu</keyname><forenames>Cho-Ying</forenames></author><author><keyname>Ding</keyname><forenames>Jian-Jiun</forenames></author></authors><title>Occluded Face Recognition Using Low-rank Regression with Generalized
  Gradient Direction</title><categories>eess.IV cs.CV cs.NA</categories><journal-ref>Pattern Recognition (PR), Elsevier, vol. 80, pp. 256-268, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a very effective method to solve the contiguous face occlusion
recognition problem is proposed. It utilizes the robust image gradient
direction features together with a variety of mapping functions and adopts a
hierarchical sparse and low-rank regression model. This model unites the sparse
representation in dictionary learning and the low-rank representation on the
error term that is usually messy in the gradient domain. We call it the &quot;weak
low-rankness&quot; optimization problem, which can be efficiently solved by the
framework of Alternating Direction Method of Multipliers (ADMM). The optimum of
the error term has a similar weak low-rank structure as the reference error map
and the recognition performance can be enhanced by leaps and bounds using weak
low-rankness optimization. Extensive experiments are conducted on real-world
disguise / occlusion data and synthesized contiguous occlusion data. These
experiments show that the proposed gradient direction-based hierarchical
adaptive sparse and low-rank (GD-HASLR) algorithm has the best performance
compared to state-of-the-art methods, including popular convolutional neural
network-based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02435</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02435</id><created>2019-06-06</created><updated>2019-09-11</updated><authors><author><keyname>Zhai</keyname><forenames>Yuexiang</forenames></author><author><keyname>Yang</keyname><forenames>Zitong</forenames></author><author><keyname>Liao</keyname><forenames>Zhenyu</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Complete Dictionary Learning via $\ell^4$-Norm Maximization over the
  Orthogonal Group</title><categories>cs.LG eess.SP stat.CO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the fundamental problem of learning a complete
(orthogonal) dictionary from samples of sparsely generated signals. Most
existing methods solve the dictionary (and sparse representations) based on
heuristic algorithms, usually without theoretical guarantees for either
optimality or complexity. The recent $\ell^1$-minimization based methods do
provide such guarantees but the associated algorithms recover the dictionary
one column at a time. In this work, we propose a new formulation that maximizes
the $\ell^4$-norm over the orthogonal group, to learn the entire dictionary. We
prove that under a random data model, with nearly minimum sample complexity,
the global optima of the $\ell^4$ norm are very close to signed permutations of
the ground truth. Inspired by this observation, we give a conceptually simple
and yet effective algorithm based on &quot;matching, stretching, and projection&quot;
(MSP). The algorithm provably converges locally at a superlinear (cubic) rate
and cost per iteration is merely an SVD. In addition to strong theoretical
guarantees, experiments show that the new algorithm is significantly more
efficient and effective than existing methods, including KSVD and
$\ell^1$-based methods. Preliminary experimental results on mixed real imagery
data clearly demonstrate advantages of so learned dictionary over classic PCA
bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02444</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02444</id><created>2019-06-06</created><updated>2019-10-24</updated><authors><author><keyname>Kolar</keyname><forenames>Davor</forenames></author><author><keyname>Lisjak</keyname><forenames>Dragutin</forenames></author><author><keyname>Pajak</keyname><forenames>Michal</forenames></author><author><keyname>Pavkovic</keyname><forenames>Danijel</forenames></author></authors><title>Fault Diagnosis of Rotary Machines using Deep Convolutional Neural
  Network with three axis signal input</title><categories>cs.LG eess.SP stat.ML</categories><comments>I need to do a major revision of this article to make it publishable</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent trends focusing on Industry 4.0 concept and smart manufacturing arise
a data-driven fault diagnosis as key topic in condition-based maintenance.
Fault diagnosis is considered as an essential task in rotary machinery since
possibility of an early detection and diagnosis of the faulty condition can
save both time and money. Traditional data-driven techniques of fault diagnosis
require signal processing for feature extraction, as they are unable to work
with raw signal data, consequently leading to need for expert knowledge and
human work. The emergence of deep learning architectures in condition-based
maintenance promises to ensure high performance fault diagnosis while lowering
necessity for expert knowledge and human work. This paper presents developed
technique for deep learning-based data-driven fault diagnosis of rotary
machinery. The proposed technique input raw three axis accelerometer signal as
high-definition image into deep learning layers which automatically extract
signal features, enabling high classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02482</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02482</id><created>2019-06-06</created><updated>2019-06-18</updated><authors><author><keyname>Kubo</keyname><forenames>Yuki</forenames></author><author><keyname>Takamune</keyname><forenames>Norihiro</forenames></author><author><keyname>Kitamura</keyname><forenames>Daichi</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>Efficient Full-Rank Spatial Covariance Estimation Using Independent
  Low-Rank Matrix Analysis for Blind Source Separation</title><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures, To appear in the Proceedings of the 27th European
  Signal Processing Conference (EUSIPCO 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new algorithm that efficiently separates a
directional source and diffuse background noise based on independent low-rank
matrix analysis (ILRMA). ILRMA is one of the state-of-the-art techniques of
blind source separation (BSS) and is based on a rank-1 spatial model. Although
such a model does not hold for diffuse noise, ILRMA can accurately estimate the
spatial parameters of the directional source. Motivated by this fact, we
utilize these estimates to restore the lost spatial basis of diffuse noise,
which can be considered as an efficient full-rank spatial covariance
estimation. BSS experiments show the efficacy of the proposed method in terms
of the computational cost and separation performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02492</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02492</id><created>2019-06-06</created><authors><author><keyname>Hanselmann</keyname><forenames>Markus</forenames></author><author><keyname>Strauss</keyname><forenames>Thilo</forenames></author><author><keyname>Dormann</keyname><forenames>Katharina</forenames></author><author><keyname>Ulmer</keyname><forenames>Holger</forenames></author></authors><title>CANet: An Unsupervised Intrusion Detection System for High Dimensional
  CAN Bus Data</title><categories>cs.CR cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel neural network architecture for detecting intrusions on
the CAN bus. The Controller Area Network (CAN) is the standard communication
method between the Electronic Control Units (ECUs) of automobiles. However, CAN
lacks security mechanisms and it has recently been shown that it can be
attacked remotely. Hence, it is desirable to monitor CAN traffic to detect
intrusions. In order to detect both, known and unknown intrusion scenarios, we
consider a novel unsupervised learning approach which we call CANet. To our
knowledge, this is the first deep learning based intrusion detection system
(IDS) that takes individual CAN messages with different IDs and evaluates them
in the moment they are received. This is a significant advancement because
messages with different IDs are typically sent at different times and with
different frequencies. Our method is evaluated on real and synthetic CAN data.
For reproducibility of the method, our synthetic data is publicly available. A
comparison with previous machine learning based methods shows that CANet
outperforms them by a significant margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02526</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02526</id><created>2019-06-06</created><authors><author><keyname>Liu</keyname><forenames>Tie</forenames></author><author><keyname>Xu</keyname><forenames>Mai</forenames></author><author><keyname>Wang</keyname><forenames>Zulin</forenames></author></authors><title>Removing Rain in Videos: A Large-scale Database and A Two-stream
  ConvLSTM Approach</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rain removal has recently attracted increasing research attention, as it is
able to enhance the visibility of rain videos. However, the existing learning
based rain removal approaches for videos suffer from insufficient training
data, especially when applying deep learning to remove rain. In this paper, we
establish a large-scale video database for rain removal (LasVR), which consists
of 316 rain videos. Then, we observe from our database that there exist the
temporal correlation of clean content and similar patterns of rain across video
frames. According to these two observations, we propose a two-stream
convolutional long- and short- term memory (ConvLSTM) approach for rain removal
in videos. The first stream is composed of the subnet for rain detection, while
the second stream is the subnet of rain removal that leverages the features
from the rain detection subnet. Finally, the experimental results on both
synthetic and real rain videos show the proposed approach performs better than
other state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02540</identifier>
 <datestamp>2019-11-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02540</id><created>2019-06-06</created><updated>2019-11-21</updated><authors><author><keyname>Scannell</keyname><forenames>Cian M.</forenames></author><author><keyname>Chiribiri</keyname><forenames>Amedeo</forenames></author><author><keyname>Villa</keyname><forenames>Adriana D. M.</forenames></author><author><keyname>Breeuwer</keyname><forenames>Marcel</forenames></author><author><keyname>Lee</keyname><forenames>Jack</forenames></author></authors><title>Hierarchical Bayesian myocardial perfusion quantification</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>Published in Medical Image Analysis</comments><doi>10.1016/j.media.2019.101611</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Purpose: Tracer-kinetic models can be used for the quantitative assessment of
contrast-enhanced MRI data. However, the model-fitting can produce unreliable
results due to the limited data acquired and the high noise levels. Such
problems are especially prevalent in myocardial perfusion MRI leading to the
compromise of constrained numerical deconvolutions and segmental signal
averaging being commonly used as alternatives to the more complex
tracer-kinetic models. Methods: In this work, the use of hierarchical Bayesian
inference for the parameter estimation is explored. It is shown that with
Bayesian inference it is possible to reliably fit the two-compartment exchange
model to perfusion data. The use of prior knowledge on the ranges of kinetic
parameters and the fact that neighbouring voxels are likely to have similar
kinetic properties combined with a Markov chain Monte Carlo based fitting
procedure significantly improves the reliability of the perfusion estimates
with compared to the traditional least-squares approach. The method is assessed
using both simulated and patient data. Results: The average (standard
deviation) normalised mean square error for the distinct noise realisations of
a simulation phantom falls from 0.32 (0.55) with the least-squares fitting to
0.13 (0.2) using Bayesian inference. The assessment of the presence of coronary
artery disease based purely on the quantitative MBF maps obtained using
Bayesian inference matches the visual assessment in all 24 slices. When using
the maps obtained by the least-squares fitting, a corresponding assessment is
only achieved in 16/24 slices. Conclusion: Bayesian inference allows a
reliable, fully automated and user-independent assessment of myocardial
perfusion on a voxel-wise level using the two-compartment exchange model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02572</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02572</id><created>2019-06-06</created><updated>2019-11-15</updated><authors><author><keyname>Clink</keyname><forenames>Dena J.</forenames></author><author><keyname>Klinck</keyname><forenames>Holger</forenames></author></authors><title>GIBBONFINDR: An R package for the detection and classification of
  acoustic signals</title><categories>eess.AS cs.LG cs.SD q-bio.QM</categories><comments>R package</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent improvements in recording technology, data storage and battery
life have led to an increased interest in the use of passive acoustic
monitoring for a variety of research questions. One of the main obstacles in
implementing wide scale acoustic monitoring programs in terrestrial
environments is the lack of user-friendly, open source programs for processing
large sound archives. Here we describe the new, open-source R package
GIBBONFINDR which has functions for detection, classification and visualization
of acoustic signals using a variety of readily available machine learning
algorithms in the R programming environment. We provide a case study showing
how GIBBONFINDR functions can be used in a workflow to detect and classify
Bornean gibbon (Hylobates muelleri) calls in long-term acoustic data sets
recorded in Danum Valley Conservation Area, Sabah, Malaysia. Machine learning
is currently one of the most rapidly growing fields-- with applications across
many disciplines-- and our goal is to make commonly used signal processing
techniques and machine learning algorithms readily available for ecologists who
are interested in incorporating bioacoustics techniques into their research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02580</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02580</id><created>2019-06-06</created><authors><author><keyname>Beckenbach</keyname><forenames>Lukas</forenames></author><author><keyname>Osinenko</keyname><forenames>Pavel</forenames></author><author><keyname>Streif</keyname><forenames>Stefan</forenames></author></authors><title>Model predictive control with stage cost shaping inspired by
  reinforcement learning</title><categories>math.OC cs.SY eess.SY math.DS</categories><comments>2 figures</comments><msc-class>93C10, 93C40, 93C55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a suboptimality study of a particular model predictive
control with a stage cost shaping based on the ideas of reinforcement learning.
The focus of the suboptimality study is to derive quantities relating the
infinite-horizon cost function under the said variant of model predictive
control to the respective infinite-horizon value function. The basis control
scheme involves usual stabilizing constraints comprising of a terminal set and
a terminal cost in the form of a local Lyapunov function. The stage cost is
adapted using the principles of Q-learning, a particular approach to
reinforcement learning. The work is concluded by case studies with two systems
for wide ranges of initial conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02603</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02603</id><created>2019-06-06</created><updated>2019-09-19</updated><authors><author><keyname>Parker</keyname><forenames>Kevin J.</forenames></author></authors><title>The first order statistics of backscatter from the fractal branching
  vasculature</title><categories>q-bio.QM eess.SP</categories><comments>26 pages, 14 figures. This article has been submitted to The Journal
  of the Acoustical Society of America. After it is published, it will be found
  at http://asa.scitation.org/journal/jas</comments><journal-ref>J Acoust Soc Am 146(5) p.3318-3326, 2019</journal-ref><doi>10.1121/1.5132934</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The issue of speckle statistics from ultrasound images of soft tissues such
as the liver has a long and rich history. A number of theoretical
distributions, some related to random scatterers or fades in optics and radar,
have been formulated for pulse-echo interference patterns. This work proposes
an alternative framework in which the dominant echoes are presumed to result
from Born scattering from fluid filled vessels that permeate the tissue
parenchyma. These are modeled as a branching, fractal, self-similar, multi
scale collection of cylindrical scatterers governed by a power law distribution
relating the number of branches at each radius. A deterministic accounting of
the echo envelopes across the scales from small to large is undertaken, leading
to a closed form theoretical formula for the histogram of the envelope of the
echoes. The normalized histogram is found to be related to the classical Burr
distribution, with the key power law parameter directly related to that of the
number density of vessels vs. diameter, frequently reported in the range of 2
to 4. Examples are given from liver scans to demonstrate the applicability of
the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02604</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02604</id><created>2019-06-05</created><authors><author><keyname>Moretti</keyname><forenames>Claudio</forenames></author><author><keyname>Gigan</keyname><forenames>Sylvain</forenames></author></authors><title>Readout of fluorescence functional signals through highly scattering
  tissue</title><categories>physics.optics eess.IV physics.bio-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorescence is a powerful mean to probe information processing in the
mammalian brain. However, neuronal tissues are highly heterogeneous and thus
opaque to light. A wide set of non-invasive or invasive techniques for
scattered light rejection, optical sectioning or localized excitation, have
been developed, but non-invasive optical recording of activity through highly
scattering layer beyond the ballistic regime is to date impossible. Here, we
show that functional signals from fluorescent time-varying sources located
below an highly scattering tissue can be retrieved efficiently, by exploiting
matrix factorization algorithms to demix this information from low contrast
fluorescence speckle patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02618</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02618</id><created>2019-06-06</created><authors><author><keyname>Pr&#xe9;tet</keyname><forenames>Laure</forenames></author><author><keyname>Hennequin</keyname><forenames>Romain</forenames></author><author><keyname>Royo-Letelier</keyname><forenames>Jimena</forenames></author><author><keyname>Vaglio</keyname><forenames>Andrea</forenames></author></authors><title>Singing voice separation: a study on training data</title><categories>cs.SD eess.AS</categories><journal-ref>ICASSP 2019 - 2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)</journal-ref><doi>10.1109/ICASSP.2019.8683555</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent years, singing voice separation systems showed increased
performance due to the use of supervised training. The design of training
datasets is known as a crucial factor in the performance of such systems. We
investigate on how the characteristics of the training dataset impacts the
separation performances of state-of-the-art singing voice separation
algorithms. We show that the separation quality and diversity are two important
and complementary assets of a good training dataset. We also provide insights
on possible transforms to perform data augmentation for this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02646</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02646</id><created>2019-06-06</created><authors><author><keyname>Hooshmand</keyname><forenames>Ali</forenames></author><author><keyname>Sharma</keyname><forenames>Ratnesh</forenames></author></authors><title>Energy Predictive Models with Limited Data using Transfer Learning</title><categories>cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of developing predictive models with
limited data for energy assets such as electricity loads, PV power generations,
etc. We specifically investigate the cases where the amount of historical data
is not sufficient to effectively train the prediction model. We first develop
an energy predictive model based on convolutional neural network (CNN) which is
well suited to capture the interaday, daily, and weekly cyclostationary
patterns, trends and seasonalities in energy assets time series. A transfer
learning strategy is then proposed to address the challenge of limited training
data. We demonstrate our approach on a usecase of daily electricity demand
forecasting. we show practicing the transfer learning strategy on the CNN model
results in significant improvement to existing forecasting methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02673</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02673</id><created>2019-06-01</created><authors><author><keyname>Schrenk</keyname><forenames>Bernhard</forenames><affiliation>AIT Austrian Institute of Technology</affiliation></author></authors><title>Synchronized Wavelength-Swept Signal Transmission and its Ability to
  Evade Optical Reflection Crosstalk</title><categories>eess.SP physics.app-ph</categories><doi>10.1364/OL.44.002771</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coherent homodyne detection requires a precise matching of emission
wavelengths between transmitter and local oscillator at the receiver.
Injection-locking can provide all-optical synchronization of the emission
frequencies, even under wavelength-swept emission. By adapting the sweep
parameters to the conditions in the optical fiber plant, transmission
impairments can be mitigated. In this regard I experimentally demonstrate that
a wavelength-hopping yet locked transceiver pair, which builds on conceptually
simple externally modulated laser technology, features a much higher robustness
to reflection crosstalk. The reception penalty due to distortions arising at a
Fresnel reflection in the transmission path can be reduced by &gt;90% at a low
optical signal-to-reflection ratio of ~0 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02678</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02678</id><created>2019-06-03</created><authors><author><keyname>Stamatescu</keyname><forenames>Grigore</forenames></author><author><keyname>Dragana</keyname><forenames>Cristian</forenames></author><author><keyname>Stamatescu</keyname><forenames>Iulia</forenames></author><author><keyname>Ichim</keyname><forenames>Loretta</forenames></author><author><keyname>Popescu</keyname><forenames>Dan</forenames></author></authors><title>IoT-Enabled Distributed Data Processing for Precision Agriculture</title><categories>eess.SP</categories><comments>6 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large scale monitoring systems, enabled by the emergence of networked
embedded sensing devices, offer the opportunity of fine grained online
spatio-temporal collection, communication and analysis of physical parameters.
Various applications have been proposed and validated so far for environmental
monitoring, security and industrial control systems. One particular application
domain has been shown suitable for the requirements of precision agriculture
where such systems can improve yields, increase efficiency and reduce input
usage. We present a data analysis and processing approach for distributed
monitoring of crops and soil where hierarchical aggregation and modelling
primitives contribute to the robustness of the network by alleviating
communication bottlenecks and reducing the energy required for redundant data
transmissions. The focus is on leveraging the fog computing paradigm to exploit
local node computing resources and generate events towards upper decision
systems. Key metrics are reported which highlight the improvements achieved. A
case study is carried out on real field data for crop and soil monitoring with
outlook on operational and implementation constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02679</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02679</id><created>2019-06-03</created><authors><author><keyname>Shi</keyname><forenames>Yan</forenames></author><author><keyname>Feng</keyname><forenames>Dezhi</forenames></author><author><keyname>Biswas</keyname><forenames>Subir</forenames></author></authors><title>A Natural Language-Inspired Multi-label Video Streaming Traffic
  Classification Method Based on Deep Neural Networks</title><categories>eess.SP cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a deep-learning based traffic classification method for
identifying multiple streaming video sources at the same time within an
encrypted tunnel. The work defines a novel feature inspired by Natural Language
Processing (NLP) that allows existing NLP techniques to help the traffic
classification. The feature extraction method is described, and a large dataset
containing video streaming and web traffic is created to verify its
effectiveness. Results are obtained by applying several NLP methods to show
that the proposed method performs well on both binary and multilabel traffic
classification problems. We also show the ability to achieve zero-shot learning
with the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02684</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02684</id><created>2019-06-06</created><authors><author><keyname>Mustafa</keyname><forenames>Ahmad</forenames></author><author><keyname>Alfarraj</keyname><forenames>Motaz</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Estimation of Acoustic Impedance from Seismic Data using Temporal
  Convolutional Network</title><categories>eess.SP eess.IV physics.geo-ph</categories><comments>Published in SEG Technical Program Expanded Abstracts 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In exploration seismology, seismic inversion refers to the process of
inferring physical properties of the subsurface from seismic data. Knowledge of
physical properties can prove helpful in identifying key structures in the
subsurface for hydrocarbon exploration. In this work, we propose a workflow for
predicting acoustic impedance (AI) from seismic data using a network
architecture based on Temporal Convolutional Network by posing the problem as
that of sequence modeling. The proposed workflow overcomes some of the problems
that other network architectures usually face, like gradient vanishing in
Recurrent Neural Networks, or overfitting in Convolutional Neural Networks. The
proposed workflow was used to predict AI on Marmousi 2 dataset with an average
$r^{2}$ coefficient of $91\%$ on a hold-out validation set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02686</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02686</id><created>2019-06-05</created><authors><author><keyname>Thompson</keyname><forenames>Brian</forenames><affiliation>The MITRE Corporation</affiliation></author><author><keyname>Cedel</keyname><forenames>Dave</forenames><affiliation>The MITRE Corporation</affiliation></author><author><keyname>Martin</keyname><forenames>Jeremy</forenames><affiliation>The MITRE Corporation</affiliation></author><author><keyname>Ryan</keyname><forenames>Peter</forenames><affiliation>The MITRE Corporation</affiliation></author><author><keyname>Kern</keyname><forenames>Sarah</forenames><affiliation>The MITRE Corporation</affiliation></author></authors><title>Fusion of Mobile Device Signal Data Attributes Enables Multi-Protocol
  Entity Resolution and Enhanced Large-Scale Tracking</title><categories>eess.SP cs.CR</categories><comments>21 pages, 10 figures</comments><acm-class>I.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Use of persistent identifiers in wireless communication protocols is a known
privacy concern as they can be used to track the location of mobile devices.
Furthermore, inherent structure in the assignment of hardware identifiers as
well as upper-layer network protocol data attributes can leak additional device
information. We introduce SEXTANT, a computational framework that combines
improvements on previously published device identification techniques with
novel spatio-temporal correlation algorithms to perform multi-protocol entity
resolution, enabling large-scale tracking of mobile devices across protocol
domains. Experiments using simulated data representing Las Vegas residents and
visitors over a 30-day period, consisting of about 300,000 multi-protocol
mobile devices generating over 200 million sensor observations, demonstrate
SEXTANT's ability to perform effectively at scale while being robust to data
heterogeneity, sparsity, and noise, highlighting the urgent need for the
adoption of new standards to protect the privacy of mobile device users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02687</identifier>
 <datestamp>2019-11-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02687</id><created>2019-06-04</created><updated>2019-11-22</updated><authors><author><keyname>Sabbagh</keyname><forenames>David</forenames></author><author><keyname>Ablin</keyname><forenames>Pierre</forenames></author><author><keyname>Varoquaux</keyname><forenames>Gael</forenames></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames></author><author><keyname>Engemann</keyname><forenames>Denis A.</forenames></author></authors><title>Manifold-regression to predict from MEG/EEG brain signals without source
  modeling</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetoencephalography and electroencephalography (M/EEG) can reveal neuronal
dynamics non-invasively in real-time and are therefore appreciated methods in
medicine and neuroscience. Recent advances in modeling brain-behavior
relationships have highlighted the effectiveness of Riemannian geometry for
summarizing the spatially correlated time-series from M/EEG in terms of their
covariance. However, after artefact-suppression, M/EEG data is often rank
deficient which limits the application of Riemannian concepts. In this article,
we focus on the task of regression with rank-reduced covariance matrices. We
study two Riemannian approaches that vectorize the M/EEG covariance
between-sensors through projection into a tangent space. The Wasserstein
distance readily applies to rank-reduced data but lacks affine-invariance. This
can be overcome by finding a common subspace in which the covariance matrices
are full rank, enabling the affine-invariant geometric distance. We
investigated the implications of these two approaches in synthetic generative
models, which allowed us to control estimation bias of a linear model for
prediction. We show that Wasserstein and geometric distances allow perfect
out-of-sample prediction on the generative models. We then evaluated the
methods on real data with regard to their effectiveness in predicting age from
M/EEG covariance matrices. The findings suggest that the data-driven Riemannian
methods outperform different sensor-space estimators and that they get close to
the performance of biophysics-driven source-localization model that requires
MRI acquisitions and tedious data processing. Our study suggests that the
proposed Riemannian methods can serve as fundamental building-blocks for
automated large-scale analysis of M/EEG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02745</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02745</id><created>2019-06-05</created><authors><author><keyname>Yao</keyname><forenames>Xinghua</forenames></author><author><keyname>Cheng</keyname><forenames>Qiang</forenames></author><author><keyname>Zhang</keyname><forenames>Guo-Qiang</forenames></author></authors><title>Automated Classification of Seizures against Nonseizures: A Deep
  Learning Approach</title><categories>eess.SP cs.LG stat.ML</categories><comments>12 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1903.09326</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In current clinical practice, electroencephalograms (EEG) are reviewed and
analyzed by well-trained neurologists to provide supports for therapeutic
decisions. The way of manual reviewing is labor-intensive and error prone.
Automatic and accurate seizure/nonseizure classification methods are needed.
One major problem is that the EEG signals for seizure state and nonseizure
state exhibit considerable variations. In order to capture essential seizure
features, this paper integrates an emerging deep learning model, the
independently recurrent neural network (IndRNN), with a dense structure and an
attention mechanism to exploit temporal and spatial discriminating features and
overcome seizure variabilities. The dense structure is to ensure maximum
information flow between layers. The attention mechanism is to capture spatial
features. Evaluations are performed in cross-validation experiments over the
noisy CHB-MIT data set. The obtained average sensitivity, specificity and
precision of 88.80%, 88.60% and 88.69% are better than using the current
state-of-the-art methods. In addition, we explore how the segment length
affects the classification performance. Thirteen different segment lengths are
assessed, showing that the classification performance varies over the segment
lengths, and the maximal fluctuating margin is more than 4%. Thus, the segment
length is an important factor influencing the classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02772</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02772</id><created>2019-05-26</created><updated>2019-12-02</updated><authors><author><keyname>Cao</keyname><forenames>Zehong</forenames></author><author><keyname>Liu</keyname><forenames>Yu-Ting</forenames></author><author><keyname>Chuang</keyname><forenames>Chun-Hsiang</forenames></author><author><keyname>Lin</keyname><forenames>Yang-Yin</forenames></author><author><keyname>Hsieh</keyname><forenames>Tsung-Yu</forenames></author><author><keyname>Fan</keyname><forenames>Chieh-Ning</forenames></author><author><keyname>Pal</keyname><forenames>Nikhil R.</forenames></author><author><keyname>Lin</keyname><forenames>Chin-Teng</forenames></author></authors><title>An Extended Adaptive Subspace Self-Organizing Map (EASSOM) Imbalanced
  Learning and Its Applications in EEG</title><categories>eess.SP cs.LG</categories><comments>Submitting to IEEE Transactions on Cybernetics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel oversampling technique addressing highly
imbalanced distributions in benchmark and electroencephalogram (EEG) datasets.
Presently, conventional machine learning technologies do not adequately address
imbalanced data with an anomalous class distribution and underrepresented data.
To balance the class distributions, an extended adaptive subspace
self-organizing map (EASSOM) that combines a local mapping scheme and the
globally competitive rule is proposed to artificially generate synthetic
samples that focus on minority class samples and its application in EEG. The
EASSOM is configured with feature-invariant characteristics, including
translation, scaling, and rotation, and it retains the independence of the
basis vectors in each module. Specifically, basis vectors that are generated
via each EASSOM module can avoid generating repeated representative features
that only increase the computational load. Several benchmark experimental
results demonstrate that the proposed EASSOM method incorporating a supervised
learning approach could be superior to other existing oversampling techniques,
and three EEG applications present the improvement of classification accuracy
using the proposed EASSOM method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02812</identifier>
 <datestamp>2019-12-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02812</id><created>2019-05-10</created><updated>2019-12-19</updated><authors><author><keyname>Araujo</keyname><forenames>Flavio Abreu</forenames></author><author><keyname>Riou</keyname><forenames>Mathieu</forenames></author><author><keyname>Torrejon</keyname><forenames>Jacob</forenames></author><author><keyname>Tsunegi</keyname><forenames>Sumito</forenames></author><author><keyname>Querlioz</keyname><forenames>Damien</forenames></author><author><keyname>Yakushiji</keyname><forenames>Kay</forenames></author><author><keyname>Fukushima</keyname><forenames>Akio</forenames></author><author><keyname>Kubota</keyname><forenames>Hitoshi</forenames></author><author><keyname>Yuasa</keyname><forenames>Shinji</forenames></author><author><keyname>Stiles</keyname><forenames>Mark D.</forenames></author><author><keyname>Grollier</keyname><forenames>Julie</forenames></author></authors><title>Role of non-linear data processing on speech recognition task in the
  framework of reservoir computing</title><categories>eess.AS cs.SD eess.SP</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reservoir computing neural network architecture is widely used to test
hardware systems for neuromorphic computing. One of the preferred tasks for
bench-marking such devices is automatic speech recognition. However, this task
requires acoustic transformations from sound waveforms with varying amplitudes
to frequency domain maps that can be seen as feature extraction techniques.
Depending on the conversion method, these may obscure the contribution of the
neuromorphic hardware to the overall speech recognition performance. Here, we
quantify and separate the contributions of the acoustic transformations and the
neuromorphic hardware to the speech recognition success rate. We show that the
non-linearity in the acoustic transformation plays a critical role in feature
extraction. We compute the gain in word success rate provided by a reservoir
computing device compared to the acoustic transformation only, and show that it
is an appropriate benchmark for comparing different hardware. Finally, we
experimentally and numerically quantify the impact of the different acoustic
transformations for neuromorphic hardware based on magnetic nano-oscillators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02817</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02817</id><created>2019-06-06</created><updated>2019-08-04</updated><authors><author><keyname>Zhu</keyname><forenames>Zhuotun</forenames></author><author><keyname>Liu</keyname><forenames>Chenxi</forenames></author><author><keyname>Yang</keyname><forenames>Dong</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author><author><keyname>Xu</keyname><forenames>Daguang</forenames></author></authors><title>V-NAS: Neural Architecture Search for Volumetric Medical Image
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>Accepted by 3DV, camera ready version. 8 pages, 4 figures and 5
  tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning algorithms, in particular 2D and 3D fully convolutional neural
networks (FCNs), have rapidly become the mainstream methodology for volumetric
medical image segmentation. However, 2D convolutions cannot fully leverage the
rich spatial information along the third axis, while 3D convolutions suffer
from the demanding computation and high GPU memory consumption. In this paper,
we propose to automatically search the network architecture tailoring to
volumetric medical image segmentation problem. Concretely, we formulate the
structure learning as differentiable neural architecture search, and let the
network itself choose between 2D, 3D or Pseudo-3D (P3D) convolutions at each
layer. We evaluate our method on 3 public datasets, i.e., the NIH Pancreas
dataset, the Lung and Pancreas dataset from the Medical Segmentation Decathlon
(MSD) Challenge. Our method, named V-NAS, consistently outperforms other
state-of-the-arts on the segmentation task of both normal organ (NIH Pancreas)
and abnormal organs (MSD Lung tumors and MSD Pancreas tumors), which shows the
power of chosen architecture. Moreover, the searched architecture on one
dataset can be well generalized to other datasets, which demonstrates the
robustness and practical use of our proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02846</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02846</id><created>2019-06-06</created><updated>2019-08-19</updated><authors><author><keyname>Shen</keyname><forenames>Yiqiu</forenames></author><author><keyname>Wu</keyname><forenames>Nan</forenames></author><author><keyname>Phang</keyname><forenames>Jason</forenames></author><author><keyname>Park</keyname><forenames>Jungkyu</forenames></author><author><keyname>Kim</keyname><forenames>Gene</forenames></author><author><keyname>Moy</keyname><forenames>Linda</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author><author><keyname>Geras</keyname><forenames>Krzysztof J.</forenames></author></authors><title>Globally-Aware Multiple Instance Classifier for Breast Cancer Screening</title><categories>cs.LG eess.IV stat.ML</categories><comments>Accepted to MLMI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models designed for visual classification tasks on natural
images have become prevalent in medical image analysis. However, medical images
differ from typical natural images in many ways, such as significantly higher
resolutions and smaller regions of interest. Moreover, both the global
structure and local details play important roles in medical image analysis
tasks. To address these unique properties of medical images, we propose a
neural network that is able to classify breast cancer lesions utilizing
information from both a global saliency map and multiple local patches. The
proposed model outperforms the ResNet-based baseline and achieves
radiologist-level performance in the interpretation of screening mammography.
Although our model is trained only with image-level labels, it is able to
generate pixel-level saliency maps that provide localization of possible
malignant findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02859</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02859</id><created>2019-06-06</created><updated>2020-02-02</updated><authors><author><keyname>Yurtsever</keyname><forenames>Ekim</forenames></author><author><keyname>Liu</keyname><forenames>Yongkang</forenames></author><author><keyname>Lambert</keyname><forenames>Jacob</forenames></author><author><keyname>Miyajima</keyname><forenames>Chiyomi</forenames></author><author><keyname>Takeuchi</keyname><forenames>Eijiro</forenames></author><author><keyname>Takeda</keyname><forenames>Kazuya</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Risky Action Recognition in Lane Change Video Clips using Deep
  Spatiotemporal Networks with Segmentation Mask Transfer</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><comments>8 pages, 3 figures, 1 table. The code is open-source</comments><journal-ref>2019 IEEE Intelligent Transportation Systems Conference (ITSC),
  Auckland, New Zealand, 2019, pp. 3100-3107</journal-ref><doi>10.1109/ITSC.2019.8917362</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Advanced driver assistance and automated driving systems rely on risk
estimation modules to predict and avoid dangerous situations. Current methods
use expensive sensor setups and complex processing pipeline, limiting their
availability and robustness. To address these issues, we introduce a novel deep
learning based action recognition framework for classifying dangerous lane
change behavior in short video clips captured by a monocular camera. We
designed a deep spatiotemporal classification network that uses pre-trained
state-of-the-art instance segmentation network Mask R-CNN as its spatial
feature extractor for this task. The Long-Short Term Memory (LSTM) and
shallower final classification layers of the proposed method were trained on a
semi-naturalistic lane change dataset with annotated risk labels. A
comprehensive comparison of state-of-the-art feature extractors was carried out
to find the best network layout and training strategy. The best result, with a
0.937 AUC score, was obtained with the proposed network. Our code and trained
models are available open-source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02871</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02871</id><created>2019-06-06</created><updated>2019-07-16</updated><authors><author><keyname>Lee</keyname><forenames>Mengyuan</forenames></author><author><keyname>Yu</keyname><forenames>Guanding</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Graph Embedding based Wireless Link Scheduling with Few Training Samples</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link scheduling in device-to-device (D2D) networks is usually formulated as a
non-convex combinatorial problem, which is generally NP-hard and difficult to
get the optimal solution. Traditional methods to solve this problem are mainly
based on mathematical optimization techniques, where accurate channel state
information (CSI), usually obtained through channel estimation and feedback, is
needed. To overcome the high computational complexity of the traditional
methods and eliminate the costly channel estimation stage, machine leaning (ML)
has been introduced recently to address the wireless link scheduling problems.
In this paper, we propose a novel graph embedding based method for link
scheduling in D2D networks. We first construct a fully-connected directed graph
for the D2D network, where each D2D pair is a node while interference links
among D2D pairs are the edges. Then we compute a low-dimensional feature vector
for each node in the graph. The graph embedding process is based on the
distances of both communication and interference links, therefore without
requiring the accurate CSI. By utilizing a multi-layer classifier, a scheduling
strategy can be learned in a supervised manner based on the graph embedding
results for each node. We also propose an unsupervised manner to train the
graph embedding based method to further reinforce the scalability and
generalizability and develop a K-nearest neighbor graph representation method
to reduce the computational complexity. Extensive simulation demonstrates that
the proposed method is near-optimal compared with the existing state-of-art
methods but is with only hundreds of training samples. It is also competitive
in terms of scalability and generalizability to more complicated scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02894</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02894</id><created>2019-06-07</created><authors><author><keyname>Zaghloul</keyname><forenames>Zaghloul Saad</forenames></author><author><keyname>Bayoumi</keyname><forenames>Magdy</forenames></author></authors><title>Early Prediction of Epilepsy Seizures VLSI BCI System</title><categories>eess.SP cs.HC</categories><comments>Novel predictive BCI VLSI architecture</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Controlling the surrounding world and predicting future events has always
seemed like a dream, but that could become a reality using a
Brain-Computer/Machine Interface (BCI/BMI). Epilepsy is a group of neurological
diseases characterized by epileptic seizures. It affects millions of people
worldwide, with 80 percent of cases occurring in developing countries. This can
result in accidents and sudden, unexpected death. Seizures can happen
undetectably in newborns, comatose, or motor-impaired patients, especially due
to the fact that many medical personnel is not qualified for EEG signal
analysis. Therefore, a portable automated detection and monitoring solution is
in high demand. Thus, in this study, a system of a wireless wearable adaptive
for early prediction of epilepsy seizures is proposed, works via minimally
invasive wireless technology paired with an external control device (e.g., a
doctors smartphone), with a higher than standard accuracy 71 percent and
prediction time (14.56 sec). This novel architecture has not only opened new
opportunities for daily usable BCI implementations, but they can also save a
life by helping to prevent a seizure fatal consequences
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02901</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02901</id><created>2019-06-07</created><authors><author><keyname>Zhang</keyname><forenames>Yizhe</forenames></author><author><keyname>Ying</keyname><forenames>Michael T. C.</forenames></author><author><keyname>Chen</keyname><forenames>Danny Z.</forenames></author></authors><title>Decompose-and-Integrate Learning for Multi-class Segmentation in Medical
  Images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>To appear in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation maps of medical images annotated by medical experts contain rich
spatial information. In this paper, we propose to decompose annotation maps to
learn disentangled and richer feature transforms for segmentation problems in
medical images. Our new scheme consists of two main stages: decompose and
integrate. Decompose: by annotation map decomposition, the original
segmentation problem is decomposed into multiple segmentation sub-problems;
these new segmentation sub-problems are modeled by training multiple deep
learning modules, each with its own set of feature transforms. Integrate: a
procedure summarizes the solutions of the modules in the previous stage; a
final solution is then formed for the original segmentation problem. Multiple
ways of annotation map decomposition are presented and a new end-to-end
trainable K-to-1 deep network framework is developed for implementing our
proposed &quot;decompose-and-integrate&quot; learning scheme. In experiments, we
demonstrate that our decompose-and-integrate segmentation, utilizing
state-of-the-art fully convolutional networks (e.g., DenseVoxNet in 3D and
CUMedNet in 2D), improves segmentation performance on multiple 3D and 2D
datasets. Ablation study confirms the effectiveness of our proposed learning
scheme for medical images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02930</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02930</id><created>2019-06-07</created><authors><author><keyname>Lavaei</keyname><forenames>Abolfazl</forenames></author><author><keyname>Soudjani</keyname><forenames>Sadegh</forenames></author><author><keyname>Zamani</keyname><forenames>Majid</forenames></author></authors><title>Compositional Abstraction-based Synthesis of General MDPs via
  Approximate Probabilistic Relations</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a compositional approach for constructing abstractions of general
Markov decision processes using approximate probabilistic relations. The
abstraction framework is based on the notion of $\delta$-lifted relations,
using which one can quantify the distance in probability between the
interconnected gMDPs and that of their abstractions. This new approximate
relation unifies compositionality results in the literature by incorporating
the dependencies between state transitions explicitly and by allowing abstract
models to have either finite or infinite state spaces. Accordingly, one can
leverage the proposed results to perform analysis and synthesis over abstract
models, and then carry the results over concrete ones. To this end, we first
propose our compositionality results using the new approximate probabilistic
relation which is based on lifting. We then focus on a class of stochastic
nonlinear dynamical systems and construct their abstractions using both model
order reduction and space discretization in a unified framework. We provide
conditions for simultaneous existence of relations incorporating the structure
of the network. Finally, we demonstrate the effectiveness of the proposed
results by considering a network of four nonlinear dynamical subsystems
(together 12 dimensions) and constructing finite abstractions from their
reduced-order versions (together 4 dimensions) in a unified compositional
framework. We benchmark our results against the compositional abstraction
techniques that construct both infinite abstractions (reduced-order models) and
finite MDPs in two consecutive steps. We show that our approach is much less
conservative than the ones available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02939</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02939</id><created>2019-06-07</created><updated>2019-08-10</updated><authors><author><keyname>Fan</keyname><forenames>Rui</forenames></author><author><keyname>Jiao</keyname><forenames>Jianhao</forenames></author><author><keyname>Ye</keyname><forenames>Haoyang</forenames></author><author><keyname>Yu</keyname><forenames>Yang</forenames></author><author><keyname>Pitas</keyname><forenames>Ioannis</forenames></author><author><keyname>Liu</keyname><forenames>Ming</forenames></author></authors><title>Key Ingredients of Self-Driving Cars</title><categories>cs.RO cs.CV cs.LG cs.SY eess.SP</categories><comments>5 pages, 2 figures, EUSIPCO 2019 Satellite Workshop: Signal
  Processing, Computer Vision and Deep Learning for Autonomous Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past decade, many research articles have been published in the area
of autonomous driving. However, most of them focus only on a specific
technological area, such as visual environment perception, vehicle control,
etc. Furthermore, due to fast advances in the self-driving car technology, such
articles become obsolete very fast. In this paper, we give a brief but
comprehensive overview on key ingredients of autonomous cars (ACs), including
driving automation levels, AC sensors, AC software, open source datasets,
industry leaders, AC applications and existing challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02940</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02940</id><created>2019-06-07</created><updated>2019-07-27</updated><authors><author><keyname>Trinh</keyname><forenames>Trieu H.</forenames></author><author><keyname>Luong</keyname><forenames>Minh-Thang</forenames></author><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author></authors><title>Selfie: Self-supervised Pretraining for Image Embedding</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a pretraining technique called Selfie, which stands for SELFie
supervised Image Embedding. Selfie generalizes the concept of masked language
modeling of BERT (Devlin et al., 2019) to continuous data, such as images, by
making use of the Contrastive Predictive Coding loss (Oord et al., 2018). Given
masked-out patches in an input image, our method learns to select the correct
patch, among other &quot;distractor&quot; patches sampled from the same image, to fill in
the masked location. This classification objective sidesteps the need for
predicting exact pixel values of the target patches. The pretraining
architecture of Selfie includes a network of convolutional blocks to process
patches followed by an attention pooling network to summarize the content of
unmasked patches before predicting masked ones. During finetuning, we reuse the
convolutional weights found by pretraining. We evaluate Selfie on three
benchmarks (CIFAR-10, ImageNet 32 x 32, and ImageNet 224 x 224) with varying
amounts of labeled data, from 5% to 100% of the training sets. Our pretraining
method provides consistent improvements to ResNet-50 across all settings
compared to the standard supervised training of the same network. Notably, on
ImageNet 224 x 224 with 60 examples per class (5%), our method improves the
mean accuracy of ResNet-50 from 35.6% to 46.7%, an improvement of 11.1 points
in absolute accuracy. Our pretraining method also improves ResNet-50 training
stability, especially on low data regime, by significantly lowering the
standard deviation of test accuracies across different runs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02959</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02959</id><created>2019-06-07</created><authors><author><keyname>Sidorov</keyname><forenames>Denis</forenames></author><author><keyname>Tao</keyname><forenames>Qing</forenames></author><author><keyname>Muftahov</keyname><forenames>Ildar</forenames></author><author><keyname>Zhukov</keyname><forenames>Aleksei</forenames></author><author><keyname>Karamov</keyname><forenames>Dmitriy</forenames></author><author><keyname>Dreglea</keyname><forenames>Aliona</forenames></author><author><keyname>Liu</keyname><forenames>Fang</forenames></author></authors><title>Energy balancing using charge/discharge storages control and load
  forecasts in a renewable-energy-based grids</title><categories>eess.SP</categories><comments>6 pages; accepted to 38th China Control Conference 2019</comments><msc-class>45D05 65D99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Renewable-energy-based grids development needs new methods to maintain the
balance between the load and generation using the efficient energy storages
models. Most of the available energy storages models do not take into account
such important features as the nonlinear dependence of efficiency on lifetime
and changes in capacity over time horizon, the distribution of load between
several independent storages. In order to solve these problems the Volterra
integral dynamical models are employed. Such models allow to determine the
alternating power function for given/forecasted load and generation datasets.
In order to efficiently solve this problem, the load forecasting models were
proposed using deep learning and support vector regression models. Forecasting
models use various features including average daily temperature, load values
with time shift and moving averages. Effectiveness of the proposed energy
balancing method using the state-of-the-art forecasting models is demonstrated
on the real datasets of Germany's electric grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02961</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02961</id><created>2019-06-07</created><authors><author><keyname>Lee</keyname><forenames>Chonho</forenames></author><author><keyname>Tanikawa</keyname><forenames>Chihiro</forenames></author><author><keyname>Lim</keyname><forenames>Jae-Yeon</forenames></author><author><keyname>Yamashiro</keyname><forenames>Takashi</forenames></author></authors><title>Deep Learning based Cephalometric Landmark Identification using
  Landmark-dependent Multi-scale Patches</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A deep neural network based cephalometric landmark identification model is
proposed. Two neural networks, named patch classification and point estimation,
are trained by multi-scale image patches cropped from 935 Cephalograms (of
Japanese young patients), whose size and orientation vary based on
landmark-dependent criteria examined by orthodontists. The proposed model
identifies both 22 hard and 11 soft tissue landmarks. In order to evaluate the
proposed model, (i) landmark estimation accuracy by Euclidean distance error
between true and estimated values, and (ii) success rate that the estimated
landmark was located within the corresponding norm using confidence ellipse,
are computed. The proposed model successfully identified hard tissue landmarks
within the error range of 1.32 - 3.5 mm and with a mean success rate of 96.4%,
and soft tissue landmarks with the error range of 1.16 - 4.37 mm and with a
mean success rate of 75.2%. We verify that considering the landmark-dependent
size and orientation of patches helps improve the estimation accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02965</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02965</id><created>2019-06-07</created><authors><author><keyname>Sijtsma</keyname><forenames>Pieter</forenames><affiliation>LVA</affiliation></author><author><keyname>Dinsenmeyer</keyname><forenames>Alice</forenames><affiliation>LVA</affiliation></author><author><keyname>Antoni</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LVA</affiliation></author><author><keyname>Leclere</keyname><forenames>Quentin</forenames><affiliation>LVA</affiliation></author></authors><title>Beamforming and other methods for denoising microphone array data</title><categories>eess.AS eess.SP</categories><comments>2019 AIAA/CEAS Aeroacoustics conference, May 2019, Delft, Netherlands</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measured acoustic data can be contaminated by noise. This typically happens
when microphones are mounted in a wind tunnel wall or on the fuselage of an
aircraft, where hydrodynamic pressure fluctuations of the Turbulent Boundary
Layer (TBL) can mask the acoustic pressures of interest. For measurements done
with an array of microphones, methods exist for denoising the acoustic data.
Use is made of the fact that the noise is usually concentrated in the diagonal
of the Cross-Spectral Matrix, because of the short spatial coherence of TBL
noise. This paper reviews several existing denoising methods and considers the
use of Conventional Beamforming, Source Power Integration and CLEAN-SC for this
purpose. A comparison between the methods is made using synthesized array data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02975</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02975</id><created>2019-06-07</created><updated>2020-01-19</updated><authors><author><keyname>Fonseca</keyname><forenames>Eduardo</forenames></author><author><keyname>Plakal</keyname><forenames>Manoj</forenames></author><author><keyname>Font</keyname><forenames>Frederic</forenames></author><author><keyname>Ellis</keyname><forenames>Daniel P. W.</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Audio tagging with noisy labels and minimal supervision</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>DCASE2019 Workshop</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces Task 2 of the DCASE2019 Challenge, titled &quot;Audio
tagging with noisy labels and minimal supervision&quot;. This task was hosted on the
Kaggle platform as &quot;Freesound Audio Tagging 2019&quot;. The task evaluates systems
for multi-label audio tagging using a large set of noisy-labeled data, and a
much smaller set of manually-labeled data, under a large vocabulary setting of
80 everyday sound classes. In addition, the proposed dataset poses an acoustic
mismatch problem between the noisy train set and the test set due to the fact
that they come from different web audio sources. This can correspond to a
realistic scenario given by the difficulty in gathering large amounts of
manually labeled data. We present the task setup, the FSDKaggle2019 dataset
prepared for this scientific evaluation, and a baseline system consisting of a
convolutional neural network. All these resources are freely available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02987</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02987</id><created>2019-06-07</created><authors><author><keyname>Petrou</keyname><forenames>Loukas</forenames></author><author><keyname>Karousios</keyname><forenames>Petros</forenames></author><author><keyname>Georgiou</keyname><forenames>Julius</forenames></author></authors><title>Asynchronous Circuits as an Enabler of Scalable And Programmable
  Metasurfaces</title><categories>eess.SP physics.app-ph</categories><journal-ref>2018 IEEE International Symposium on Circuits and Systems (ISCAS)</journal-ref><doi>10.1109/ISCAS.2018.8351672</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Metamaterials and metasurfaces have given possibilities for manipulating
electromagnetic (EM) waves that in the past would have seemed impossible. The
majority of metasurface designs are suitable for a particular frequency and
angle of incidence. One long-sought objective is the design of programmable
metasurfaces to dynamically manipulate a variety of incoming EM frequencies and
angles. In order to do this, a large-scale mesh of networked chips are required
below the metasurface, which apart from adapting electrical impedance
properties, also communicate with each other, thus relaying information about
meta-atom settings, as well as forwarding possible distributed measurements
taken. This paper describes why an asynchronous mixed-signal ASIC is
advantageous for the control of scalable, EM absorbing, metasurfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02990</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02990</id><created>2019-06-07</created><updated>2019-06-12</updated><authors><author><keyname>Lu</keyname><forenames>Ya</forenames></author><author><keyname>Stathopoulou</keyname><forenames>Thomai</forenames></author><author><keyname>Vasiloglou</keyname><forenames>Maria F.</forenames></author><author><keyname>Christodoulidis</keyname><forenames>Stergios</forenames></author><author><keyname>Blum</keyname><forenames>Beat</forenames></author><author><keyname>Walser</keyname><forenames>Thomas</forenames></author><author><keyname>Meier</keyname><forenames>Vinzenz</forenames></author><author><keyname>Stanga</keyname><forenames>Zeno</forenames></author><author><keyname>Mougiakakou</keyname><forenames>Stavroula G.</forenames></author></authors><title>An Artificial Intelligence-Based System for Nutrient Intake Assessment
  of Hospitalised Patients</title><categories>cs.CV eess.IV</categories><comments>EMBC2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regular nutrient intake monitoring in hospitalised patients plays a critical
role in reducing the risk of disease-related malnutrition (DRM). Although
several methods to estimate nutrient intake have been developed, there is still
a clear demand for a more reliable and fully automated technique, as this could
improve the data accuracy and reduce both the participant burden and the health
costs. In this paper, we propose a novel system based on artificial
intelligence to accurately estimate nutrient intake, by simply processing RGB
depth image pairs captured before and after a meal consumption. For the
development and evaluation of the system, a dedicated and new database of
images and recipes of 322 meals was assembled, coupled to data annotation using
innovative strategies. With this database, a system was developed that employed
a novel multi-task neural network and an algorithm for 3D surface construction.
This allowed sequential semantic food segmentation and estimation of the volume
of the consumed food, and permitted fully automatic estimation of nutrient
intake for each food type with a 15% estimation error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.02999</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.02999</id><created>2019-06-07</created><authors><author><keyname>Luo</keyname><forenames>Luyang</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xi</forenames></author><author><keyname>Dou</keyname><forenames>Qi</forenames></author><author><keyname>Lin</keyname><forenames>Huangjin</forenames></author><author><keyname>Zhou</keyname><forenames>Juan</forenames></author><author><keyname>Li</keyname><forenames>Gongjie</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author></authors><title>Deep Angular Embedding and Feature Correlation Attention for Breast MRI
  Cancer Analysis</title><categories>eess.IV cs.CV</categories><comments>Accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate and automatic analysis of breast MRI plays an important role in
early diagnosis and successful treatment planning for breast cancer. Due to the
heterogeneity nature, accurate diagnosis of tumors remains a challenging task.
In this paper, we propose to identify breast tumor in MRI by Cosine Margin
Sigmoid Loss (CMSL) with deep learning (DL) and localize possible cancer lesion
by COrrelation Attention Map (COAM) based on the learned features. The CMSL
embeds tumor features onto a hypersphere and imposes a decision margin through
cosine constraints. In this way, the DL model could learn more separable
inter-class features and more compact intra-class features in the angular
space. Furthermore, we utilize the correlations among feature vectors to
generate attention maps that could accurately localize cancer candidates with
only image-level label. We build the largest breast cancer dataset involving
10,290 DCE-MRI scan volumes for developing and evaluating the proposed methods.
The model driven by CMSL achieved classification accuracy of 0.855 and AUC of
0.902 on the testing set, with sensitivity and specificity of 0.857 and 0.852,
respectively, outperforming other competitive methods overall. In addition, the
proposed COAM accomplished more accurate localization of the cancer center
compared with other state-of-the-art weakly supervised localization method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03012</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03012</id><created>2019-06-07</created><authors><author><keyname>Henarejos</keyname><forenames>Pol</forenames></author><author><keyname>V&#xe1;zquez</keyname><forenames>Miguel &#xc1;ngel</forenames></author><author><keyname>P&#xe9;rez-Neira</keyname><forenames>Ana Isabel</forenames></author></authors><title>Deep Learning For Experimental Hybrid Terrestrial and Satellite
  Interference Management</title><categories>eess.SP cs.IT cs.LG math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Interference Management is a vast topic present in many disciplines. The
majority of wireless standards suffer the drawback of interference intrusion
and the network efficiency drop due to that. Traditionally, interference
management has been addressed by proposing signal processing techniques that
minimize their effects locally. However, the fast evolution of future
communications makes difficult to adapt to new era. In this paper we propose
the use of Deep Learning techniques to present a compact system for
interference management. In particular, we describe two subsystems capable to
detect the presence of interference, even in high Signal to Interference Ratio
(SIR), and interference classification in several radio standards. Finally, we
present results based on real signals captured from terrestrial and satellite
networks and the conclusions unveil the courageous future of AI and wireless
communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03040</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03040</id><created>2019-05-14</created><authors><author><keyname>Blandin</keyname><forenames>Sebastien</forenames></author><author><keyname>Wynter</keyname><forenames>Laura</forenames></author><author><keyname>Poonawala</keyname><forenames>Hasan</forenames></author><author><keyname>Laguna</keyname><forenames>Sean</forenames></author><author><keyname>Dura</keyname><forenames>Basile</forenames></author></authors><title>FASTER: Fusion AnalyticS for public Transport Event Response</title><categories>cs.CY cs.LG cs.SY eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing urban concentration raises operational challenges that can benefit
from integrated monitoring and decision support. Such complex systems need to
leverage the full stack of analytical methods, from state estimation using
multi-sensor fusion for situational awareness, to prediction and computation of
optimal responses. The FASTER platform that we describe in this work, deployed
at nation scale and handling 1.5 billion public transport trips a year, offers
such a full stack of techniques for this large-scale, real-time problem. FASTER
provides fine-grained situational awareness and real-time decision support with
the objective of improving the public transport commuter experience. The
methods employed range from statistical machine learning to agent-based
simulation and mixed-integer optimization. In this work we present an overview
of the challenges and methods involved, with details of the commuter movement
prediction module, as well as a discussion of open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03050</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03050</id><created>2019-06-07</created><updated>2019-08-06</updated><authors><author><keyname>Hu</keyname><forenames>Chenyu</forenames></author><author><keyname>Tong</keyname><forenames>Zhisheng</forenames></author><author><keyname>Liu</keyname><forenames>Zhentao</forenames></author><author><keyname>Huang</keyname><forenames>Zengfeng</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Han</keyname><forenames>Shensheng</forenames></author></authors><title>Optimization of light fields in ghost imaging using dictionary learning</title><categories>eess.IV</categories><comments>14 pages, 6 figures</comments><doi>10.1364/OE.27.028734</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ghost imaging (GI) is a novel imaging technique based on the second-order
correlation of light fields. Due to limited number of samplings in practice,
traditional GI methods often reconstruct objects with unsatisfactory quality.
To improve the imaging results, many reconstruction methods have been
developed, yet the reconstruction quality is still fundamentally restricted by
the modulated light fields. In this paper, we propose to improve the imaging
quality of GI by optimizing the light fields, which is realized via matrix
optimization for a learned dictionary incorporating the sparsity prior of
objects. A closed-form solution of the sampling matrix, which enables
successive sampling, is derived. Through simulation and experimental results,
it is shown that the proposed scheme leads to better imaging quality compared
to the state-of-the-art optimization methods for light fields, especially at a
low sampling rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03051</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03051</id><created>2019-06-07</created><updated>2019-12-23</updated><authors><author><keyname>Liu</keyname><forenames>Feihong</forenames></author><author><keyname>Feng</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Geng</forenames></author><author><keyname>Wu</keyname><forenames>Ye</forenames></author><author><keyname>Hong</keyname><forenames>Yoonmi</forenames></author><author><keyname>Yap</keyname><forenames>Pew-Thian</forenames></author><author><keyname>Shen</keyname><forenames>Dinggang</forenames></author></authors><title>DeepBundle: Fiber Bundle Parcellation with Graph Convolution Neural
  Networks</title><categories>eess.IV cs.AI cs.LG</categories><comments>8 pages</comments><doi>10.1007/978-3-030-35817-4_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parcellation of whole-brain tractography streamlines is an important step for
tract-based analysis of brain white matter microstructure. Existing fiber
parcellation approaches rely on accurate registration between an atlas and the
tractograms of an individual, however, due to large individual differences,
accurate registration is hard to guarantee in practice. To resolve this issue,
we propose a novel deep learning method, called DeepBundle, for
registration-free fiber parcellation. Our method utilizes graph convolution
neural networks (GCNNs) to predict the parcellation label of each fiber tract.
GCNNs are capable of extracting the geometric features of each fiber tract and
harnessing the resulting features for accurate fiber parcellation and
ultimately avoiding the use of atlases and any registration method. We evaluate
DeepBundle using data from the Human Connectome Project. Experimental results
demonstrate the advantages of DeepBundle and suggest that the geometric
features extracted from each fiber tract can be used to effectively parcellate
the fiber tracts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03106</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03106</id><created>2019-05-30</created><authors><author><keyname>Alreshidi</keyname><forenames>Eissa</forenames></author></authors><title>Smart Sustainable Agriculture (SSA) Solution Underpinned by Internet of
  Things (IoT) and Artificial Intelligence (AI)</title><categories>eess.SP</categories><journal-ref>International Journal of Advanced Computer Science and
  Applications Vol. 10, No. 5, 2019. Pages 93-102</journal-ref><doi>10.14569/IJACSA.2019.0100513</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Things (IoT) and Artificial Intelligence (AI) have been
employed in agriculture over a long period of time, alongside other advanced
computing technologies. However, increased attention is currently being paid to
the use of such smart technologies. Agriculture has provided an important
source of food for human beings over many thousands of years, including the
development of appropriate farming methods for different types of crops. The
emergence of new advanced IoT technologies has the potential to monitor the
agricultural environment to ensure high-quality products. However, there
remains a lack of research and development in relation to Smart Sustainable
Agriculture (SSA), accompanied by complex obstacles arising from the
fragmentation of agricultural processes, i.e. the control and operation of
IoT/AI machines; data sharing and management; interoperability; and large
amounts of data analysis and storage. This study firstly, explores existing
IoT/AI technologies adopted for SSA and secondly, identifies IoT/AI technical
architecture capable of underpinning the development of SSA platforms. As well
as contributing to the current body of knowledge, this research reviews
research and development within SSA and provides an IoT/AI architecture to
establish a Smart, Sustainable Agriculture platform as a solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03110</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03110</id><created>2019-06-06</created><authors><author><keyname>Bellucci</keyname><forenames>Matthieu</forenames></author><author><keyname>Miralles</keyname><forenames>Luis</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Atif</forenames></author><author><keyname>Mac Namee</keyname><forenames>Brian</forenames></author></authors><title>ZeLiC and ZeChipC: Time Series Interpolation Methods for Lebesgue or
  Event-based Sampling</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lebesgue sampling is based on collecting information depending on the values
of the signal. Although the interpolation methods for periodic sampling have
been a topic of research for a long time, there is a lack of study in methods
capable of taking advantage of the Lebesgue sampling characteristics to
reconstruct time series more accurately. Indeed, Lebesgue sampling contains
additional information about the shape of the signal in-between two sampled
points. Using this information would allow us to generate an interpolated
signal closer to the original one. That is to say, the average distance between
the interpolated signal and the original signal will be smaller than a signal
interpolated with other interpolation methods. In this paper, we propose two
novel time series interpolation methods specifically designed for Lebesgue
sampling called ZeLiC and ZeChipC. ZeLiC is an algorithm that combines both
Zero-order hold interpolation and Linear interpolation to reconstruct time
series. ZeChipC is a similar idea, it is a combination of Zero-order hold and
PCHIP interpolation. Zero-order hold interpolation is favourable for
interpolating abrupt changes while Linear and PCHIP interpolation are more
suitable for smooth transitions. In order to apply one method or the other, we
have introduced a new concept called tolerated region. ZeLiC and ZeChipC
include a new functionality to adapt the reconstructed signal to concave/convex
regions. The proposed methods have been compared with the state-of-the-art
interpolation methods using Lebesgue sampling and have offered higher average
performance. Additionally, we have compared the performance of the methods
using both Riemann and Lebesgue sampling using an approximate number of sampled
points. The performance of the combination &quot;Lebesgue sampling with ZeChipC
interpolation method&quot; is clearly much better than any other combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03153</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03153</id><created>2019-06-07</created><authors><author><keyname>Keenan</keyname><forenames>Tiarnan D.</forenames></author><author><keyname>Dharssi</keyname><forenames>Shazia</forenames></author><author><keyname>Peng</keyname><forenames>Yifan</forenames></author><author><keyname>Chen</keyname><forenames>Qingyu</forenames></author><author><keyname>Agr&#xf3;n</keyname><forenames>Elvira</forenames></author><author><keyname>Wong</keyname><forenames>Wai T.</forenames></author><author><keyname>Lu</keyname><forenames>Zhiyong</forenames></author><author><keyname>Chew</keyname><forenames>Emily Y.</forenames></author></authors><title>A deep learning approach for automated detection of geographic atrophy
  from color fundus photographs</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in Ophthalmology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To assess the utility of deep learning in the detection of
geographic atrophy (GA) from color fundus photographs; secondary aim to explore
potential utility in detecting central GA (CGA). Design: A deep learning model
was developed to detect the presence of GA in color fundus photographs, and two
additional models to detect CGA in different scenarios. Participants: 59,812
color fundus photographs from longitudinal follow up of 4,582 participants in
the AREDS dataset. Gold standard labels were from human expert reading center
graders using a standardized protocol. Methods: A deep learning model was
trained to use color fundus photographs to predict GA presence from a
population of eyes with no AMD to advanced AMD. A second model was trained to
predict CGA presence from the same population. A third model was trained to
predict CGA presence from the subset of eyes with GA. For training and testing,
5-fold cross-validation was employed. For comparison with human clinician
performance, model performance was compared with that of 88 retinal
specialists. Results: The deep learning models (GA detection, CGA detection
from all eyes, and centrality detection from GA eyes) had AUC of 0.933-0.976,
0.939-0.976, and 0.827-0.888, respectively. The GA detection model had
accuracy, sensitivity, specificity, and precision of 0.965, 0.692, 0.978, and
0.584, respectively. The CGA detection model had equivalent values of 0.966,
0.763, 0.971, and 0.394. The centrality detection model had equivalent values
of 0.762, 0.782, 0.729, and 0.799. Conclusions: A deep learning model
demonstrated high accuracy for the automated detection of GA. The AUC was
non-inferior to that of human retinal specialists. Deep learning approaches may
also be applied to the identification of CGA. The code and pretrained models
are publicly available at https://github.com/ncbi-nlp/DeepSeeNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03165</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03165</id><created>2019-06-07</created><updated>2020-01-02</updated><authors><author><keyname>Wu</keyname><forenames>Qingqing</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Beamforming Optimization for Wireless Network Aided by Intelligent
  Reflecting Surface with Discrete Phase Shifts</title><categories>cs.IT cs.ET eess.SP math.IT</categories><comments>Published in IEEE Transactions on Communications. We show the
  performance of IRS with discrete phase shifts. The most inspiring result is
  that using IRS with even 1-bit elements still achieves the same squared
  power/SNR gain as in the ideal continuous case, i.e., $O(N^2)$. More works at
  https://elewuqq.wixsite.com/mysite</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) is a cost-effective solution for
achieving high spectrum and energy efficiency in future wireless networks by
leveraging massive low-cost passive elements that are able to reflect the
signals with adjustable phase shifts. Prior works on IRS mainly consider
continuous phase shifts at reflecting elements, which are practically difficult
to implement due to the hardware limitation. In contrast, we study in this
paper an IRS-aided wireless network, where an IRS with only a finite number of
phase shifts at each element is deployed to assist in the communication from a
multi-antenna access point (AP) to multiple single-antenna users. We aim to
minimize the transmit power at the AP by jointly optimizing the continuous
transmit precoding at the AP and the discrete reflect phase shifts at the IRS,
subject to a given set of minimum signal-to-interference-plus-noise ratio
(SINR) constraints at the user receivers. The considered problem is shown to be
a mixed-integer non-linear program (MINLP) and thus is difficult to solve in
general. To tackle this problem, we first study the single-user case with one
user assisted by the IRS and propose both optimal and suboptimal algorithms for
solving it. Besides, we analytically show that as compared to the ideal case
with continuous phase shifts, the IRS with discrete phase shifts achieves the
same squared power gain in terms of asymptotically large number of reflecting
elements, while a constant proportional power loss is incurred that depends
only on the number of phase-shift levels. The proposed designs for the
single-user case are also extended to the general setup with multiple users
among which some are aided by the IRS. Simulation results verify our
performance analysis as well as the effectiveness of our proposed designs as
compared to various benchmark schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03169</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03169</id><created>2019-06-04</created><updated>2019-06-18</updated><authors><author><keyname>Lin</keyname><forenames>Jinzhi</forenames></author><author><keyname>Feng</keyname><forenames>Shengzhong</forenames></author><author><keyname>Yang</keyname><forenames>Zhile</forenames></author><author><keyname>Zhang</keyname><forenames>Yun</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author></authors><title>A Novel Deep Neural Network Based Approach for Sparse Code Multiple
  Access</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><comments>21 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse code multiple access (SCMA) has been one of non-orthogonal multiple
access (NOMA) schemes aiming to support high spectral efficiency and ubiquitous
access requirements for 5G wireless communication networks. Conventional SCMA
approaches are confronting remarkable challenges in designing low complexity
high accuracy decoding algorithm and constructing optimum codebooks.
Fortunately, the recent spotlighted deep learning technologies are of
significant potentials in solving many communication engineering problems.
Inspired by this, we explore approaches to improve SCMA performances with the
help of deep learning methods. We propose and train a deep neural network (DNN)
called DL-SCMA to learn to decode SCMA modulated signals corrupted by additive
white Gaussian noise (AWGN). Putting encoding and decoding together, an
autoencoder called AE-SCMA is established and trained to generate optimal SCMA
codewords and reconstruct original bits. Furthermore, by manipulating the
mapping vectors, an autoencoder is able to generalize SCMA, thus a dense code
multiple access (DCMA) scheme is proposed. Simulations show that the DNN SCMA
decoder significantly outperforms the conventional message passing algorithm
(MPA) in terms of bit error rate (BER), symbol error rate (SER) and
computational complexity, and AE-SCMA also demonstrates better performances via
constructing better SCMA codebooks. The performance of deep learning aided DCMA
is superior to the SCMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03180</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03180</id><created>2019-04-25</created><authors><author><keyname>Chen</keyname><forenames>Xizi</forenames></author><author><keyname>Zhu</keyname><forenames>Jingyang</forenames></author><author><keyname>Jiang</keyname><forenames>Jingbo</forenames></author><author><keyname>Tsui</keyname><forenames>Chi-Ying</forenames></author></authors><title>CompRRAE: RRAM-based Convolutional Neural Network Accelerator with
  Reduced Computations through a Runtime Activation Estimation</title><categories>eess.SP eess.IV</categories><comments>7 pages, 6 figures, Accepted by ASP-DAC 2019</comments><doi>10.1145/3287624.3287640</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently Resistive-RAM (RRAM) crossbar has been used in the design of the
accelerator of convolutional neural networks (CNNs) to solve the memory wall
issue. However, the intensive multiply-accumulate computations (MACs) executed
at the crossbars during the inference phase are still the bottleneck for the
further improvement of energy efficiency and throughput. In this work, we
explore several methods to reduce the computations for the RRAM-based CNN
accelerators. First, the output sparsity resulting from the widely employed
Rectified Linear Unit is exploited, and a significant portion of computations
are bypassed through an early detection of the negative output activations.
Second, an adaptive approximation is proposed to terminate the MAC early when
the sum of the partial results of the remaining computations is considered to
be within a certain range of the intermediate accumulated result and thus has
an insignificant contribution to the inference. In order to determine these
redundant computations, a novel runtime estimation on the maximum and minimum
values of each output activation is developed and used during the MAC
operation. Experimental results show that around 70% of the computations can be
reduced during the inference with a negligible accuracy loss smaller than 0.2%.
As a result, the energy efficiency and the throughput are improved by over 2.9
and 2.8 times, respectively, compared with the state-of-the-art RRAM-based
accelerators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03181</identifier>
 <datestamp>2019-06-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03181</id><created>2019-05-01</created><authors><author><keyname>Chen</keyname><forenames>Jinyin</forenames></author><author><keyname>Su</keyname><forenames>Mengmeng</forenames></author><author><keyname>Shen</keyname><forenames>Shijing</forenames></author><author><keyname>Xiong</keyname><forenames>Hui</forenames></author><author><keyname>Zheng</keyname><forenames>Haibin</forenames></author></authors><title>POBA-GA: Perturbation Optimized Black-Box Adversarial Attacks via
  Genetic Algorithm</title><categories>cs.CR cs.LG cs.NE eess.SP</categories><journal-ref>Computers and Security, Volume 85, August 2019, Pages 89-106</journal-ref><doi>10.1016/j.cose.2019.04.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most deep learning models are easily vulnerable to adversarial attacks.
Various adversarial attacks are designed to evaluate the robustness of models
and develop defense model. Currently, adversarial attacks are brought up to
attack their own target model with their own evaluation metrics. And most of
the black-box adversarial attack algorithms cannot achieve the expected success
rate compared with white-box attacks. In this paper, comprehensive evaluation
metrics are brought up for different adversarial attack methods. A novel
perturbation optimized black-box adversarial attack based on genetic algorithm
(POBA-GA) is proposed for achieving white-box comparable attack performances.
Approximate optimal adversarial examples are evolved through evolutionary
operations including initialization, selection, crossover and mutation. Fitness
function is specifically designed to evaluate the example individual in both
aspects of attack ability and perturbation control. Population diversity
strategy is brought up in evolutionary process to promise the approximate
optimal perturbations obtained. Comprehensive experiments are carried out to
testify POBA-GA's performances. Both simulation and application results prove
that our method is better than current state-of-art black-box attack methods in
aspects of attack capability and perturbation control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03211</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03211</id><created>2019-06-07</created><authors><author><keyname>Beuchert</keyname><forenames>Jonas</forenames></author><author><keyname>Solowjow</keyname><forenames>Friedrich</forenames></author><author><keyname>Raisch</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author><author><keyname>Seel</keyname><forenames>Thomas</forenames></author></authors><title>Hierarchical Event-triggered Learning for Cyclically Excited Systems
  with Application to Wireless Sensor Networks</title><categories>cs.SY eess.SP</categories><comments>6 pages and 6 figures; to appear in IEEE Control Systems Letters</comments><journal-ref>IEEE Control Systems Letters, vol. 4, no. 1, pp. 103-108, Jan.
  2020</journal-ref><doi>10.1109/LCSYS.2019.2922005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication load is a limiting factor in many real-time systems.
Event-triggered state estimation and event-triggered learning methods reduce
network communication by sending information only when it cannot be adequately
predicted based on previously transmitted data. This paper proposes an
event-triggered learning approach for nonlinear discrete-time systems with
cyclic excitation. The method automatically recognizes cyclic patterns in data
- even when they change repeatedly - and reduces communication load whenever
the current data can be accurately predicted from previous cycles. Nonetheless,
a bounded error between original and received signal is guaranteed. The cyclic
excitation model, which is used for predictions, is updated hierarchically,
i.e., a full model update is only performed if updating a small number of model
parameters is not sufficient. A nonparametric statistical test enforces that
model updates happen only if the cyclic excitation changed with high
probability. The effectiveness of the proposed methods is demonstrated using
the application example of wireless real-time pitch angle measurements of a
human foot in a feedback-controlled neuroprosthesis. The experimental results
show that communication load can be reduced by 70 % while the root-mean-square
error between measured and received angle is less than 1{\deg}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03214</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03214</id><created>2019-06-07</created><updated>2019-10-22</updated><authors><author><keyname>Im</keyname><forenames>Daniel Jiwoong</forenames></author><author><keyname>Prakhya</keyname><forenames>Sridhama</forenames></author><author><keyname>Yan</keyname><forenames>Jinyao</forenames></author><author><keyname>Turaga</keyname><forenames>Srinivas</forenames></author><author><keyname>Branson</keyname><forenames>Kristin</forenames></author></authors><title>Importance Weighted Adversarial Variational Autoencoders for Spike
  Inference from Calcium Imaging Data</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Importance Weighted Auto Encoder (IWAE) objective has been shown to
improve the training of generative models over the standard Variational Auto
Encoder (VAE) objective. Here, we derive importance weighted extensions to AVB
and AAE. These latent variable models use implicitly defined inference networks
whose approximate posterior density q_\phi(z|x) cannot be directly evaluated,
an essential ingredient for importance weighting. We show improved training and
inference in latent variable models with our adversarially trained importance
weighting method, and derive new theoretical connections between adversarial
generative model training criteria and marginal likelihood based methods. We
apply these methods to the important problem of inferring spiking neural
activity from calcium imaging data, a challenging posterior inference problem
in neuroscience, and show that posterior samples from the adversarial methods
outperform factorized posteriors used in VAEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03238</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03238</id><created>2019-05-28</created><updated>2019-10-14</updated><authors><author><keyname>Duda</keyname><forenames>Jarek</forenames></author></authors><title>Parametric context adaptive Laplace distribution for multimedia
  compression</title><categories>eess.IV cs.MM</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data compression often subtracts prediction and encodes the difference
(residue) e.g. assuming Laplace distribution, for example for images, videos,
audio, or numerical data. Its performance is strongly dependent on the proper
choice of width (scale parameter) of this parametric distribution, can be
improved if optimizing it based on local situation like context. For example in
popular LOCO-I \cite{loco} (JPEG-LS) lossless image compressor there is used 3
dimensional context quantized into 365 discrete possibilities treated
independently. This article discusses inexpensive approaches for exploiting
their dependencies with autoregressive ARCH-like context dependent models for
parameters of parametric distribution for residue, also evolving in time for
adaptive case. For example tested such 4 or 11 parameter models turned out to
provide similar performance as 365 parameter LOCO-I model for 48 tested images.
Beside smaller headers, such reduction of number of parameters can lead to
better generalization. In contrast to context quantization approaches,
parameterized models also allow to directly use higher dimensional contexts,
for example using information from all 3 color channels, further pixels, some
additional region classifiers, or from interleaving multi-scale scanning - for
which there is proposed Haar upscale scan combining advantages of Haar wavelets
with possibility of scanning exploiting local contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03347</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03347</id><created>2019-06-07</created><updated>2019-06-12</updated><authors><author><keyname>Zhang</keyname><forenames>Ling</forenames></author><author><keyname>Wang</keyname><forenames>Xiaosong</forenames></author><author><keyname>Yang</keyname><forenames>Dong</forenames></author><author><keyname>Sanford</keyname><forenames>Thomas</forenames></author><author><keyname>Harmon</keyname><forenames>Stephanie</forenames></author><author><keyname>Turkbey</keyname><forenames>Baris</forenames></author><author><keyname>Roth</keyname><forenames>Holger</forenames></author><author><keyname>Myronenko</keyname><forenames>Andriy</forenames></author><author><keyname>Xu</keyname><forenames>Daguang</forenames></author><author><keyname>Xu</keyname><forenames>Ziyue</forenames></author></authors><title>When Unseen Domain Generalization is Unnecessary? Rethinking Data
  Augmentation</title><categories>cs.CV eess.IV</categories><comments>9 pages, 3 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in deep learning for medical image segmentation demonstrate
expert-level accuracy. However, in clinically realistic environments, such
methods have marginal performance due to differences in image domains,
including different imaging protocols, device vendors and patient populations.
Here we consider the problem of domain generalization, when a model is trained
once, and its performance generalizes to unseen domains. Intuitively, within a
specific medical imaging modality the domain differences are smaller relative
to natural images domain variability. We rethink data augmentation for medical
3D images and propose a deep stacked transformations (DST) approach for domain
generalization. Specifically, a series of n stacked transformations are applied
to each image in each mini-batch during network training to account for the
contribution of domain-specific shifts in medical images. We comprehensively
evaluate our method on three tasks: segmentation of whole prostate from 3D MRI,
left atrial from 3D MRI, and left ventricle from 3D ultrasound. We demonstrate
that when trained on a small source dataset, (i) on average, DST models on
unseen datasets degrade only by 11% (Dice score change), compared to the
conventional augmentation (degrading 39%) and CycleGAN-based domain adaptation
method (degrading 25%); (ii) when evaluation on the same domain, DST is also
better albeit only marginally. (iii) When training on large-sized data, DST on
unseen domains reaches performance of state-of-the-art fully supervised models.
These findings establish a strong benchmark for the study of domain
generalization in medical imaging, and can be generalized to the design of
robust deep segmentation models for clinical deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03381</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03381</id><created>2019-06-07</created><authors><author><keyname>Islam</keyname><forenames>Md. Rabiul</forenames></author><author><keyname>Massicotte</keyname><forenames>Daniel</forenames></author><author><keyname>Nougarou</keyname><forenames>Francois</forenames></author><author><keyname>Massicotte</keyname><forenames>Philippe</forenames></author><author><keyname>Zhu</keyname><forenames>Wei-Ping</forenames></author></authors><title>S-ConvNet: A Shallow Convolutional Neural Network Architecture for
  Neuromuscular Activity Recognition Using Instantaneous High-Density Surface
  EMG Images</title><categories>eess.SP eess.IV</categories><comments>This paper will be submitted to IEEE Journal of Biomedical and Health
  Informatics (IEEE JBHI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of neuromuscular activity recognition using instantaneous
high-density surface electromyography (HD-sEMG) images opens up new avenues for
the development of more fluid and natural muscle-computer interfaces. However,
the existing approaches employed a very large deep convolutional neural network
(ConvNet) architecture and complex training schemes for HD-sEMG image
recognition, which requires the network architecture to be pre-trained on a
very large-scale labeled training dataset, as a result, it makes
computationally very expensive. To overcome this problem, we propose S-ConvNet
and All-ConvNet models, a simple yet efficient framework for learning
instantaneous HD-sEMG images from scratch for neuromuscular activity
recognition. Without using any pre-trained models, our proposed S-ConvNet and
All-ConvNet demonstrate very competitive recognition accuracy to the more
complex state of the art for neuromuscular activity recognition based on
instantaneous HD-sEMG images, while using a ~ 12 x smaller dataset and reducing
learning parameters to a large extent. The experimental results proved that the
S-ConvNet and All-ConvNet are highly effective for learning discriminative
features for instantaneous HD-sEMG image recognition especially in the data and
high-end resource constrained scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03402</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03402</id><created>2019-06-08</created><updated>2019-10-25</updated><authors><author><keyname>Battenberg</keyname><forenames>Eric</forenames></author><author><keyname>Mariooryad</keyname><forenames>Soroosh</forenames></author><author><keyname>Stanton</keyname><forenames>Daisy</forenames></author><author><keyname>Skerry-Ryan</keyname><forenames>RJ</forenames></author><author><keyname>Shannon</keyname><forenames>Matt</forenames></author><author><keyname>Kao</keyname><forenames>David</forenames></author><author><keyname>Bagby</keyname><forenames>Tom</forenames></author></authors><title>Effective Use of Variational Embedding Capacity in Expressive End-to-End
  Speech Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Submitted to ICLR 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has explored sequence-to-sequence latent variable models for
expressive speech synthesis (supporting control and transfer of prosody and
style), but has not presented a coherent framework for understanding the
trade-offs between the competing methods. In this paper, we propose embedding
capacity (the amount of information the embedding contains about the data) as a
unified method of analyzing the behavior of latent variable models of speech,
comparing existing heuristic (non-variational) methods to variational methods
that are able to explicitly constrain capacity using an upper bound on
representational mutual information. In our proposed model (Capacitron), we
show that by adding conditional dependencies to the variational posterior such
that it matches the form of the true posterior, the same model can be used for
high-precision prosody transfer, text-agnostic style transfer, and generation
of natural-sounding prior samples. For multi-speaker models, Capacitron is able
to preserve target speaker identity during inter-speaker prosody transfer and
when drawing samples from the latent prior. Lastly, we introduce a method for
decomposing embedding capacity hierarchically across two sets of latents,
allowing a portion of the latent variability to be specified and the remaining
variability sampled from a learned prior. Audio examples are available on the
web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03417</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03417</id><created>2019-06-08</created><updated>2019-07-13</updated><authors><author><keyname>Li</keyname><forenames>Jingxi</forenames></author><author><keyname>Mengu</keyname><forenames>Deniz</forenames></author><author><keyname>Luo</keyname><forenames>Yi</forenames></author><author><keyname>Rivenson</keyname><forenames>Yair</forenames></author><author><keyname>Ozcan</keyname><forenames>Aydogan</forenames></author></authors><title>Class-specific Differential Detection in Diffractive Optical Neural
  Networks Improves Inference Accuracy</title><categories>cs.NE cs.LG eess.IV physics.optics</categories><comments>21 pages, 6 Figures, 3 Tables</comments><journal-ref>Advanced Photonics (2019)</journal-ref><doi>10.1117/1.AP.1.4.046001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffractive deep neural networks have been introduced earlier as an optical
machine learning framework that uses task-specific diffractive surfaces
designed by deep learning to all-optically perform inference, achieving
promising performance for object classification and imaging. Here we
demonstrate systematic improvements in diffractive optical neural networks
based on a differential measurement technique that mitigates the non-negativity
constraint of light intensity. In this scheme, each class is assigned to a
separate pair of photodetectors, behind a diffractive network, and the class
inference is made by maximizing the normalized signal difference between the
detector pairs. Moreover, by utilizing the inherent parallelization capability
of optical systems, we reduced the signal coupling between the positive and
negative detectors of each class by dividing their optical path into two
jointly-trained diffractive neural networks that work in parallel. We further
made use of this parallelization approach, and divided individual classes among
multiple jointly-trained differential diffractive neural networks. Using this
class-specific differential detection in jointly-optimized diffractive
networks, our simulations achieved testing accuracies of 98.52%, 91.48% and
50.82% for MNIST, Fashion-MNIST and grayscale CIFAR-10 datasets, respectively.
Similar to ensemble methods practiced in machine learning, we also
independently-optimized multiple differential diffractive networks that
optically project their light onto a common detector plane, and achieved
testing accuracies of 98.59%, 91.06% and 51.44% for MNIST, Fashion-MNIST and
grayscale CIFAR-10, respectively. Through these systematic advances in
designing diffractive neural networks, the reported classification accuracies
set the state-of-the-art for an all-optical neural network design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03450</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03450</id><created>2019-06-08</created><authors><author><keyname>Tran</keyname><forenames>Thanh</forenames></author><author><keyname>Sweeney</keyname><forenames>Renee</forenames></author><author><keyname>Lee</keyname><forenames>Kyumin</forenames></author></authors><title>Adversarial Mahalanobis Distance-based Attentive Song Recommender for
  Automatic Playlist Continuation</title><categories>cs.IR cs.LG cs.SD eess.AS</categories><journal-ref>SIGIR 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aim to solve the automatic playlist continuation (APC)
problem by modeling complex interactions among users, playlists, and songs
using only their interaction data. Prior methods mainly rely on dot product to
account for similarities, which is not ideal as dot product is not metric
learning, so it does not convey the important inequality property. Based on
this observation, we propose three novel deep learning approaches that utilize
Mahalanobis distance. Our first approach uses user-playlist-song interactions,
and combines Mahalanobis distance scores between (i) a target user and a target
song, and (ii) between a target playlist and the target song to account for
both the user's preference and the playlist's theme. Our second approach
measures song-song similarities by considering Mahalanobis distance scores
between the target song and each member song (i.e., existing song) in the
target playlist. The contribution of each distance score is measured by our
proposed memory metric-based attention mechanism. In the third approach, we
fuse the two previous models into a unified model to further enhance their
performance. In addition, we adopt and customize Adversarial Personalized
Ranking (APR) for our three approaches to further improve their robustness and
predictive capabilities. Through extensive experiments, we show that our
proposed models outperform eight state-of-the-art models in two large-scale
real-world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03465</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03465</id><created>2019-06-08</created><authors><author><keyname>Khodakhah</keyname><forenames>Mahsa</forenames></author><author><keyname>Ardalani</keyname><forenames>Nahid</forenames></author></authors><title>Resource Management optimally in Non-Orthogonal Multiple Access Networks
  for fifth-generation by using game-theoretic</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper , we optimize the resource Allocation management by using
game-Theory . In this paper we can optimize number of users in resource
allocation management by using the user-sub-channel-soap matching algorithm
(USMA) for non-orthogonal multiple access for fifth-generation networks by
increase multiple access user and NOMA that is to accessible to 63 users. This
method reduces interference between users , which include costs , and resource
to access for other users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03467</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03467</id><created>2019-06-08</created><updated>2019-06-11</updated><authors><author><keyname>Liu</keyname><forenames>Jingya</forenames></author><author><keyname>Cao</keyname><forenames>Liangliang</forenames></author><author><keyname>Akin</keyname><forenames>Oguz</forenames></author><author><keyname>Tian</keyname><forenames>Yingli</forenames></author></authors><title>3DFPN-HS$^2$: 3D Feature Pyramid Network Based High Sensitivity and
  Specificity Pulmonary Nodule Detection</title><categories>eess.IV cs.CV</categories><comments>8 pages, 3 figures. Accepted to MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate detection of pulmonary nodules with high sensitivity and specificity
is essential for automatic lung cancer diagnosis from CT scans. Although many
deep learning-based algorithms make great progress for improving the accuracy
of nodule detection, the high false positive rate is still a challenging
problem which limited the automatic diagnosis in routine clinical practice. In
this paper, we propose a novel pulmonary nodule detection framework based on a
3D Feature Pyramid Network (3DFPN) to improve the sensitivity of nodule
detection by employing multi-scale features to increase the resolution of
nodules, as well as a parallel top-down path to transit the high-level semantic
features to complement low-level general features. Furthermore, a High
Sensitivity and Specificity (HS$^2$) network is introduced to eliminate the
falsely detected nodule candidates by tracking the appearance changes in
continuous CT slices of each nodule candidate. The proposed framework is
evaluated on the public Lung Nodule Analysis (LUNA16) challenge dataset. Our
method is able to accurately detect lung nodules at high sensitivity and
specificity and achieves $90.4\%$ sensitivity with 1/8 false positive per scan
which outperforms the state-of-the-art results $15.6\%$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03516</identifier>
 <datestamp>2019-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03516</id><created>2019-06-08</created><updated>2019-11-25</updated><authors><author><keyname>Mehta</keyname><forenames>Sachin</forenames></author><author><keyname>Hajishirzi</keyname><forenames>Hannaneh</forenames></author><author><keyname>Rastegari</keyname><forenames>Mohammad</forenames></author></authors><title>DiCENet: Dimension-wise Convolutions for Efficient Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>Technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel and generic convolutional unit, DiCE unit, that is built
using dimension-wise convolutions and dimension-wise fusion. The dimension-wise
convolutions apply light-weight convolutional filtering across each dimension
of the input tensor while dimension-wise fusion efficiently combines these
dimension-wise representations; allowing the DiCE unit to efficiently encode
spatial and channel-wise information contained in the input tensor. The DiCE
unit is simple and can be easily plugged into any architecture to improve its
efficiency and performance. Compared to depth-wise separable convolutions, the
DiCE unit shows significant improvements across different architectures. When
DiCE units are stacked to build the DiCENet model, we observe significant
improvements over state-of-the-art models across various computer vision tasks
including image classification, object detection, and semantic segmentation. On
the ImageNet dataset, the DiCENet delivers either the same or better
performance than existing models with fewer floating-point operations (FLOPs).
Notably, for a network size of about 70 MFLOPs, DiCENet outperforms the
state-of-the-art neural search architecture, MNASNet, by 4% on the ImageNet
dataset. Our code is open source and available at
\url{https://github.com/sacmehta/EdgeNets}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03547</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03547</id><created>2019-06-08</created><updated>2019-09-06</updated><authors><author><keyname>Konovalov</keyname><forenames>Dmitry A.</forenames></author><author><keyname>Jahangard</keyname><forenames>Simindokht</forenames></author><author><keyname>Schwarzkopf</keyname><forenames>Lin</forenames></author></authors><title>In Situ Cane Toad Recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted for DICTA2018 https://doi.org/10.1109/DICTA.2018.8615780</comments><journal-ref>2018 Digital Image Computing: Techniques and Applications (DICTA),
  Canberra, Australia, 2018, pp. 1-7</journal-ref><doi>10.1109/DICTA.2018.8615780</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cane toads are invasive, toxic to native predators, compete with native
insectivores, and have a devastating impact on Australian ecosystems, prompting
the Australian government to list toads as a key threatening process under the
Environment Protection and Biodiversity Conservation Act 1999. Mechanical cane
toad traps could be made more native-fauna friendly if they could distinguish
invasive cane toads from native species. Here we designed and trained a
Convolution Neural Network (CNN) starting from the Xception CNN. The XToadGmp
toad-recognition CNN we developed was trained end-to-end using heat-map
Gaussian targets. After training, XToadGmp required minimum image
pre/post-processing and when tested on 720x1280 shaped images, it achieved
97.1% classification accuracy on 1863 toad and 2892 not-toad test images, which
were not used in training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03560</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03560</id><created>2019-06-09</created><updated>2019-11-27</updated><authors><author><keyname>Pan</keyname><forenames>Bowen</forenames></author><author><keyname>Sun</keyname><forenames>Jiankai</forenames></author><author><keyname>Andonian</keyname><forenames>Alex</forenames></author><author><keyname>Zhou</keyname><forenames>Bolei</forenames></author></authors><title>Cross-view Semantic Segmentation for Sensing Surroundings</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensing surroundings is ubiquitous and effortless to humans: It takes a
single glance to extract the spatial configuration of objects as well as the
free space from the observation. To facilitate machine perception with such a
surrounding sensing capability, we introduce a novel framework for cross-view
semantic segmentation. In this framework, the View Parsing Network (VPN) is
proposed to parse the first-view observations into a top-down-view semantic map
indicating the spatial location of all the objects at pixel-level. The view
transformer module contained in VPN is designed to aggregate the surrounding
information collected from first-view observations in multiple angles and
modalities. To mitigate the issue of lacking real-world annotations, we train
the VPN in simulation environment and utilize the off-the-shelf domain
adaptation technique to transfer it to real-world data. We evaluate our VPN on
both synthetic and real-world data. The experimental results show that our
model can effectively make use of the information from different views and
multi-modalities. Thus the proposed VPN is able to accurately predict the
top-down-view semantic mask of the visible objects as well as barely seen
objects, in both synthetic and real-world environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03585</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03585</id><created>2019-06-09</created><authors><author><keyname>Saeed</keyname><forenames>Nasir</forenames></author><author><keyname>Nam</keyname><forenames>Haewoon</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A State-of-the-Art Survey on Multidimensional Scaling Based Localization
  Techniques</title><categories>eess.SP</categories><comments>Accepted in IEEE Communications Surveys and Tutorials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current and future wireless applications strongly rely on precise real-time
localization. A number of applications such as smart cities, Internet of Things
(IoT), medical services, automotive industry, underwater exploration, public
safety, and military systems require reliable and accurate localization
techniques. Generally, the most popular localization/ positioning system is the
Global Positioning System (GPS). GPS works well for outdoor environments but
fails in indoor and harsh environments. Therefore, a number of other wireless
local localization techniques are developed based on terrestrial wireless
networks, wireless sensor networks (WSNs) and wireless local area networks
(WLANs). Also, there exist localization techniques which fuse two or more
technologies to find out the location of the user, also called signal of
opportunity based localization. Most of the localization techniques require
ranging measurements such as time of arrival (ToA), time difference of arrival
(TDoA), direction of arrival (DoA) and received signal strength (RSS). There
are also range-free localization techniques which consider the proximity
information and do not require the actual ranging measurements. Dimensionality
reduction techniques are famous among the range free localization schemes.
Multidimensional scaling (MDS) is one of the dimensionality reduction technique
which has been used extensively in the recent past for wireless networks
localization. In this paper, a comprehensive survey is presented for MDS and
MDS based localization techniques in WSNs, Internet of Things (IoT), cognitive
radio networks, and 5G networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03588</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03588</id><created>2019-06-09</created><authors><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Sarkar</keyname><forenames>Achintya kr.</forenames></author><author><keyname>Dehak</keyname><forenames>Najim</forenames></author></authors><title>rVAD: An Unsupervised Segment-Based Robust Voice Activity Detection
  Method</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><comments>Paper is to appear in CSL</comments><journal-ref>Computer Speech &amp; Language, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an unsupervised segment-based method for robust voice
activity detection (rVAD). The method consists of two passes of denoising
followed by a voice activity detection (VAD) stage. In the first pass,
high-energy segments in a speech signal are detected by using a posteriori
signal-to-noise ratio (SNR) weighted energy difference and if no pitch is
detected within a segment, the segment is considered as a high-energy noise
segment and set to zero. In the second pass, the speech signal is denoised by a
speech enhancement method, for which several methods are explored. Next,
neighbouring frames with pitch are grouped together to form pitch segments, and
based on speech statistics, the pitch segments are further extended from both
ends in order to include both voiced and unvoiced sounds and likely non-speech
parts as well. In the end, a posteriori SNR weighted energy difference is
applied to the extended pitch segments of the denoised speech signal for
detecting voice activity. We evaluate the VAD performance of the proposed
method using two databases, RATS and Aurora-2, which contain a large variety of
noise conditions. The rVAD method is further evaluated, in terms of speaker
verification performance, on the RedDots 2016 challenge database and its
noise-corrupted versions. Experiment results show that rVAD is compared
favourably with a number of existing methods. In addition, we present a
modified version of rVAD where computationally intensive pitch extraction is
replaced by computationally efficient spectral flatness calculation. The
modified version significantly reduces the computational complexity at the cost
of moderately inferior VAD performance, which is an advantage when processing a
large amount of data and running on low resource devices. The source code of
rVAD is made publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03605</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03605</id><created>2019-06-09</created><authors><author><keyname>Sun</keyname><forenames>Qigong</forenames></author><author><keyname>Li</keyname><forenames>Xiufang</forenames></author><author><keyname>Li</keyname><forenames>Lingling</forenames></author><author><keyname>Liu</keyname><forenames>Xu</forenames></author><author><keyname>Liu</keyname><forenames>Fang</forenames></author><author><keyname>Jiao</keyname><forenames>Licheng</forenames></author></authors><title>Semi-supervised Complex-valued GAN for Polarimetric SAR Image
  Classification</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polarimetric synthetic aperture radar (PolSAR) images are widely used in
disaster detection and military reconnaissance and so on. However, their
interpretation faces some challenges, e.g., deficiency of labeled data,
inadequate utilization of data information and so on. In this paper, a
complex-valued generative adversarial network (GAN) is proposed for the first
time to address these issues. The complex number form of model complies with
the physical mechanism of PolSAR data and in favor of utilizing and retaining
amplitude and phase information of PolSAR data. GAN architecture and
semi-supervised learning are combined to handle deficiency of labeled data. GAN
expands training data and semi-supervised learning is used to train network
with generated, labeled and unlabeled data. Experimental results on two
benchmark data sets show that our model outperforms existing state-of-the-art
models, especially for conditions with fewer labeled data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03623</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03623</id><created>2019-06-09</created><authors><author><keyname>Alavi</keyname><forenames>Seyed Amir</forenames></author><author><keyname>Mehran</keyname><forenames>Kamyar</forenames></author><author><keyname>Hao</keyname><forenames>Yang</forenames></author><author><keyname>Rahimian</keyname><forenames>Ardavan</forenames></author><author><keyname>Mirsaeedi</keyname><forenames>Hamed</forenames></author><author><keyname>Vahidinasab</keyname><forenames>Vahid</forenames></author></authors><title>A Distributed Event-Triggered Control Strategy for DC Microgrids Based
  on Publish-Subscribe Model Over Industrial Wireless Sensor Networks</title><categories>eess.SP cs.DC cs.MA cs.NI cs.SY</categories><doi>10.1109/TSG.2018.2856893</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a complete design, analysis, and performance evaluation
of a novel distributed event-triggered control and estimation strategy for DC
microgrids. The primary objective of this work is to efficiently stabilize the
grid voltage, and to further balance the energy level of the energy storage
(ES) systems. The locally-installed distributed controllers are utilised to
reduce the number of transmitted packets and battery usage of the installed
sensors, based on a proposed event-triggered communication scheme. Also, to
reduce the network traffic, an optimal observer is employed which utilizes a
modified Kalman consensus filter (KCF) to estimate the state of the DC
microgrid via the distributed sensors. Furthermore, in order to effectively
provide an intelligent data exchange mechanism for the proposed event-triggered
controller, the publish-subscribe communication model is employed to setup a
distributed control infrastructure in industrial wireless sensor networks
(WSNs). The performance of the proposed control and estimation strategy is
validated via the simulations of a DC microgrid composed of renewable energy
sources (RESs). The results confirm the appropriateness of the implemented
strategy for the optimal utilization of the advanced industrial network
architectures in the smart grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03626</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03626</id><created>2019-06-09</created><updated>2019-10-19</updated><authors><author><keyname>Yang</keyname><forenames>Ruihan</forenames></author><author><keyname>Wang</keyname><forenames>Dingsu</forenames></author><author><keyname>Wang</keyname><forenames>Ziyu</forenames></author><author><keyname>Chen</keyname><forenames>Tianyao</forenames></author><author><keyname>Jiang</keyname><forenames>Junyan</forenames></author><author><keyname>Xia</keyname><forenames>Gus</forenames></author></authors><title>Deep Music Analogy Via Latent Representation Disentanglement</title><categories>cs.SD cs.IR cs.LG eess.AS stat.ML</categories><comments>Accepted at the International Society for Music Information Retrieval
  (ISMIR), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analogy-making is a key method for computer algorithms to generate both
natural and creative music pieces. In general, an analogy is made by partially
transferring the music abstractions, i.e., high-level representations and their
relationships, from one piece to another; however, this procedure requires
disentangling music representations, which usually takes little effort for
musicians but is non-trivial for computers. Three sub-problems arise:
extracting latent representations from the observation, disentangling the
representations so that each part has a unique semantic interpretation, and
mapping the latent representations back to actual music. In this paper, we
contribute an explicitly-constrained variational autoencoder (EC$^2$-VAE) as a
unified solution to all three sub-problems. We focus on disentangling the pitch
and rhythm representations of 8-beat music clips conditioned on chords. In
producing music analogies, this model helps us to realize the imaginary
situation of &quot;what if&quot; a piece is composed using a different pitch contour,
rhythm pattern, or chord progression by borrowing the representations from
other pieces. Finally, we validate the proposed disentanglement method using
objective measurements and evaluate the analogy examples by a subjective study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03639</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03639</id><created>2019-06-09</created><authors><author><keyname>Wu</keyname><forenames>Dufan</forenames></author><author><keyname>Gong</keyname><forenames>Kuang</forenames></author><author><keyname>Kim</keyname><forenames>Kyungsang</forenames></author><author><keyname>Li</keyname><forenames>Quanzheng</forenames></author></authors><title>Consensus Neural Network for Medical Imaging Denoising with Only Noisy
  Training Samples</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>9 pages, 2 figures, accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have been proved efficient for medical image denoising.
Current training methods require both noisy and clean images. However, clean
images cannot be acquired for many practical medical applications due to
naturally noisy signal, such as dynamic imaging, spectral computed tomography,
arterial spin labeling magnetic resonance imaging, etc. In this paper we
proposed a training method which learned denoising neural networks from noisy
training samples only. Training data in the acquisition domain was split to two
subsets and the network was trained to map one noisy set to the other. A
consensus loss function was further proposed to efficiently combine the outputs
from both subsets. A mathematical proof was provided that the proposed training
scheme was equivalent to training with noisy and clean samples when the noise
in the two subsets was uncorrelated and zero-mean. The method was validated on
Low-dose CT Challenge dataset and NYU MRI dataset and achieved improved
performance compared to existing unsupervised methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03645</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03645</id><created>2019-06-09</created><authors><author><keyname>Song</keyname><forenames>Tzu-An</forenames></author><author><keyname>Chowdhury</keyname><forenames>Samadrita Roy</forenames></author><author><keyname>Yang</keyname><forenames>Fan</forenames></author><author><keyname>Dutta</keyname><forenames>Joyita</forenames></author></authors><title>Super-resolution PET imaging using convolutional neural networks</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Positron emission tomography (PET) suffers from severe resolution limitations
which limit its quantitative accuracy. In this paper, we present a
super-resolution (SR) imaging technique for PET based on convolutional neural
networks (CNNs). To facilitate the resolution recovery process, we incorporate
high-resolution (HR) anatomical information based on magnetic resonance (MR)
imaging. We introduce the spatial location information of the input image
patches as additional CNN inputs to accommodate the spatially-variant nature of
the blur kernels in PET. We compared the performance of shallow (3-layer) and
very deep (20-layer) CNNs with various combinations of the following inputs:
low-resolution (LR) PET, radial locations, axial locations, and HR MR. To
validate the CNN architectures, we performed both realistic simulation studies
using the BrainWeb digital phantom and clinical neuroimaging data analysis. For
both simulation and clinical studies, the LR PET images were based on the
Siemens HR+ scanner. Two different scenarios were examined in simulation: one
where the target HR image is the ground-truth phantom image and another where
the target HR image is based on the Siemens HRRT scanner --- a high-resolution
dedicated brain PET scanner. The latter scenario was also examined using
clinical neuroimaging datasets. A number of factors affected relative
performance of the different CNN designs examined, including network depth,
target image quality, and the resemblance between the target and anatomical
images. In general, however, all CNNs outperformed classical penalized
deconvolution techniques by large margins both qualitatively (e.g., edge and
contrast recovery) and quantitatively (as indicated by two metrics: peak
signal-to-noise-ratio and structural similarity index).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03651</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03651</id><created>2019-06-09</created><authors><author><keyname>Zhou</keyname><forenames>You</forenames></author><author><keyname>Duan</keyname><forenames>Ruifeng</forenames></author><author><keyname>Jiang</keyname><forenames>Bofeng</forenames></author></authors><title>Low-complexity Noncoherent Maximum Likelihood Sequence Detection Scheme
  for CPM in Aeronautical Telemetry</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to high spectral efficiency and power efficiency, the continuous phase
modulation (CPM) technique with constant envelope is widely used in
aeronautical telemetry in strategic weapons and rockets, which are essential
for national defence and aeronautic application. How to improve the bit error
rate (BER) performance of CPM and keep a reasonable complexity is key for the
entire telemetry system and has been the focus of research and engineering
design. In this paper, a low-complexity noncoherent maximum likelihood sequence
detection (MLSD) scheme for CPM is proposed. In the proposed method, the
criterion of noncoherent MLSD for CPM is derived when the carrier phase is
unknown, and then a novel Viterbi algorithm (VA) with modified state vector is
designed to simplify the implementation of noncoherent MLSD. Both analysis and
experimental results show that the proposed approach has lower computational
complexity and does not need accurate carrier phase recovery, which overcomes
the shortage of traditional MLSD method. What's more, compared to the
traditional MLSD method, the proposed method also achieves almost the same
detection performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03691</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03691</id><created>2019-06-09</created><authors><author><keyname>Li</keyname><forenames>Xiangrui</forenames></author><author><keyname>Hect</keyname><forenames>Jasmine</forenames></author><author><keyname>Thomason</keyname><forenames>Moriah</forenames></author><author><keyname>Zhu</keyname><forenames>Dongxiao</forenames></author></authors><title>Interpreting Age Effects of Human Fetal Brain from Spontaneous fMRI
  using Deep 3D Convolutional Neural Networks</title><categories>eess.IV cs.LG stat.ML</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding human fetal neurodevelopment is of great clinical importance as
abnormal development is linked to adverse neuropsychiatric outcomes after
birth. Recent advances in functional Magnetic Resonance Imaging (fMRI) have
provided new insight into development of the human brain before birth, but
these studies have predominately focused on brain functional connectivity (i.e.
Fisher z-score), which requires manual processing steps for feature extraction
from fMRI images. Deep learning approaches (i.e., Convolutional Neural
Networks) have achieved remarkable success on learning directly from image
data, yet have not been applied on fetal fMRI for understanding fetal
neurodevelopment. Here, we bridge this gap by applying a novel application of
deep 3D CNN to fetal blood oxygen-level dependence (BOLD) resting-state fMRI
data. Specifically, we test a supervised CNN framework as a data-driven
approach to isolate variation in fMRI signals that relate to younger v.s. older
fetal age groups. Based on the learned CNN, we further perform sensitivity
analysis to identify brain regions in which changes in BOLD signal are strongly
associated with fetal brain age. The findings demonstrate that deep CNNs are a
promising approach for identifying spontaneous functional patterns in fetal
brain activity that discriminate age groups. Further, we discovered that
regions that most strongly differentiate groups are largely bilateral, share
similar distribution in older and younger age groups, and are areas of
heightened metabolic activity in early human development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03697</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03697</id><created>2019-06-09</created><updated>2019-06-28</updated><authors><author><keyname>Choi</keyname><forenames>Keunwoo</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author></authors><title>Deep Unsupervised Drum Transcription</title><categories>cs.SD eess.AS</categories><comments>ISMIR 2019 camera-ready</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce DrummerNet, a drum transcription system that is trained in an
unsupervised manner. DrummerNet does not require any ground-truth transcription
and, with the data-scalability of deep neural networks, learns from a large
unlabeled dataset. In DrummerNet, the target drum signal is first passed to a
(trainable) transcriber, then reconstructed in a (fixed) synthesizer according
to the transcription estimate. By training the system to minimize the distance
between the input and the output audio signals, the transcriber learns to
transcribe without ground truth transcription. Our experiment shows that
DrummerNet performs favorably compared to many other recent drum transcription
systems, both supervised and unsupervised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03720</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03720</id><created>2019-06-09</created><authors><author><keyname>Buda</keyname><forenames>Mateusz</forenames></author><author><keyname>Saha</keyname><forenames>Ashirbani</forenames></author><author><keyname>Mazurowski</keyname><forenames>Maciej A</forenames></author></authors><title>Association of genomic subtypes of lower-grade gliomas with shape
  features automatically extracted by a deep learning algorithm</title><categories>eess.IV cs.CV cs.LG</categories><journal-ref>Computers in Biology and Medicine, 109, 2019, 218-225</journal-ref><doi>10.1016/j.compbiomed.2019.05.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent analysis identified distinct genomic subtypes of lower-grade glioma
tumors which are associated with shape features. In this study, we propose a
fully automatic way to quantify tumor imaging characteristics using deep
learning-based segmentation and test whether these characteristics are
predictive of tumor genomic subtypes. We used preoperative imaging and genomic
data of 110 patients from 5 institutions with lower-grade gliomas from The
Cancer Genome Atlas. Based on automatic deep learning segmentations, we
extracted three features which quantify two-dimensional and three-dimensional
characteristics of the tumors. Genomic data for the analyzed cohort of patients
consisted of previously identified genomic clusters based on IDH mutation and
1p/19q co-deletion, DNA methylation, gene expression, DNA copy number, and
microRNA expression. To analyze the relationship between the imaging features
and genomic clusters, we conducted the Fisher exact test for 10 hypotheses for
each pair of imaging feature and genomic subtype. To account for multiple
hypothesis testing, we applied a Bonferroni correction. P-values lower than
0.005 were considered statistically significant. We found the strongest
association between RNASeq clusters and the bounding ellipsoid volume ratio
($p&lt;0.0002$) and between RNASeq clusters and margin fluctuation ($p&lt;0.005$). In
addition, we identified associations between bounding ellipsoid volume ratio
and all tested molecular subtypes ($p&lt;0.02$) as well as between angular
standard deviation and RNASeq cluster ($p&lt;0.02$). In terms of automatic tumor
segmentation that was used to generate the quantitative image characteristics,
our deep learning algorithm achieved a mean Dice coefficient of 82% which is
comparable to human performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03721</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03721</id><created>2019-06-09</created><authors><author><keyname>Cheng</keyname><forenames>Chongsheng</forenames></author><author><keyname>Na</keyname><forenames>Ri</forenames></author><author><keyname>Shen</keyname><forenames>Zhigang</forenames></author></authors><title>Thermographic Laplacian-pyramid filtering to enhance delamination
  detection in concrete structure</title><categories>eess.IV</categories><journal-ref>Infrared Physics &amp; Technology, 97, 162-176 (2019)</journal-ref><doi>10.1016/j.infrared.2018.12.039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite decades of efforts using thermography to detect delamination in
concrete decks, challenges still exist in removing environmental noise from
thermal images. The performance of conventional temperature-contrast approaches
can be significantly limited by environment-induced non-uniform temperature
distribution across imaging spaces. Time-series based methodologies were found
robust to spatial temperature non-uniformity but require the extended period to
collect data. A new empirical image filtering method is introduced in this
paper to enhance the delamination detection using blob detection method that
originated from computer vision. The proposed method employs a Laplacian of
Gaussian filter to achieve multi-scale detection of abnormal thermal patterns
by delaminated areas. Results were compared with the state-of-the-art methods
and benchmarked with time-series methods in the case of handling the
non-uniform heat distribution issue. To further evaluate the performance of the
method numerical simulations using transient heat transfer models were used to
generate the 'theoretical' noise-free thermal images for comparison.
Significant performance improvement was found compared to the conventional
methods in both indoor and outdoor tests. This methodology proved to be capable
to detect multi-size delamination using a single thermal image. It is robust to
the non-uniform temperature distribution. The limitations were discussed to
refine the applicability of the proposed procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03723</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03723</id><created>2019-06-09</created><authors><author><keyname>Cheng</keyname><forenames>Chongsheng</forenames></author><author><keyname>Shang</keyname><forenames>Zhexiong</forenames></author><author><keyname>Shen</keyname><forenames>Zhigang</forenames></author></authors><title>Bridge Deck Delamination Segmentation Based on Aerial Thermography
  Through Regularized Grayscale Morphological Reconstruction and Gradient
  Statistics</title><categories>eess.IV</categories><comments>arXiv admin note: text overlap with arXiv:1904.05723</comments><journal-ref>Infrared Physics &amp; Technology, Volume 98, May 2019, Pages 240-249</journal-ref><doi>10.1016/j.infrared.2019.03.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environmental and surface texture-induced temperature variation across the
bridge deck is a major source of errors in delamination detection through
thermography. This type of external noise poses a significant challenge for
conventional quantitative methods such as global thresholding and k-means
clustering. An iterative top-down approach is proposed for delamination
segmentation based on grayscale morphological reconstruction. A weight-decay
function was used to regularize the reconstruction for regional maxima
extraction. The mean and coefficient of variation of temperature gradient
estimated from delamination boundaries were used for discrimination. The
proposed approach was tested on a lab experiment and an in-service bridge deck.
The result showed the ability of the framework to handle the non-uniform
background situation which often occurred in practice and thus eliminates the
need for inferencing the background required by existing methods. The gradient
statistics of the delamination boundary in the thermal image were indicated as
the valid criterion refine the segmentation under the proposed framework. Thus,
improved performance was achieved compared to conventional methods. The
parameter selection and the limitation of this approach were also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03751</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03751</id><created>2019-06-09</created><updated>2019-06-26</updated><authors><author><keyname>Wen</keyname><forenames>Qingsong</forenames></author><author><keyname>Gao</keyname><forenames>Jingkun</forenames></author><author><keyname>Song</keyname><forenames>Xiaomin</forenames></author><author><keyname>Sun</keyname><forenames>Liang</forenames></author><author><keyname>Tan</keyname><forenames>Jian</forenames></author></authors><title>RobustTrend: A Huber Loss with a Combined First and Second Order
  Difference Regularization for Time Series Trend Filtering</title><categories>cs.LG eess.SP stat.AP stat.ML</categories><comments>Accepted to the 28th International Joint Conference on Artificial
  Intelligence (IJCAI 2019), 7 pages. v2: added related references and adjusted
  font size in figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting the underlying trend signal is a crucial step to facilitate time
series analysis like forecasting and anomaly detection. Besides noise signal,
time series can contain not only outliers but also abrupt trend changes in
real-world scenarios. To deal with these challenges, we propose a robust trend
filtering algorithm based on robust statistics and sparse learning.
Specifically, we adopt the Huber loss to suppress outliers, and utilize a
combination of the first order and second order difference on the trend
component as regularization to capture both slow and abrupt trend changes.
Furthermore, an efficient method is designed to solve the proposed robust trend
filtering based on majorization minimization (MM) and alternative direction
method of multipliers (ADMM). We compared our proposed robust trend filter with
other nine state-of-the-art trend filtering algorithms on both synthetic and
real-world datasets. The experiments demonstrate that our algorithm outperforms
existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03772</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03772</id><created>2019-06-09</created><authors><author><keyname>Zhang</keyname><forenames>Pengfei</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Teo</keyname><forenames>Keng Boon</forenames></author><author><keyname>Wang</keyname><forenames>Yixin</forenames></author></authors><title>Multimodal Data Fusion of Non-Gaussian Spatial Fields in Sensor Networks</title><categories>stat.ME eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a robust data fusion algorithm for field reconstruction of
multiple physical phenomena. The contribution of this paper is twofold: First,
we demonstrate how multi-spatial fields which can have any marginal
distributions and exhibit complex dependence structures can be constructed. To
this end we develop a model where a latent process of these physical phenomena
is modelled as Multiple Gaussian Process (MGP), and the dependence structure
between these phenomena is captured through a Copula process. This model has
the advantage of allowing one to choose any marginal distributions for the
physical phenomenon. Second, we develop an efficient and robust linear
estimation algorithm to predict the mean behaviour of the physical phenomena
using rank correlation instead of the conventional linear Pearson correlation.
Our approach has the advantage of avoiding the need to derive intractable
predictive posterior distribution and also has a tractable solution for the
rank correlation values. We show that our model outperforms the model which
uses the conventional linear Pearson correlation metric in terms of the
prediction mean-squared-errors (MSE). This provides the motivation for using
our models for multimodal data fusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03814</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03814</id><created>2019-06-10</created><updated>2020-01-15</updated><authors><author><keyname>Wei</keyname><forenames>Yi</forenames></author><author><keyname>Zhao</keyname><forenames>Ming-Min</forenames></author><author><keyname>Zhao</keyname><forenames>Min-jian</forenames></author><author><keyname>Lei</keyname><forenames>Ming</forenames></author></authors><title>Learned Conjugate Gradient Descent Network for Massive MIMO Detection</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the use of model-driven deep learning techniques
for massive multiple-input multiple-output (MIMO) detection. Compared with
conventional MIMO systems, massive MIMO promises improved spectral efficiency,
coverage and range. Unfortunately, these benefits are coming at the cost of
significantly increased computational complexity. To reduce the complexity of
signal detection and guarantee the performance, we present a learned conjugate
gradient descent network (LcgNet), which is constructed by unfolding the
iterative conjugate gradient descent (CG) detector. In the proposed network,
instead of calculating the exact values of the scalar step-sizes, we explicitly
learn their universal values. Also, we can enhance the proposed network by
augmenting the dimensions of these step-sizes. Furthermore, in order to reduce
the memory costs, a novel quantized LcgNet is proposed, where a low-resolution
nonuniform quantizer is integrated into the LcgNet to smartly quantize the
aforementioned step-sizes. The quantizer is based on a specially designed soft
staircase function with learnable parameters to adjust its shape. Meanwhile,
due to fact that the number of learnable parameters is limited, the proposed
networks are easy and fast to train. Numerical results demonstrate that the
proposed network can achieve promising performance with much lower complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03823</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03823</id><created>2019-06-10</created><updated>2019-07-24</updated><authors><author><keyname>Wang</keyname><forenames>Dong</forenames></author><author><keyname>Sahoo</keyname><forenames>Sujit Kumar</forenames></author><author><keyname>Dang</keyname><forenames>Cuong</forenames></author></authors><title>Noninvasive super-resolution imaging through scattering media</title><categories>physics.optics eess.IV eess.SP</categories><comments>Typos are corrected. Text is revised a bit to improve readability.
  Supplementary information about the research article is appended</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Super-resolution imaging with advanced optical systems has been
revolutionizing technical analysis in various fields from biological to
physical sciences. However, many objects are hidden by strongly scattering
media such as rough wall corners or biological tissues that scramble light
paths, create speckle patterns and hinder object's visualization, let alone
super-resolution imaging. Here, we realize a method to do non-invasive
super-resolution imaging through scattering media based on stochastic optical
scattering localization imaging (SOSLI) technique. Simply by capturing multiple
speckle patterns of photo-switchable emitters in our demonstration, the
stochastic approach utilizes the speckle correlation properties of scattering
media to retrieve an image with more than five-fold resolution enhancement
compared to the diffraction limit, while posing no fundamental limit in
achieving higher spatial resolution. More importantly, we demonstrate our SOSLI
to do non-invasive super-resolution imaging through not only optical diffusers,
i.e. static scattering media, but also biological tissues, i.e. dynamic
scattering media with decorrelation of up to 80%. Our approach paves the way to
non-invasively visualize various samples behind scattering media at
unprecedented levels of detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03870</identifier>
 <datestamp>2019-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03870</id><created>2019-06-10</created><authors><author><keyname>Jia</keyname><forenames>Bijue</forenames></author><author><keyname>Lv</keyname><forenames>Jiancheng</forenames></author><author><keyname>Liu</keyname><forenames>Dayiheng</forenames></author></authors><title>Deep Learning-Based Automatic Downbeat Tracking: A Brief Review</title><categories>cs.IR cs.SD eess.AS</categories><comments>22 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1605.08396 by other authors</comments><journal-ref>Multimedia Systems, 2019, 25(6): 617-638</journal-ref><doi>10.1007/s00530-019-00607-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an important format of multimedia, music has filled almost everyone's
life. Automatic analyzing music is a significant step to satisfy people's need
for music retrieval and music recommendation in an effortless way. Thereinto,
downbeat tracking has been a fundamental and continuous problem in Music
Information Retrieval (MIR) area. Despite significant research efforts,
downbeat tracking still remains a challenge. Previous researches either focus
on feature engineering (extracting certain features by signal processing, which
are semi-automatic solutions); or have some limitations: they can only model
music audio recordings within limited time signatures and tempo ranges.
Recently, deep learning has surpassed traditional machine learning methods and
has become the primary algorithm in feature learning; the combination of
traditional and deep learning methods also has made better performance. In this
paper, we begin with a background introduction of downbeat tracking problem.
Then, we give detailed discussions of the following topics: system
architecture, feature extraction, deep neural network algorithms, datasets, and
evaluation strategy. In addition, we take a look at the results from the annual
benchmark evaluation--Music Information Retrieval Evaluation eXchange
(MIREX)--as well as the developments in software implementations. Although much
has been achieved in the area of automatic downbeat tracking, some problems
still remain. We point out these problems and conclude with possible directions
and challenges for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03883</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03883</id><created>2019-06-10</created><authors><author><keyname>Poggiolini</keyname><forenames>Pierluigi</forenames></author></authors><title>A Closed-Form GN-Model Non-Linear Interference Coherence Term</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we report on the details of the derivation of approximate
closed-form results related to the coherence effect in non-linear noise
accumulation, in the context of the GN-model of fiber non-linearity. The
coherence effect is particularly important in relation to the non-linearity
noise produced by a single transmission channel onto itself. We derive new
results, not shown before, that provide a more accurate representation of
coherent accumulation of NLI than previous closed-form formulas. The
availability of such closed-form formulas is important in the context of
real-time management and optimization of physical-layer aware optical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03906</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03906</id><created>2019-06-10</created><authors><author><keyname>Wang</keyname><forenames>Guotai</forenames></author><author><keyname>Shapey</keyname><forenames>Jonathan</forenames></author><author><keyname>Li</keyname><forenames>Wenqi</forenames></author><author><keyname>Dorent</keyname><forenames>Reuben</forenames></author><author><keyname>Demitriadis</keyname><forenames>Alex</forenames></author><author><keyname>Bisdas</keyname><forenames>Sotirios</forenames></author><author><keyname>Paddick</keyname><forenames>Ian</forenames></author><author><keyname>Bradford</keyname><forenames>Robert</forenames></author><author><keyname>Ourselin</keyname><forenames>Sebastien</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author></authors><title>Automatic Segmentation of Vestibular Schwannoma from T2-Weighted MRI by
  Deep Spatial Attention with Hardness-Weighted Loss</title><categories>eess.IV cs.CV</categories><comments>9 pages, 4 figures, submitted to MICCAI</comments><doi>10.1007/978-3-030-32245-8_30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic segmentation of vestibular schwannoma (VS) tumors from magnetic
resonance imaging (MRI) would facilitate efficient and accurate volume
measurement to guide patient management and improve clinical workflow. The
accuracy and robustness is challenged by low contrast, small target region and
low through-plane resolution. We introduce a 2.5D convolutional neural network
(CNN) able to exploit the different in-plane and through-plane resolutions
encountered in standard of care imaging protocols. We use an attention module
to enable the CNN to focus on the small target and propose a supervision on the
learning of attention maps for more accurate segmentation. Additionally, we
propose a hardness-weighted Dice loss function that gives higher weights to
harder voxels to boost the training of CNNs. Experiments with ablation studies
on the VS tumor segmentation task show that: 1) the proposed 2.5D CNN
outperforms its 2D and 3D counterparts, 2) our supervised attention mechanism
outperforms unsupervised attention, 3) the voxel-level hardness-weighted Dice
loss can improve the performance of CNNs. Our method achieved an average Dice
score and ASSD of 0.87 and 0.43~mm respectively. This will facilitate patient
management decisions in clinical practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03909</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03909</id><created>2019-06-10</created><updated>2019-06-12</updated><authors><author><keyname>Yazar</keyname><forenames>Ahmet</forenames></author><author><keyname>Arslan</keyname><forenames>H&#xfc;seyin</forenames></author></authors><title>Selection of Waveform Parameters Using Machine Learning for 5G and
  Beyond</title><categories>eess.SP</categories><comments>It has been accepted for presentation in 2019 IEEE 30th Annual
  International Symposium on Personal, Indoor and Mobile Radio Communications
  (PIMRC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flexibility is one of the essential requirements in future cellular
communications technologies. Providing customized communications solutions for
each user and service type cannot be possible without the flexibility in 5G and
beyond. Different optimizations need to be done for the flexibility related
structures of 5G and beyond systems. In this paper, a novel machine learning
(ML) based selection mechanism for the configurable waveform parameters is
designed from the flexibility perspective. Moreover, a simulation based dataset
generation methodology is proposed for ML systems. Results of computer
simulations are presented using the generated dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03915</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03915</id><created>2019-06-10</created><authors><author><keyname>Kong</keyname><forenames>Linglin</forenames></author></authors><title>User mode selection of NOMA based D2D communication for maximum
  sum-revenue</title><categories>eess.SP</categories><comments>This paper was submitted to IEEE for possible publication</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Device to Device (D2D) communication underlying cellular communication can
improve the utilization efficiency of resources, and the cellular user
equipment (C-UE) can utilize the rental resources for D2D user equipment (D-UE)
to obtain revenue. In 5g communication, non-orthogonal multiple access (NOMA)
is another promising technology. In this paper, cellular users can choose to
apply orthogonal multiple access (OMA) mode or NOMA mode to rent their own
resources to get the maximum benefit. We proposed a dual-arm bandit machine
model to solve this mode selection game and proved the effectiveness of our
scheme through simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.03975</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.03975</id><created>2019-06-01</created><authors><author><keyname>Hong</keyname><forenames>Kris Y.</forenames></author><author><keyname>Pinheiro</keyname><forenames>Pedro O.</forenames></author><author><keyname>Weichenthal</keyname><forenames>Scott</forenames></author></authors><title>Predicting Global Variations in Outdoor PM2.5 Concentrations using
  Satellite Images and Deep Convolutional Neural Networks</title><categories>eess.IV cs.LG</categories><comments>8 pages, 6 figures, Submitted to Scientific Reports</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we present a new method of estimating global variations in outdoor
PM$_{2.5}$ concentrations using satellite images combined with ground-level
measurements and deep convolutional neural networks. Specifically, new deep
learning models were trained over the global PM$_{2.5}$ concentration range
($&lt;$1-436 $\mu$g/m$^3$) using a large database of satellite images paired with
ground level PM$_{2.5}$ measurements available from the World Health
Organization. Final model selection was based on a systematic evaluation of
well-known architectures for the convolutional base including InceptionV3,
Xception, and VGG16. The Xception architecture performed best and the final
global model had a root mean square error (RMSE) value of 13.01 $\mu$g/m$^3$
(R$^2$=0.75) in the disjoint test set. The predictive performance of our new
global model (called IMAGE-PM$_{2.5}$) is similar to the current
state-of-the-art model used in the Global Burden of Disease study but relies
only on satellite images as input. As a result, the IMAGE-PM$_{2.5}$ model
offers a fast, cost-effective means of estimating global variations in
long-term average PM$_{2.5}$ concentrations and may be particularly useful for
regions without ground monitoring data or detailed emissions inventories. The
IMAGE-PM$_{2.5}$ model can be used as a stand-alone method of global exposure
estimation or incorporated into more complex hierarchical model structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04013</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04013</id><created>2019-06-06</created><authors><author><keyname>Khawaja</keyname><forenames>Wahab Ali Gulzar</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Matolak</keyname><forenames>David</forenames></author></authors><title>Ultra-Wideband Air-to-Ground Propagation Channel Characterization in an
  Open Area</title><categories>eess.SP</categories><comments>Submitted to IEEE Transactions on Aerospace and Electronic Systems
  (under review). arXiv admin note: text overlap with arXiv:1812.06603</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the air-to-ground (AG) ultra-wideband (UWB) propagation
channel through measurements between 3.1 GHz to 4.8 GHz using
unmanned-aerial-vehicles (UAVs). Different line-of-sight (LOS) and obstructed-
LOS scenarios and two antenna orientations were used in the experiments.
Channel statistics for different propagation scenarios were obtained, and the
Saleh-Valenzuela (SV) model was found to provide a good fit for the statistical
channel model. An analytical path loss model based on antenna gains in the
elevation plane is provided for unobstructed UAV hovering and moving (in a
circular path) propagation scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04021</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04021</id><created>2019-06-10</created><updated>2019-10-13</updated><authors><author><keyname>Wu</keyname><forenames>Chong</forenames></author><author><keyname>Zhang</keyname><forenames>Le</forenames></author><author><keyname>Cao</keyname><forenames>Jiawang</forenames></author><author><keyname>Yan</keyname><forenames>Hong</forenames></author></authors><title>Superpixel Tensor Pooling for Visual Tracking using Multiple Midlevel
  Visual Cues Fusion</title><categories>eess.IV</categories><comments>8 pages, 7 figures. in IEEE Access</comments><doi>10.1109/ACCESS.2019.2946939</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a method called superpixel tensor pooling tracker
which can fuse multiple midlevel cues captured by superpixels into sparse
pooled tensor features. Our method first adopts the superpixel method to
generate different patches (superpixels) from the target template or
candidates. Then for each superpixel, it encodes different midlevel cues
including HSI color, RGB color, and spatial coordinates into a histogram matrix
to construct a new feature space. Next, these matrices are formed to a third
order tensor. After that, the tensor is pooled into the sparse representation.
Then the incremental positive and negative subspaces learning is performed. Our
method has both good characteristics of midlevel cues and sparse representation
hence is more robust to large appearance variations and can capture compact and
informative appearance of the target object. To validate the proposed method,
we compare it with state-of-the-art methods on 24 sequences with multiple
visual tracking challenges. Experiment results demonstrate that our method
outperforms them significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04027</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04027</id><created>2019-06-10</created><updated>2019-06-11</updated><authors><author><keyname>Gaina</keyname><forenames>Raluca D.</forenames></author><author><keyname>Stephenson</keyname><forenames>Matthew</forenames></author></authors><title>&quot;Did You Hear That?&quot; Learning to Play Video Games from Audio Cues</title><categories>cs.AI cs.LG cs.SD eess.AS</categories><comments>4 pages, 2 figures, accepted at IEEE COG 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Game-playing AI research has focused for a long time on learning to play
video games from visual input or symbolic information. However, humans benefit
from a wider array of sensors which we utilise in order to navigate the world
around us. In particular, sounds and music are key to how many of us perceive
the world and influence the decisions we make. In this paper, we present
initial experiments on game-playing agents learning to play video games solely
from audio cues. We expand the Video Game Description Language to allow for
audio specification, and the General Video Game AI framework to provide new
audio games and an API for learning agents to make use of audio observations.
We analyse the games and the audio game design process, include initial results
with simple Q~Learning agents, and encourage further research in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04045</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04045</id><created>2019-06-07</created><updated>2019-07-26</updated><authors><author><keyname>Baumgartner</keyname><forenames>Christian F.</forenames></author><author><keyname>Tezcan</keyname><forenames>Kerem C.</forenames></author><author><keyname>Chaitanya</keyname><forenames>Krishna</forenames></author><author><keyname>H&#xf6;tker</keyname><forenames>Andreas M.</forenames></author><author><keyname>Muehlematter</keyname><forenames>Urs J.</forenames></author><author><keyname>Schawkat</keyname><forenames>Khoschy</forenames></author><author><keyname>Becker</keyname><forenames>Anton S.</forenames></author><author><keyname>Donati</keyname><forenames>Olivio</forenames></author><author><keyname>Konukoglu</keyname><forenames>Ender</forenames></author></authors><title>PHiSeg: Capturing Uncertainty in Medical Image Segmentation</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted to MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation of anatomical structures and pathologies is inherently
ambiguous. For instance, structure borders may not be clearly visible or
different experts may have different styles of annotating. The majority of
current state-of-the-art methods do not account for such ambiguities but rather
learn a single mapping from image to segmentation. In this work, we propose a
novel method to model the conditional probability distribution of the
segmentations given an input image. We derive a hierarchical probabilistic
model, in which separate latent variables are responsible for modelling the
segmentation at different resolutions. Inference in this model can be
efficiently performed using the variational autoencoder framework. We show that
our proposed method can be used to generate significantly more realistic and
diverse segmentation samples compared to recent related work, both, when
trained with annotations from a single or multiple annotators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04049</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04049</id><created>2019-06-10</created><authors><author><keyname>Parekh</keyname><forenames>Vishwa S.</forenames></author><author><keyname>Laterra</keyname><forenames>John</forenames></author><author><keyname>Bettegowda</keyname><forenames>Chetan</forenames></author><author><keyname>Bocchieri</keyname><forenames>Alex E.</forenames></author><author><keyname>Pillai</keyname><forenames>Jay J.</forenames></author><author><keyname>Jacobs</keyname><forenames>Michael A.</forenames></author></authors><title>Multiparametric Deep Learning and Radiomics for Tumor Grading and
  Treatment Response Assessment of Brain Cancer: Preliminary Results</title><categories>eess.IV cs.LG physics.med-ph q-bio.QM</categories><comments>6 pages, 4 figure, 2 tables, radiomics, brain</comments><msc-class>94A17, 68T10</msc-class><acm-class>I.4.7; I.4.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radiomics is an exciting new area of texture research for extracting
quantitative and morphological characteristics of pathological tissue. However,
to date, only single images have been used for texture analysis. We have
extended radiomic texture methods to use multiparametric (mp) data to get more
complete information from all the images. These mpRadiomic methods could
potentially provide a platform for stratification of tumor grade as well as
assessment of treatment response in brain tumors. In brain, multiparametric MRI
(mpMRI) are based on contrast enhanced T1-weighted imaging (T1WI), T2WI, Fluid
Attenuated Inversion Recovery (FLAIR), Diffusion Weighted Imaging (DWI) and
Perfusion Weighted Imaging (PWI). Therefore, we applied our multiparametric
radiomic framework (mpRadiomic) on 24 patients with brain tumors (8 grade II
and 16 grade IV). The mpRadiomic framework classified grade IV tumors from
grade II tumors with a sensitivity and specificity of 93% and 100%,
respectively, with an AUC of 0.95. For treatment response, the mpRadiomic
framework classified pseudo-progression from true-progression with an AUC of
0.93. In conclusion, the mpRadiomic analysis was able to effectively capture
the multiparametric brain MRI texture and could be used as potential biomarkers
for distinguishing grade IV from grade II tumors as well as determining
true-progression from pseudo-progression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04055</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04055</id><created>2019-06-10</created><updated>2019-08-13</updated><authors><author><keyname>Watson</keyname><forenames>Ryan M.</forenames></author><author><keyname>Gross</keyname><forenames>Jason N.</forenames></author><author><keyname>Taylor</keyname><forenames>Clark N.</forenames></author><author><keyname>Leishman</keyname><forenames>Robert C.</forenames></author></authors><title>Enabling Robust State Estimation through Measurement Error Covariance
  Adaptation</title><categories>cs.RO eess.SP</categories><comments>14 pages, 13 figures, Submitted to IEEE Transactions on Aerospace And
  Electronic Systems</comments><doi>10.1109/TAES.2019.2941103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate platform localization is an integral component of most robotic
systems. As these robotic systems become more ubiquitous, it is necessary to
develop robust state estimation algorithms that are able to withstand novel and
non-cooperative environments. When dealing with novel and non-cooperative
environments, little is known a priori about the measurement error uncertainty,
thus, there is a requirement that the uncertainty models of the localization
algorithm be adaptive. Within this paper, we propose the batch covariance
estimation technique, which enables robust state estimation through the
iterative adaptation of the measurement uncertainty model. The adaptation of
the measurement uncertainty model is granted through non-parametric clustering
of the residuals, which enables the characterization of the measurement
uncertainty via a Gaussian mixture model. The provided Gaussian mixture model
can be utilized within any non-linear least squares optimization algorithm by
approximately characterizing each observation with the sufficient statistics of
the assigned cluster (i.e., each observation's uncertainty model is updated
based upon the assignment provided by the non-parametric clustering algorithm).
The proposed algorithm is verified on several GNSS collected data sets, where
it is shown that the proposed technique exhibits some advantages when compared
to other robust estimation techniques when confronted with degraded data
quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04078</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04078</id><created>2019-06-10</created><updated>2020-01-29</updated><authors><author><keyname>Bu</keyname><forenames>Fankun</forenames></author><author><keyname>Yuan</keyname><forenames>Yuxuan</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyu</forenames></author><author><keyname>Dehghanpour</keyname><forenames>Kaveh</forenames></author><author><keyname>Kimber</keyname><forenames>Anne</forenames></author></authors><title>A Time-Series Distribution Test System Based on Real Utility Data</title><categories>eess.SP</categories><doi>10.1109/NAPS46351.2019.8999982</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide a time-series distribution test system. This test
system is a fully observable distribution grid in Midwest U.S. with smart
meters (SM) installed at all end users. Our goal is to share a real U.S.
distribution grid model without modification. This grid model is comprehensive
and representative since it consists of both overhead lines and underground
cables, and it has standard distribution grid components such as capacitor
banks, line switches, substation transformers with load tap changer and
secondary distribution transformers. An important uniqueness of this grid model
is it has one-year smart meter measurements at all nodes, thus bridging the gap
between existing test feeders and quasi-static time-series based distribution
system analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04090</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04090</id><created>2019-06-10</created><authors><author><keyname>Nguyen</keyname><forenames>Ly V.</forenames></author><author><keyname>Ngo</keyname><forenames>Duy T.</forenames></author><author><keyname>Tran</keyname><forenames>Nghi H.</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author><author><keyname>Nguyen</keyname><forenames>Duy H. N.</forenames></author></authors><title>Supervised and Semi-Supervised Learning for MIMO Blind Detection with
  Low-Resolution ADCs</title><categories>eess.SP cs.IT math.IT</categories><comments>14 pages, 10 figures, submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of low-resolution analog-to-digital converters (ADCs) is considered
to be an effective technique to reduce the power consumption and hardware
complexity of wireless transceivers. However, in systems with low-resolution
ADCs, obtaining channel state information (CSI) is difficult due to significant
distortions in the received signals. The primary motivation of this paper is to
show that learning techniques can mitigate the impact of CSI unavailability. We
study the blind detection problem in multiple-input-multiple-output (MIMO)
systems with low-resolution ADCs using learning approaches. Two methods, which
employ a sequence of pilot symbol vectors as the initial training data, are
proposed. The first method exploits the use of a cyclic redundancy check (CRC)
to obtain more training data, which helps improve the detection accuracy. The
second method is based on the perspective that the to-be-decoded data can
itself assist the learning process, so no further training information is
required except the pilot sequence. For the case of 1-bit ADCs, we provide a
performance analysis of the vector error rate for the proposed methods. Based
on the analytical results, a criterion for designing transmitted signals is
also presented. Simulation results show that the proposed methods outperform
existing techniques and are also more robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04155</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04155</id><created>2019-06-07</created><authors><author><keyname>Burggraaff</keyname><forenames>Olivier</forenames></author><author><keyname>Schmidt</keyname><forenames>Norbert</forenames></author><author><keyname>Zamorano</keyname><forenames>Jaime</forenames></author><author><keyname>Pauly</keyname><forenames>Klaas</forenames></author><author><keyname>Pascual</keyname><forenames>Sergio</forenames></author><author><keyname>Tapia</keyname><forenames>Carlos</forenames></author><author><keyname>Spyrakos</keyname><forenames>Evangelos</forenames></author><author><keyname>Snik</keyname><forenames>Frans</forenames></author></authors><title>Standardized spectral and radiometric calibration of consumer cameras</title><categories>physics.ins-det astro-ph.IM eess.IV physics.optics</categories><comments>27 pages, 11 figures, accepted for publication in Optics Express</comments><doi>10.1364/OE.27.019075</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consumer cameras, particularly onboard smartphones and UAVs, are now commonly
used as scientific instruments. However, their data processing pipelines are
not optimized for quantitative radiometry and their calibration is more complex
than that of scientific cameras. The lack of a standardized calibration
methodology limits the interoperability between devices and, in the
ever-changing market, ultimately the lifespan of projects using them. We
present a standardized methodology and database (SPECTACLE) for spectral and
radiometric calibrations of consumer cameras, including linearity, bias
variations, read-out noise, dark current, ISO speed and gain, flat-field, and
RGB spectral response. This includes golden standard ground-truth methods and
do-it-yourself methods suitable for non-experts. Applying this methodology to
seven popular cameras, we found high linearity in RAW but not JPEG data,
inter-pixel gain variations &gt;400% correlated with large-scale bias and read-out
noise patterns, non-trivial ISO speed normalization functions, flat-field
correction factors varying by up to 2.79 over the field of view, and both
similarities and differences in spectral response. Moreover, these results
differed wildly between camera models, highlighting the importance of
standardization and a centralized database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04159</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04159</id><created>2019-06-10</created><updated>2019-11-14</updated><authors><author><keyname>Chen</keyname><forenames>Yuxin</forenames></author><author><keyname>Fan</keyname><forenames>Jianqing</forenames></author><author><keyname>Ma</keyname><forenames>Cong</forenames></author><author><keyname>Yan</keyname><forenames>Yuling</forenames></author></authors><title>Inference and Uncertainty Quantification for Noisy Matrix Completion</title><categories>stat.ML cs.IT cs.LG eess.SP math.IT math.OC math.ST stat.TH</categories><comments>published at Proceedings of the National Academy of Sciences Nov
  2019, 116 (46) 22931-22937</comments><doi>10.1073/pnas.1910053116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noisy matrix completion aims at estimating a low-rank matrix given only
partial and corrupted entries. Despite substantial progress in designing
efficient estimation algorithms, it remains largely unclear how to assess the
uncertainty of the obtained estimates and how to perform statistical inference
on the unknown matrix (e.g.~constructing a valid and short confidence interval
for an unseen entry).
  This paper takes a step towards inference and uncertainty quantification for
noisy matrix completion. We develop a simple procedure to compensate for the
bias of the widely used convex and nonconvex estimators. The resulting
de-biased estimators admit nearly precise non-asymptotic distributional
characterizations, which in turn enable optimal construction of confidence
intervals\,/\,regions for, say, the missing entries and the low-rank factors.
Our inferential procedures do not rely on sample splitting, thus avoiding
unnecessary loss of data efficiency. As a byproduct, we obtain a sharp
characterization of the estimation accuracy of our de-biased estimators, which,
to the best of our knowledge, are the first tractable algorithms that provably
achieve full statistical efficiency (including the preconstant). The analysis
herein is built upon the intimate link between convex and nonconvex
optimization --- an appealing feature recently discovered by
\cite{chen2019noisy}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04160</identifier>
 <datestamp>2019-06-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04160</id><created>2019-06-10</created><authors><author><keyname>Ginosar</keyname><forenames>Shiry</forenames></author><author><keyname>Bar</keyname><forenames>Amir</forenames></author><author><keyname>Kohavi</keyname><forenames>Gefen</forenames></author><author><keyname>Chan</keyname><forenames>Caroline</forenames></author><author><keyname>Owens</keyname><forenames>Andrew</forenames></author><author><keyname>Malik</keyname><forenames>Jitendra</forenames></author></authors><title>Learning Individual Styles of Conversational Gesture</title><categories>cs.CV cs.LG eess.AS</categories><comments>CVPR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human speech is often accompanied by hand and arm gestures. Given audio
speech input, we generate plausible gestures to go along with the sound.
Specifically, we perform cross-modal translation from &quot;in-the-wild'' monologue
speech of a single speaker to their hand and arm motion. We train on unlabeled
videos for which we only have noisy pseudo ground truth from an automatic pose
detection system. Our proposed model significantly outperforms baseline methods
in a quantitative comparison. To support research toward obtaining a
computational understanding of the relationship between gesture and speech, we
release a large video dataset of person-specific gestures. The project website
with video, code and data can be found at
http://people.eecs.berkeley.edu/~shiry/speech2gesture .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04165</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04165</id><created>2019-06-07</created><authors><author><keyname>Miller</keyname><forenames>Derek</forenames></author></authors><title>Leveraging BERT for Extractive Text Summarization on Lectures</title><categories>cs.CL cs.LG cs.SD eess.AS stat.ML</categories><comments>7 Pages, First Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last two decades, automatic extractive text summarization on lectures
has demonstrated to be a useful tool for collecting key phrases and sentences
that best represent the content. However, many current approaches utilize dated
approaches, producing sub-par outputs or requiring several hours of manual
tuning to produce meaningful results. Recently, new machine learning
architectures have provided mechanisms for extractive summarization through the
clustering of output embeddings from deep learning models. This paper reports
on the project called Lecture Summarization Service, a python based RESTful
service that utilizes the BERT model for text embeddings and KMeans clustering
to identify sentences closes to the centroid for summary selection. The purpose
of the service was to provide students a utility that could summarize lecture
content, based on their desired number of sentences. On top of the summary
work, the service also includes lecture and summary management, storing content
on the cloud which can be used for collaboration. While the results of
utilizing BERT for extractive summarization were promising, there were still
areas where the model struggled, providing feature research opportunities for
further improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04217</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04217</id><created>2019-06-10</created><authors><author><keyname>Stavrou</keyname><forenames>Photios A.</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author><author><keyname>Tanaka</keyname><forenames>Takashi</forenames></author></authors><title>Sequential Source Coding for Stochastic Systems Subject to Finite Rate
  Constraints</title><categories>eess.SY cs.IT cs.SY math.DS math.IT math.OC</categories><comments>34 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply a sequential source coding framework to analyze
fundamental performance limitations of stochastic control systems subject to
feedback data-rate constraints. We first show that the characterization of the
rate-distortion region obtained using sequential codes with a per-time average
distortion constraint can be simplified for spatially IID $m$-order Markov
sources and generalized to total (across time) average distortion constraints.
Furthermore, we show that the corresponding minimum total-rate achieved by
sequential codes is precisely the nonanticipative rate distortion function
(NRDF) also known as sequential RDF. We use our findings to derive {\it
analytical} non-asymptotic, finite-dimensional bounds on the minimum achievable
performance in two control-related application examples. (a) A parallel
time-varying Gauss-Markov process with identically distributed spatial
components that is quantized and transmitted with an instantaneous data-rate,
obtained though the solution of a dynamic reverse-waterfilling algorithm,
through a noiseless channel to a minimum mean-squared error (MMSE) decoder. For
this example, we derive non-asymptotic lower and upper bounds (per dimension)
on the minimum achievable total-rate. (b) A time-varying quantized LQG
closed-loop control system, with identically distributed spatial components and
with a random resource allocation. For this example, we apply the results
obtained from the quantized state estimation problem to derive analogous bounds
on the non-asymptotic total-cost of control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04231</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04231</id><created>2019-06-10</created><authors><author><keyname>Fung</keyname><forenames>Yi Ren</forenames></author><author><keyname>Guan</keyname><forenames>Ziqiang</forenames></author><author><keyname>Kumar</keyname><forenames>Ritesh</forenames></author><author><keyname>Wu</keyname><forenames>Joie Yeahuay</forenames></author><author><keyname>Fiterau</keyname><forenames>Madalina</forenames></author></authors><title>Alzheimer's Disease Brain MRI Classification: Challenges and Insights</title><categories>eess.IV cs.CV</categories><comments>5 pages, 2 figures, IJCAI ARIAL workshop paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, many papers have reported state-of-the-art performance on
Alzheimer's Disease classification with MRI scans from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) dataset using convolutional neural networks.
However, we discover that when we split that data into training and testing
sets at the subject level, we are not able to obtain similar performance,
bringing the validity of many of the previous studies into question.
Furthermore, we point out that previous works use different subsets of the ADNI
data, making comparison across similar works tricky. In this study, we present
the results of three splitting methods, discuss the motivations behind their
validity, and report our results using all of the available subjects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04232</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04232</id><created>2019-06-10</created><authors><author><keyname>Mozaffari</keyname><forenames>M. Hamed</forenames></author><author><keyname>Lee</keyname><forenames>Won-Sook</forenames></author></authors><title>BowNet: Dilated Convolution Neural Network for Ultrasound Tongue Contour
  Extraction</title><categories>eess.IV cs.CV cs.LG cs.NE cs.SD eess.AS</categories><comments>23 pages, 15 figures, 10 tables</comments><journal-ref>BowNet: Dilated convolutional neural network for ultrasound tongue
  contour extraction, 2019, The Journal of the Acoustical Society of America,
  pages 2940-2941, volume 146, number 4</journal-ref><doi>10.1121/1.5137212</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound imaging is safe, relatively affordable, and capable of real-time
performance. One application of this technology is to visualize and to
characterize human tongue shape and motion during a real-time speech to study
healthy or impaired speech production. Due to the noisy nature of ultrasound
images with low-contrast characteristic, it might require expertise for
non-expert users to recognize organ shape such as tongue surface (dorsum). To
alleviate this difficulty for quantitative analysis of tongue shape and motion,
tongue surface can be extracted, tracked, and visualized instead of the whole
tongue region. Delineating the tongue surface from each frame is a cumbersome,
subjective, and error-prone task. Furthermore, the rapidity and complexity of
tongue gestures have made it a challenging task, and manual segmentation is not
a feasible solution for real-time applications. Employing the power of
state-of-the-art deep neural network models and training techniques, it is
feasible to implement new fully-automatic, accurate, and robust segmentation
methods with the capability of real-time performance, applicable for tracking
of the tongue contours during the speech. This paper presents two novel deep
neural network models named BowNet and wBowNet benefits from the ability of
global prediction of decoding-encoding models, with integrated multi-scale
contextual information, and capability of full-resolution (local) extraction of
dilated convolutions. Experimental results using several ultrasound tongue
image datasets revealed that the combination of both localization and
globalization searching could improve prediction result significantly.
Assessment of BowNet models using both qualitatively and quantitatively studies
showed them outstanding achievements in terms of accuracy and robustness in
comparison with similar techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04233</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04233</id><created>2019-06-10</created><updated>2019-09-12</updated><authors><author><keyname>Hodari</keyname><forenames>Zack</forenames></author><author><keyname>Watts</keyname><forenames>Oliver</forenames></author><author><keyname>King</keyname><forenames>Simon</forenames></author></authors><title>Using generative modelling to produce varied intonation for speech
  synthesis</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Accepted for the 10th ISCA Speech Synthesis Workshop (SSW10)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike human speakers, typical text-to-speech (TTS) systems are unable to
produce multiple distinct renditions of a given sentence. This has previously
been addressed by adding explicit external control. In contrast, generative
models are able to capture a distribution over multiple renditions and thus
produce varied renditions using sampling. Typical neural TTS models learn the
average of the data because they minimise mean squared error. In the context of
prosody, taking the average produces flatter, more boring speech: an &quot;average
prosody&quot;. A generative model that can synthesise multiple prosodies will, by
design, not model average prosody. We use variational autoencoders (VAEs) which
explicitly place the most &quot;average&quot; data close to the mean of the Gaussian
prior. We propose that by moving towards the tails of the prior distribution,
the model will transition towards generating more idiosyncratic, varied
renditions. Focusing here on intonation, we investigate the trade-off between
naturalness and intonation variation and find that typical acoustic models can
either be natural, or varied, but not both. However, sampling from the tails of
the VAE prior produces much more varied intonation than the traditional
approaches, whilst maintaining the same level of naturalness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04237</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04237</id><created>2019-06-10</created><updated>2019-12-15</updated><authors><author><keyname>Alfaseeh</keyname><forenames>Lama</forenames></author><author><keyname>Farooq</keyname><forenames>Bilal</forenames></author></authors><title>Multi-Level Taxonomy and Critical Review of Eco-Routing Methods</title><categories>eess.SY cs.SY math.OC</categories><comments>During the journal review process we have extensively changed this
  manuscript. An updated version will be submitted as a new submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Routing decisions are initially based on minimizing travel time.
Nevertheless, eco-routing considers the environmental aspect (e.g. emissions,
fuel, and exposure) and was introduced to replace the initial routing concept
to mitigate the undesirable impact of transportation systems on the
environment. This review paper aims to provide a four level taxonomy and map
eco-routing studies to the proposed taxonomy. Furthermore, the strengths and
weaknesses of the presented models are summarized. In the literature reviewed,
special emphasis was given to the role of vehicle connectivity in eco-routing.
The main findings include: the microscopic level of aggregation of the flow and
emission/fuel models was rarely employed for large case studies due to the
associated complexity; one objective was optimized at a time for a majority of
the studies; and all of the reviewed studies were applied in a centralized
routing system environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04256</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04256</id><created>2019-06-10</created><authors><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Elzanaty</keyname><forenames>Ahmed</forenames></author></authors><title>On the LoRa Modulation for IoT: Waveform Properties and Spectral
  Analysis</title><categories>cs.NI eess.SP</categories><comments>8 pages, 5 figures, accepted for publication in IEEE Internet of
  Things Journal</comments><doi>10.1109/JIOT.2019.2919151</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important modulation technique for Internet of Things (IoT) is the one
proposed by the LoRa allianceTM. In this paper we analyze the M-ary LoRa
modulation in the time and frequency domains. First, we provide the signal
description in the time domain, and show that LoRa is a memoryless continuous
phase modulation. The cross-correlation between the transmitted waveforms is
determined, proving that LoRa can be considered approximately an orthogonal
modulation only for large M. Then, we investigate the spectral characteristics
of the signal modulated by random data, obtaining a closed-form expression of
the spectrum in terms of Fresnel functions. Quite surprisingly, we found that
LoRa has both continuous and discrete spectra, with the discrete spectrum
containing exactly a fraction 1/M of the total signal power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04258</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04258</id><created>2019-06-10</created><authors><author><keyname>Safarpour</keyname><forenames>Mehdi</forenames></author><author><keyname>Hautala</keyname><forenames>Ilkka</forenames></author><author><keyname>Lopez</keyname><forenames>Miguel Bordallo</forenames></author><author><keyname>Silven</keyname><forenames>Olli</forenames></author></authors><title>Transport Triggered Array Processor for Vision Applications</title><categories>eess.SP cs.AR cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-level sensory data processing in many Internet-of-Things (IoT) devices
pursue energy efficiency by utilizing sleep modes or slowing the clocking to
the minimum. To curb the share of stand-by power dissipation in those designs,
near-threshold/sub-threshold operational points or ultra-low-leakage processes
in fabrication are employed. Those limit the clocking rates significantly,
reducing the computing throughputs of individual processing cores. In this
contribution we explore compensating for the performance loss of operating in
near-threshold region (Vdd =0.6V) through massive parallelization. Benefits of
near-threshold operation and massive parallelism are optimum energy consumption
per instruction operation and minimized memory roundtrips, respectively. The
Processing Elements (PE) of the design are based on Transport Triggered
Architecture. The fine grained programmable parallel solution allows for fast
and efficient computation of learnable low-level features (e.g. local binary
descriptors and convolutions). Other operations, including Max-pooling have
also been implemented. The programmable design achieves excellent energy
efficiency for Local Binary Patterns computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04263</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04263</id><created>2019-06-10</created><authors><author><keyname>Lotufo</keyname><forenames>Mauricio Alejandro</forenames></author><author><keyname>Colangelo</keyname><forenames>Luigi</forenames></author><author><keyname>Novara</keyname><forenames>Carlo</forenames></author></authors><title>Feedback Linearization for Quadrotors UAV</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper &quot;Control Design for UAV Quadrotors via Embedded Model Control&quot;
[1], the authors designed a complete control unit for a UAV Quadrotor, based on
the Embedded Model Control (EMC) methodology, in combination with the Feedback
Linearization (FL); when applied to non-linear systems. Specifically, [1]
proposes to use the FL as a novel way to design the internal model for the EMC
state and disturbance predictor. To support the treatise in [1], in this report
the feedback-linearized model of the UAV quadrotor leveraged in [1] is
step-by-step derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04264</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04264</id><created>2019-06-10</created><updated>2019-08-21</updated><authors><author><keyname>Plessen</keyname><forenames>Mogens Graf</forenames></author></authors><title>Optimal In-field Routing for Full and Partial Field Coverage with
  Arbitrary Non-Convex Fields and Multiple Obstacle Areas</title><categories>eess.SY cs.SY</categories><comments>12 pages, 2 columns, 7 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the context of optimising the logistics in agriculture this paper
relates to optimal in-field routing for full and partial field coverage with
arbitrary non-convex fields and multiple obstacle areas. It is distinguished
between nine different in-field routing tasks: two for full-field coverage,
seven for partial-field coverage and one for shortest path planning between any
two vertices of the transition graph. It differentiates between equal or
different start and end vertices for a task, coverage of only a subset of
vertices, and a subset of edges or combinations. The proposed methods are
developed primarily for applying sprays and fertilisers with larger operating
widths and with fields where there is unique headland path. Partial field
coverage where, e.g., only a specific subset of edges has to be covered is
relevant for precision agriculture and also for optimised logistical operation
of smaller-sized machinery with limited loading capacities. The result of this
research is the proposition of two compatible algorithms for optimal full and
partial field coverage path planning, respectively. These are evaluated on
three real-world fields to demonstrate their characteristics and computational
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04301</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04301</id><created>2019-06-10</created><authors><author><keyname>Mozaffari</keyname><forenames>M. Hamed</forenames></author><author><keyname>Lee</keyname><forenames>Won-Sook</forenames></author></authors><title>Transfer Learning for Ultrasound Tongue Contour Extraction with
  Different Domains</title><categories>cs.LG cs.CL cs.SD eess.AS eess.IV stat.ML</categories><comments>3 figures, 9 pages, 1 table, 16 references</comments><journal-ref>The Journal of the Acoustical Society of America 146, 2940 (2019)</journal-ref><doi>10.1121/1.5137211</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical ultrasound technology is widely used in routine clinical applications
such as disease diagnosis and treatment as well as other applications like
real-time monitoring of human tongue shapes and motions as visual feedback in
second language training. Due to the low-contrast characteristic and noisy
nature of ultrasound images, it might require expertise for non-expert users to
recognize tongue gestures. Manual tongue segmentation is a cumbersome,
subjective, and error-prone task. Furthermore, it is not a feasible solution
for real-time applications. In the last few years, deep learning methods have
been used for delineating and tracking tongue dorsum. Deep convolutional neural
networks (DCNNs), which have shown to be successful in medical image analysis
tasks, are typically weak for the same task on different domains. In many
cases, DCNNs trained on data acquired with one ultrasound device, do not
perform well on data of varying ultrasound device or acquisition protocol.
Domain adaptation is an alternative solution for this difficulty by
transferring the weights from the model trained on a large annotated legacy
dataset to a new model for adapting on another different dataset using
fine-tuning. In this study, after conducting extensive experiments, we
addressed the problem of domain adaptation on small ultrasound datasets for
tongue contour extraction. We trained a U-net network comprises of an
encoder-decoder path from scratch, and then with several surrogate scenarios,
some parts of the trained network were fine-tuned on another dataset as the
domain-adapted networks. We repeat scenarios from target to source domains to
find a balance point for knowledge transfer from source to target and vice
versa. The performance of new fine-tuned networks was evaluated on the same
task with images from different domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04310</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04310</id><created>2019-06-10</created><authors><author><keyname>Apolinario</keyname><forenames>Marco</forenames></author><author><keyname>Bustamante</keyname><forenames>Samuel Huaman</forenames></author><author><keyname>Morales</keyname><forenames>Giorgio</forenames></author><author><keyname>Telles</keyname><forenames>Joel</forenames></author><author><keyname>Diaz</keyname><forenames>Daniel</forenames></author></authors><title>Estimation of 2D Velocity Model using Acoustic Signals and Convolutional
  Neural Networks</title><categories>eess.SP cs.LG cs.SD eess.AS</categories><comments>Submitted to IEEE XXVI International Conference on Electronics,
  Electrical Engineering and Computing (INTERCON 2019). Lima, Peru</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The parameters estimation of a system using indirect measurements over the
same system is a problem that occurs in many fields of engineering, known as
the inverse problem. It also happens in the field of underwater acoustic,
especially in mediums that are not transparent enough. In those cases, shape
identification of objects using only acoustic signals is a challenge because it
is carried out with information of echoes that are produced by objects with
different densities from that of the medium. In general, these echoes are
difficult to understand since their information is usually noisy and redundant.
In this paper, we propose a model of convolutional neural network with an
Encoder-Decoder configuration to estimate both localization and shape of
objects, which produce reflected signals. This model allows us to obtain a 2D
velocity model. The model was trained with data generated by the
finite-difference method, and it achieved a value of 98.58% in the intersection
over union metric 75.88% in precision and 64.69% in sensibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04323</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04323</id><created>2019-06-10</created><authors><author><keyname>Collobert</keyname><forenames>Ronan</forenames></author><author><keyname>Hannun</keyname><forenames>Awni</forenames></author><author><keyname>Synnaeve</keyname><forenames>Gabriel</forenames></author></authors><title>Word-level Speech Recognition with a Dynamic Lexicon</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a direct-to-word sequence model with a dynamic lexicon. Our word
network constructs word embeddings dynamically from the character level tokens.
The word network can be integrated seamlessly with arbitrary sequence models
including Connectionist Temporal Classification and encoder-decoder models with
attention. Sub-word units are commonly used in speech recognition yet are
generated without the use of acoustic context. We show our direct-to-word model
can achieve word error rate gains over sub-word level models for speech
recognition. Furthermore, we empirically validate that the word-level
embeddings we learn contain significant acoustic information, making them more
suitable for use in speech recognition. We also show that our direct-to-word
approach retains the ability to predict words not seen at training time without
any retraining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04333</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04333</id><created>2019-06-10</created><authors><author><keyname>Al-Kadi</keyname><forenames>Omar S.</forenames></author></authors><title>Multiscale Nakagami parametric imaging for improved liver tumor
  localization</title><categories>eess.IV cs.CV q-bio.QM q-bio.TO</categories><comments>IEEE International Conference on Image Processing (ICIP), USA, pp.
  3384-3388, 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective ultrasound tissue characterization is usually hindered by complex
tissue structures. The interlacing of speckle patterns complicates the correct
estimation of backscatter distribution parameters. Nakagami parametric imaging
based on localized shape parameter mapping can model different backscattering
conditions. However, performance of the constructed Nakagami image depends on
the sensitivity of the estimation method to the backscattered statistics and
scale of analysis. Using a fixed focal region of interest in estimating the
Nakagami parametric image would increase estimation variance. In this work,
localized Nakagami parameters are estimated adaptively by means of maximum
likelihood estimation on a multiscale basis. The varying size kernel integrates
the goodness-of-fit of the backscattering distribution parameters at multiple
scales for more stable parameter estimation. Results show improved quantitative
visualization of changes in tissue specular reflections, suggesting a potential
approach for improving tumor localization in low contrast ultrasound images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04359</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04359</id><created>2019-06-10</created><updated>2019-07-29</updated><authors><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author><author><keyname>Cheng</keyname><forenames>Huitao</forenames></author><author><keyname>Ying</keyname><forenames>Leslie</forenames></author><author><keyname>Xiao</keyname><forenames>Taohui</forenames></author><author><keyname>Ke</keyname><forenames>Ziwen</forenames></author><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Zheng</keyname><forenames>Hairong</forenames></author><author><keyname>Liang</keyname><forenames>Dong</forenames></author></authors><title>DeepcomplexMRI: Exploiting deep residual network for fast parallel MR
  imaging with complex convolution</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a multi-channel image reconstruction method, named
DeepcomplexMRI, to accelerate parallel MR imaging with residual complex
convolutional neural network. Different from most existing works which rely on
the utilization of the coil sensitivities or prior information of predefined
transforms, DeepcomplexMRI takes advantage of the availability of a large
number of existing multi-channel groudtruth images and uses them as labeled
data to train the deep residual convolutional neural network offline. In
particular, a complex convolutional network is proposed to take into account
the correlation between the real and imaginary parts of MR images. In addition,
the k space data consistency is further enforced repeatedly in between layers
of the network. The evaluations on in vivo datasets show that the proposed
method has the capability to recover the desired multi-channel images. Its
comparison with state-of-the-art method also demonstrates that the proposed
method can reconstruct the desired MR images more accurately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04368</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04368</id><created>2019-06-10</created><authors><author><keyname>Amuru</keyname><forenames>Saidhiraj</forenames></author></authors><title>Beam Learning -- Using Machine Learning for Finding Beam Directions</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper is an extension of the ICC 2017 paper titled &quot;Beam
  Learning&quot;. It was written before the onslaught of deep learning techniques</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beamforming is the key enabler for wireless communications in the mmWave
bands. 802.11ad and WiGig are wireless technologies that currently use the 60
GHz unlicensed mmWave spectrum via beamforming techniques. It is likely that 5G
systems will be considered for 60GHz unlicensed spectrum (apart from other
unlicensed bands) deployments and hence must co-exist with 802.11ad and WiGig.
3GPP is taking steps towards achieving the same and the standardization for
this is underway. The first step to achieve this co-existence is to find the
interference-free directions, in other words identify the directions in which
the nodes using these incumbent technologies are communicating and eliminate
those directions from further communications. Such a mechanism can help to
exploit the spatial holes rather than avoid communications even when only a few
spatial directions are used by incumbents. Such a mechanism trivially increases
the throughput of the proposed 5G systems. However, since the incumbent
technologies may be unknown to the 5G mmWave nodes and their behavior may also
be unknown apriori (for instance, parameters such as duty cycle, power levels,
CSMA parameter used by 802.11ad are unknown to the 5G nodes), this spatial
direction finding must be performed in a blind manner. In this paper, we use
multi-armed bandits-based algorithms, a variant of machine learning algorithms,
to blindly detect the beam directions (both along azimuth and elevation i.e.,
3D-beamforming) used for communication by the incumbents. This work paves the
way for combining the powerful of machine learning algorithms into 5G
unlicensed mmWave systems. Numerical results show the superior performance of
these algorithms over techniques that are commonly employed in such blind
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04378</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04378</id><created>2019-06-10</created><authors><author><keyname>Khosravan</keyname><forenames>Naji</forenames></author><author><keyname>Mortazi</keyname><forenames>Aliasghar</forenames></author><author><keyname>Wallace</keyname><forenames>Michael</forenames></author><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author></authors><title>PAN: Projective Adversarial Network for Medical Image Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted for presentation in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial learning has been proven to be effective for capturing long-range
and high-level label consistencies in semantic segmentation. Unique to medical
imaging, capturing 3D semantics in an effective yet computationally efficient
way remains an open problem. In this study, we address this computational
burden by proposing a novel projective adversarial network, called PAN, which
incorporates high-level 3D information through 2D projections. Furthermore, we
introduce an attention module into our framework that helps for a selective
integration of global information directly from our segmentor to our
adversarial network. For the clinical application we chose pancreas
segmentation from CT scans. Our proposed framework achieved state-of-the-art
performance without adding to the complexity of the segmentor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04403</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04403</id><created>2019-06-11</created><authors><author><keyname>Miranda</keyname><forenames>Icaro Marcelino</forenames></author><author><keyname>Aranha</keyname><forenames>Claus</forenames></author><author><keyname>Ladeira</keyname><forenames>Marcelo</forenames></author></authors><title>Classification of EEG Signals using Genetic Programming for Feature
  Construction</title><categories>cs.NE eess.SP</categories><comments>9 pages, accepted to the GECCO 2019 conference</comments><doi>10.1145/3321707.3321737</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of electroencephalogram (EEG) waves is of critical importance
for the diagnosis of sleep disorders, such as sleep apnea and insomnia, besides
that, seizures, epilepsy, head injuries, dizziness, headaches and brain tumors.
In this context, one important task is the identification of visible structures
in the EEG signal, such as sleep spindles and K-complexes. The identification
of these structures is usually performed by visual inspection from human
experts, a process that can be error prone and susceptible to biases. Therefore
there is interest in developing technologies for the automated analysis of EEG.
In this paper, we propose a new Genetic Programming (GP) framework for feature
construction and dimensionality reduction from EEG signals. We use these
features to automatically identify spindles and K-complexes on data from the
DREAMS project. Using 5 different classifiers, the set of attributes produced
by GP obtained better AUC scores than those obtained from PCA or the full set
of attributes. Also, the results obtained from the proposed framework obtained
a better balance of Specificity and Recall than other models recently proposed
in the literature. Analysis of the features most used by GP also suggested
improvements for data acquisition protocols in future EEG examinations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04419</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04419</id><created>2019-06-11</created><updated>2019-11-10</updated><authors><author><keyname>Zreik</keyname><forenames>Majd</forenames></author><author><keyname>van Hamersvelt</keyname><forenames>Robbert W.</forenames></author><author><keyname>Khalili</keyname><forenames>Nadieh</forenames></author><author><keyname>Wolterink</keyname><forenames>Jelmer M.</forenames></author><author><keyname>Voskuil</keyname><forenames>Michiel</forenames></author><author><keyname>Viergever</keyname><forenames>Max A.</forenames></author><author><keyname>Leiner</keyname><forenames>Tim</forenames></author><author><keyname>I&#x161;gum</keyname><forenames>Ivana</forenames></author></authors><title>Deep learning analysis of coronary arteries in cardiac CT angiography
  for detection of patients requiring invasive coronary angiography</title><categories>eess.IV cs.CV</categories><comments>This work has been accepted to IEEE TMI for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In patients with obstructive coronary artery disease, the functional
significance of a coronary artery stenosis needs to be determined to guide
treatment. This is typically established through fractional flow reserve (FFR)
measurement, performed during invasive coronary angiography (ICA). We present a
method for automatic and non-invasive detection of patients requiring ICA,
employing deep unsupervised analysis of complete coronary arteries in cardiac
CT angiography (CCTA) images. We retrospectively collected CCTA scans of 187
patients, 137 of them underwent invasive FFR measurement in 192 different
coronary arteries. These FFR measurements served as a reference standard for
the functional significance of the coronary stenosis. The centerlines of the
coronary arteries were extracted and used to reconstruct straightened
multi-planar reformatted (MPR) volumes. To automatically identify arteries with
functionally significant stenosis that require ICA, each MPR volume was encoded
into a fixed number of encodings using two disjoint 3D and 1D convolutional
autoencoders performing spatial and sequential encodings, respectively.
Thereafter, these encodings were employed to classify arteries using a support
vector machine classifier. The detection of coronary arteries requiring
invasive evaluation, evaluated using repeated cross-validation experiments,
resulted in an area under the receiver operating characteristic curve of $0.81
\pm 0.02$ on the artery-level, and $0.87 \pm 0.02$ on the patient-level. The
results demonstrate the feasibility of automatic non-invasive detection of
patients that require ICA and possibly subsequent coronary artery intervention.
This could potentially reduce the number of patients that unnecessarily undergo
ICA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04428</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04428</id><created>2019-06-11</created><authors><author><keyname>Stoyka</keyname><forenames>Kateryna</forenames></author><author><keyname>Ohashi</keyname><forenames>Ricieri Akihito Pessinatti</forenames></author><author><keyname>Femia</keyname><forenames>Nicola</forenames></author></authors><title>Behavioral Switching Loss Modeling of Inverter Modules</title><categories>math.NA cs.NA eess.SP</categories><comments>4 pages, 15th International Conference on Synthesis, Modeling,
  Analysis and Simulation Methods and Applications to Circuit Design (SMACD),
  Prague, Czech Republic, 2-5 July 2018</comments><doi>10.1109/SMACD.2018.8434850</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new behavioral model for switching power loss
evaluation in phase-shifted full-bridge inverter Power Modules (PoMs). The
proposed model has been identified by means of a Genetic Programming (GP)
algorithm combined with a Multi-Objective Optimization (MOO) technique. A large
set of loss data, evaluated by means of analytical loss formulas, has been
considered for the identification of a compact behavioral model. The GP-MOO
approach considers the inverter switching frequency, input voltage, duty-cycle
and load resistance as model input variables, and the MOSFET gate driver
voltage and resistance as parameters influencing the coefficients values of the
identified loss formula. The behavioral model loss predictions confirm their
reliability for a wide range of operating conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04441</identifier>
 <datestamp>2020-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04441</id><created>2019-06-11</created><authors><author><keyname>Ferraioli</keyname><forenames>Giampaolo</forenames></author><author><keyname>Pascazio</keyname><forenames>Vito</forenames></author><author><keyname>Vitale</keyname><forenames>Sergio</forenames></author></authors><title>A Novel Cost Function for Despeckling using Convolutional Neural
  Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted on JURSE 2019 - Joint Urban Remote Sensing Event</comments><journal-ref>2019 Joint Urban Remote Sensing Event (JURSE), Vannes, France,
  2019, pp. 1-4</journal-ref><doi>10.1109/JURSE.2019.8809042</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Removing speckle noise from SAR images is still an open issue. It is well
know that the interpretation of SAR images is very challenging and despeckling
algorithms are necessary to improve the ability of extracting information. An
urban environment makes this task more heavy due to different structures and to
different objects scale. Following the recent spread of deep learning methods
related to several remote sensing applications, in this work a convolutional
neural networks based algorithm for despeckling is proposed. The network is
trained on simulated SAR data. The paper is mainly focused on the
implementation of a cost function that takes account of both spatial
consistency of image and statistical properties of noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04459</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04459</id><created>2019-06-11</created><authors><author><keyname>Scholl</keyname><forenames>Stefan</forenames></author></authors><title>Classification of Radio Signals and HF Transmission Modes with Deep
  Learning</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates deep neural networks for radio signal classification.
Instead of performing modulation recognition and combining it with further
analysis methods, the classifier operates directly on the IQ data of the
signals and outputs the transmission mode. A data set of radio signals of 18
different modes, that commonly occur in the HF radio band, is presented and
used as a showcase example. The data set considers HF channel properties and is
used to train four different deep neural network architectures. The results of
the best networks show an excellent accuracy of up to 98%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04467</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04467</id><created>2019-06-11</created><authors><author><keyname>Lauritzen</keyname><forenames>Andreas D.</forenames></author><author><keyname>Papademetris</keyname><forenames>Xenophon</forenames></author><author><keyname>Turovets</keyname><forenames>Sergei</forenames></author><author><keyname>Onofrey</keyname><forenames>John A.</forenames></author></authors><title>Evaluation of CT Image Synthesis Methods:From Atlas-based Registration
  to Deep Learning</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computed tomography (CT) is a widely used imaging modality for medical
diagnosis and treatment. In electroencephalography (EEG), CT imaging is
necessary for co-registering with magnetic resonance imaging (MRI) and for
creating more accurate head models for the brain electrical activity due to
better representation of bone anatomy. Unfortunately, CT imaging exposes
patients to potentially harmful sources of ionizing radiation. Image synthesis
methods present a solution for avoiding extra radiation exposure. In this
paper, we perform image synthesis to create a realistic, synthetic CT image
from MRI of the same subject, and we present a comparison of different image
synthesis techniques. Using a dataset of 30 paired MRI and CT image volumes,
our results compare image synthesis using deep neural network regression,
state-of-the-art adversarial deep learning, as well as atlas-based synthesis
utilizing image registration. We also present a novel synthesis method that
combines multi-atlas registration as a prior to deep learning algorithms, in
which we perform a weighted addition of synthetic CT images, derived from
atlases, to the output of a deep neural network to obtain a residual type of
learning. In addition to evaluating the quality of the synthetic CT images, we
also demonstrate that image synthesis methods allow for more accurate bone
segmentation using the synthetic CT imaging than would otherwise be possible by
segmenting the bone in the MRI directly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04474</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04474</id><created>2019-06-11</created><authors><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author><author><keyname>Mao</keyname><forenames>Yijie</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Rate-Splitting Unifying SDMA, OMA, NOMA, and Multicasting in MISO
  Broadcast Channel: A Simple Two-User Rate Analysis</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering a two-user multi-antenna Broadcast Channel, this paper shows that
linearly precoded Rate-Splitting (RS) with Successive Interference Cancellation
(SIC) receivers is a flexible framework for non-orthogonal transmission that
generalizes, and subsumes as special cases, four seemingly different
strategies, namely Space Division Multiple Access (SDMA) based on linear
precoding, Orthogonal Multiple Access (OMA), Non- Orthogonal Multiple Access
(NOMA) based on linearly precoded superposition coding with SIC, and
physical-layer multicasting. The paper studies the sum-rate and shows
analytically how RS unifies, outperforms, and specializes to SDMA, OMA, NOMA,
and multicasting as a function of the disparity of the channel strengths and
the angle between the user channel directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04529</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04529</id><created>2019-06-11</created><authors><author><keyname>de Loynes</keyname><forenames>Basile</forenames></author><author><keyname>Navarro</keyname><forenames>Fabien</forenames></author><author><keyname>Oliver</keyname><forenames>Baptiste</forenames></author></authors><title>LocLets: Localized Graph Wavelets for Processing Frequency Sparse
  Signals on Graphs</title><categories>eess.SP math.FA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, a new family of graph wavelets, abbreviated LocLets for
\textit{Loc}alized graph wave\textit{Lets}, is introduced. These wavelets are
localized in the Fourier domain on subsets of the graph Laplacian spectrum.
LocLets are built upon the Spectral Graph Wavelet Transform (SGWT) and adapt
better to signals that are sparse in the Fourier domain than standard SGWT. In
fact, as a refinement of SGWT, LocLets benefits from the Chebyshev's machinery
to ensure the LocLets transform remains an efficient and scalable tool for
signal processing on large graphs. In addition, LocLets exploits signals
sparsity in various ways: compactness, efficiency and ease of use of the
transform are improved for sparse signals in the Fourier domain. As typical
examples of such sparse signals, there are smooth and highly non-smooth
signals. For these latter signals, their mixtures or even a wider class of
signals, it is shown in this paper that LocLets provide substantial
improvements in standard noise reduction tasks compared to advanced
graph-wavelet based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04550</identifier>
 <datestamp>2019-10-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04550</id><created>2019-06-11</created><authors><author><keyname>Ghiasvand</keyname><forenames>Siavash</forenames></author><author><keyname>Ciorba</keyname><forenames>Florina M.</forenames></author></authors><title>Anomaly Detection in High Performance Computers: A Vicinity Perspective</title><categories>cs.DC cs.CV cs.SY eess.SY</categories><comments>9 pages, Submitted to the 18th IEEE International Symposium on
  Parallel and Distributed Computing</comments><msc-class>97R99</msc-class><doi>10.1109/ispdc.2019.00024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In response to the demand for higher computational power, the number of
computing nodes in high performance computers (HPC) increases rapidly. Exascale
HPC systems are expected to arrive by 2020. With drastic increase in the number
of HPC system components, it is expected to observe a sudden increase in the
number of failures which, consequently, poses a threat to the continuous
operation of the HPC systems. Detecting failures as early as possible and,
ideally, predicting them, is a necessary step to avoid interruptions in HPC
systems operation. Anomaly detection is a well-known general purpose approach
for failure detection, in computing systems. The majority of existing methods
are designed for specific architectures, require adjustments on the computing
systems hardware and software, need excessive information, or pose a threat to
users' and systems' privacy. This work proposes a node failure detection
mechanism based on a vicinity-based statistical anomaly detection approach
using passively collected and anonymized system log entries. Application of the
proposed approach on system logs collected over 8 months indicates an anomaly
detection precision between 62% to 81%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04577</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04577</id><created>2019-06-08</created><updated>2019-09-05</updated><authors><author><keyname>Sar&#x131;ta&#x15f;</keyname><forenames>Serkan</forenames></author><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author></authors><title>Hypothesis Testing under Subjective Priors and Costs as a Signaling Game</title><categories>math.OC eess.SP</categories><comments>27 pages. arXiv admin note: substantial text overlap with
  arXiv:1804.01357</comments><doi>10.1109/TSP.2019.2935908</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many communication, sensor network, and networked control problems involve
agents (decision makers) which have either misaligned objective functions or
subjective probabilistic models. In the context of such setups, we consider
binary signaling problems in which the decision makers (the transmitter and the
receiver) have subjective priors and/or misaligned objective functions.
Depending on the commitment nature of the transmitter to his policies, we
formulate the binary signaling problem as a Bayesian game under either Nash or
Stackelberg equilibrium concepts and establish equilibrium solutions and their
properties. We show that there can be informative or non-informative equilibria
in the binary signaling game under the Stackelberg and Nash assumptions, and
derive the conditions under which an informative equilibrium exists for the
Stackelberg and Nash setups. For the corresponding team setup, however, an
equilibrium typically always exists and is always informative. Furthermore, we
investigate the effects of small perturbations in priors and costs on
equilibrium values around the team setup (with identical costs and priors), and
show that the Stackelberg equilibrium behavior is not robust to small
perturbations whereas the Nash equilibrium is.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04578</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04578</id><created>2019-06-11</created><updated>2019-06-17</updated><authors><author><keyname>Tsang</keyname><forenames>Mankei</forenames></author></authors><title>Semiparametric estimation for incoherent optical imaging</title><categories>eess.IV physics.optics quant-ph</categories><comments>15 pages, 3 figures. v2: minor improvements</comments><journal-ref>Phys. Rev. Research 1, 033006 (2019)</journal-ref><doi>10.1103/PhysRevResearch.1.033006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of semiparametric estimation offers an elegant way of computing
the Cram\'er-Rao bound for a parameter of interest in the midst of infinitely
many nuisance parameters. Here I apply the theory to the problem of moment
estimation for incoherent imaging under the effects of diffraction and photon
shot noise. Using a Hilbert-space formalism designed for Poisson processes, I
derive exact semiparametric Cram\'er-Rao bounds and efficient estimators for
both direct imaging and a quantum-inspired measurement method called
spatial-mode demultiplexing (SPADE). The results establish the superiority of
SPADE even when little prior information about the object is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04591</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04591</id><created>2019-06-10</created><authors><author><keyname>Naranjo-Alcazar</keyname><forenames>Javier</forenames></author><author><keyname>Perez-Castanos</keyname><forenames>Sergi</forenames></author><author><keyname>Zuccarello</keyname><forenames>Pedro</forenames></author><author><keyname>Cobos</keyname><forenames>Maximo</forenames></author></authors><title>DCASE 2019: CNN depth analysis with different channel inputs for
  Acoustic Scene Classification</title><categories>cs.SD cs.LG eess.AS</categories><journal-ref>Detection and Classification of Acoustic Scenes and Events
  Challenge 2019 - DCASE 2019 Technical Report</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this technical report is to describe the framework used in
Task 1, Acoustic scene classification (ASC), of the DCASE 2019 challenge. The
presented approach is based on Log-Mel spectrogram representations and
VGG-based Convolutional Neural Networks (CNNs). Three different CNNs, with very
similar architectures, have been implemented. Themain difference is the number
of filters in their convolutional blocks. Experiments show that the depth of
the network is not the most relevant factor for improving the accuracy of the
results.The performance seems to be more sensitive to the input audio
representation. This conclusion is important for the implementation of
real-time audio recognition and classification systemon edge devices. In the
presented experiments the best audio representation is the Log-Mel spectrogram
of the harmonic andpercussive sources plus the Log-Mel spectrogram of the
difference between left and right stereo-channels. Also, in order to improve
accuracy, ensemble methods combining different model predictions with different
inputs are explored. Besides geometric and arithmetic means, ensembles
aggregated with the Orness Weighted Averaged (OWA) operator have shown
interesting andnovel results. The proposed framework outperforms the baseline
system by 14.34 percentage points. For Task 1a, the obtained development
accuracy is 76.84 percent, being 62.5 percent the baseline, whereas the
accuracy obtained in public leaderboard is 77.33 percent,being 64.33 percent
the baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04610</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04610</id><created>2019-06-11</created><authors><author><keyname>Khani</keyname><forenames>Mehrdad</forenames></author><author><keyname>Alizadeh</keyname><forenames>Mohammad</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Fleming</keyname><forenames>Phil</forenames></author></authors><title>Adaptive Neural Signal Detection for Massive MIMO</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symbol detection for Massive Multiple-Input Multiple-Output (MIMO) is a
challenging problem for which traditional algorithms are either impractical or
suffer from performance limitations. Several recently proposed learning-based
approaches achieve promising results on simple channel models (e.g., i.i.d.
Gaussian). However, their performance degrades significantly on real-world
channels with spatial correlation. We propose MMNet, a deep learning MIMO
detection scheme that significantly outperforms existing approaches on
realistic channels with the same or lower computational complexity. MMNet's
design builds on the theory of iterative soft-thresholding algorithms and uses
a novel training algorithm that leverages temporal and spectral correlation to
accelerate training. Together, these innovations allow MMNet to train online
for every realization of the channel. On i.i.d. Gaussian channels, MMNet
requires two orders of magnitude fewer operations than existing deep learning
schemes but achieves near-optimal performance. On spatially-correlated
channels, it achieves the same error rate as the next-best learning scheme
(OAMPNet) at 2.5dB lower SNR and with at least 10x less computational
complexity. MMNet is also 4--8dB better overall than a classic linear scheme
like the minimum mean square error (MMSE) detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04649</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04649</id><created>2019-06-11</created><updated>2019-06-12</updated><authors><author><keyname>Rickmann</keyname><forenames>Anne-Marie</forenames></author><author><keyname>Roy</keyname><forenames>Abhijit Guha</forenames></author><author><keyname>Sarasua</keyname><forenames>Ignacio</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Wachinger</keyname><forenames>Christian</forenames></author></authors><title>`Project &amp; Excite' Modules for Segmentation of Volumetric Medical Scans</title><categories>eess.IV cs.CV</categories><comments>Accepted for International Conference on Medical Image Computing and
  Computer Assisted Intervention (MICCAI) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully Convolutional Neural Networks (F-CNNs) achieve state-of-the-art
performance for image segmentation in medical imaging. Recently, squeeze and
excitation (SE) modules and variations thereof have been introduced to
recalibrate feature maps channel- and spatial-wise, which can boost performance
while only minimally increasing model complexity. So far, the development of SE
has focused on 2D images. In this paper, we propose `Project &amp; Excite' (PE)
modules that base upon the ideas of SE and extend them to operating on 3D
volumetric images. `Project &amp; Excite' does not perform global average pooling,
but squeezes feature maps along different slices of a tensor separately to
retain more spatial information that is subsequently used in the excitation
step. We demonstrate that PE modules can be easily integrated in 3D U-Net,
boosting performance by 5% Dice points, while only increasing the model
complexity by 2%. We evaluate the PE module on two challenging tasks,
whole-brain segmentation of MRI scans and whole-body segmentation of CT scans.
Code: https://github.com/ai-med/squeeze_and_excitation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04679</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04679</id><created>2019-06-11</created><authors><author><keyname>Berberich</keyname><forenames>Julian</forenames></author><author><keyname>K&#xf6;hler</keyname><forenames>Johannes</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Matthias A.</forenames></author><author><keyname>Allg&#xf6;wer</keyname><forenames>Frank</forenames></author></authors><title>Data-Driven Model Predictive Control with Stability and Robustness
  Guarantees</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a robust data-driven model predictive control (MPC) scheme to
control linear time-invariant (LTI) systems. The scheme uses an implicit model
description based on behavioral systems theory and past measured trajectories.
In particular, it does not require any prior identification step, but only an
initially measured input-output trajectory as well as an upper bound on the
order of the unknown system. First, we prove exponential stability of a nominal
data-driven MPC scheme with terminal equality constraints in the case of no
measurement noise. For bounded additive output measurement noise, we propose a
robust modification of the scheme, including a slack variable with
regularization in the cost. We prove that the application of this robust MPC
scheme in a multi-step fashion leads to practical exponential stability of the
closed loop w.r.t. the noise level. The presented results provide the first
(theoretical) analysis of closed-loop properties, resulting from a simple,
purely data-driven MPC scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04681</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04681</id><created>2019-06-11</created><updated>2019-06-13</updated><authors><author><keyname>Savioli</keyname><forenames>Nicol&#xf3;</forenames></author></authors><title>A Hybrid Approach Between Adversarial Generative Networks and
  Actor-Critic Policy Gradient for Low Rate High-Resolution Image Compression</title><categories>eess.IV cs.LG stat.ML</categories><comments>4 pages, 2 figures, IEEE Conference on Computer Vision and Pattern
  Recognition, Workshop and Challenge on Learned Image Compression (CLIC) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image compression is an essential approach for decreasing the size in bytes
of the image without deteriorating the quality of it. Typically, classic
algorithms are used but recently deep-learning has been successfully applied.
In this work, is presented a deep super-resolution work-flow for image
compression that maps low-resolution JPEG image to the high-resolution. The
pipeline consists of two components: first, an encoder-decoder neural network
learns how to transform the downsampling JPEG images to high resolution.
Second, a combination between Generative Adversarial Networks (GANs) and
reinforcement learning Actor-Critic (A3C) loss pushes the encoder-decoder to
indirectly maximize High Peak Signal-to-Noise Ratio (PSNR). Although PSNR is a
fully differentiable metric, this work opens the doors to new solutions for
maximizing non-differential metrics through an end-to-end approach between
encoder-decoder networks and reinforcement learning policy gradient methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04689</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04689</id><created>2019-06-11</created><authors><author><keyname>Wang</keyname><forenames>Miaomiao</forenames></author><author><keyname>Tayebi</keyname><forenames>Abdelhamid</forenames></author></authors><title>Hybrid Nonlinear Observers for Inertial Navigation Using Landmark
  Measurements</title><categories>math.OC cs.RO cs.SY eess.SY</categories><comments>Submitted to IEEE Transactions on Automatic Control, 14 pages, 3
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of attitude, position and linear velocity
estimation for rigid body systems relying on landmark measurements. We propose
two hybrid nonlinear observers on the matrix Lie group $SE_2(3)$, leading to
global exponential stability. The first observer relies on fixed gains, while
the second one uses variable gains depending on the solution of a continuous
Riccati equation (CRE). These observers are then extended to handle biased
angular velocity measurements. Both simulation and experimental results are
presented to illustrate the performance of the proposed observers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04704</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04704</id><created>2019-06-11</created><authors><author><keyname>Khalili</keyname><forenames>N.</forenames></author><author><keyname>Turk</keyname><forenames>E.</forenames></author><author><keyname>Zreik</keyname><forenames>M.</forenames></author><author><keyname>Viergever</keyname><forenames>M. A.</forenames></author><author><keyname>Benders</keyname><forenames>M. J. N. L.</forenames></author><author><keyname>Isgum</keyname><forenames>I.</forenames></author></authors><title>Generative adversarial network for segmentation of motion affected
  neonatal brain MRI</title><categories>eess.IV cs.CV</categories><comments>Accepted in Medical Image Computing and Computer Assisted
  Intervention 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic neonatal brain tissue segmentation in preterm born infants is a
prerequisite for evaluation of brain development. However, automatic
segmentation is often hampered by motion artifacts caused by infant head
movements during image acquisition. Methods have been developed to remove or
minimize these artifacts during image reconstruction using frequency domain
data. However, frequency domain data might not always be available. Hence, in
this study we propose a method for removing motion artifacts from the already
reconstructed MR scans. The method employs a generative adversarial network
trained with a cycle consistency loss to transform slices affected by motion
into slices without motion artifacts, and vice versa. In the experiments 40
T2-weighted coronal MR scans of preterm born infants imaged at 30 weeks
postmenstrual age were used. All images contained slices affected by motion
artifacts hampering automatic tissue segmentation. To evaluate whether
correction allows more accurate image segmentation, the images were segmented
into 8 tissue classes: cerebellum, myelinated white matter, basal ganglia and
thalami, ventricular cerebrospinal fluid, white matter, brain stem, cortical
gray matter, and extracerebral cerebrospinal fluid. Images corrected for motion
and corresponding segmentations were qualitatively evaluated using 5-point
Likert scale. Before the correction of motion artifacts, median image quality
and quality of corresponding automatic segmentations were assigned grade 2
(poor) and 3 (moderate), respectively. After correction of motion artifacts,
both improved to grades 3 and 4, respectively. The results indicate that
correction of motion artifacts in the image space using the proposed approach
allows accurate segmentation of brain tissue classes in slices affected by
motion artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04713</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04713</id><created>2019-06-11</created><authors><author><keyname>Khalili</keyname><forenames>N.</forenames></author><author><keyname>Lessmann</keyname><forenames>N.</forenames></author><author><keyname>Turk</keyname><forenames>E.</forenames></author><author><keyname>Claessens</keyname><forenames>N.</forenames></author><author><keyname>de Heus</keyname><forenames>R.</forenames></author><author><keyname>Kolk</keyname><forenames>T.</forenames></author><author><keyname>Viergever</keyname><forenames>M. A.</forenames></author><author><keyname>Benders</keyname><forenames>M. J. N. L.</forenames></author><author><keyname>Isgum</keyname><forenames>I.</forenames></author></authors><title>Automatic brain tissue segmentation in fetal MRI using convolutional
  neural networks</title><categories>eess.IV cs.CV</categories><comments>Published in Magnetic Resonance Imaging, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MR images of fetuses allow clinicians to detect brain abnormalities in an
early stage of development. The cornerstone of volumetric and morphologic
analysis in fetal MRI is segmentation of the fetal brain into different tissue
classes. Manual segmentation is cumbersome and time consuming, hence automatic
segmentation could substantially simplify the procedure. However, automatic
brain tissue segmentation in these scans is challenging owing to artifacts
including intensity inhomogeneity, caused in particular by spontaneous fetal
movements during the scan. Unlike methods that estimate the bias field to
remove intensity inhomogeneity as a preprocessing step to segmentation, we
propose to perform segmentation using a convolutional neural network that
exploits images with synthetically introduced intensity inhomogeneity as data
augmentation. The method first uses a CNN to extract the intracranial volume.
Thereafter, another CNN with the same architecture is employed to segment the
extracted volume into seven brain tissue classes: cerebellum, basal ganglia and
thalami, ventricular cerebrospinal fluid, white matter, brain stem, cortical
gray matter and extracerebral cerebrospinal fluid. To make the method
applicable to slices showing intensity inhomogeneity artifacts, the training
data was augmented by applying a combination of linear gradients with random
offsets and orientations to image slices without artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04720</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04720</id><created>2019-06-11</created><authors><author><keyname>Sung</keyname><forenames>Yongjin</forenames></author></authors><title>Snapshot projection optical tomography</title><categories>physics.optics eess.IV physics.bio-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new plenoptic microscopy configuration consisting of an
objective lens and a micro-lens array (MLA), which is used as a tube lens. The
new system that we named as snapshot projection optical tomography (SPOT) can
directly record the projection images corresponding with different viewing
angles, and it contrasts with existing plenoptic imaging, which uses an MLA as
a Shack-Hartmann sensor. For a theoretical analysis, we extended a 3-D forward
imaging model for high-NA telecentric system. We also acquired the image of a
6-$\mu$m fluorescence bead, which clearly showed the optical-sectioning
capability of SPOT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04735</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04735</id><created>2019-06-11</created><authors><author><keyname>Abbara</keyname><forenames>Alia</forenames></author><author><keyname>Baker</keyname><forenames>Antoine</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>On the Universality of Noiseless Linear Estimation with Respect to the
  Measurement Matrix</title><categories>stat.ML cs.IT cs.LG eess.SP math.IT math.ST stat.TH</categories><comments>13 pages, 4 figures</comments><journal-ref>Journal of Physics A: Mathematical and Theoretical (2019)</journal-ref><doi>10.1088/1751-8121/ab59ef</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a noiseless linear estimation problem, one aims to reconstruct a vector x*
from the knowledge of its linear projections y=Phi x*. There have been many
theoretical works concentrating on the case where the matrix Phi is a random
i.i.d. one, but a number of heuristic evidence suggests that many of these
results are universal and extend well beyond this restricted case. Here we
revisit this problematic through the prism of development of message passing
methods, and consider not only the universality of the l1 transition, as
previously addressed, but also the one of the optimal Bayesian reconstruction.
We observed that the universality extends to the Bayes-optimal minimum
mean-squared (MMSE) error, and to a range of structured matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04739</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04739</id><created>2019-06-11</created><authors><author><keyname>Shafiei</keyname><forenames>Sajjad</forenames></author><author><keyname>Mihaita</keyname><forenames>Adriana-Simona</forenames></author><author><keyname>Cai</keyname><forenames>Chen</forenames></author></authors><title>Trip Table Estimation and Prediction for Dynamic Traffic Assignment
  Applications</title><categories>eess.SP cs.AI cs.LG stat.ML</categories><comments>6 pages, 6 figures, preprint at the 26th ITS World Congress 21-25 Oct
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study focuses on estimating and predicting time-varying origin to
destination (OD) trip tables for a dynamic traffic assignment (DTA) model. A
bi-level optimisation problem is formulated and solved to estimate OD flows
from pre-existent demand matrix and historical traffic flow counts. The
estimated demand is then considered as an input for a time series OD demand
prediction model to support the DTA model for short-term traffic condition
forecasting. Results show a high capability of the proposed OD demand
estimation method to reduce the DTA model error through an iterative solution
algorithm. Moreover, the applicability of the OD demand prediction approach is
investigated for an incident analysis application for a major corridor in
Sydney, Australia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04749</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04749</id><created>2019-06-11</created><authors><author><keyname>Wang</keyname><forenames>Chao</forenames></author><author><keyname>Ballard</keyname><forenames>Grey</forenames></author><author><keyname>Plemmons</keyname><forenames>Robert</forenames></author><author><keyname>Prasad</keyname><forenames>Sudhakar</forenames></author></authors><title>Joint 3D Localization and Classification of Space Debris using a
  Multispectral Rotating Point Spread Function</title><categories>eess.IV cs.CV cs.NA math.NA</categories><comments>25 pages</comments><doi>10.1364/AO.58.008598</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of joint three-dimensional (3D) localization and
material classification of unresolved space debris using a multispectral
rotating point spread function (RPSF). The use of RPSF allows one to estimate
the 3D locations of point sources from their rotated images acquired by a
single 2D sensor array, since the amount of rotation of each source image about
its x, y location depends on its axial distance z. Using multi-spectral images,
with one RPSF per spectral band, we are able not only to localize the 3D
positions of the space debris but also classify their material composition. We
propose a three-stage method for achieving joint localization and
classification. In Stage 1, we adopt an optimization scheme for localization in
which the spectral signature of each material is assumed to be uniform, which
significantly improves efficiency and yields better localization results than
possible with a single spectral band. In Stage 2, we estimate the spectral
signature and refine the localization result via an alternating approach. We
process classification in the final stage. Both Poisson noise and Gaussian
noise models are considered, and the implementation of each is discussed.
Numerical tests using multispectral data from NASA show the efficiency of our
three-stage approach and illustrate the improvement of point source
localization and spectral classification from using multiple bands over a
single band.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04762</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04762</id><created>2019-06-11</created><updated>2019-12-20</updated><authors><author><keyname>Pereira</keyname><forenames>Marcus A</forenames></author><author><keyname>Wang</keyname><forenames>Ziyi</forenames></author><author><keyname>Chen</keyname><forenames>Tianrong</forenames></author><author><keyname>Reed</keyname><forenames>Emily</forenames></author><author><keyname>Theodorou</keyname><forenames>Evangelos A</forenames></author></authors><title>Deep 2FBSDEs For Systems With Control Multiplicative Noise</title><categories>cs.LG cs.SY eess.SY math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deep recurrent neural network architecture to solve a class of
stochastic optimal control problems described by fully nonlinear Hamilton
Jacobi Bellmanpartial differential equations. Such PDEs arise when one
considers stochastic dynamics characterized by uncertainties that are additive
and control multiplicative. Stochastic models with the aforementioned
characteristics have been used in computational neuroscience, biology, finance
and aerospace systems and provide a more accurate representation of actuation
than models with additive uncertainty. Previous literature has established the
inadequacy of the linear HJB theory and instead rely on a non-linear
Feynman-Kac lemma resulting in a second order forward-backward stochastic
differential equations representation. However, the proposed solutions that use
this representation suffer from compounding errors and computational complexity
leading to lack of scalability. In this paper, we propose a deep learning based
algorithm that leverages the second order Forward-Backward SDE representation
and LSTM based recurrent neural networks to not only solve such Stochastic
Optimal Control problems but also overcome the problems faced by previous
approaches and scales well to high dimensional systems. The resulting control
algorithm is tested on non-linear systems in robotics and biomechanics to
demonstrate feasibility and out-performance against previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04775</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04775</id><created>2019-06-07</created><authors><author><keyname>&#xc7;iflikli</keyname><forenames>Cebrail</forenames></author><author><keyname>Al-Obaidi</keyname><forenames>Waeal</forenames></author><author><keyname>Al-Obaidi</keyname><forenames>Musaab</forenames></author></authors><title>The Performance Of Convolutional Coding Based Cooperative Communication:
  Relay Position And Power Allocation Analysis</title><categories>eess.SP</categories><doi>10.5121/ijcnc.2019.11304</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Wireless communication faces adversities due to noise, fading, and path loss.
Multiple-Input Multiple-Output (MIMO) systems are used to overcome individual
fading effect by employing transmit diversity. Duo to user single-antenna,
Cooperation between at least two users is able to provide spatial diversity.
This paper presents the evaluation of the performances of the Amplify and
Forward (AF) cooperative system for different relay positions using several
network topologies over Rayleigh and Rician fading channel. Furthermore, we
present the performances of AF cooperative system with various power
allocation. The results show that cooperative communication with convolutional
coding shows an outperformance compared to the non-convolutional, which is a
promising solution for high data-rate networks such as (WSN), Ad hoc, (IoT),
and even mobile networks. When topologies are compared, the simulation shows
that, linear topology offers the best BER performance, in contrast when the
relay acts as source and the source take the relay place, the analysis result
shows that, equilateral triangle topology has the best BER performance and
stability, and the system performance with inter-user Rician fading channel is
better than the performance of the system with inter-user Rayleigh fading
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04803</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04803</id><created>2019-06-11</created><updated>2019-12-11</updated><authors><author><keyname>Hoeller-Jr.</keyname><forenames>Arliones</forenames></author><author><keyname>Souza</keyname><forenames>Richard Demo</forenames></author><author><keyname>Alves</keyname><forenames>Hirley</forenames></author><author><keyname>L&#xf3;pez</keyname><forenames>Onel L. Alcaraz</forenames></author><author><keyname>Montejo-S&#xe1;nchez</keyname><forenames>Samuel</forenames></author><author><keyname>Pellenz</keyname><forenames>Marcelo Eduardo</forenames></author></authors><title>Optimum LoRaWAN Configuration Under Wi-SUN Interference</title><categories>eess.SP cs.NI</categories><comments>11 pages, 6 figures, published on IEEE Access</comments><journal-ref>IEEE Access, vol. 7, pp. 170936-170948, 2019</journal-ref><doi>10.1109/ACCESS.2019.2955750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart Utility Networks (SUN) rely on the Wireless-SUN (Wi-SUN) specification
for years. Recently practitioners and researchers have considered Low-Power
Wide-Area Networks (LPWAN) like LoRaWAN for SUN applications. With distinct
technologies deployed in the same area and sharing unlicensed bands, one can
expect these networks to interfere with one another. This paper builds over a
LoRaWAN model to optimize network parameters while accounting for
inter-technology interference. Our analytic model accounts for the interference
LoRaWAN receives from IEEE 802.15.4g networks, which forms the bottom layers of
Wi-SUN systems. We derive closed-form equations for the expected reliability of
LoRaWAN in such scenarios. We set the model parameters with data from real
measurements of the interplay among the technologies. Finally, we propose two
optimization algorithms to determine the best LoRaWAN configurations, given a
targeted minimum reliability level. The algorithms maximize either
communication range or the number of users given constraints on the minimum
number of users, minimum communication range, and minimum reliability. We
validate the models and algorithms through numerical analysis and simulations.
The proposed methods are useful tools for planning interference-limited
networks with requirements of minimum reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04810</identifier>
 <datestamp>2020-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04810</id><created>2019-06-11</created><updated>2020-02-18</updated><authors><author><keyname>Abate</keyname><forenames>Matthew</forenames></author><author><keyname>Klett</keyname><forenames>Corbin</forenames></author><author><keyname>Coogan</keyname><forenames>Samuel</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Lyapunov Differential Equation Hierarchy and Polynomial Lyapunov
  Functions for Switched Linear Systems</title><categories>eess.SY cs.SY</categories><comments>8 pages, 2 figures</comments><msc-class>93D05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the problem of searching for homogeneous polynomial
Lyapunov functions for stable switched linear systems. Specifically, we show an
equivalence between polynomial Lyapunov functions for systems of this class and
quadratic Lyapunov functions for a related hierarchy of Lyapunov differential
equations. This creates an intuitive procedure for checking the stability
properties of switched linear systems and a computationally competitive
algorithm is presented for generating high-order homogeneous polynomial
Lyapunov functions in this manner. Additionally, we provide a comparison
between polynomial Lyapunov functions generated with our proposed approach and
polynomial Lyapunov functions generated with a more traditional sum-of-squares
based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04888</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04888</id><created>2019-06-11</created><authors><author><keyname>Chavez</keyname><forenames>Arturo Gomez</forenames></author><author><keyname>Xu</keyname><forenames>Qingwen</forenames></author><author><keyname>Mueller</keyname><forenames>Christian A.</forenames></author><author><keyname>Schwertfeger</keyname><forenames>S&#xf6;ren</forenames></author><author><keyname>Birk</keyname><forenames>Andreas</forenames></author></authors><title>Adaptive Navigation Scheme for Optimal Deep-Sea Localization Using
  Multimodal Perception Cues</title><categories>cs.RO cs.CV cs.SY eess.SY</categories><comments>Submitted to IROS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underwater robot interventions require a high level of safety and
reliability. A major challenge to address is a robust and accurate acquisition
of localization estimates, as it is a prerequisite to enable more complex
tasks, e.g. floating manipulation and mapping. State-of-the-art navigation in
commercial operations, such as oil &amp; gas production (OGP), rely on costly
instrumentation. These can be partially replaced or assisted by visual
navigation methods, especially in deep-sea scenarios where equipment deployment
has high costs and risks. Our work presents a multimodal approach that adapts
state-of-the-art methods from on-land robotics, i.e., dense point cloud
generation in combination with plane representation and registration, to boost
underwater localization performance. A two-stage navigation scheme is proposed
that initially generates a coarse probabilistic map of the workspace, which is
used to filter noise from computed point clouds and planes in the second stage.
Furthermore, an adaptive decision-making approach is introduced that determines
which perception cues to incorporate into the localization filter to optimize
accuracy and computation performance. Our approach is investigated first in
simulation and then validated with data from field trials in OGP monitoring and
maintenance scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04926</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04926</id><created>2019-06-11</created><updated>2019-06-13</updated><authors><author><keyname>Chen</keyname><forenames>Yize</forenames></author><author><keyname>Tan</keyname><forenames>Yushi</forenames></author><author><keyname>Zhang</keyname><forenames>Ling</forenames></author><author><keyname>Zhang</keyname><forenames>Baosen</forenames></author></authors><title>Vulnerabilities of Power System Operations to Load Forecasting Data
  Injection Attacks</title><categories>math.OC eess.SP</categories><comments>11 pages, 10 figures; in submission to journal. Extended and journal
  version to arXiv:1904.06606</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the security threats of power system operation brought by a class of
data injection attacks upon load forecasting algorithms. In particular, with
minimal assumptions on the knowledge and ability of the attacker, we design
attack data on input features for load forecasting algorithms in a black-box
approach. System operators can be oblivious of such wrong load forecasts, which
lead to uneconomical or even insecure decisions in commitment and dispatch.
This paper is the first attempt to bring up the security issues of load
forecasting algorithms to our knowledge, and show that accurate load
forecasting algorithm is not necessarily robust to malicious attacks. More
severely, attackers are able to design targeted attacks on system operations
strategically with additional topology information. We demonstrate the impact
of load forecasting attacks on two IEEE test cases. We show our attack strategy
is able to cause load shedding with high probability under various settings in
the 14-bus test case, and also demonstrate system-wide threats in the 118-bus
test case with limited local attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04962</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04962</id><created>2019-06-12</created><updated>2019-08-12</updated><authors><author><keyname>Han</keyname><forenames>Changhee</forenames></author><author><keyname>Kitamura</keyname><forenames>Yoshiro</forenames></author><author><keyname>Kudo</keyname><forenames>Akira</forenames></author><author><keyname>Ichinose</keyname><forenames>Akimichi</forenames></author><author><keyname>Rundo</keyname><forenames>Leonardo</forenames></author><author><keyname>Furukawa</keyname><forenames>Yujiro</forenames></author><author><keyname>Umemoto</keyname><forenames>Kazuki</forenames></author><author><keyname>Li</keyname><forenames>Yuanzhong</forenames></author><author><keyname>Nakayama</keyname><forenames>Hideki</forenames></author></authors><title>Synthesizing Diverse Lung Nodules Wherever Massively: 3D
  Multi-Conditional GAN-based CT Image Augmentation for Object Detection</title><categories>cs.CV eess.IV</categories><comments>9 pages, 6 figures, accepted to 3DV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate Computer-Assisted Diagnosis, relying on large-scale annotated
pathological images, can alleviate the risk of overlooking the diagnosis.
Unfortunately, in medical imaging, most available datasets are
small/fragmented. To tackle this, as a Data Augmentation (DA) method, 3D
conditional Generative Adversarial Networks (GANs) can synthesize desired
realistic/diverse 3D images as additional training data. However, no 3D
conditional GAN-based DA approach exists for general bounding box-based 3D
object detection, while it can locate disease areas with physicians' minimum
annotation cost, unlike rigorous 3D segmentation. Moreover, since lesions vary
in position/size/attenuation, further GAN-based DA performance requires
multiple conditions. Therefore, we propose 3D Multi-Conditional GAN (MCGAN) to
generate realistic/diverse 32 X 32 X 32 nodules placed naturally on lung
Computed Tomography images to boost sensitivity in 3D object detection. Our
MCGAN adopts two discriminators for conditioning: the context discriminator
learns to classify real vs synthetic nodule/surrounding pairs with noise
box-centered surroundings; the nodule discriminator attempts to classify real
vs synthetic nodules with size/attenuation conditions. The results show that 3D
Convolutional Neural Network-based detection can achieve higher sensitivity
under any nodule size/attenuation at fixed False Positive rates and overcome
the medical data paucity with the MCGAN-generated realistic nodules---even
expert physicians fail to distinguish them from the real ones in Visual Turing
Test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04968</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04968</id><created>2019-06-12</created><updated>2019-06-17</updated><authors><author><keyname>Zhang</keyname><forenames>Xinglong</forenames></author><author><keyname>Jiang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Zhizhong</forenames></author><author><keyname>Song</keyname><forenames>Shengli</forenames></author></authors><title>A hierarchical Lyapunov-based cascade adaptive control scheme for
  lower-limb exoskeleton</title><categories>eess.SY cs.SY</categories><comments>12 pages, 10 figures, 1 table</comments><journal-ref>European Journal of Control, available online 9 June 2019</journal-ref><doi>10.1016/j.ejcon.2019.06.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a hierarchical Lyapunov-based adaptive cascade control
scheme for a lower-limb exoskeleton with control saturation. The proposed
approach is composed by two control levels with cascade structure. At the
higher layer of the structure, a Lyapunov-based back-stepping regulator
including adaptive estimation of uncertain parameters and friction force is
designed for the leg dynamics, to minimize the deviation of the joint position
and its reference value. At the lower layer, a Lyapunov-based neural network
adaptive controller is in charge of computing control action for the hydraulic
servo system, to follow the force reference computed at the high level, also to
compensate for model uncertainty, nonlinearity, and control saturation. The
proposed approach shows to be capable in minimizing the interaction torque
between machine and human, and suitable for possible imprecise models. The
robustness of the closed-loop system is discussed under input constraint.
Simulation experiments are reported, which shows that the proposed scheme is
effective in imposing smaller interaction torque with respect to PD controller,
and in control of models with uncertainty and nonlinearity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04972</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04972</id><created>2019-06-12</created><authors><author><keyname>Won</keyname><forenames>Minz</forenames></author><author><keyname>Chun</keyname><forenames>Sanghyuk</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Toward Interpretable Music Tagging with Self-Attention</title><categories>cs.SD eess.AS</categories><comments>13 pages, 12 figures; code:
  https://github.com/minzwon/self-attention-music-tagging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-attention is an attention mechanism that learns a representation by
relating different positions in the sequence. The transformer, which is a
sequence model solely based on self-attention, and its variants achieved
state-of-the-art results in many natural language processing tasks. Since music
composes its semantics based on the relations between components in sparse
positions, adopting the self-attention mechanism to solve music information
retrieval (MIR) problems can be beneficial. Hence, we propose a self-attention
based deep sequence model for music tagging. The proposed architecture consists
of shallow convolutional layers followed by stacked Transformer encoders.
Compared to conventional approaches using fully convolutional or recurrent
neural networks, our model is more interpretable while reporting competitive
results. We validate the performance of our model with the MagnaTagATune and
the Million Song Dataset. In addition, we demonstrate the interpretability of
the proposed architecture with a heat map visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04994</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.04994</id><created>2019-06-12</created><authors><author><keyname>Halbauer</keyname><forenames>Hardy</forenames></author><author><keyname>Weber</keyname><forenames>Andreas</forenames></author><author><keyname>Wiegner</keyname><forenames>Dirk</forenames></author><author><keyname>Wild</keyname><forenames>Thorsten</forenames></author></authors><title>Energy Efficient Massive MIMO Array Configurations</title><categories>eess.SP</categories><doi>10.1109/GLOCOMW.2018.8644331</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high spectral efficiency of massive MIMO (Multiple Input Multiple Output)
is mainly achieved through the exploitation of spatial multiplexing, i.e. by
using a high number of MIMO layers that are applied simultaneously to many
users. The power consumption of a massive MIMO base station is determined by
the hardware driving a high number of antenna ports and elements. This paper
focuses on practical deployment situations with varying user load. During hours
with low number of users a certain significant part of hardware power
consumption would remain with conventional massive MIMO processing, while the
full potential of spectral efficiency cannot be exploited due to the low number
of users, resulting in low power efficiency and cost. We investigate the impact
of different hybrid array architectures on spectral efficiency, average user
throughput and power consumption and show how to design a massive MIMO system
with significantly improved energy efficiency for a given target scenario,
while maintaining a targeted service quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05008</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05008</id><created>2019-06-12</created><authors><author><keyname>Dlamini</keyname><forenames>Thembelihle</forenames></author><author><keyname>Gamb&#x131;n</keyname><forenames>&#xc1;ngel Fernandez</forenames></author></authors><title>Adaptive Resource Management for a Virtualized Computing Platform within
  Edge Computing</title><categories>eess.SY cs.SY</categories><comments>9 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In virtualized computing platforms, energy consumption is related to the
computing-plus-communication processes. However, most of the proposed energy
consumption models and energy saving solutions found in literature consider
only the active Virtual Machines (VMs), thus the overall operational energy
expenditure is usually related to solely the computation process. To address
this shortcoming, in this paper we consider a computing-plus-communication
energy model, within the Multi-access Edge Computing (MEC) paradigm, and then
put forward a combination of a traffic engineering- and MEC Location
Service-based online server management algorithm with Energy Harvesting (EH)
capabilities, called Automated Resource Controller for Energy-aware Server
(ARCES), for autoscaling and reconfiguring the computing-plus-communication
resources. The main goal is to minimize the overall energy consumption, under
hard per-task delay constraints (i.e., Quality of Service (QoS)). ARCES jointly
performs (i) a short-term server demand and harvested solar energy forecasting,
(ii) VM soft-scaling, workload and processing rate allocation and lastly, (iii)
switching on/off of transmission drivers (i.e., fast tunable lasers) coupled
with the location-aware traffic scheduling. Our numerical results reveal that
ARCES achieves on average energy savings of 69%, and an energy consumption
ranging from 31%-45%and from 21%-25% at different values of per-VM
reconfiguration cost, with respect to the case where no energy management is
applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05015</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05015</id><created>2019-06-12</created><updated>2019-09-03</updated><authors><author><keyname>Zhu</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Xiao-Yang</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Deep Reinforcement Learning for Unmanned Aerial Vehicle-Assisted
  Vehicular Networks</title><categories>cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) are envisioned to complement the 5G
communication infrastructure in future smart cities. Hot spots easily appear in
road intersections, where effective communication among vehicles is
challenging. UAVs may serve as relays with the advantages of low price, easy
deployment, line-of-sight links, and flexible mobility. In this paper, we study
a UAV-assisted vehicular network where the UAV jointly adjusts its transmission
control (power and channel) and 3D flight to maximize the total throughput.
First, we formulate a Markov decision process (MDP) problem by modeling the
mobility of the UAV/vehicles and the state transitions. Secondly, we solve the
target problem using a deep reinforcement learning method, namely, the deep
deterministic policy gradient (DDPG), and propose three solutions with
different control objectives. Considering the energy consumption of 3D flight,
we extend the proposed solutions to maximize the total throughput per energy
unit by encouraging or discouraging the UAV's mobility. To achieve this goal,
the DDPG framework is modified. Thirdly, in a simplified model with small state
space and action space, we verify the optimality of proposed algorithms.
Comparing with two baseline schemes, we demonstrate the effectiveness of
proposed algorithms in a realistic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05023</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05023</id><created>2019-06-12</created><authors><author><keyname>Wan</keyname><forenames>Shuo</forenames></author><author><keyname>Lu</keyname><forenames>Jiaxun</forenames></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Towards Big data processing in IoT: Path Planning and Resource
  Management of UAV Base Stations in Mobile-Edge Computing System</title><categories>cs.NI cs.IT cs.SY eess.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heavy data load and wide cover range have always been crucial problems for
online data processing in internet of things (IoT). Recently, mobile-edge
computing (MEC) and unmanned aerial vehicle base stations (UAV-BSs) have
emerged as promising techniques in IoT. In this paper, we propose a three-layer
online data processing network based on MEC technique. On the bottom layer, raw
data are generated by widely distributed sensors, which reflects local
information. Upon them, unmanned aerial vehicle base stations (UAV-BSs) are
deployed as moving MEC servers, which collect data and conduct initial steps of
data processing. On top of them, a center cloud receives processed results and
conducts further evaluation. As this is an online data processing system, the
edge nodes should stabilize delay to ensure data freshness. Furthermore,
limited onboard energy poses constraints to edge processing capability. To
smartly manage network resources for saving energy and stabilizing delay, we
develop an online determination policy based on Lyapunov Optimization. In cases
of low data rate, it tends to reduce edge processor frequency for saving
energy. In the presence of high data rate, it will smartly allocate bandwidth
for edge data offloading. Meanwhile, hovering UAV-BSs bring a large and
flexible service coverage, which results in the problem of effective path
planning. In this paper, we apply deep reinforcement learning and develop an
online path planning algorithm. Taking observations of around environment as
input, a CNN network is trained to predict the reward of each action. By
simulations, we validate its effectiveness in enhancing service coverage. The
result will contribute to big data processing in future IoT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05085</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05085</id><created>2019-06-12</created><updated>2019-11-28</updated><authors><author><keyname>K&#xf6;pf</keyname><forenames>Florian</forenames></author><author><keyname>Westermann</keyname><forenames>Johannes</forenames></author><author><keyname>Flad</keyname><forenames>Michael</forenames></author><author><keyname>Hohmann</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Adaptive Optimal Control for Reference Tracking Independent of
  Exo-System Dynamics</title><categories>eess.SY cs.LG cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-free control based on the idea of Reinforcement Learning is a promising
approach that has recently gained extensive attention. However,
Reinforcement-Learning-based control methods solely focus on the regulation
problem or learn to track a reference that is generated by a time-invariant
exo-system. In the latter case, controllers are only able to track the
time-invariant reference dynamics which they have been trained on and need to
be re-trained each time the reference dynamics change. Consequently, these
methods fail in a number of applications which obviously rely on a trajectory
not being generated by an exo-system. One prominent example is autonomous
driving. This paper provides for the first time an adaptive optimal control
method capable to track reference trajectories not being generated by a
time-invariant exo-system. The main innovation is a novel Q-function that
directly incorporates a given reference trajectory on a moving horizon. This
new Q-function exhibits a particular structure which allows the design of an
efficient, iterative, provably convergent Reinforcement Learning algorithm that
enables optimal tracking. Two real-world examples demonstrate the effectiveness
of our new method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05096</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05096</id><created>2019-06-03</created><authors><author><keyname>Liu</keyname><forenames>Runze</forenames></author><author><keyname>Yang</keyname><forenames>Jianlei</forenames></author><author><keyname>Chen</keyname><forenames>Yiran</forenames></author><author><keyname>Zhao</keyname><forenames>Weisheng</forenames></author></authors><title>eSLAM: An Energy-Efficient Accelerator for Real-Time ORB-SLAM on FPGA
  Platform</title><categories>eess.SP cs.CV cs.RO eess.IV</categories><comments>to appear in DAC 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Simultaneous Localization and Mapping (SLAM) is a critical task for
autonomous navigation. However, due to the computational complexity of SLAM
algorithms, it is very difficult to achieve real-time implementation on
low-power platforms.We propose an energy efficient architecture for real-time
ORB (Oriented-FAST and Rotated- BRIEF) based visual SLAM system by accelerating
the most time consuming stages of feature extraction and matching on FPGA
platform.Moreover, the original ORB descriptor pattern is reformed as a
rotational symmetric manner which is much more hardware friendly. Optimizations
including rescheduling and parallelizing are further utilized to improve the
throughput and reduce the memory footprint. Compared with Intel i7 and ARM
Cortex-A9 CPUs on TUM dataset, our FPGA realization achieves up to 3X and 31X
frame rate improvement, as well as up to 71X and 25X energy efficiency
improvement, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05113</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05113</id><created>2019-06-12</created><updated>2020-01-06</updated><authors><author><keyname>Yurtsever</keyname><forenames>Ekim</forenames></author><author><keyname>Lambert</keyname><forenames>Jacob</forenames></author><author><keyname>Carballo</keyname><forenames>Alexander</forenames></author><author><keyname>Takeda</keyname><forenames>Kazuya</forenames></author></authors><title>A Survey of Autonomous Driving: Common Practices and Emerging
  Technologies</title><categories>cs.RO cs.SY eess.SY</categories><comments>26 pages, 15 figures. Submitted to IEEE Transactions on Intelligent
  Vehicles -V2: Minor edits in References</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated driving systems (ADSs) promise a safe, comfortable and efficient
driving experience. However, fatalities involving vehicles equipped with ADSs
are on the rise. The full potential of ADSs cannot be realized unless the
robustness of state-of-the-art improved further. This paper discusses unsolved
problems and surveys the technical aspect of automated driving. Studies
regarding present challenges, high-level system architectures, emerging
methodologies and core functions: localization, mapping, perception, planning,
and human machine interface, were thoroughly reviewed. Furthermore, the
state-of-the-art was implemented on our own platform and various algorithms
were compared in a real-world driving setting. The paper concludes with an
overview of available datasets and tools for ADS development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05117</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05117</id><created>2019-06-07</created><authors><author><keyname>Byreddy</keyname><forenames>P. R.</forenames></author><author><keyname>Chen</keyname><forenames>Z.</forenames></author><author><keyname>Bakshi</keyname><forenames>H. S.</forenames></author><author><keyname>Choi</keyname><forenames>W.</forenames></author><author><keyname>Blanchard</keyname><forenames>A.</forenames></author><author><keyname>O</keyname><forenames>K. K.</forenames></author></authors><title>274-GHz CMOS Signal Generator with an On-Chip Patch Antenna in a QFN
  Package</title><categories>eess.SP</categories><comments>2 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A 274-GHz signal generator with an on-chip antenna in a quad-flat no-leads
(QFN) package is demonstrated. The circuit is fabricated in a 65-nm
Complementary Metal Oxide Semiconductor (CMOS) process. The effective isotropic
radiated power (EIRP) measured from the packaged signal generator is -12.8-dBm
at 274GHz with DC power consumption of 26.3mW. The packaging material can help
improve the antenna performance, and integrated circuits with on-chip antennas
operating at ~300GHz can be packaged using low-cost techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05122</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05122</id><created>2019-06-10</created><authors><author><keyname>Yoshida</keyname><forenames>Tsuyoshi</forenames></author><author><keyname>Karlsson</keyname><forenames>Magnus</forenames></author><author><keyname>Agrell</keyname><forenames>Erik</forenames></author></authors><title>Preferred Design of Hierarchical Distribution Matching</title><categories>eess.SP</categories><comments>3 pages, 1 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distribution matching and dematching (DM/invDM) are key functions in
probabilistic shaping (PS). Recently techniques for low complexity
implementation of DM/invDM have been well studied. Our previously proposed
hierarchical DM (HiDM) is one of the good candidates, with capacity-approaching
performance with reasonable hardware resources. Though we explained the recipe
of HiDM construction with a small example having a short DM word length, there
might still be difficulties to expand it to longer DM word lengths. To improve
the reproducibility of our work, this paper explains the key parameters in an
HiDM having a DM word length more than 100 symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05125</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05125</id><created>2019-06-12</created><authors><author><keyname>Holme</keyname><forenames>H. Christian M.</forenames></author></authors><title>Preparatory data analysis for the reconstruction of real-time MRI data</title><categories>physics.med-ph eess.IV</categories><comments>Master's Thesis at the Georg-August Universit\&quot;at G\&quot;ottingen,
  submitted 2016-02-18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-time magnetic resonance imaging (MRI) poses unique challenges related to
the speed of data acquisition and to the degree of undersampling necessary to
achieve this speed. This Master's thesis introduces and evaluates two
pre-processing approaches for these problems: Coil compression to reduce the
data volume and a channel selection algorithm to reduce streak artifacts which
arise as a consequence of undersampling. Both approaches are tested on real
data covering anatomical imaging of the head and of the heart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05169</identifier>
 <datestamp>2020-01-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05169</id><created>2019-06-12</created><updated>2020-01-03</updated><authors><author><keyname>Chevalier</keyname><forenames>Samuel</forenames></author><author><keyname>Vorobev</keyname><forenames>Petr</forenames></author><author><keyname>Turitsyn</keyname><forenames>Konstantin</forenames></author></authors><title>A Passivity Interpretation of Energy-Based Forced Oscillation Source
  Location Methods</title><categories>eess.SY cs.SY</categories><comments>14 pages, re-submitted to IEEE TPWRS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a systematic framework for analyzing how low frequency
forced oscillations propagate in electric power systems. Using this framework,
the paper shows how to mathematically justify the so-called Dissipating Energy
Flow (DEF) forced oscillation source location technique. The DEF's specific
deficiencies are pinpointed, and its underlying energy function is analyzed via
incremental passivity theory. This analysis is then used to prove that there
exists no passivity transformation (i.e. quadratic energy function) which can
simultaneously render all components of a lossy classical power system passive.
The paper goes on to develop a simulation-free algorithm for predicting the
performance of the DEF method in a generalized power system, and it analyzes
the passivity of three non-classical load and generation components. The
proposed propagation framework and performance algorithm are both tested and
illustrated on the IEEE 39-bus New England system and the WECC 179-bus system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05174</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05174</id><created>2019-06-12</created><authors><author><keyname>Hanna</keyname><forenames>Samer</forenames></author><author><keyname>Krijestorac</keyname><forenames>Enes</forenames></author><author><keyname>Yan</keyname><forenames>Han</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>UAV Swarms as Amplify-and-Forward MIMO Relays</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles provide new opportunities for performance
improvements in future wireless communications systems. For example, they can
act as relays that extend the range of a communication link and improve the
capacity. Unlike conventional relays that are deployed at fixed locations, UAVs
can change their positions to optimize the capacity or range on demand. In this
paper, we consider using a swarm of UAVs as amplify-and-forward MIMO relays to
provide connectivity between an obstructed multi-antenna equipped source and
destination. We start by optimizing UAV placement for the single antenna case,
and analyze its dependence on the noise introduced by the relay, its gain, and
transmit power constraint. We extend our analysis for an arbitrary UAV swarm
and show how the MIMO link capacity can be optimized by changing the distance
of the swarm to the source and the destination. Then, we consider the effect of
optimizing the positions of the UAVs within the swarm and derive an upper bound
for the capacity at any given placement of the swarm. We also propose a simple
near optimal approach to find the positions that optimize the capacity for the
end-to-end link given that the source and the destination have uniform
rectangular arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05178</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05178</id><created>2019-06-12</created><authors><author><keyname>Duanmu</keyname><forenames>Zhengfang</forenames></author><author><keyname>Liu</keyname><forenames>Wentao</forenames></author><author><keyname>Wang</keyname><forenames>Zhou</forenames></author></authors><title>Modeling Generalized Rate-Distortion Functions</title><categories>eess.IV</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many multimedia applications require precise understanding of the
rate-distortion characteristics measured by the function relating visual
quality to media attributes, for which we term it the generalized
rate-distortion (GRD) function. In this study, we explore the GRD behavior of
compressed digital videos in a three-dimensional space of bitrate, resolution,
and viewing device/condition. Our analysis on a large-scale video dataset
reveals that empirical parametric models are systematically biased while
exhaustive search methods require excessive computation time to depict the GRD
surfaces. By exploiting the properties that all GRD functions share, we develop
an Robust Axial-Monotonic Clough-Tocher (RAMCT) interpolation method to model
the GRD function. This model allows us to accurately reconstruct the complete
GRD function of a source video content from a moderate number of measurements.
To further reduce the computational cost, we present a novel sampling scheme
based on a probabilistic model and an information measure. The proposed
sampling method constructs a sequence of quality queries by minimizing the
overall informativeness in the remaining samples. Experimental results show
that the proposed algorithm significantly outperforms state-of-the-art
approaches in accuracy and efficiency. Finally, we demonstrate the usage of the
proposed model in three applications: rate-distortion curve prediction,
per-title encoding profile generation, and video encoder comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05204</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05204</id><created>2019-06-12</created><updated>2020-02-22</updated><authors><author><keyname>Sharf</keyname><forenames>Miel</forenames></author><author><keyname>Koch</keyname><forenames>Anne</forenames></author><author><keyname>Zelazo</keyname><forenames>Daniel</forenames></author><author><keyname>Allg&#xf6;wer</keyname><forenames>Frank</forenames></author></authors><title>Model-Free Practical Cooperative Control for Diffusively Coupled Systems</title><categories>eess.SY cs.SY math.OC</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a data-based controller design framework for
diffusively coupled systems with guaranteed convergence to an
$\epsilon$-neighborhood of the desired formation. The controller is comprised
of a fixed controller with an adjustable gain on each edge. Via passivity
theory and network optimization we not only prove that there exists a gain
attaining the desired formation control goal, but we present a data-based
method to find an upper bound on this gain. Furthermore, by allowing for
additional experiments, the conservatism of the upper bound can be reduced via
iterative sampling schemes. The introduced scheme is based on the assumption of
passive systems, which we relax by discussing different methods for estimating
the systems' passivity shortage, as well as applying transformations
passivizing them. Finally, we illustrate the developed model-free cooperative
control scheme with a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05251</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05251</id><created>2019-06-11</created><authors><author><keyname>Dai</keyname><forenames>Yuxiang</forenames></author><author><keyname>Zhuang</keyname><forenames>Peixian</forenames></author></authors><title>Compressed Sensing MRI via a Multi-scale Dilated Residual Convolution
  Network</title><categories>cs.CV cs.LG eess.IV</categories><comments>27 pages and 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging (MRI) reconstruction is an active inverse problem
which can be addressed by conventional compressed sensing (CS) MRI algorithms
that exploit the sparse nature of MRI in an iterative optimization-based
manner. However, two main drawbacks of iterative optimization-based CSMRI
methods are time-consuming and are limited in model capacity. Meanwhile, one
main challenge for recent deep learning-based CSMRI is the trade-off between
model performance and network size. To address the above issues, we develop a
new multi-scale dilated network for MRI reconstruction with high speed and
outstanding performance. Comparing to convolutional kernels with same receptive
fields, dilated convolutions reduce network parameters with smaller kernels and
expand receptive fields of kernels to obtain almost same information. To
maintain the abundance of features, we present global and local residual
learnings to extract more image edges and details. Then we utilize
concatenation layers to fuse multi-scale features and residual learnings for
better reconstruction. Compared with several non-deep and deep learning CSMRI
algorithms, the proposed method yields better reconstruction accuracy and
noticeable visual improvements. In addition, we perform the noisy setting to
verify the model stability, and then extend the proposed model on a MRI
super-resolution task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05284</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05284</id><created>2019-06-12</created><updated>2019-11-25</updated><authors><author><keyname>Hussein</keyname><forenames>Shady Abu</forenames></author><author><keyname>Tirer</keyname><forenames>Tom</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author></authors><title>Image-Adaptive GAN based Reconstruction</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted to AAAI 2020. Code available at
  https://github.com/shadyabh/IAGAN</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent years, there has been a significant improvement in the quality
of samples produced by (deep) generative models such as variational
auto-encoders and generative adversarial networks. However, the representation
capabilities of these methods still do not capture the full distribution for
complex classes of images, such as human faces. This deficiency has been
clearly observed in previous works that use pre-trained generative models to
solve imaging inverse problems. In this paper, we suggest to mitigate the
limited representation capabilities of generators by making them image-adaptive
and enforcing compliance of the restoration with the observations via
back-projections. We empirically demonstrate the advantages of our proposed
approach for image super-resolution and compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05332</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05332</id><created>2019-06-12</created><authors><author><keyname>Gu</keyname><forenames>Xiuye</forenames></author><author><keyname>Wang</keyname><forenames>Yijie</forenames></author><author><keyname>wu</keyname><forenames>Chongruo</forenames></author><author><keyname>lee</keyname><forenames>Yong-Jae</forenames></author><author><keyname>Wang</keyname><forenames>Panqu</forenames></author></authors><title>HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow
  Estimation on Large-scale Point Clouds</title><categories>cs.CV cs.LG eess.IV</categories><journal-ref>CVPR 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel deep neural network architecture for end-to-end scene flow
estimation that directly operates on large-scale 3D point clouds. Inspired by
Bilateral Convolutional Layers (BCL), we propose novel DownBCL, UpBCL, and
CorrBCL operations that restore structural information from unstructured point
clouds, and fuse information from two consecutive point clouds. Operating on
discrete and sparse permutohedral lattice points, our architectural design is
parsimonious in computational cost. Our model can efficiently process a pair of
point cloud frames at once with a maximum of 86K points per frame. Our approach
achieves state-of-the-art performance on the FlyingThings3D and KITTI Scene
Flow 2015 datasets. Moreover, trained on synthetic data, our approach shows
great generalization ability on real-world data and on different point
densities without fine-tuning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05339</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05339</id><created>2019-06-12</created><authors><author><keyname>Buchhave</keyname><forenames>Preben</forenames></author><author><keyname>Velte</keyname><forenames>Clara M.</forenames></author><author><keyname>George</keyname><forenames>William K.</forenames></author></authors><title>The effect of dead time on randomly sampled power spectral estimates</title><categories>physics.flu-dyn eess.SP</categories><journal-ref>Experiments in Fluids, vol: 55, issue: 2, 2014</journal-ref><doi>10.1007/s00348-014-1680-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate power spectra of a randomly sampled stationary stochastic
signal, e.g. a spatial component of a turbulent velocity. We extend the methods
of previous authors that basically assumed point or delta function sampling by
including features characteristic of real measurement systems. We consider both
the effect on the measured spectrum of a finite sampling time, i.e., a finite
time during which the signal is acquired, and a finite dead time, that is a
time in which the signal processor is busy evaluating a data point and
therefore unable to measure a subsequent data point arriving within the dead
time delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05343</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05343</id><created>2019-06-12</created><authors><author><keyname>Buchhave</keyname><forenames>Preben</forenames></author><author><keyname>Velte</keyname><forenames>Clara M.</forenames></author></authors><title>Reduction of noise and bias in randomly sampled power spectra</title><categories>physics.flu-dyn eess.SP</categories><journal-ref>Experiments in Fluids, vol: 56, issue: 79, 2015</journal-ref><doi>10.1007/s00348-015-1922-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the origin of noise and distortions in power spectral estimates
of randomly sampled data, specifically velocity data measured with a burst-mode
laser Doppler anemometer. The analysis guides us to new ways of reducing noise
and removing spectral bias, e.g. distortions caused by modifications of the
ideal Poisson sample rate caused by dead time effects and correlations between
velocity and sample rate. The noise and dead time effects for finite records
are shown to tend to previous results for infinite time records and ensemble
averages. For finite records we show that the measured sampling function can be
used to correct the spectra for noise and dead time effects by a deconvolution
process. We also describe a novel version of a power spectral estimator based
on a fast slotted autocovariance algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05356</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05356</id><created>2019-06-11</created><authors><author><keyname>Mao</keyname><forenames>Tuo</forenames></author><author><keyname>Mihaita</keyname><forenames>Adriana-Simona</forenames></author><author><keyname>Cai</keyname><forenames>Chen</forenames></author></authors><title>Traffic signal control optimization under severe incident conditions
  using Genetic Algorithm</title><categories>eess.SY cs.LG cs.SY</categories><comments>14 pages, 15 figures, preprint for the 26th ITS World Congress 21-25
  Oct 2019, Singapore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic control optimization is a challenging task for various traffic
centres in the world and majority of approaches focus only on applying adaptive
methods under normal (recurrent) traffic conditions. But optimizing the control
plans when severe incidents occur still remains a hard topic to address,
especially if a high number of lanes or entire intersections are affected. This
paper aims at tackling this problem and presents a novel methodology for
optimizing the traffic signal timings in signalized urban intersections, under
non-recurrent traffic incidents. The approach relies on deploying genetic
algorithms (GA) by considering the phase durations as decision variables and
the objective function to minimize as the total travel time in the network.
Firstly, we develop the GA algorithm on a signalized testbed network under
recurrent traffic conditions, with the purpose of fine-tuning the algorithm for
crossover, mutation, fitness calculation, and obtain the optimal phase
durations. Secondly, we apply the optimal signal timings previously found under
severe incidents affecting the traffic flow in the network but without any
further optimization. Lastly, we further apply the GA optimization under
incident conditions and show that our approach improved the total travel time
by almost 40.76%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05360</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05360</id><created>2019-06-12</created><updated>2019-06-20</updated><authors><author><keyname>Chen</keyname><forenames>Mason T.</forenames></author><author><keyname>Mahmood</keyname><forenames>Faisal</forenames></author><author><keyname>Sweer</keyname><forenames>Jordan A.</forenames></author><author><keyname>Durr</keyname><forenames>Nicholas J.</forenames></author></authors><title>GANPOP: Generative Adversarial Network Prediction of Optical Properties
  from Single Snapshot Wide-field Images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deep learning framework for wide-field, content-aware estimation
of absorption and scattering coefficients of tissues, called Generative
Adversarial Network Prediction of Optical Properties (GANPOP). Spatial
frequency domain imaging is used to obtain ground-truth optical properties from
in vivo human hands, freshly resected human esophagectomy samples and
homogeneous tissue phantoms. Images of objects with either flat-field or
structured illumination are paired with registered optical property maps and
are used to train conditional generative adversarial networks that estimate
optical properties from a single input image. We benchmark this approach by
comparing GANPOP to a single-snapshot optical property (SSOP) technique, using
a normalized mean absolute error (NMAE) metric. In human gastrointestinal
specimens, GANPOP estimates both reduced scattering and absorption coefficients
at 660 nm from a single 0.2/mm spatial frequency illumination image with 58%
higher accuracy than SSOP. When applied to both in vivo and ex vivo swine
tissues, a GANPOP model trained solely on human specimens and phantoms
estimates optical properties with approximately 43% improvement over SSOP,
indicating adaptability to sample variety. Moreover, we demonstrate that GANPOP
estimates optical properties from flat-field illumination images with similar
error to SSOP, which requires structured-illumination. Given a training set
that appropriately spans the target domain, GANPOP has the potential to enable
rapid and accurate wide-field measurements of optical properties, even from
conventional imaging systems with flat-field illumination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05367</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05367</id><created>2019-06-12</created><authors><author><keyname>Stright</keyname><forenames>James</forenames></author><author><keyname>Edrington</keyname><forenames>Chris</forenames></author></authors><title>A steady-state stability analysis of uniform synchronous power grid
  topologies</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motter et al. derived a real-valued master stability function which
determines whether and to what degree a given power grid is asymptotically
stable. Stright and Edrington adopted certain uniformity assumptions on a
grid's components and demonstrated how differences in topologies obtained using
these components can affect the stabilities of the resulting grids. Building on
this work, we show via simulations the physical significance of stability as
opposed to instability. We show that for stable topologies, increased stability
can correspond to decreased generator torque ripple. We also describe how some
elementary changes in grid topology can affect stability values. Known
stability values for certain abstract circulant grids are used to quantify
stability enhancement as interconnection density increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05372</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05372</id><created>2019-06-12</created><updated>2019-06-15</updated><authors><author><keyname>Tan</keyname><forenames>Kiat Chuan</forenames></author><author><keyname>Liu</keyname><forenames>Yulong</forenames></author><author><keyname>Ambrose</keyname><forenames>Barbara</forenames></author><author><keyname>Tulig</keyname><forenames>Melissa</forenames></author><author><keyname>Belongie</keyname><forenames>Serge</forenames></author></authors><title>The Herbarium Challenge 2019 Dataset</title><categories>cs.CV eess.IV</categories><comments>Part of the 6th Fine-Grained Visual Categorization Workshop (FGVC6)
  at CVPR 2019. Dataset available at
  https://github.com/visipedia/herbarium_comp</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Herbarium sheets are invaluable for botanical research, and considerable time
and effort is spent by experts to label and identify specimens on them. In view
of recent advances in computer vision and deep learning, developing an
automated approach to help experts identify specimens could significantly
accelerate research in this area. Whereas most existing botanical datasets
comprise photos of specimens in the wild, herbarium sheets exhibit dried
specimens, which poses new challenges. We present a challenge dataset of
herbarium sheet images labeled by experts, with the intent of facilitating the
development of automated identification techniques for this challenging
scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05399</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05399</id><created>2019-06-12</created><authors><author><keyname>Costa</keyname><forenames>Marcelo Azevedo</forenames></author><author><keyname>Mineti</keyname><forenames>Leandro Brioschi</forenames></author><author><keyname>Prates</keyname><forenames>Marcos Oliveira</forenames></author><author><keyname>Cardenas</keyname><forenames>Ramiro Ruiz</forenames></author></authors><title>Dynamic Time Scan Forecasting</title><categories>stat.AP eess.SP stat.CO</categories><comments>15 pages, 7 figures, working paper, version 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic time scan forecasting method relies on the premise that the most
important pattern in a time series precedes the forecasting window, i.e., the
last observed values. Thus, a scan procedure is applied to identify similar
patterns, or best matches, throughout the time series. As oppose to euclidean
distance, or any distance function, a similarity function is dynamically
estimated in order to match previous values to the last observed values.
Goodness-of-fit statistics are used to find the best matches. Using the
respective similarity functions, the observed values proceeding the best
matches are used to create a forecasting pattern, as well as forecasting
intervals. Remarkably, the proposed method outperformed statistical and machine
learning approaches in a real case wind speed forecasting problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05421</identifier>
 <datestamp>2020-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05421</id><created>2019-06-12</created><updated>2020-01-21</updated><authors><author><keyname>Muthirayan</keyname><forenames>Deepan</forenames></author><author><keyname>Khargonekar</keyname><forenames>Pramod P.</forenames></author></authors><title>Memory Augmented Neural Network Adaptive Controller for Strict Feedback
  Nonlinear Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the adaptive nonlinear control problem for strict
feedback nonlinear systems, where the functions that determine the dynamics of
the system are completely unknown. We assume that certain upper bounds for the
functions $g_i$s of the system are known. The objective of the control design
is to design an adaptive controller that can adapt to changes in the unknown
functions that are even abrupt. We propose a novel backstepping memory
augmented NN (MANN) adaptive control method for the control of strict feedback
non-linear systems. Here, each NN, in the backstepping NN adaptive controller,
is augmented with an external working memory. The NN can write relevant
information to its working memory and later retrieve them to modify its output,
thus providing it with the capability to leverage past learned information
effectively and improve its speed of learning. We propose a specific design for
this external memory interface and show that the proposed control design
achieves bounded stability for the closed loop system. We also provide
substantial numerical evidence showing that the proposed memory augmentation
improves the speed of learning by a significant margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05427</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05427</id><created>2019-06-12</created><authors><author><keyname>Glickman</keyname><forenames>Mark E.</forenames></author><author><keyname>Brown</keyname><forenames>Jason I.</forenames></author><author><keyname>Song</keyname><forenames>Ryan B.</forenames></author></authors><title>(A) Data in the Life: Authorship Attribution of Lennon-McCartney Songs</title><categories>cs.SD eess.AS</categories><comments>44 pages, 5 figures</comments><msc-class>62P99, 62F15</msc-class><doi>10.1162/99608f92.130f856e</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The songwriting duo of John Lennon and Paul McCartney, the two founding
members of the Beatles, composed some of the most popular and memorable songs
of the last century. Despite having authored songs under the joint credit
agreement of Lennon-McCartney, it is well-documented that most of their songs
or portions of songs were primarily written by exactly one of the two.
Furthermore, the authorship of some Lennon-McCartney songs is in dispute, with
the recollections of authorship based on previous interviews with Lennon and
McCartney in conflict. For Lennon-McCartney songs of known and unknown
authorship written and recorded over the period 1962-66, we extracted musical
features from each song or song portion. These features consist of the
occurrence of melodic notes, chords, melodic note pairs, chord change pairs,
and four-note melody contours. We developed a prediction model based on
variable screening followed by logistic regression with elastic net
regularization. Out-of-sample classification accuracy for songs with known
authorship was 76\%, with a $c$-statistic from an ROC analysis of 83.7\%. We
applied our model to the prediction of songs and song portions with unknown or
disputed authorship.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05451</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05451</id><created>2019-06-12</created><authors><author><keyname>Zhang</keyname><forenames>Zhichao</forenames></author></authors><title>N-dimensional Heisenberg's uncertainty principle for fractional Fourier
  transform</title><categories>math-ph eess.SP math.FA math.MP</categories><comments>23 pages</comments><msc-class>28A10, 42A38, 42B10, 81V80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sharper uncertainty inequality which exhibits a lower bound larger than
that in the classical N-dimensional Heisenberg's uncertainty principle is
obtained, and extended from N-dimensional Fourier transform domain to two
N-dimensional fractional Fourier transform domains. The conditions that reach
the equality relation of the uncertainty inequalities are deduced. Example and
simulation are performed to illustrate that the newly derived uncertainty
principles are truly sharper than the existing ones in the literature. The new
proposals' applications in time-frequency and optical system analysis are also
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05453</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05453</id><created>2019-06-12</created><updated>2019-08-11</updated><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Cong</keyname><forenames>Yirui</forenames></author><author><keyname>Wang</keyname><forenames>Xiangke</forenames></author><author><keyname>Xu</keyname><forenames>Xin</forenames></author><author><keyname>Shen</keyname><forenames>Lincheng</forenames></author></authors><title>Coordinated Path Following Control of Fixed-wing Unmanned Aerial
  Vehicles</title><categories>eess.SY cs.SY eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the problem of coordinated path following for
fixed-wing UAVs with speed constraints in 2D plane. The objective is to steer a
fleet of UAVs along the path(s) while achieving the desired sequenced inter-UAV
arc distance. In contrast to the previous coordinated path following studies,
we are able through our proposed hybrid control law to deal with the forward
speed and the angular speed constraints of fixed-wing UAVs. More specifically,
the hybrid control law makes all the UAVs work at two different levels: those
UAVs whose path following errors are within an invariant set (i.e., the
designed coordination set) work at the coordination level; and the other UAVs
work at the single-agent level. At the coordination level, we prove that even
with speed constraints, the proposed control law can make sure the path
following errors reduce to zero, while the desired arc distances converge to
the desired value. At the single-agent level, the convergence analysis for the
path following error entering the coordination set is provided. We develop a
hardware-in-the-loop simulation testbed of the multi-UAV system by using actual
autopilots and the X-Plane simulator. The effectiveness of the proposed
approach is corroborated with both MATLAB and the testbed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05472</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05472</id><created>2019-06-13</created><authors><author><keyname>Riaz</keyname><forenames>Shariq</forenames></author><author><keyname>Mancarella</keyname><forenames>Pierluigi</forenames></author></authors><title>On Feasibility and Flexibility Operating Regions of Virtual Power Plants
  and TSO/DSO interfaces</title><categories>eess.SY cs.SY eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Distributed energy resources are an ideal candidate for the provision of
additional flexibility required by power system to support the increasing
penetration of renewable energy sources. The integrating large number of
resources in the existing market structure, particularly in the light of
providing flexibility services, is envisioned through the concept of virtual
power plant (VPP). To this end, it is crucial to establish a clear methodology
for VPP flexibility modelling. In this context, this paper first puts forward
the need to clarify the difference between feasibility and flexibility
potential of a VPP, and then propose a methodology for the evaluation of
relevant operating regions. Similar concepts can also be used to modelling
TSO/DSO interface operation. Several case studies are designed to reflect the
distinct information conveyed by feasibility and flexibility operating regions
in the presence of &quot;slow&quot; and &quot;fast&quot; responding resources for a VPP partaking
in provision of energy and grid support services. The results also highlight
the impact of flexible load and importantly network topology on the VPP
feasibility (FOR) and flexibility (FXOR) operating regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05478</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05478</id><created>2019-06-13</created><updated>2020-02-08</updated><authors><author><keyname>Mohan</keyname><forenames>Sreyas</forenames></author><author><keyname>Kadkhodaie</keyname><forenames>Zahra</forenames></author><author><keyname>Simoncelli</keyname><forenames>Eero P.</forenames></author><author><keyname>Fernandez-Granda</keyname><forenames>Carlos</forenames></author></authors><title>Robust and interpretable blind image denoising via bias-free
  convolutional neural networks</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Published as conference paper in ICLR 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep convolutional networks often append additive constant (&quot;bias&quot;) terms to
their convolution operations, enabling a richer repertoire of functional
mappings. Biases are also used to facilitate training, by subtracting mean
response over batches of training images (a component of &quot;batch
normalization&quot;). Recent state-of-the-art blind denoising methods (e.g., DnCNN)
seem to require these terms for their success. Here, however, we show that
these networks systematically overfit the noise levels for which they are
trained: when deployed at noise levels outside the training range, performance
degrades dramatically. In contrast, a bias-free architecture -- obtained by
removing the constant terms in every layer of the network, including those used
for batch normalization-- generalizes robustly across noise levels, while
preserving state-of-the-art performance within the training range. Locally, the
bias-free network acts linearly on the noisy image, enabling direct analysis of
network behavior via standard linear-algebraic tools. These analyses provide
interpretations of network functionality in terms of nonlinear adaptive
filtering, and projection onto a union of low-dimensional subspaces, connecting
the learning-based method to more traditional denoising methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05480</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05480</id><created>2019-06-13</created><updated>2019-08-18</updated><authors><author><keyname>Choi</keyname><forenames>Jae-Seok</forenames></author><author><keyname>Kim</keyname><forenames>Yongwoo</forenames></author><author><keyname>Kim</keyname><forenames>Munchurl</forenames></author></authors><title>S3: A Spectral-Spatial Structure Loss for Pan-Sharpening Networks</title><categories>cs.CV eess.IV</categories><comments>Accepted for publication in IEEE Geoscience and Remote Sensing
  Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, many deep-learning-based pan-sharpening methods have been proposed
for generating high-quality pan-sharpened (PS) satellite images. These methods
focused on various types of convolutional neural network (CNN) structures,
which were trained by simply minimizing a spectral loss between network outputs
and the corresponding high-resolution multi-spectral (MS) target images.
However, due to different sensor characteristics and acquisition times,
high-resolution panchromatic (PAN) and low-resolution MS image pairs tend to
have large pixel misalignments, especially for moving objects in the images.
Conventional CNNs trained with only the spectral loss with these satellite
image datasets often produce PS images of low visual quality including
double-edge artifacts along strong edges and ghosting artifacts on moving
objects. In this letter, we propose a novel loss function, called a
spectral-spatial structure (S3) loss, based on the correlation maps between MS
targets and PAN inputs. Our proposed S3 loss can be very effectively utilized
for pan-sharpening with various types of CNN structures, resulting in
significant visual improvements on PS images with suppressed artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05507</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05507</id><created>2019-06-13</created><authors><author><keyname>Rabiee</keyname><forenames>Azam</forenames></author><author><keyname>Kim</keyname><forenames>Tae-Ho</forenames></author><author><keyname>Lee</keyname><forenames>Soo-Young</forenames></author></authors><title>Adjusting Pleasure-Arousal-Dominance for Continuous Emotional
  Text-to-speech Synthesizer</title><categories>eess.AS cs.SD</categories><comments>Interspeech2019, Show and Tell demonstration
  https://www.youtube.com/watch?v=MAOk_ZxuA0I&amp;feature=youtu.be</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emotion is not limited to discrete categories of happy, sad, angry, fear,
disgust, surprise, and so on. Instead, each emotion category is projected into
a set of nearly independent dimensions, named pleasure (or valence), arousal,
and dominance, known as PAD. The value of each dimension varies from -1 to 1,
such that the neutral emotion is in the center with all-zero values. Training
an emotional continuous text-to-speech (TTS) synthesizer on the independent
dimensions provides the possibility of emotional speech synthesis with
unlimited emotion categories. Our end-to-end neural speech synthesizer is based
on the well-known Tacotron. Empirically, we have found the optimum network
architecture for injecting the 3D PADs. Moreover, the PAD values are adjusted
for the speech synthesis purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05528</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05528</id><created>2019-06-13</created><authors><author><keyname>Vishnevskiy</keyname><forenames>Valery</forenames></author><author><keyname>Rau</keyname><forenames>Richard</forenames></author><author><keyname>Goksel</keyname><forenames>Orcun</forenames></author></authors><title>Deep Variational Networks with Exponential Weighting for Learning
  Computed Tomography</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted to MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tomographic image reconstruction is relevant for many medical imaging
modalities including X-ray, ultrasound (US) computed tomography (CT) and
photoacoustics, for which the access to full angular range tomographic
projections might be not available in clinical practice due to physical or time
constraints. Reconstruction from incomplete data in low signal-to-noise ratio
regime is a challenging and ill-posed inverse problem that usually leads to
unsatisfactory image quality. While informative image priors may be learned
using generic deep neural network architectures, the artefacts caused by an
ill-conditioned design matrix often have global spatial support and cannot be
efficiently filtered out by means of convolutions. In this paper we propose to
learn an inverse mapping in an end-to-end fashion via unrolling optimization
iterations of a prototypical reconstruction algorithm. We herein introduce a
network architecture that performs filtering jointly in both sinogram and
spatial domains. To efficiently train such deep network we propose a novel
regularization approach based on deep exponential weighting. Experiments on US
and X-ray CT data show that our proposed method is qualitatively and
quantitatively superior to conventional non-linear reconstruction methods as
well as state-of-the-art deep networks for image reconstruction. Fast inference
time of the proposed algorithm allows for sophisticated reconstructions in
real-time critical settings, demonstrated with US SoS imaging of an ex vivo
bovine phantom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05562</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05562</id><created>2019-06-13</created><authors><author><keyname>Lian</keyname><forenames>Feier</forenames></author><author><keyname>Chakrabortty</keyname><forenames>Aranya</forenames></author><author><keyname>Duel-Hallen</keyname><forenames>Alexandra</forenames></author></authors><title>Game-Theoretic Mixed $H_2/H_{\infty}$ Control with Sparsity Constraint
  for Multi-agent Networked Control Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-agent networked control systems (NCSs) are often subject to model
uncertainty and are limited by large communication cost, associated with
feedback of data between the system nodes. To provide robustness against model
uncertainty and to reduce the communication cost, this paper investigates the
mixed $H_2/H_{\infty}$ control problem for NCS under the sparsity constraint.
First, proximal alternating linearized minimization (PALM) is employed to solve
the centralized social optimization where the agents have the same optimization
objective. Next, we investigate a sparsity-constrained noncooperative game,
which accommodates different control-performance criteria of different agents,
and propose a best-response dynamics algorithm based on PALM that converges to
an approximate Generalized Nash Equilibrium (GNE) of this game. A special case
of this game, where the agents have the same $H_2$ objective, produces a
partially-distributed social optimization solution. We validate the proposed
algorithms using a network with unstable node dynamics and demonstrate the
superiority of the proposed PALM-based method to a previously investigated
sparsity-constrained mixed $H_2/H_{\infty}$ controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05567</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05567</id><created>2019-06-13</created><authors><author><keyname>Ghamnia</keyname><forenames>Imene</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author><author><keyname>Yuan-Wu</keyname><forenames>Yi</forenames></author></authors><title>Rate Balancing for Multiuser MIMO Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate and solve the rate balancing problem in the downlink for a
multiuser Multiple-Input-Multiple-Output (MIMO) system. In particular, we adopt
a transceiver structure to maximize the worst-case rate of the user while
satisfying a total transmit power constraint. Most of the existing solutions
either perform user Mean Squared Error (MSE) balancing or streamwise rate
balancing, which is suboptimal in the MIMO case. The original rate balancing
problem in the downlink is complicated due to the coupled structure of the
transmit filters. This optimization problem is here solved in an alternating
manner by exploiting weighted MSE uplink/downlink duality with proven
convergence to a local optimum. Simulation results are provided to validate the
proposed algorithm and demonstrate its performance improvement over unweighted
MSE balancing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05591</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05591</id><created>2019-06-13</created><updated>2019-10-03</updated><authors><author><keyname>Kozdoba</keyname><forenames>Mark</forenames></author><author><keyname>Moroshko</keyname><forenames>Edward</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author><author><keyname>Crammer</keyname><forenames>Koby</forenames></author></authors><title>Variance Estimation For Dynamic Regression via Spectrum Thresholding</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the dynamic linear regression problem, where the predictor vector
may vary with time. This problem can be modelled as a linear dynamical system,
where the parameters that need to be learned are the variance of both the
process noise and the observation noise. The classical approach to learning the
variance is via the maximum likelihood estimator -- a non-convex optimization
problem prone to local minima and with no finite sample complexity bounds. In
this paper we study the global system operator: the operator that maps the
noises vectors to the output. In particular, we obtain estimates on its
spectrum, and as a result derive the {\em first known} variance estimators with
sample complexity guarantees for dynamic regression problems. We evaluate the
approach on synthetic and real-world benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05652</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05652</id><created>2019-06-12</created><updated>2019-12-30</updated><authors><author><keyname>Yu</keyname><forenames>Haotian</forenames></author><author><keyname>Chen</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Zhang</keyname><forenames>Zhao</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author><author><keyname>Zheng</keyname><forenames>Dongliang</forenames></author><author><keyname>Han</keyname><forenames>Jing</forenames></author></authors><title>Dynamic 3-D measurement based on fringe-to-fringe transformation using
  deep learning</title><categories>eess.IV</categories><comments>16 pages, 12 figures, 1 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fringe projection profilometry (FPP) has become increasingly important in
dynamic 3-D shape measurement. In FPP, it is necessary to retrieve the phase of
the measured object before shape profiling. However, traditional phase
retrieval techniques often require a large number of fringes, which may
generate motion-induced error for dynamic objects. In this paper, a novel phase
retrieval technique based on deep learning is proposed, which uses an
end-to-end deep convolution neural network to transform a single or two fringes
into the phase retrieval required fringes. When the object's surface is located
in a restricted depth, the presented network only requires a single fringe as
the input, which otherwise requires two fringes in an unrestricted depth. The
proposed phase retrieval technique is first theoretically analyzed, and then
numerically and experimentally verified on its applicability for dynamic 3-D
measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05678</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05678</id><created>2019-06-13</created><authors><author><keyname>Larson</keyname><forenames>Chris</forenames></author><author><keyname>Lahlou</keyname><forenames>Tarek</forenames></author><author><keyname>Mingels</keyname><forenames>Diana</forenames></author><author><keyname>Kulis</keyname><forenames>Zachary</forenames></author><author><keyname>Mueller</keyname><forenames>Erik</forenames></author></authors><title>Telephonetic: Making Neural Language Models Robust to ASR and Semantic
  Noise</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech processing systems rely on robust feature extraction to handle
phonetic and semantic variations found in natural language. While techniques
exist for desensitizing features to common noise patterns produced by
Speech-to-Text (STT) and Text-to-Speech (TTS) systems, the question remains how
to best leverage state-of-the-art language models (which capture rich semantic
features, but are trained on only written text) on inputs with ASR errors. In
this paper, we present Telephonetic, a data augmentation framework that helps
robustify language model features to ASR corrupted inputs. To capture phonetic
alterations, we employ a character-level language model trained using
probabilistic masking. Phonetic augmentations are generated in two stages: a
TTS encoder (Tacotron 2, WaveGlow) and a STT decoder (DeepSpeech). Similarly,
semantic perturbations are produced by sampling from nearby words in an
embedding space, which is computed using the BERT language model. Words are
selected for augmentation according to a hierarchical grammar sampling
strategy. Telephonetic is evaluated on the Penn Treebank (PTB) corpus, and
demonstrates its effectiveness as a bootstrapping technique for transferring
neural language models to the speech domain. Notably, our language model
achieves a test perplexity of 37.49 on PTB, which to our knowledge is
state-of-the-art among models trained only on PTB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05681</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05681</id><created>2019-06-11</created><authors><author><keyname>Tripathi</keyname><forenames>Suraj</forenames></author><author><keyname>Kumar</keyname><forenames>Abhay</forenames></author><author><keyname>Ramesh</keyname><forenames>Abhiram</forenames></author><author><keyname>Singh</keyname><forenames>Chirag</forenames></author><author><keyname>Yenigalla</keyname><forenames>Promod</forenames></author></authors><title>Deep Learning based Emotion Recognition System Using Speech Features and
  Transcriptions</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Accepted in CICLing 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a speech emotion recognition method based on speech
features and speech transcriptions (text). Speech features such as Spectrogram
and Mel-frequency Cepstral Coefficients (MFCC) help retain emotion-related
low-level characteristics in speech whereas text helps capture semantic
meaning, both of which help in different aspects of emotion detection. We
experimented with several Deep Neural Network (DNN) architectures, which take
in different combinations of speech features and text as inputs. The proposed
network architectures achieve higher accuracies when compared to
state-of-the-art methods on a benchmark dataset. The combined MFCC-Text
Convolutional Neural Network (CNN) model proved to be the most accurate in
recognizing emotions in IEMOCAP data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05682</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05682</id><created>2019-06-11</created><authors><author><keyname>Tripathi</keyname><forenames>Suraj</forenames></author><author><keyname>Kumar</keyname><forenames>Abhay</forenames></author><author><keyname>Ramesh</keyname><forenames>Abhiram</forenames></author><author><keyname>Singh</keyname><forenames>Chirag</forenames></author><author><keyname>Yenigalla</keyname><forenames>Promod</forenames></author></authors><title>Focal Loss based Residual Convolutional Neural Network for Speech
  Emotion Recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted in CICLing 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a Residual Convolutional Neural Network (ResNet) based on
speech features and trained under Focal Loss to recognize emotion in speech.
Speech features such as Spectrogram and Mel-frequency Cepstral Coefficients
(MFCCs) have shown the ability to characterize emotion better than just plain
text. Further Focal Loss, first used in One-Stage Object Detectors, has shown
the ability to focus the training process more towards hard-examples and
down-weight the loss assigned to well-classified examples, thus preventing the
model from being overwhelmed by easily classifiable examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05687</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05687</id><created>2019-06-12</created><authors><author><keyname>Deng</keyname><forenames>Mo</forenames></author><author><keyname>Goy</keyname><forenames>Alexandre</forenames></author><author><keyname>Li</keyname><forenames>Shuai</forenames></author><author><keyname>Arthur</keyname><forenames>Kwabena</forenames></author><author><keyname>Barbastathis</keyname><forenames>George</forenames></author></authors><title>Low Photon Budget Phase Retrieval with Perceptual Loss Trained Deep
  Neural Networks</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNNs) are efficient solvers for ill-posed problems and
have been shown to outperform classical optimization techniques in several
computational imaging problems. DNNs are trained by solving an optimization
problem implies the choice of an appropriate loss function, i.e., the function
to optimize. In a recent paper [A. Goy \textit{et al.}, Phys. Rev. Lett.
121(24), 243902 (2018)], we showed that DNNs trained with the negative Pearson
correlation coefficient as the loss function are particularly fit for
photon-starved phase retrieval problems, which are fundamentally affected by
strong Poison noise. In this paper we demonstrate that the use of a perceptual
loss function significantly improves the reconstructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05695</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05695</id><created>2019-06-12</created><authors><author><keyname>Oksuz</keyname><forenames>lkay</forenames></author><author><keyname>Clough</keyname><forenames>James</forenames></author><author><keyname>Ruijsink</keyname><forenames>Bram</forenames></author><author><keyname>Puyol-Anton</keyname><forenames>Esther</forenames></author><author><keyname>Bustin</keyname><forenames>Aurelien</forenames></author><author><keyname>Cruz</keyname><forenames>Gastao</forenames></author><author><keyname>Prieto</keyname><forenames>Claudia</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author><author><keyname>Schnabel</keyname><forenames>Julia A.</forenames></author></authors><title>Detection and Correction of Cardiac MR Motion Artefacts during
  Reconstruction from K-space</title><categories>eess.IV cs.CV</categories><comments>Accepted to MICCAI 2019. arXiv admin note: text overlap with
  arXiv:1808.05130</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In fully sampled cardiac MR (CMR) acquisitions, motion can lead to corruption
of k-space lines, which can result in artefacts in the reconstructed images. In
this paper, we propose a method to automatically detect and correct
motion-related artefacts in CMR acquisitions during reconstruction from k-space
data. Our correction method is inspired by work on undersampled CMR
reconstruction, and uses deep learning to optimize a data-consistency term for
under-sampled k-space reconstruction. Our main methodological contribution is
the addition of a detection network to classify motion-corrupted k-space lines
to convert the problem of artefact correction to a problem of reconstruction
using the data consistency term. We train our network to automatically correct
for motion-related artefacts using synthetically corrupted cine CMR k-space
data as well as uncorrupted CMR images. Using a test set of 50 2D+time cine CMR
datasets from the UK Biobank, we achieve good image quality in the presence of
synthetic motion artefacts. We quantitatively compare our method with a variety
of techniques for recovering good image quality and showcase better performance
compared to state of the art denoising techniques with a PSNR of 37.1.
Moreover, we show that our method preserves the quality of uncorrupted images
and therefore can be also utilized as a general image reconstruction algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05698</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05698</id><created>2019-06-13</created><updated>2019-10-21</updated><authors><author><keyname>Delabays</keyname><forenames>Robin</forenames></author><author><keyname>Tyloo</keyname><forenames>Melvyn</forenames></author><author><keyname>Jacquod</keyname><forenames>Philippe</forenames></author></authors><title>Rate of change of frequency under line contingencies in high voltage
  electric power networks with uncertainties</title><categories>nlin.AO eess.SP physics.soc-ph</categories><comments>6 pages, 5 figures</comments><journal-ref>Chaos 29, 103130 (2019)</journal-ref><doi>10.1063/1.5115002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In modern electric power networks with fast evolving operational conditions,
assessing the impact of contingencies is becoming more and more crucial.
Contingencies of interest can be roughly classified into nodal power
disturbances and line faults. Despite their higher relevance, line
contingencies have been significantly less investigated analytically than nodal
disturbances. The main reason for this is that nodal power disturbances are
additive perturbations, while line contingencies are multiplicative
perturbations, which modify the interaction graph of the network. They are,
therefore, significantly more challenging to tackle analytically. Here, we
assess the direct impact of a line loss by means of the maximal Rate of Change
of Frequency (RoCoF) incurred by the system. We show that the RoCoF depends on
the initial power flow on the removed line and on the inertia of the bus where
it is measured. We further derive analytical expressions for the expectation
and variance of the maximal RoCoF, in terms of the expectations and variances
of the power profile in the case of power systems with power uncertainties.
This gives analytical tools to identify the most critical lines in an electric
power grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05704</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05704</id><created>2019-06-13</created><authors><author><keyname>Kamburjan</keyname><forenames>Eduard</forenames></author><author><keyname>Mitsch</keyname><forenames>Stefan</forenames></author><author><keyname>Kettenbach</keyname><forenames>Martina</forenames></author><author><keyname>H&#xe4;hnle</keyname><forenames>Reiner</forenames></author></authors><title>Modeling and Verifying Cyber-Physical Systems with Hybrid Active Objects</title><categories>eess.SY cs.LO cs.PL cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal modeling of cyber-physical systems (CPS) is hard, because they pose
the double challenge of combined discrete-continuous dynamics and concurrent
behavior. Existing formal specification and verification languages for CPS are
designed on top of their underlying proof search technology. They lack
high-level structuring elements. In addition, they are not efficiently
executable. This makes formal CPS models hard to understand and to validate,
hence impairs their usability. Instead, we suggest to model CPS in an Active
Objects (AO) language designed for concise, intuitive modeling of concurrent
systems. To this end, we extend the AO language ABS and its runtime environment
with Hybrid Active Objects (HAO). CPS models and requirements formalized in HAO
must follow certain communication patterns that permit automatic translation
into differential dynamic logic, a sequential hybrid program logic.
Verification is achieved by discharging the resulting formulas with the theorem
prover KeYmaera X. We demonstrate the practicality of our approach with case
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05721</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05721</id><created>2019-06-12</created><authors><author><keyname>Chowdhery</keyname><forenames>Aakanksha</forenames></author><author><keyname>Warden</keyname><forenames>Pete</forenames></author><author><keyname>Shlens</keyname><forenames>Jonathon</forenames></author><author><keyname>Howard</keyname><forenames>Andrew</forenames></author><author><keyname>Rhodes</keyname><forenames>Rocky</forenames></author></authors><title>Visual Wake Words Dataset</title><categories>cs.CV eess.IV</categories><comments>10 pages, 4 figures</comments><acm-class>I.2.10; B.7.1; I.5.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The emergence of Internet of Things (IoT) applications requires intelligence
on the edge. Microcontrollers provide a low-cost compute platform to deploy
intelligent IoT applications using machine learning at scale, but have
extremely limited on-chip memory and compute capability. To deploy computer
vision on such devices, we need tiny vision models that fit within a few
hundred kilobytes of memory footprint in terms of peak usage and model size on
device storage. To facilitate the development of microcontroller friendly
models, we present a new dataset, Visual Wake Words, that represents a common
microcontroller vision use-case of identifying whether a person is present in
the image or not, and provides a realistic benchmark for tiny vision models.
Within a limited memory footprint of 250 KB, several state-of-the-art mobile
models achieve accuracy of 85-90% on the Visual Wake Words dataset. We
anticipate the proposed dataset will advance the research on tiny vision models
that can push the pareto-optimal boundary in terms of accuracy versus memory
usage for microcontroller applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05735</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05735</id><created>2019-06-13</created><authors><author><keyname>T.</keyname><forenames>Dagnachew Azene</forenames></author><author><keyname>Miozzo</keyname><forenames>Marco</forenames></author><author><keyname>Dini</keyname><forenames>Paolo</forenames></author></authors><title>Dynamic Control of Functional Splits for Energy Harvesting Virtual Small
  Cells: a Distributed Reinforcement Learning Approach</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a network scenario where the baseband processes of
the virtual small cells powered solely by energy harvesters and batteries can
be opportunistically executed in a grid-connected edge computing server,
co-located at the macro base station site. We state the corresponding energy
minimization problem and propose multi-agent Reinforcement Learning (RL) to
solve it. Distributed Fuzzy Q-Learning and Q-Learning on-line algorithms are
tailored for our purposes. Coordination among the multiple agents is achieved
by broadcasting system level information to the independent learners. The
evaluation of the network performance confirms that coordination via
broadcasting may achieve higher system level gains than un-coordinated
solutions and cumulative rewards closer to the off-line bounds. Finally, our
analysis permits to evaluate the benefits of continuous state/action
representation for the learning algorithms in terms of faster convergence,
higher cumulative reward and more adaptation to changing environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05762</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05762</id><created>2019-06-13</created><updated>2019-10-12</updated><authors><author><keyname>Yan</keyname><forenames>Hanshu</forenames></author><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Yang</keyname><forenames>Wenhan</forenames></author><author><keyname>Feng</keyname><forenames>Jiashi</forenames></author></authors><title>Unsupervised Image Noise Modeling with Self-Consistent GAN</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise modeling lies in the heart of many image processing tasks. However,
existing deep learning methods for noise modeling generally require clean and
noisy image pairs for model training; these image pairs are difficult to obtain
in many realistic scenarios. To ameliorate this problem, we propose a
self-consistent GAN (SCGAN), that can directly extract noise maps from noisy
images, thus enabling unsupervised noise modeling. In particular, the SCGAN
introduces three novel self-consistent constraints that are complementary to
one another, viz.: the noise model should produce a zero response over a clean
input; the noise model should return the same output when fed with a specific
pure noise input; and the noise model also should re-extract a pure noise map
if the map is added to a clean image. These three constraints are simple yet
effective. They jointly facilitate unsupervised learning of a noise model for
various noise types. To demonstrate its wide applicability, we deploy the SCGAN
on three image processing tasks including blind image denoising, rain streak
removal, and noisy image super-resolution. The results demonstrate the
effectiveness and superiority of our method over the state-of-the-art methods
on a variety of benchmark datasets, even though the noise types vary
significantly and paired clean images are not available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05773</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05773</id><created>2019-06-13</created><authors><author><keyname>Kassa</keyname><forenames>Mateos</forenames></author><author><keyname>Hall</keyname><forenames>Carrie</forenames></author><author><keyname>Pamminger</keyname><forenames>Michael</forenames></author><author><keyname>Wallner</keyname><forenames>Thomas</forenames></author></authors><title>Knock Intensity Distribution and a Stochastic Control Framework for
  Knock Control</title><categories>eess.SY cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main factors limiting the efficiency of spark-ignited engines is
the occurrence of engine knock. In high temperature and high pressure
in-cylinder conditions, the fuel-air mixture auto-ignites creating pressure
shock waves in the cylinder. Knock can significantly damage the engine and
hinder its performance; as such, conservative knock control strategies are
generally implemented that avoid such operating conditions at the cost of lower
thermal efficiencies. Significant improvements in the performance of
conventional knock controllers are possible if the properties of the knock
process are better characterized and exploited in knock controller designs. One
of the methods undertaken to better characterize knocking instances is to
employ a probabilistic approach, in which the likelihood of knock is derived
from the statistical distribution of knock intensity. In this paper, it is
shown that knock intensity values at a fixed operating point for single fuel
and dual fuel engines are accurately described using a mixed lognormal
distribution. The fitting accuracy is compared against those for a randomly
generated mixed-lognormally distributed data set, and shown to exceed a 95%
accuracy threshold for almost all of the operating points tested. Additionally,
this paper discusses a stochastic knock control approach that leverages the
mixed lognormal distribution to adjust spark timing based on knock intensity
measurements. This more informed knock control strategy would allow for
improvements in engine performance and fuel efficiency by minimizing knock
occurrences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05774</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05774</id><created>2019-06-13</created><updated>2019-10-08</updated><authors><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Deep Unfolding for Communications Systems: A Survey and Some New
  Directions</title><categories>eess.SP cs.IT math.IT</categories><comments>IEEE Workshop on Signal Processing Systems (SiPS) 2019, special
  session on &quot;Practical Machine-Learning-Aided Communications Systems.&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep unfolding is a method of growing popularity that fuses iterative
optimization algorithms with tools from neural networks to efficiently solve a
range of tasks in machine learning, signal and image processing, and
communication systems. This survey summarizes the principle of deep unfolding
and discusses its recent use for communication systems with focus on detection
and precoding in multi-antenna (MIMO) wireless systems and belief propagation
decoding of error-correcting codes. To showcase the efficacy and generality of
deep unfolding, we describe a range of other tasks relevant to communication
systems that can be solved using this emerging paradigm. We conclude the survey
by outlining a list of open research problems and future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05777</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05777</id><created>2019-05-30</created><authors><author><keyname>Shi</keyname><forenames>Maolin</forenames></author><author><keyname>Sun</keyname><forenames>Wei</forenames></author><author><keyname>Song</keyname><forenames>Xueguan</forenames></author><author><keyname>Li</keyname><forenames>Hongyou</forenames></author></authors><title>High-low level support vector regression prediction approach (HL-SVR)
  for data modeling with input parameters of unequal sample sizes</title><categories>eess.SP cs.LG stat.AP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Support vector regression (SVR) has been widely used to reduce the high
computational cost of computer simulation. SVR assumes the input parameters
have equal sample sizes, but unequal sample sizes are often encountered in
engineering practices. To solve this issue, a new prediction approach based on
SVR, namely as high-low-level SVR approach (HL-SVR) is proposed for data
modeling of input parameters of unequal sample sizes in this paper. The
proposed approach is consisted of low-level SVR models for the input parameters
of larger sample sizes and high-level SVR model for the input parameters of
smaller sample sizes. For each training point of the input parameters of
smaller sample sizes, one low-level SVR model is built based on its
corresponding input parameters of larger sample sizes and their responses of
interest. The high-level SVR model is built based on the obtained responses
from the low-level SVR models and the input parameters of smaller sample sizes.
Several numerical examples are used to validate the performance of HL-SVR. The
experimental results indicate that HL-SVR can produce more accurate prediction
results than conventional SVR. The proposed approach is applied on the stress
analysis of dental implant, which the structural parameters have massive
samples but the material of implant can only be selected from several Ti and
its alloys. The prediction performance of the proposed approach is much better
than the conventional SVR. The proposed approach can be used for the design,
optimization and analysis of engineering systems with input parameters of
unequal sample sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05791</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05791</id><created>2019-06-13</created><authors><author><keyname>Sui</keyname><forenames>Wenbo</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Jorge Pulpeiro</forenames></author><author><keyname>Hall</keyname><forenames>Carrie M.</forenames></author></authors><title>Modeling and Control of Combustion Phasing in Dual-Fuel Compression
  Ignition Engines</title><categories>eess.SY cs.SY physics.app-ph</categories><journal-ref>J. Eng. Gas Turbines Power 141(5), 051005 (Nov 28, 2018)</journal-ref><doi>10.1115/1.4041871</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual fuel engines can achieve high efficiencies and low emissions but also
can encounter high cylinder-to-cylinder variations on multi-cylinder engines.
In order to avoid these variations, they require a more complex method for
combustion phasing control such as model-based control. Since the combustion
process in these engines is complex, typical models of the system are complex
as well and there is a need for simpler, computationally efficient,
control-oriented models of the dual fuel combustion process. In this paper, a
mean-value combustion phasing model is designed and calibrated and two control
strategies are proposed. Combustion phasing is predicted using a knock integral
model, burn duration model and a Wiebe function and this model is used in both
an adaptive closed loop controller and an open loop controller. These two
control methodologies are tested and compared in simulations. Both control
strategies are able to reach steady state in 5 cycles after a transient and
have steady state errors in CA50 that are less than 0.1 crank angle degree
(CAD) with the adaptive control strategy and less than 1.5 CAD with the
model-based feedforward control method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05795</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05795</id><created>2019-06-13</created><authors><author><keyname>Dindin</keyname><forenames>Meryll</forenames></author><author><keyname>Umeda</keyname><forenames>Yuhei</forenames></author><author><keyname>Chazal</keyname><forenames>Frederic</forenames></author></authors><title>Topological Data Analysis for Arrhythmia Detection through Modular
  Neural Networks</title><categories>cs.LG eess.SP stat.ML</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an innovative and generic deep learning approach to
monitor heart conditions from ECG signals.We focus our attention on both the
detection and classification of abnormal heartbeats, known as arrhythmia. We
strongly insist on generalization throughout the construction of a
deep-learning model that turns out to be effective for new unseen patient. The
novelty of our approach relies on the use of topological data analysis as basis
of our multichannel architecture, to diminish the bias due to individual
differences. We show that our structure reaches the performances of the
state-of-the-art methods regarding arrhythmia detection and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05797</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05797</id><created>2019-06-13</created><authors><author><keyname>Straub</keyname><forenames>Julian</forenames></author><author><keyname>Whelan</keyname><forenames>Thomas</forenames></author><author><keyname>Ma</keyname><forenames>Lingni</forenames></author><author><keyname>Chen</keyname><forenames>Yufan</forenames></author><author><keyname>Wijmans</keyname><forenames>Erik</forenames></author><author><keyname>Green</keyname><forenames>Simon</forenames></author><author><keyname>Engel</keyname><forenames>Jakob J.</forenames></author><author><keyname>Mur-Artal</keyname><forenames>Raul</forenames></author><author><keyname>Ren</keyname><forenames>Carl</forenames></author><author><keyname>Verma</keyname><forenames>Shobhit</forenames></author><author><keyname>Clarkson</keyname><forenames>Anton</forenames></author><author><keyname>Yan</keyname><forenames>Mingfei</forenames></author><author><keyname>Budge</keyname><forenames>Brian</forenames></author><author><keyname>Yan</keyname><forenames>Yajie</forenames></author><author><keyname>Pan</keyname><forenames>Xiaqing</forenames></author><author><keyname>Yon</keyname><forenames>June</forenames></author><author><keyname>Zou</keyname><forenames>Yuyang</forenames></author><author><keyname>Leon</keyname><forenames>Kimberly</forenames></author><author><keyname>Carter</keyname><forenames>Nigel</forenames></author><author><keyname>Briales</keyname><forenames>Jesus</forenames></author><author><keyname>Gillingham</keyname><forenames>Tyler</forenames></author><author><keyname>Mueggler</keyname><forenames>Elias</forenames></author><author><keyname>Pesqueira</keyname><forenames>Luis</forenames></author><author><keyname>Savva</keyname><forenames>Manolis</forenames></author><author><keyname>Batra</keyname><forenames>Dhruv</forenames></author><author><keyname>Strasdat</keyname><forenames>Hauke M.</forenames></author><author><keyname>De Nardi</keyname><forenames>Renzo</forenames></author><author><keyname>Goesele</keyname><forenames>Michael</forenames></author><author><keyname>Lovegrove</keyname><forenames>Steven</forenames></author><author><keyname>Newcombe</keyname><forenames>Richard</forenames></author></authors><title>The Replica Dataset: A Digital Replica of Indoor Spaces</title><categories>cs.CV cs.GR eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce Replica, a dataset of 18 highly photo-realistic 3D indoor scene
reconstructions at room and building scale. Each scene consists of a dense
mesh, high-resolution high-dynamic-range (HDR) textures, per-primitive semantic
class and instance information, and planar mirror and glass reflectors. The
goal of Replica is to enable machine learning (ML) research that relies on
visually, geometrically, and semantically realistic generative models of the
world - for instance, egocentric computer vision, semantic segmentation in 2D
and 3D, geometric inference, and the development of embodied agents (virtual
robots) performing navigation, instruction following, and question answering.
Due to the high level of realism of the renderings from Replica, there is hope
that ML systems trained on Replica may transfer directly to real world image
and video data. Together with the data, we are releasing a minimal C++ SDK as a
starting point for working with the Replica dataset. In addition, Replica is
`Habitat-compatible', i.e. can be natively used with AI Habitat for training
and testing embodied agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05819</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05819</id><created>2019-06-13</created><authors><author><keyname>Liu</keyname><forenames>Anqi</forenames></author><author><keyname>Shi</keyname><forenames>Guanya</forenames></author><author><keyname>Chung</keyname><forenames>Soon-Jo</forenames></author><author><keyname>Anandkumar</keyname><forenames>Anima</forenames></author><author><keyname>Yue</keyname><forenames>Yisong</forenames></author></authors><title>Robust Regression for Safe Exploration in Control</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of safe learning and exploration in sequential control
problems. The goal is to safely collect data samples from an operating
environment to learn an optimal controller. A central challenge in this setting
is how to quantify uncertainty in order to choose provably-safe actions that
allow us to collect useful data and reduce uncertainty, thereby achieving both
improved safety and optimality. To address this challenge, we present a deep
robust regression model that is trained to directly predict the uncertainty
bounds for safe exploration. We then show how to integrate our robust
regression approach with model-based control methods by learning a dynamic
model with robustness bounds. We derive generalization bounds under domain
shifts for learning and connect them with safety and stability bounds in
control. We demonstrate empirically that our robust regression approach can
outperform conventional Gaussian process (GP) based safe exploration in
settings where it is difficult to specify a good GP prior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05845</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05845</id><created>2019-06-13</created><updated>2019-07-15</updated><authors><author><keyname>Abhishek</keyname><forenames>Kumar</forenames></author><author><keyname>Hamarneh</keyname><forenames>Ghassan</forenames></author></authors><title>Mask2Lesion: Mask-Constrained Adversarial Skin Lesion Image Synthesis</title><categories>eess.IV cs.CV</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skin lesion segmentation is a vital task in skin cancer diagnosis and further
treatment. Although deep learning based approaches have significantly improved
the segmentation accuracy, these algorithms are still reliant on having a large
enough dataset in order to achieve adequate results. Inspired by the immense
success of generative adversarial networks (GANs), we propose a GAN-based
augmentation of the original dataset in order to improve the segmentation
performance. In particular, we use the segmentation masks available in the
training dataset to train the Mask2Lesion model, and use the model to generate
new lesion images given any arbitrary mask, which are then used to augment the
original training dataset. We test Mask2Lesion augmentation on the ISBI ISIC
2017 Skin Lesion Segmentation Challenge dataset and achieve an improvement of
5.17% in the mean Dice score as compared to a model trained with only classical
data augmentation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05896</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05896</id><created>2019-06-13</created><updated>2019-11-21</updated><authors><author><keyname>Lazarow</keyname><forenames>Justin</forenames></author><author><keyname>Lee</keyname><forenames>Kwonjoon</forenames></author><author><keyname>Shi</keyname><forenames>Kunyu</forenames></author><author><keyname>Tu</keyname><forenames>Zhuowen</forenames></author></authors><title>Learning Instance Occlusion for Panoptic Segmentation</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Panoptic segmentation requires segments of both &quot;things&quot; (countable object
instances) and &quot;stuff&quot; (uncountable and amorphous regions) within a single
output. A common approach involves the fusion of instance segmentation (for
&quot;things&quot;) and semantic segmentation (for &quot;stuff&quot;) into a non-overlapping
placement of segments, and resolves occlusions (or overlaps). However, instance
ordering with detection confidence do not correlate well with natural occlusion
relationship. To resolve this issue, we propose a branch that is tasked with
modeling how two instance masks should overlap one another as a binary
relation. Our method, named OCFusion, is lightweight but particularly effective
on the &quot;things&quot; portion of the standard panoptic segmentation benchmarks,
bringing significant gains (up to +3.2 PQ^Th and +2.0 overall PQ) on the COCO
dataset --- only requiring a short amount of fine-tuning. OCFusion is trained
with the ground truth relation derived automatically from the existing dataset
annotations. We obtain state-of-the-art results on COCO and show competitive
results on the Cityscapes panoptic segmentation benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05917</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05917</id><created>2019-06-13</created><authors><author><keyname>Kandalan</keyname><forenames>Roya Norouzi</forenames></author><author><keyname>Namuduri</keyname><forenames>Kamesh</forenames></author></authors><title>A Comprehensive Survey of Navigation Systems for the Visual Impaired</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sight is essential for humans to navigate their surrounding environment
independently. Tasks that are simple for the sighted are often close to
impossible for the visually impaired. Throughout the years, many researchers
dedicated their time and efforts to design and implement technologies and
devices that can help the visually impaired to navigate in unknown areas
independently. A navigation assistive system for the visually impaired is built
on multiple components of which localization, navigation, obstacle avoidance,
and human-machine interaction form the essential components. Individual
components have been explored extensively in the literature and it is a
daunting task to review it in its entirety. In this paper, a compact but
comprehensive collection of available methods to build each component has been
provided. The discussed methods may not have been implemented for a navigation
assistive technology for visually impaired directly but they can be employed to
build an individual building block. Given that every approach has its own
challenges, methods to combat those challenges have been presented. The purpose
of this paper is to provide researchers with a shortcut to review most of the
available methods to build each component, provide them with the essential
knowledge to understand the nuances in each component and give them a baseline
to start with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05953</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05953</id><created>2019-06-13</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Pinaky</forenames></author><author><keyname>Beck</keyname><forenames>James L.</forenames></author></authors><title>Exploiting Convexification for Bayesian Optimal Sensor Placement by
  Maximization of Mutual Information</title><categories>stat.AP eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian optimal sensor placement, in its full generality, seeks to maximize
the mutual information between uncertain model parameters and the predicted
data to be collected from the sensors for the purpose of performing Bayesian
inference. Equivalently, the expected information entropy of the posterior of
the model parameters is minimized over all possible sensor configurations for a
given sensor budget. In the context of structural dynamical systems, this
minimization is computationally expensive because of the large number of
possible sensor configurations. Here, a very efficient convex relaxation scheme
is presented to determine informative and possibly-optimal solutions to the
problem, thereby bypassing the necessity for an exhaustive, and often
infeasible, combinatorial search. The key idea is to relax the binary sensor
location vector so that its components corresponding to all possible sensor
locations lie in the unit interval. Then, the optimization over this vector is
a convex problem that can be efficiently solved. This method always yields a
unique solution for the relaxed problem, which is often binary and therefore
the optimal solution to the original problem. When not binary, the relaxed
solution is often suggestive of what the optimal solution for the original
problem is. An illustrative example using a fifty-story shear building model
subject to sinusoidal ground motion is presented, including a case where there
are over 47 trillion possible sensor configurations. The solutions and
computational effort are compared to greedy and heuristic methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05956</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05956</id><created>2019-06-13</created><authors><author><keyname>Kim</keyname><forenames>Sungwoong</forenames></author><author><keyname>Kim</keyname><forenames>Ildoo</forenames></author><author><keyname>Lim</keyname><forenames>Sungbin</forenames></author><author><keyname>Baek</keyname><forenames>Woonhyuk</forenames></author><author><keyname>Kim</keyname><forenames>Chiheon</forenames></author><author><keyname>Cho</keyname><forenames>Hyungjoo</forenames></author><author><keyname>Yoon</keyname><forenames>Boogeon</forenames></author><author><keyname>Kim</keyname><forenames>Taesup</forenames></author></authors><title>Scalable Neural Architecture Search for 3D Medical Image Segmentation</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a neural architecture search (NAS) framework is proposed for
3D medical image segmentation, to automatically optimize a neural architecture
from a large design space. Our NAS framework searches the structure of each
layer including neural connectivities and operation types in both of the
encoder and decoder. Since optimizing over a large discrete architecture space
is difficult due to high-resolution 3D medical images, a novel stochastic
sampling algorithm based on a continuous relaxation is also proposed for
scalable gradient based optimization. On the 3D medical image segmentation
tasks with a benchmark dataset, an automatically designed architecture by the
proposed NAS framework outperforms the human-designed 3D U-Net, and moreover
this optimized architecture is well suited to be transferred for different
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05962</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05962</id><created>2019-06-13</created><authors><author><keyname>Chao</keyname><forenames>Guan-Lin</forenames></author><author><keyname>Chan</keyname><forenames>William</forenames></author><author><keyname>Lane</keyname><forenames>Ian</forenames></author></authors><title>Speaker-Targeted Audio-Visual Models for Speech Recognition in
  Cocktail-Party Environments</title><categories>eess.AS cs.CL cs.CV cs.SD</categories><comments>Published in INTERSPEECH 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech recognition in cocktail-party environments remains a significant
challenge for state-of-the-art speech recognition systems, as it is extremely
difficult to extract an acoustic signal of an individual speaker from a
background of overlapping speech with similar frequency and temporal
characteristics. We propose the use of speaker-targeted acoustic and
audio-visual models for this task. We complement the acoustic features in a
hybrid DNN-HMM model with information of the target speaker's identity as well
as visual features from the mouth region of the target speaker. Experimentation
was performed using simulated cocktail-party data generated from the GRID
audio-visual corpus by overlapping two speakers's speech on a single acoustic
channel. Our audio-only baseline achieved a WER of 26.3%. The audio-visual
model improved the WER to 4.4%. Introducing speaker identity information had an
even more pronounced effect, improving the WER to 3.6%. Combining both
approaches, however, did not significantly improve performance further. Our
work demonstrates that speaker-targeted models can significantly improve the
speech recognition in cocktail party environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05969</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.05969</id><created>2019-06-13</created><updated>2019-09-26</updated><authors><author><keyname>Torunbalci</keyname><forenames>Mustafa Mert</forenames></author><author><keyname>Sridaran</keyname><forenames>Suresh</forenames></author><author><keyname>Ruby</keyname><forenames>Richard</forenames></author><author><keyname>Bhave</keyname><forenames>Sunil</forenames></author></authors><title>Mechanically Modulated Microwave Circulator</title><categories>eess.SP</categories><comments>Transducers 2019</comments><journal-ref>20th International Conference on Solid-State Sensors, Actuators
  and Microsystems (Transducers'19), Berlin, Germany, June 2019, pp. 713-716</journal-ref><doi>10.1109/TRANSDUCERS.2019.8808670</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a differential FBAR circulator that uses the bending mode
to mechanically modulate the FBAR mode without any varactors or switches. The
differential FBAR circulator achieves a 61.5 dB isolation (IX) with an
insertion loss (IL) of 1.8 dB at 2.68 GHz, demonstrating the first MEMS-only
circulator. The isolation bandwidth at -25 dB is 4.7 MHz and power handling of
the circulator is limited by the FBARs to +34 dBm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06007</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06007</id><created>2019-06-13</created><authors><author><keyname>Guo</keyname><forenames>Jiajia</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Convolutional Neural Network based Multiple-Rate Compressive Sensing for
  Massive MIMO CSI Feedback: Design, Simulation, and Analysis</title><categories>eess.SP cs.IT math.IT</categories><comments>28 pages, 11 figures, 7 tables. This work has been submitted to the
  IEEE for possible publication. Copyright may be transferred without notice,
  after which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (MIMO) is a promising technology to
increase link capacity and energy efficiency. However, these benefits are based
on available channel state information (CSI) at the base station (BS).
Therefore, user equipment (UE) needs to keep on feeding CSI back to the BS,
thereby consuming precious bandwidth resource. Large-scale antennas at the BS
for massive MIMO seriously increase this overhead. In this paper, we propose a
multiple-rate compressive sensing neural network framework to compress and
quantize the CSI. This framework not only improves reconstruction accuracy but
also decreases storage space at the UE, thus enhancing the system feasibility.
Specifically, we establish two network design principles for CSI feedback,
propose a new network architecture, CsiNet+, according to these principles, and
develop a novel quantization framework and training strategy. Next, we further
introduce two different variable-rate approaches, namely, SM-CsiNet+ and
PM-CsiNet+, which decrease the parameter number at the UE by 38.0% and 46.7%,
respectively. Experimental results show that CsiNet+ outperforms the
state-of-the-art network by a margin but only slightly increases the parameter
number. We also investigate the compression and reconstruction mechanism behind
deep learning-based CSI feedback methods via parameter visualization, which
provides a guideline for subsequent research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06017</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06017</id><created>2019-06-14</created><updated>2019-09-16</updated><authors><author><keyname>Yang</keyname><forenames>Yan</forenames></author><author><keyname>Yang</keyname><forenames>Zhifang</forenames></author><author><keyname>Yu</keyname><forenames>Juan</forenames></author><author><keyname>Zhang</keyname><forenames>Baosen</forenames></author></authors><title>Fast Calculation of Probabilistic Power Flow: A Model-based Deep
  Learning Approach</title><categories>eess.SP cs.LG cs.SY eess.SY</categories><comments>Submitted to IEEE Transaction on Smartgrid</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic power flow (PPF) plays a critical role in power system
analysis. However, the high computational burden makes it challenging for the
practical implementation of PPF. This paper proposes a model-based deep
learning approach to overcome the computational challenge. A deep neural
network (DNN) is used to approximate the power flow calculation and is trained
according to the physical power flow equations to improve its learning ability.
The training process consists of several steps: 1) the branch flows are added
into the objective function of the DNN as a penalty term, which improves the
approximation accuracy of the DNN; 2) the gradients used in the back
propagation process are simplified according to the physical characteristics of
the transmission grid, which accelerates the training speed while maintaining
effective guidance of the physical model; and 3) an improved initialization
method for the DNN parameters is proposed to improve the convergence speed. The
simulation results demonstrate the accuracy and efficiency of the proposed
method in standard IEEE and utility benchmark systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06021</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06021</id><created>2019-06-14</created><authors><author><keyname>Shafin</keyname><forenames>Rubayet</forenames><affiliation>Charlie</affiliation></author><author><keyname>Chen</keyname><forenames>Hao</forenames><affiliation>Charlie</affiliation></author><author><keyname>Nam</keyname><forenames>Young Han</forenames><affiliation>Charlie</affiliation></author><author><keyname>Hur</keyname><forenames>Sooyoung</forenames><affiliation>Charlie</affiliation></author><author><keyname>Park</keyname><forenames>Jeongho</forenames><affiliation>Charlie</affiliation></author><author><keyname>Jianzhong</keyname><affiliation>Charlie</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>Reed</keyname><forenames>Jeffrey</forenames></author><author><keyname>Liu</keyname><forenames>Lingjia</forenames></author></authors><title>Self-Tuning Sectorization: Deep Reinforcement Learning Meets Broadcast
  Beam Optimization</title><categories>eess.SP cs.IT math.IT</categories><comments>30 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beamforming in multiple input multiple output (MIMO) systems is one of the
key technologies for modern wireless communication. Creating appropriate
sector-specific broadcast beams are essential for enhancing the coverage of
cellular network and for improving the broadcast operation for control signals.
However, in order to maximize the coverage, patterns for broadcast beams need
to be adapted based on the users' distribution and movement over time. In this
work, we present self-tuning sectorization: a deep reinforcement learning
framework to optimize MIMO broadcast beams autonomously and dynamically based
on user' distribution in the network. Taking directly UE measurement results as
input, deep reinforcement learning agent can track and predict the UE
distribution pattern and come up with the best broadcast beams for each cell.
Extensive simulation results show that the introduced framework can achieve the
optimal coverage, and converge to the oracle solution for both single sector
and multiple sectors environment, and for both periodic and Markov mobility
patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06025</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06025</id><created>2019-06-14</created><authors><author><keyname>Gurugopinath</keyname><forenames>Sanjeev</forenames></author><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author><author><keyname>Al-Hammadi</keyname><forenames>Yousof</forenames></author><author><keyname>Muhaidat</keyname><forenames>Sami</forenames></author></authors><title>Cache-Aided Non-Orthogonal Multiple Access for 5G-Enabled Vehicular
  Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing demand for rich multimedia services and the emergence of the
Internet-of-Things (IoT) pose challenging requirements for the next generation
vehicular networks. Such challenges are largely related to high spectral
efficiency and low latency requirements in the context of massive content
delivery and increased connectivity. In this respect, caching and
non-orthogonal multiple access (NOMA) paradigms have been recently proposed as
potential solutions to effectively address some of these key challenges. In the
present contribution, we introduce cache-aided NOMA as an enabling technology
for vehicular networks. In this context, we first consider the full file
caching case, where each vehicle caches and requests entire files using the
NOMA principle. Without loss of generality, we consider a two-user vehicular
network communication scenario under double Nakagami$-m$ fading conditions and
propose an optimum power allocation policy. To this end, an optimization
problem that maximizes the overall probability of successful decoding of files
at each vehicle is formulated and solved. Furthermore, we consider the case of
split file caching, where each file is divided into two parts. A joint power
allocation optimization problem is formulated, where power allocation across
vehicles and cached split files is investigated. The offered analytic results
are corroborated by extensive results from computer simulations and interesting
insights are developed. Indicatively, it is shown that the proposed
caching-aided NOMA outperforms the conventional NOMA technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06027</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06027</id><created>2019-06-14</created><authors><author><keyname>Shi</keyname><forenames>Yangming</forenames></author><author><keyname>Wu</keyname><forenames>Xiaopo</forenames></author><author><keyname>Zhu</keyname><forenames>Ming</forenames></author></authors><title>Low-light Image Enhancement Algorithm Based on Retinex and Generative
  Adversarial Network</title><categories>cs.CV eess.IV</categories><comments>9 pages,10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-light image enhancement is generally regarded as a challenging task in
image processing, especially for the complex visual tasks at night or weakly
illuminated. In order to reduce the blurs or noises on the low-light images, a
large number of papers have contributed to applying different technologies.
Regretfully, most of them had served little purposes in coping with the
extremely poor illumination parts of images or test in practice. In this work,
the authors propose a novel approach for processing low-light images based on
the Retinex theory and generative adversarial network (GAN), which is composed
of the decomposition part for splitting the image into illumination image and
reflected image, and the enhancement part for generating high-quality image.
Such a discriminative network is expected to make the generated image clearer.
Couples of experiments have been implemented under the circumstance of
different lighting strength on the basis of Converted See-In-the-Dark (CSID)
datasets, and the satisfactory results have been achieved with exceeding
expectation that much encourages the authors. In a word, the proposed GAN-based
network and employed Retinex theory in this work have proven to be effective in
dealing with the low-light image enhancement problems, which will benefit the
image processing with no doubt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06042</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06042</id><created>2019-06-14</created><authors><author><keyname>Islambek</keyname><forenames>Akhmarzhan</forenames></author><author><keyname>Yang</keyname><forenames>Kecheng</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Kai</forenames></author></authors><title>FPGA-based real-time autocorrelator and its application in dynamic light
  scattering</title><categories>eess.SP</categories><doi>10.1016/j.ijleo.2019.163047</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital correlators play a significant role in dynamic light scattering (DLS)
technology, which characterizes particle size distribution. We present a field
programmable gate array (FPGA)-based digital correlator that can be applied to
process DLS data. To satisfy the DLS requirements in the FPGA logic with
limited resources, a multiple lag time period (multi-{\tau} ) method is
employed that does not require storing the full data set in memory. Moreover,
the device directly accepts the transistor-transistor logic (TTL) signal from
the photon counting detector by measuring the time intervals between photon
events and calculates the autocorrelation functions in real time. Furthermore,
we derive estimates for the error arising from the use of the multi-{\tau}
correlator. We implement all the necessary operations in a single Xilinx FPGA
chip with a lag time from 10 ns to 45 min, including a highly optimized photon
counter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06058</identifier>
 <datestamp>2020-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06058</id><created>2019-06-14</created><updated>2019-06-17</updated><authors><author><keyname>Haarburger</keyname><forenames>Christoph</forenames></author><author><keyname>Baumgartner</keyname><forenames>Michael</forenames></author><author><keyname>Truhn</keyname><forenames>Daniel</forenames></author><author><keyname>Broeckmann</keyname><forenames>Mirjam</forenames></author><author><keyname>Schneider</keyname><forenames>Hannah</forenames></author><author><keyname>Schrading</keyname><forenames>Simone</forenames></author><author><keyname>Kuhl</keyname><forenames>Christiane</forenames></author><author><keyname>Merhof</keyname><forenames>Dorit</forenames></author></authors><title>Multi Scale Curriculum CNN for Context-Aware Breast MRI Malignancy
  Classification</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted to MICCAI 2019</comments><doi>10.1007/978-3-030-32251-9_54</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification of malignancy for breast cancer and other cancer types is
usually tackled as an object detection problem: Individual lesions are first
localized and then classified with respect to malignancy. However, the drawback
of this approach is that abstract features incorporating several lesions and
areas that are not labelled as a lesion but contain global medically relevant
information are thus disregarded: especially for dynamic contrast-enhanced
breast MRI, criteria such as background parenchymal enhancement and location
within the breast are important for diagnosis and cannot be captured by object
detection approaches properly.
  In this work, we propose a 3D CNN and a multi scale curriculum learning
strategy to classify malignancy globally based on an MRI of the whole breast.
Thus, the global context of the whole breast rather than individual lesions is
taken into account. Our proposed approach does not rely on lesion
segmentations, which renders the annotation of training data much more
effective than in current object detection approaches.
  Achieving an AUROC of 0.89, we compare the performance of our approach to
Mask R-CNN and Retina U-Net as well as a radiologist. Our performance is on par
with approaches that, in contrast to our method, rely on pixelwise
segmentations of lesions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06113</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06113</id><created>2019-06-14</created><authors><author><keyname>Laga</keyname><forenames>Hamid</forenames></author></authors><title>A Survey on Deep Learning Architectures for Image-based Depth
  Reconstruction</title><categories>cs.CV cs.GR cs.RO eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating depth from RGB images is a long-standing ill-posed problem, which
has been explored for decades by the computer vision, graphics, and machine
learning communities. In this article, we provide a comprehensive survey of the
recent developments in this field. We will focus on the works which use deep
learning techniques to estimate depth from one or multiple images. Deep
learning, coupled with the availability of large training datasets, have
revolutionized the way the depth reconstruction problem is being approached by
the research community. In this article, we survey more than 100 key
contributions that appeared in the past five years, summarize the most commonly
used pipelines, and discuss their benefits and limitations. In retrospect of
what has been achieved so far, we also conjecture what the future may hold for
learning-based depth reconstruction research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06114</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06114</id><created>2019-06-14</created><updated>2019-07-08</updated><authors><author><keyname>Han</keyname><forenames>Changhee</forenames></author><author><keyname>Rundo</keyname><forenames>Leonardo</forenames></author><author><keyname>Murao</keyname><forenames>Kohei</forenames></author><author><keyname>Milacski</keyname><forenames>Zolt&#xe1;n &#xc1;d&#xe1;m</forenames></author><author><keyname>Umemoto</keyname><forenames>Kazuki</forenames></author><author><keyname>Nakayama</keyname><forenames>Hideki</forenames></author><author><keyname>Satoh</keyname><forenames>Shin'ichi</forenames></author></authors><title>GAN-based Multiple Adjacent Brain MRI Slice Reconstruction for
  Unsupervised Alzheimer's Disease Diagnosis</title><categories>eess.IV cs.CV</categories><comments>7 pages, 4 figures, accepted to CIBB 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised learning can discover various unseen diseases, relying on
large-scale unannotated medical images of healthy subjects. Towards this,
unsupervised methods reconstruct a single medical image to detect outliers
either in the learned feature space or from high reconstruction loss. However,
without considering continuity between multiple adjacent images, they cannot
directly discriminate diseases composed of the accumulation of subtle
anatomical anomalies, such as Alzheimer's Disease (AD). Moreover, no study
shows how unsupervised anomaly detection is associated with disease stages.
Therefore, we propose a two-step method using Generative Adversarial
Network-based multiple adjacent brain MRI slice reconstruction to detect AD at
various stages: (Reconstruction) Wasserstein loss with Gradient Penalty + L1
loss---trained on 3 healthy slices to reconstruct the next 3
ones---reconstructs unseen healthy/AD cases; (Diagnosis) Average/Maximum loss
(e.g., L2 loss) per scan discriminates them, comparing the reconstructed/ground
truth images. The results show that we can reliably detect AD at a very early
stage with Area Under the Curve (AUC) 0.780 while also detecting AD at a late
stage much more accurately with AUC 0.917; since our method is unsupervised, it
should also discover and alert any anomalies including rare disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06147</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06147</id><created>2019-06-12</created><updated>2019-07-28</updated><authors><author><keyname>Moriya</keyname><forenames>Yasufumi</forenames></author><author><keyname>Sanabria</keyname><forenames>Ramon</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author><author><keyname>Jones</keyname><forenames>Gareth J. F.</forenames></author></authors><title>Grounding Object Detections With Transcriptions</title><categories>cs.MM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vast amount of audio-visual data is available on the Internet thanks to
video streaming services, to which users upload their content. However, there
are difficulties in exploiting available data for supervised statistical models
due to the lack of labels. Unfortunately, generating labels for such amount of
data through human annotation can be expensive, time-consuming and prone to
annotation errors. In this paper, we propose a method to automatically extract
entity-video frame pairs from a collection of instruction videos by using
speech transcriptions and videos. We conduct experiments on image recognition
and visual grounding tasks on the automatically constructed entity-video frame
dataset of How2. The models will be evaluated on new manually annotated portion
of How2 dev5 and val set and on the Flickr30k dataset. This work constitutes a
first step towards meta-algorithms capable of automatically construct
task-specific training sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06148</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06148</id><created>2019-06-14</created><updated>2019-06-20</updated><authors><author><keyname>Br&#xfc;gger</keyname><forenames>Robin</forenames></author><author><keyname>Baumgartner</keyname><forenames>Christian F.</forenames></author><author><keyname>Konukoglu</keyname><forenames>Ender</forenames></author></authors><title>A Partially Reversible U-Net for Memory-Efficient Volumetric Image
  Segmentation</title><categories>cs.CV eess.IV</categories><comments>Accepted to MICCAI 2019; Edit v2: Added reference to related work of
  Blumberg et al</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key drawbacks of 3D convolutional neural networks for segmentation
is their memory footprint, which necessitates compromises in the network
architecture in order to fit into a given memory budget. Motivated by the
RevNet for image classification, we propose a partially reversible U-Net
architecture that reduces memory consumption substantially. The reversible
architecture allows us to exactly recover each layer's outputs from the
subsequent layer's ones, eliminating the need to store activations for
backpropagation. This alleviates the biggest memory bottleneck and enables very
deep (theoretically infinitely deep) 3D architectures. On the BraTS challenge
dataset, we demonstrate substantial memory savings. We further show that the
freed memory can be used for processing the whole field-of-view (FOV) instead
of patches. Increasing network depth led to higher segmentation accuracy while
growing the memory footprint only by a very small fraction, thanks to the
partially reversible architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06151</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06151</id><created>2019-06-10</created><authors><author><keyname>Ullo</keyname><forenames>Silvia L.</forenames></author><author><keyname>Langenkamp</keyname><forenames>Maximillian S.</forenames></author><author><keyname>Oikarinen</keyname><forenames>Tuomas P.</forenames></author><author><keyname>Del Rosso</keyname><forenames>Maria P.</forenames></author><author><keyname>Sebastianelli</keyname><forenames>Alessandro</forenames></author><author><keyname>Piccirillo</keyname><forenames>Federica</forenames></author><author><keyname>Sica</keyname><forenames>Stefania</forenames></author></authors><title>Landslide Geohazard Assessment With Convolutional Neural Networks Using
  Sentinel-2 Imagery Data</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>4 pages, 3 figures, 1 table, accepted to 2019 IEEE IGARSS Conference
  that will be held in Japan next July</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the authors aim to combine the latest state of the art models
in image recognition with the best publicly available satellite images to
create a system for landslide risk mitigation. We focus first on landslide
detection and further propose a similar system to be used for prediction. Such
models are valuable as they could easily be scaled up to provide data for
hazard evaluation, as satellite imagery becomes increasingly available. The
goal is to use satellite images and correlated data to enrich the public
repository of data and guide disaster relief efforts for locating precise areas
where landslides have occurred. Different image augmentation methods are used
to increase diversity in the chosen dataset and create more robust
classification. The resulting outputs are then fed into variants of 3-D
convolutional neural networks. A review of the current literature indicates
there is no research using CNNs (Convolutional Neural Networks) and freely
available satellite imagery for classifying landslide risk. The model has shown
to be ultimately able to achieve a significantly better than baseline accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06158</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06158</id><created>2019-06-08</created><updated>2019-07-14</updated><authors><author><keyname>Masoumi</keyname><forenames>Majid</forenames></author><author><keyname>Toews</keyname><forenames>Matthew</forenames></author><author><keyname>Lombaert</keyname><forenames>Herve</forenames></author></authors><title>WaveletBrain: Characterization of human brain via spectral graph
  wavelets</title><categories>eess.IV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early diagnosis of Alzheimer's disease plays a key role in understanding the
degree of the patient's mental decline and determining preventive therapies. In
this study, we introduce WaveletBrain, a novel representation of the white and
gray matter surfaces of the cortex. The proposed framework innovates by
deriving localized shape information from a global harmonic representation,
that can be used in large-scale population studies of surface data. Results
show that WaveletBrain leads to statistically significant improvements in
comparison to the ShapeDNA representation in a variety of experiments including
(i) classification of Alzheimer's disease, normal aging, and mild cognitive
impairment, (ii) sex classification and (iii) age prediction of subjects. We
performed our analysis on 719 patients and 2,876 surfaces. While this work
focuses primarily on Alzheimer's disease diagnosis, our proposed framework can
be used to address general surface analysis problems in neuroscience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06171</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06171</id><created>2019-06-13</created><authors><author><keyname>McBride</keyname><forenames>John M.</forenames></author><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>Imperfect fifths pack into musical scales</title><categories>cs.SD eess.AS q-bio.NC</categories><comments>including SI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Musical scales are used in cultures throughout the world, but the question as
to how they evolved remains open. Some suggest that scales based on the
harmonic series are inherently pleasant, while others propose that scales are
chosen that are easy to sing, hear and reproduce accurately. However, testing
these theories has been hindered by the sparseness of empirical evidence. Here,
to enable such examination, we assimilate data from diverse ethnomusicological
sources into a cross-cultural database of scales. We generate populations of
scales based on proposed and alternative theories and assess their similarity
to empirical distributions from the database. Most scales can be explained as
tending to include intervals roughly corresponding to perfect fifths
(&quot;imperfect fifths&quot;), and packing arguments explain the salient features of the
distributions. Scales are also preferred if their intervals are compressible,
which could facilitate efficient communication and memory of melodies. While no
single theory can explain all scales, which appear to evolve according to
different selection pressures, the simplest harmonicity-based, imperfect-fifths
packing model best fits the empirical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06180</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06180</id><created>2019-06-13</created><updated>2019-09-05</updated><authors><author><keyname>Nazib</keyname><forenames>Abdullah</forenames></author><author><keyname>Fookes</keyname><forenames>Clinton</forenames></author><author><keyname>Perrin</keyname><forenames>Dimitri</forenames></author></authors><title>Dense Deformation Network for High Resolution Tissue Cleared Image
  Registration</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The recent application of deep learning in various areas of medical image
analysis has brought excellent performance gains. In particular, technologies
based on deep learning in medical image registration can outperform traditional
optimisation-based registration algorithms both in registration time and
accuracy. However, the U-net based architectures used in most of the image
registration frameworks downscale the data, which removes global information
and affects the deformation. In this paper, we present a densely connected
convolutional architecture for deformable image registration. Our proposed
dense network downsizes data only in one stage and have dense connections
instead of the skip connections in U-net architecture. The training of the
network is unsupervised and does not require ground-truth deformation or any
synthetic deformation as a label. The proposed architecture is trained and
tested on two different versions of tissue-cleared data, at 10\% and 25\%
resolution of the original single-cell-resolution dataset. We demonstrate
comparable registration performance to state-of-the-art registration methods
and superior performance to the deep-learning based VoxelMorph method in terms
of accuracy and increased resolution handling ability. In both resolutions, the
proposed DenseDeformation network outperforms VoxelMorph in registration
accuracy. Importantly, it can register brains in one minute where conventional
methods can take hours at 25\% resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06188</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06188</id><created>2019-06-14</created><updated>2019-08-12</updated><authors><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Oksuz</keyname><forenames>Ilkay</forenames></author><author><keyname>Puyol-Anton</keyname><forenames>Esther</forenames></author><author><keyname>Ruijsink</keyname><forenames>Bram</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author><author><keyname>Schnabel</keyname><forenames>Julia A.</forenames></author></authors><title>Global and Local Interpretability for Cardiac MRI Classification</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted at MICCAI 2019, 9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning methods for classifying medical images have demonstrated
impressive accuracy in a wide range of tasks but often these models are hard to
interpret, limiting their applicability in clinical practice. In this work we
introduce a convolutional neural network model for identifying disease in
temporal sequences of cardiac MR segmentations which is interpretable in terms
of clinically familiar measurements. The model is based around a variational
autoencoder, reducing the input into a low-dimensional latent space in which
classification occurs. We then use the recently developed `concept activation
vector' technique to associate concepts which are diagnostically meaningful
(eg. clinical biomarkers such as `low left-ventricular ejection fraction') to
certain vectors in the latent space. These concepts are then qualitatively
inspected by observing the change in the image domain resulting from
interpolations in the latent space in the direction of these vectors. As a
result, when the model classifies images it is also capable of providing
naturally interpretable concepts relevant to that classification and
demonstrating the meaning of those concepts in the image domain. Our approach
is demonstrated on the UK Biobank cardiac MRI dataset where we detect the
presence of coronary artery disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06191</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06191</id><created>2019-06-14</created><updated>2020-01-15</updated><authors><author><keyname>Fortunati</keyname><forenames>Stefano</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Gini</keyname><forenames>Fulvio</forenames></author><author><keyname>Greco</keyname><forenames>Maria S.</forenames></author><author><keyname>Himed</keyname><forenames>Braham</forenames></author></authors><title>Massive MIMO Radar for Target Detection</title><categories>eess.SP cs.IT math.IT</categories><comments>12 pages, 6 figures, accepted for publication in IEEE Transactions on
  Signal Processing. A related work has been presented at ICASSP19, Brighton,
  UK, and is available at arXiv:1904.04184</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the seminal paper by Marzetta from 2010, the Massive MIMO paradigm in
communication systems has changed from being a theoretical scaled-up version of
MIMO, with an infinite number of antennas, to a practical technology. Its key
concepts have been adopted in the 5G new radio standard and base stations,
where $64$ fully-digital transceivers have been commercially deployed.
Motivated by these recent developments, this paper considers a co-located MIMO
radar with $M_T$ transmitting and $M_R$ receiving antennas and explores the
potential benefits of having a large number of virtual spatial antenna channels
$N=M_TM_R$. Particularly, we focus on the target detection problem and develop
a \textit{robust} Wald-type test that guarantees certain detection performance,
regardless of the unknown statistical characterization of the clutter
disturbance. Closed-form expressions for the probabilities of false alarm and
detection are derived for the asymptotic regime $N\to \infty$. Numerical
results are used to validate the asymptotic analysis in the finite system
regime with different disturbance models. Our results imply that there always
exists a sufficient number of antennas for which the performance requirements
are satisfied, without any a-priori knowledge of the clutter statistics. This
is referred to as the Massive MIMO regime of the radar system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06196</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06196</id><created>2019-06-14</created><authors><author><keyname>Kossaifi</keyname><forenames>Jean</forenames></author><author><keyname>Bulat</keyname><forenames>Adrian</forenames></author><author><keyname>Panagakis</keyname><forenames>Yannis</forenames></author><author><keyname>Pantic</keyname><forenames>Maja</forenames></author></authors><title>Efficient N-Dimensional Convolutions via Higher-Order Factorization</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the unprecedented success of deep convolutional neural networks came the
quest for training always deeper networks. However, while deeper neural
networks give better performance when trained appropriately, that depth also
translates in memory and computation heavy models, typically with tens of
millions of parameters. Several methods have been proposed to leverage
redundancies in the network to alleviate this complexity. Either a pretrained
network is compressed, e.g. using a low-rank tensor decomposition, or the
architecture of the network is directly modified to be more effective. In this
paper, we study both approaches in a unified framework, under the lens of
tensor decompositions. We show how tensor decomposition applied to the
convolutional kernel relates to efficient architectures such as MobileNet.
Moreover, we propose a tensor-based method for efficient higher order
convolutions, which can be used as a plugin replacement for N-dimensional
convolutions. We demonstrate their advantageous properties both theoretically
and empirically for image classification, for both 2D and 3D convolutional
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06224</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06224</id><created>2019-06-14</created><authors><author><keyname>Reyes-Figueroa</keyname><forenames>Alan</forenames></author><author><keyname>Rivera</keyname><forenames>Mariano</forenames></author></authors><title>Deep neural network for fringe pattern filtering and normalisation</title><categories>eess.IV cs.CV eess.SP physics.optics</categories><comments>13 pages (including references), 15 figures</comments><msc-class>68U10, 68T10</msc-class><acm-class>I.2.6; I.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new framework for processing Fringe Patterns (FP). Our novel
approach builds upon the hypothesis that the denoising and normalisation of FPs
can be learned by a deep neural network if enough pairs of corrupted and
cleaned FPs are provided. Although similar proposals have been reported in the
literature, we propose an improvement of a well-known deep neural network
architecture, which produces high-quality results in terms of stability and
repeatability. We test the performance of our method in various scenarios: FPs
corrupted with different degrees of noise, and corrupted with different noise
distributions. We compare our methodology versus other state-of-the-art
methods. The experimental results (on both synthetic and real data) demonstrate
the capabilities and potential of this new paradigm for processing
interferograms. We expect our work would motivate more sophisticated
developments in this direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06225</identifier>
 <datestamp>2019-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06225</id><created>2019-06-14</created><updated>2019-10-29</updated><authors><author><keyname>Eisen</keyname><forenames>Mark</forenames></author><author><keyname>Rashid</keyname><forenames>Mohammad M.</forenames></author><author><keyname>Cavalcanti</keyname><forenames>Dave</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author></authors><title>Control-Aware Scheduling for Low Latency Wireless Systems with Deep
  Learning</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of scheduling transmissions over low-latency wireless
communication links to control various control systems. Low-latency
requirements are critical in developing wireless technology for industrial
control and Tactile Internet, but are inherently challenging to meet while also
maintaining reliable performance. An alternative to ultra reliable low latency
communications is a framework in which reliability is adapted to control system
demands. We formulate the control-aware scheduling problem as a constrained
statistical optimization problem in which the optimal scheduler is a function
of current control and channel states. The scheduler is parameterized with a
deep neural network, and the constrained problem is solved using techniques
from primal-dual learning, which have a necessary model-free property in that
they do not require explicit knowledge of channels models, performance metrics,
or system dynamics to execute. The resulting control-aware deep scheduler is
evaluated in empirical simulations and strong performance is shown relative to
other model-free heuristic scheduling methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06231</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06231</id><created>2019-06-14</created><authors><author><keyname>Zhang</keyname><forenames>Jialin</forenames></author><author><keyname>Sun</keyname><forenames>Jiasong</forenames></author><author><keyname>Chen</keyname><forenames>Qian</forenames></author><author><keyname>Zuo</keyname><forenames>Chao</forenames></author></authors><title>Resolution analysis in a lens-free on-chip digital holographic
  microscope</title><categories>physics.optics eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lens-free on-chip digital holographic microscopy (LFOCDHM) is a modern
imaging technique whereby the sample is placed directly onto or very close to
the digital sensor, and illuminated by a partially coherent source located far
above it. The scattered object wave interferes with the reference (unscattered)
wave at the plane where a digital sensor is situated, producing a digital
hologram that can be processed in several ways to extract and numerically
reconstruct an in-focus image using the back propagation algorithm. Without
requiring any lenses and other intermediate optical components, the LFOCDHM has
unique advantages of offering a large effective numerical aperture (NA) close
to unity across the native wide field-of-view (FOV) of the imaging sensor in a
cost-effective and compact design. However, unlike conventional coherent
diffraction limited imaging systems, where the limiting aperture is used to
define the system performance, typical lens-free microscopes only produce
compromised imaging resolution that far below the ideal coherent diffraction
limit. At least five major factors may contribute to this limitation, namely,
the sample-to-sensor distance, spatial and temporal coherence of the
illumination, finite size of the equally spaced sensor pixels, and finite
extent of the image sub-FOV used for the reconstruction, which have not been
systematically and rigorously explored until now. In this work, we derive five
transfer function models that account for all these physical effects and
interactions of these models on the imaging resolution of LFOCDHM. We also
examine how our theoretical models can be utilized to optimize the optical
design or predict the theoretical resolution limit of a given LFOCDHM system.
We present a series of simulations and experiments to confirm the validity of
our theoretical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06234</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06234</id><created>2019-06-14</created><authors><author><keyname>Bahadori</keyname><forenames>Niloofar</forenames></author><author><keyname>Namvar</keyname><forenames>Nima</forenames></author><author><keyname>Kelley</keyname><forenames>Brian</forenames></author><author><keyname>Homaifar</keyname><forenames>Abdollah</forenames></author></authors><title>Device-to-Device Communications in Millimeter Wave Band: Impact of Beam
  Alignment Error</title><categories>eess.SP</categories><comments>6 pages, submitted and accepted at Wireless Telecommunication
  Symposium 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exploiting the millimeter wave (mmWave) band has recently attracted
considerable attention as a potential solution to widespread deployment of
device-to-device (D2D) communication challenges, namely, spectrum scarcity and
interference. However, its directional nature makes the utilization of mmWave
band a challenging task as it requires careful beam alignment between the D2D
transmitter and receiver. In this paper, we investigate the impact of
inaccurate angle-of-arrival (AoA) estimation as a beam alignment impairment on
the performance of a directional mmWave D2D network. We have used tools from
stochastic geometry to quantify the signal-to-interference-plus-noise ratio
(SINR) coverage probability in the presence of beam misalignment, which can be
applied to evaluate D2D network performance. Moreover, the analytical results
are verified to be reliable and effective through extensive simulations.
Finally, the coverage probability of the D2D network with erroneous beam
alignment is compared to the network with perfect beam alignment. The numerical
results indicate that the beam misalignment can lead to significant losses in
the network's coverage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06281</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06281</id><created>2019-06-14</created><updated>2019-06-17</updated><authors><author><keyname>Zharkov</keyname><forenames>Andrey</forenames></author><author><keyname>Zagaynov</keyname><forenames>Ivan</forenames></author></authors><title>Universal Barcode Detector via Semantic Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Barcodes are used in many commercial applications, thus fast and robust
reading is important. There are many different types of barcodes, some of them
look similar while others are completely different. In this paper we introduce
new fast and robust deep learning detector based on semantic segmentation
approach. It is capable of detecting barcodes of any type simultaneously both
in the document scans and in the wild by means of a single model. The detector
achieves state-of-the-art results on the ArTe-Lab 1D Medium Barcode Dataset
with detection rate 0.995. Moreover, developed detector can deal with more
complicated object shapes like very long but narrow or very small barcodes. The
proposed approach can also identify types of detected barcodes and performs at
real-time speed on CPU environment being much faster than previous
state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06289</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06289</id><created>2019-06-14</created><updated>2020-02-23</updated><authors><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Shlezinger</keyname><forenames>Nir</forenames></author><author><keyname>Xu</keyname><forenames>Xingyu</forenames></author><author><keyname>Ma</keyname><forenames>Dingyou</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Multi-Carrier Agile Phased Array Radar</title><categories>eess.SP cs.IT math.IT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern radar systems are expected to operate reliably in congested
environments. A candidate technology for meeting these demands is frequency
agile radar (FAR), which randomly changes its carrier frequencies. FAR is known
to improve the electronic counter-countermeasures (ECCM) performance while
facilitating operation in congested setups. To enhance the target recovery
performance of FAR in complex electromagnetic environments, we propose two
radar schemes extending FAR to multi-carrier waveforms. The first is Wideband
Multi-carrier Agile Radar (WMAR), which transmits/receives wideband waveforms
simultaneously with every antenna. To mitigate the demanding hardware
requirements associated with wideband waveforms used by WMAR, we next propose
multi-Carrier AgilE phaSed Array Radar (CAESAR). CAESAR uses narrowband
monotone waveforms, thus facilitating ease of implementation of the system,
while introducing {\em spatial agility}. We characterize the transmitted and
received signals of the proposed schemes, and develop an algorithm for
recovering the targets, based on concepts from compressed sensing to estimate
the range-Doppler parameters of the targets. We then derive conditions which
guarantee their accurate reconstruction. Our numerical study demonstrates that
both multi-carrier schemes improve performance compared to FAR while
maintaining its practical benefits. We also demonstrate that the performance of
CAESAR, which uses monotone waveforms, is within a small gap from the wideband
radar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06301</identifier>
 <datestamp>2019-06-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06301</id><created>2019-06-14</created><authors><author><keyname>Vougioukas</keyname><forenames>Konstantinos</forenames></author><author><keyname>Ma</keyname><forenames>Pingchuan</forenames></author><author><keyname>Petridis</keyname><forenames>Stavros</forenames></author><author><keyname>Pantic</keyname><forenames>Maja</forenames></author></authors><title>Video-Driven Speech Reconstruction using Generative Adversarial Networks</title><categories>eess.AS cs.CV cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech is a means of communication which relies on both audio and visual
information. The absence of one modality can often lead to confusion or
misinterpretation of information. In this paper we present an end-to-end
temporal model capable of directly synthesising audio from silent video,
without needing to transform to-and-from intermediate features. Our proposed
approach, based on GANs is capable of producing natural sounding, intelligible
speech which is synchronised with the video. The performance of our model is
evaluated on the GRID dataset for both speaker dependent and speaker
independent scenarios. To the best of our knowledge this is the first method
that maps video directly to raw audio and the first to produce intelligible
speech when tested on previously unseen speakers. We evaluate the synthesised
audio not only based on the sound quality but also on the accuracy of the
spoken words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06337</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06337</id><created>2019-06-14</created><authors><author><keyname>Vougioukas</keyname><forenames>Konstantinos</forenames></author><author><keyname>Petridis</keyname><forenames>Stavros</forenames></author><author><keyname>Pantic</keyname><forenames>Maja</forenames></author></authors><title>Realistic Speech-Driven Facial Animation with GANs</title><categories>cs.CV cs.LG eess.AS</categories><comments>arXiv admin note: text overlap with arXiv:1805.09313</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech-driven facial animation is the process that automatically synthesizes
talking characters based on speech signals. The majority of work in this domain
creates a mapping from audio features to visual features. This approach often
requires post-processing using computer graphics techniques to produce
realistic albeit subject dependent results. We present an end-to-end system
that generates videos of a talking head, using only a still image of a person
and an audio clip containing speech, without relying on handcrafted
intermediate features. Our method generates videos which have (a) lip movements
that are in sync with the audio and (b) natural facial expressions such as
blinks and eyebrow movements. Our temporal GAN uses 3 discriminators focused on
achieving detailed frames, audio-visual synchronization, and realistic
expressions. We quantify the contribution of each component in our model using
an ablation study and we provide insights into the latent representation of the
model. The generated videos are evaluated based on sharpness, reconstruction
quality, lip-reading accuracy, synchronization as well as their ability to
generate natural blinks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06355</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06355</id><created>2019-06-14</created><authors><author><keyname>Szurley</keyname><forenames>Joseph</forenames></author><author><keyname>Kolter</keyname><forenames>J. Zico</forenames></author></authors><title>Perceptual Based Adversarial Audio Attacks</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has shown the possibility of adversarial attacks on automatic
speechrecognition (ASR) systems. However, in the vast majority of work in this
area, theattacks have been executed only in the digital space, or have involved
short phrasesand static room settings. In this paper, we demonstrate a
physically realizableaudio adversarial attack. We base our approach
specifically on a psychoacoustic-property-based loss function, and automated
generation of room impulse responses, to create adversarial attacks that are
robust when played over a speaker in multiple environments. We show that such
attacks are possible even while being virtually imperceptible to listeners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06380</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06380</id><created>2019-06-14</created><authors><author><keyname>Mahmood</keyname><forenames>Aamir</forenames></author><author><keyname>Ashraf</keyname><forenames>Muhammad Ikram</forenames></author><author><keyname>Gidlund</keyname><forenames>Mikael</forenames></author><author><keyname>Torsner</keyname><forenames>Johan</forenames></author><author><keyname>Sachs</keyname><forenames>Joachim</forenames></author></authors><title>Time Synchronization in 5G Wireless Edge: Requirements and Solutions for
  Critical-MTC</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless edge is about distributing intelligence to the wireless devices
wherein the distribution of accurate time reference is essential for
time-critical machine-type communication (cMTC). In 5G-based cMTC, enabling
time synchronization in the wireless edge means moving beyond the current
synchronization needs and solutions in 5G radio access. In this article, we
analyze the device-level synchronization needs of potential cMTC applications:
industrial automation, power distribution, vehicular communication, and live
audio/video production. We present an over-the-air (OTA) synchronization scheme
comprised of 5G air interface parameters, and discuss their associated timing
errors. We evaluate the estimation error in device-to-base station propagation
delay from timing advance (TA) under random errors and show how to reduce the
estimation error. In the end, we identify the random errors specific to dense
multipath fading environments and discuss countermeasures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06408</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06408</id><created>2019-06-14</created><authors><author><keyname>Maleki</keyname><forenames>Nahal</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author></authors><title>On Bandwidth Constrained Distributed Detection of a Deterministic Signal
  in Correlated Noise</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Neyman-Pearson (NP) distributed binary detection problem in a
bandwidth constrained wireless sensor network, where the fusion center (FC) is
responsible for fusing signals received from sensors and making a final
decision about the presence or absence of a signal source in correlated
Gaussian noises. Given this signal model, our goals are (i) to investigate
whether or not randomized transmission can improve detection performance, under
communication rate constraint, and (ii) to explore how the correlation among
observation noises would impact performance. To achieve these goals, we propose
two novel schemes that combine the concepts of censoring and randomized
transmission (which we name CRT-I and CRT-II schemes) and compare them with the
pure censoring scheme. In CRT (pure censoring) schemes, we map randomly
(deterministically) a sensor's observation to a ternary transmit symbol $u_k
\in \{-1,0,1\}$ where ``$0$'' corresponds to no transmission (sensor censors).
Assuming sensors transmit $u_k$'s over orthogonal fading channels, we formulate
and address two system-level constrained optimization problems: in the first
problem we minimize the probability of miss detection at the FC, subject to
constraints on the probabilities of transmission and false alarm at the FC; in
the second (dual) problem we minimize the probability of transmission, subject
to constraints on the probabilities of miss detection and false alarm at the
FC. Based on the expressions of the objective functions and the constraints in
each problem, we propose different optimization techniques to address these two
problems. Through analysis and simulations, we explore and provide the
conditions (in terms of communication channel signal-to-noise ratio, degree of
correlation among sensor observation noises, and maximum allowed false alarm
probability) under which CRT schemes outperform pure censoring scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06418</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06418</id><created>2019-06-14</created><authors><author><keyname>Zang</keyname><forenames>J. W.</forenames></author><author><keyname>Wang</keyname><forenames>X. T.</forenames></author><author><keyname>Alvarez-Melcon</keyname><forenames>A.</forenames></author><author><keyname>Gomez-Diaz</keyname><forenames>J. S.</forenames></author></authors><title>Nonreciprocal Yagi-Uda Filtering Antennas</title><categories>eess.SP</categories><doi>10.1109/LAWP.2019.2947847</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel and compact nonreciprocal filtering antenna based
on temporal modulation. The device is composed of a third order filtering
section integrated into a Yagi-Uda planar printed antenna. Strong
nonreciprocity in transmission and reception is achieved at the same operation
frequency by time-modulating the resonators of the filtering section. These
resonators are implemented as quarter wavelength microstrip lines terminated
with varactors located on the ground plane. Such plane is also employed as a
reflector for the Yagi-Uda antenna and to host the coplanar waveguides that
feed low-frequency signals to the varactors, thus leading to a very compact
design. A prototype is manufactured and successfully tested at 2.4 GHz, showing
isolation greater than 20 dB between transmission and reception modes in both
E- and H- planes for all directions in space and a gain drop of only 3.5 dB
compared to a reference antenna. The proposed devices can easily be integrated
with other electronic circuits and may find exciting applications in
communication, radar, and sensing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06427</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06427</id><created>2019-06-14</created><authors><author><keyname>Shateri</keyname><forenames>Mohammadhadi</forenames></author><author><keyname>Messina</keyname><forenames>Francisco</forenames></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author><author><keyname>Labeau</keyname><forenames>Fabrice</forenames></author></authors><title>Deep Recurrent Adversarial Learning for Privacy-Preserving Smart Meter
  Data Release</title><categories>eess.SP cs.CR cs.IT cs.LG math.IT stat.ML</categories><comments>21 pages, 9 figures. Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart Meters (SMs) are an important component of smart electrical grids, but
they have also generated serious concerns about privacy data of consumers. In
this paper, we present a general formulation of the privacy-preserving problem
in SMs from an information-theoretic perspective. In order to capture the
casual time series structure of the power measurements, we employ Directed
Information (DI) as an adequate measure of privacy. On the other hand, to cope
with a variety of potential applications of SMs data, we study different
distortion measures along with the standard squared-error distortion. This
formulation leads to a quite general training objective (or loss) which is
optimized under a deep learning adversarial framework where two Recurrent
Neural Networks (RNNs), referred to as the releaser and the attacker, are
trained with opposite goals. An exhaustive empirical study is then performed to
validate the proposed approach for different privacy problems in three actual
data sets. Finally, we study the impact of the data mismatch problem, which
occurs when the releaser and the attacker have different training data sets and
show that privacy may not require a large level of distortion in real-world
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06428</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06428</id><created>2019-06-14</created><authors><author><keyname>Shi</keyname><forenames>Zhengshan</forenames></author><author><keyname>Cancino-Chac&#xf3;n</keyname><forenames>Carlos</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>User Curated Shaping of Expressive Performances</title><categories>cs.SD cs.HC cs.LG eess.AS</categories><comments>4 pages, ICML 2019 Machine Learning for Music Discovery Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Musicians produce individualized, expressive performances by manipulating
parameters such as dynamics, tempo and articulation. This manipulation of
expressive parameters is informed by elements of score information such as
pitch, meter, and tempo and dynamics markings (among others). In this paper we
present an interactive interface that gives users the opportunity to explore
the relationship between structural elements of a score and expressive
parameters. This interface draws on the basis function models, a data-driven
framework for expressive performance. In this framework, expressive parameters
are modeled as a function of score features, i.e., numerical encodings of
specific aspects of a musical score, using neural networks. With the proposed
interface, users are able to weight the contribution of individual score
features and understand how an expressive performance is constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06461</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06461</id><created>2019-06-14</created><authors><author><keyname>Tan</keyname><forenames>Yushi</forenames></author><author><keyname>Das</keyname><forenames>Arindam K.</forenames></author><author><keyname>Arabshahi</keyname><forenames>Payman</forenames></author><author><keyname>Kirschen</keyname><forenames>Daniel S.</forenames></author></authors><title>Post-disaster Repair Scheduling in Partially Automated Electricity
  Distribution Networks</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural disasters require repairing all damaged components in electricity
distribution networks. Optimal scheduling repair crews to minimize the
aggregate duration of interruptions reduces the harm. We consider the fact that
the number of switches is much smaller than the number of edges. The problem is
modeled by a parallel identical machine scheduling with group soft precedence
constraints to minimize the total weighted energization time. We propose an
LP-based list scheduling algorithm and a conversion algorithm and analyze their
theoretical performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06472</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06472</id><created>2019-06-15</created><updated>2020-02-25</updated><authors><author><keyname>Teyfouri</keyname><forenames>N.</forenames><affiliation>School of Advanced Technologies in Medicine, Medical Image and Signal Processing Research Center, Isfahan University of Medical Sciences</affiliation></author><author><keyname>Rabbani</keyname><forenames>H.</forenames><affiliation>School of Advanced Technologies in Medicine, Medical Image and Signal Processing Research Center, Isfahan University of Medical Sciences</affiliation></author><author><keyname>Kafieh</keyname><forenames>R.</forenames><affiliation>School of Advanced Technologies in Medicine, Medical Image and Signal Processing Research Center, Isfahan University of Medical Sciences</affiliation></author><author><keyname>Jabbari</keyname><forenames>Iraj</forenames><affiliation>Department of Nuclear Engineering, Faculty of Advanced Sciences and Technologies, University of Isfahan</affiliation></author></authors><title>An Exact and Fast CBCT Reconstruction via Pseudo-Polar Fourier Transform
  based Discrete Grangeat's Formula</title><categories>eess.IV cs.NA math.NA</categories><comments>16 pages, 28 figures, 7 Table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent application of Fourier Based Iterative Reconstruction Method
(FIRM) has made it possible to achieve high-quality 2D images from a fan beam
Computed Tomography (CT) scan with a limited number of projections in a fast
manner. The proposed methodology in this article is designed to provide 3D
Radon space in linogram fashion to facilitate the use of FIRM with cone beam
projections (CBP) for the reconstruction of 3D images in a low dose Cone Beam
CT (CBCT).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06476</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06476</id><created>2019-06-15</created><authors><author><keyname>Paul</keyname><forenames>Somdyuti</forenames></author><author><keyname>Norkin</keyname><forenames>Andrey</forenames></author><author><keyname>Bovik</keyname><forenames>Alan C.</forenames></author></authors><title>Speeding up VP9 Intra Encoder with Hierarchical Deep Learning Based
  Partition Prediction</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In VP9 video codec, the sizes of blocks are decided during encoding by
recursively partitioning 64$\times$64 superblocks using rate-distortion
optimization (RDO). This process is computationally intensive because of the
combinatorial search space of possible partitions of a superblock. Here, we
propose a deep learning based alternative framework to predict the intra-mode
superblock partitions in the form of a four-level partition tree, using a
hierarchical fully convolutional network (H-FCN). We created a large database
of VP9 superblocks and the corresponding partitions to train an H-FCN model,
which was subsequently integrated with the VP9 encoder to reduce the intra-mode
encoding time. The experimental results establish that our approach speeds up
intra-mode encoding by 69.7% on average, at the expense of a 1.71% increase in
the Bjontegaard-Delta bitrate (BD-rate). While VP9 provides several built-in
speed levels which are designed to provide faster encoding at the expense of
decreased rate-distortion performance, we find that our model is able to
outperform the fastest recommended speed level of the reference VP9 encoder for
the good quality intra encoding configuration, in terms of both speedup and
BD-rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06515</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06515</id><created>2019-06-15</created><authors><author><keyname>Chaffre</keyname><forenames>Thomas</forenames></author><author><keyname>Tudal</keyname><forenames>Kevin</forenames></author><author><keyname>Bertrand</keyname><forenames>Sylvain</forenames></author><author><keyname>Prevost</keyname><forenames>Lionel</forenames></author></authors><title>Exploiting Physical Contacts for Robustness Improvement of a
  Dot-Painting Mission by a Micro Air Vehicle</title><categories>cs.RO cs.SY eess.SY</categories><journal-ref>ICINCO 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of dot painting on a wall by a quadrotor
Micro Air Vehicle (MAV), using on-board low cost sensors (monocular camera and
IMU) for localization. A method is proposed to cope with uncertainties on the
initial positioning of the MAV with respect to the wall and to deal with walls
composed of multiple segments. This method is based on an online estimation
algorithm that makes use of information of physical contacts detected by the
drone during the flight to improve the positioning accuracy of the painted
dots. Simulation results are presented to assess quantitatively the efficiency
of the proposed approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06559</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06559</id><created>2019-06-15</created><authors><author><keyname>Costa</keyname><forenames>Luciano da Fontoura</forenames></author></authors><title>Modeling Consonance and its Relationships with Temperament, Harmony, and
  Electronic Amplification</title><categories>cs.SD cs.CY eess.AS physics.pop-ph</categories><comments>13 pages, 14 figures, 2 tables. A working manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After briefly revising the concepts of consonance/dissonance, a respective
mathematic-computational model is described, based on Helmholtz's consonance
theory and also considering the partials intensity. It is then applied to
characterize five scale temperaments, as well as some minor and major triads
and electronic amplification. In spite of the simplicity of the described
model, a surprising agreement is often observed between the obtained
consonances/dissonances and the typically observed properties of scales and
chords. The representation of temperaments as graphs where links correspond to
consonance (or dissonance) is presented and used to compare distinct
temperaments, allowing the identification of two main groups of scales. The
interesting issue of nonlinearities in electronic music amplification is also
addressed while considering quadratic distortions, and it is shown that such
nonlinearities can have drastic effect in changing the original patterns of
consonance and dissonance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06563</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06563</id><created>2019-06-15</created><authors><author><keyname>Mu</keyname><forenames>Tianjie</forenames></author><author><keyname>Chen</keyname><forenames>Xiaohui</forenames></author><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Yin</keyname><forenames>Huarui</forenames></author><author><keyname>Wang</keyname><forenames>Weidong</forenames></author></authors><title>An End-to-End Block Autoencoder For Physical Layer Based On Neural
  Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>4 pages, 15 figures, submitted to IEEE Wireless Communications
  Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Learning has been widely applied in the area of image processing and
natural language processing. In this paper, we propose an end-to-end
communication structure based on autoencoder where the transceiver can be
optimized jointly. A neural network roles as a combination of channel encoder
and modulator. In order to deal with input sequences parallelly, we introduce
block scheme, which means that the autoencoder divides the input sequence into
a series of blocks. Each block contains fixed number of bits for encoding and
modulating operation. Through training, the proposed system is able to produce
the modulated constellation diagram of each block. The simulation results show
that our autoencoder performs better than other autoencoder-based systems under
additive Gaussian white noise (AWGN) and fading channels. We also prove that
the bit error rate (BER) of proposed system can achieve an acceptable range
with increasing the number of symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06575</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06575</id><created>2019-06-15</created><updated>2020-02-23</updated><authors><author><keyname>Liu</keyname><forenames>Kewen</forenames></author><author><keyname>Ma</keyname><forenames>Yuan</forenames></author><author><keyname>Xiong</keyname><forenames>Hongxia</forenames></author><author><keyname>Yan</keyname><forenames>Zejun</forenames></author><author><keyname>Zhou</keyname><forenames>Zhijun</forenames></author><author><keyname>Liu</keyname><forenames>Chaoyang</forenames></author><author><keyname>Fang</keyname><forenames>Panpan</forenames></author><author><keyname>Li</keyname><forenames>Xiaojun</forenames></author><author><keyname>Chen</keyname><forenames>Yalei</forenames></author></authors><title>Single Image Super-resolution via Dense Blended Attention Generative
  Adversarial Network for Clinical Diagnosis</title><categories>eess.IV cs.CV</categories><comments>We abandoned this paper due to its limitation only applied on medical
  images, please view our lastest work at arXiv:1911.03464</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  During training phase, more connections (e.g. channel concatenation in last
layer of DenseNet) means more occupied GPU memory and lower GPU utilization,
requiring more training time. The increase of training time is also not
conducive to launch application of SR algorithms. This's why we abandoned
DenseNet as basic network. Futhermore, we abandoned this paper due to its
limitation only applied on medical images. Please view our lastest work applied
on general images at arXiv:1911.03464.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06579</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06579</id><created>2019-06-15</created><updated>2019-06-23</updated><authors><author><keyname>Yoo</keyname><forenames>YoungJoon</forenames></author><author><keyname>Han</keyname><forenames>Dongyoon</forenames></author><author><keyname>Yun</keyname><forenames>Sangdoo</forenames></author></authors><title>EXTD: Extremely Tiny Face Detector via Iterative Filter Reuse</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new multi-scale face detector having an extremely
tiny number of parameters (EXTD),less than 0.1 million, as well as achieving
comparable performance to deep heavy detectors. While existing multi-scale face
detectors extract feature maps with different scales from a single backbone
network, our method generates the feature maps by iteratively reusing a shared
lightweight and shallow backbone network. This iterative sharing of the
backbone network significantly reduces the number of parameters, and also
provides the abstract image semantics captured from the higher stage of the
network layers to the lower-level feature map. The proposed idea is employed by
various model architectures and evaluated by extensive experiments. From the
experiments from WIDER FACE dataset, we show that the proposed face detector
can handle faces with various scale and conditions, and achieved comparable
performance to the more massive face detectors that few hundreds and tens times
heavier in model size and floating point operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06586</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06586</id><created>2019-06-15</created><authors><author><keyname>Arslan</keyname><forenames>Yuksel</forenames></author></authors><title>A New Approach to Real Time Impulsive Sound Detection for Surveillance
  Applications</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the surveillance systems for public safety are solely based on one or
more video cameras. These camera systems have some drawbacks such that they
have poor performance in adverse weather conditions or during night time.
Therefore most of the time, some other sensors should accompany to video
cameras. Although audio surveillance is in its early stage, there has been
considerable amount of work in this area in the last decade. In this paper we
make a review of impulsive sound detection algorithms. Sounds from dangerous
events such as gunshots, explosions, human screaming can be classified as
impulsive sounds, so this paper reviews all impulsive sound detection
algorithms along with impulsive noise detection algorithms although they
progress in their own path. These dangerous sound events have no other
detection means except audio. We try to adapt some algorithms used in impulsive
noise detection to the area of impulsive sound detection. Tests show that
Warped Linear Prediction (WLP) can be used for impulsive sound detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06591</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06591</id><created>2019-06-15</created><authors><author><keyname>Dash</keyname><forenames>Dinesh</forenames></author></authors><title>Plane Sweep Algorithms for Data Collection in Wireless Sensor Network
  using Mobile Sink</title><categories>cs.NI cs.CG eess.SP</categories><comments>13 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Usage of mobile sink(s) for data gathering in wireless sensor networks(WSNs)
improves the performance of WSNs in many respects such as power consumption,
lifetime, etc. In some applications, the mobile sink $MS$ travels along a
predefined path to collect data from the nearby sensors, which are referred as
sub-sinks. Due to the slow speed of the $MS$, the data delivery latency is
high. However, optimizing the {\em data gathering schedule}, i.e. optimizing
the transmission schedule of the sub-sinks to the $MS$ and the movement speed
of the $MS$ can reduce data gathering latency. We formulate two novel
optimization problems for data gathering in minimum time. The first problem
determines an optimal data gathering schedule of the $MS$ by controlling the
data transmission schedule and the speed of the $MS$, where the data
availabilities of the sub-sinks are given. The second problem generalizes the
first, where the data availabilities of the sub-sinks are unknown. Plane sweep
algorithms are proposed for finding optimal data gathering schedule and data
availabilities of the sub-sinks. The performances of the proposed algorithms
are evaluated through simulations. The simulation results reveal that the
optimal distribution of data among the sub-sinks together with optimal data
gathering schedule improves the data gathering time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06600</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06600</id><created>2019-06-15</created><authors><author><keyname>Kurmi</keyname><forenames>Indrajit</forenames></author><author><keyname>Schedl</keyname><forenames>David C.</forenames></author><author><keyname>Bimber</keyname><forenames>Oliver</forenames></author></authors><title>A Statistical View on Synthetic Aperture Imaging for Occlusion Removal</title><categories>cs.GR cs.CV eess.IV</categories><comments>10 pages, 11 figures, IEEE Sensors Jounral (accepted)</comments><report-no>upload03</report-no><acm-class>I.4.1; I.4.3</acm-class><doi>10.1109/JSEN.2019.2922731</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthetic apertures find applications in many fields, such as radar, radio
telescopes, microscopy, sonar, ultrasound, LiDAR, and optical imaging. They
approximate the signal of a single hypothetical wide aperture sensor with
either an array of static small aperture sensors or a single moving small
aperture sensor. Common sense in synthetic aperture sampling is that a dense
sampling pattern within a wide aperture is required to reconstruct a clear
signal. In this article we show that there exists practical limits to both,
synthetic aperture size and number of samples for the application of occlusion
removal. This leads to an understanding on how to design synthetic aperture
sampling patterns and sensors in a most optimal and practically efficient way.
We apply our findings to airborne optical sectioning which uses camera drones
and synthetic aperture imaging to computationally remove occluding vegetation
or trees for inspecting ground surfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06601</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06601</id><created>2019-06-15</created><authors><author><keyname>Majee</keyname><forenames>Soumendu</forenames></author><author><keyname>Balke</keyname><forenames>Thilo</forenames></author><author><keyname>Kemp</keyname><forenames>Craig A. J.</forenames></author><author><keyname>Buzzard</keyname><forenames>Gregery T.</forenames></author><author><keyname>Bouman</keyname><forenames>Charles A.</forenames></author></authors><title>4D X-Ray CT Reconstruction using Multi-Slice Fusion</title><categories>eess.IV cs.CV</categories><comments>8 pages, 8 figures, IEEE International Conference on Computational
  Photography 2019, Tokyo</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an increasing need to reconstruct objects in four or more dimensions
corresponding to space, time and other independent parameters. The best 4D
reconstruction algorithms use regularized iterative reconstruction approaches
such as model based iterative reconstruction (MBIR), which depends critically
on the quality of the prior modeling. Recently, Plug-and-Play methods have been
shown to be an effective way to incorporate advanced prior models using
state-of-the-art denoising algorithms designed to remove additive white
Gaussian noise (AWGN). However, state-of-the-art denoising algorithms such as
BM4D and deep convolutional neural networks (CNNs) are primarily available for
2D and sometimes 3D images. In particular, CNNs are difficult and
computationally expensive to implement in four or more dimensions, and training
may be impossible if there is no associated high-dimensional training data.
  In this paper, we present Multi-Slice Fusion, a novel algorithm for 4D and
higher-dimensional reconstruction, based on the fusion of multiple
low-dimensional denoisers. Our approach uses multi-agent consensus equilibrium
(MACE), an extension of Plug-and-Play, as a framework for integrating the
multiple lower-dimensional prior models. We apply our method to the problem of
4D cone-beam X-ray CT reconstruction for Non Destructive Evaluation (NDE) of
moving parts. This is done by solving the MACE equations using
lower-dimensional CNN denoisers implemented in parallel on a heterogeneous
cluster. Results on experimental CT data demonstrate that Multi-Slice Fusion
can substantially improve the quality of reconstructions relative to
traditional 4D priors, while also being practical to implement and train.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06612</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06612</id><created>2019-06-15</created><updated>2020-02-11</updated><authors><author><keyname>Shi</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Baosen</forenames></author></authors><title>No-regret Learning in Cournot Games</title><categories>cs.GT cs.MA cs.SY eess.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the convergence of no-regret learning in Cournot games
with continuous actions. Cournot games are the essential model for many
socio-economic systems, where players compete by strategically setting their
output quantity. We assume that players do not have full information of the
game and thus cannot pre-compute a Nash equilibrium. Two types of feedback are
considered: one is bandit feedback and the other is gradient feedback. To study
the convergence of the induced sequence of play, we introduce the notion of
convergence in measure, and show that the players' actual sequence of action
converges to the unique Nash equilibrium. In addition, our results naturally
extend the no-regret learning algorithms' time-average regret bounds to obtain
the final-iteration convergence rates. Together, our work presents
significantly sharper convergence results for learning in games without strong
assumptions on game property (e.g., monotonicity) and shows how exploiting the
game information feedback can influence the convergence rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06642</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06642</id><created>2019-06-15</created><updated>2020-01-31</updated><authors><author><keyname>Wen</keyname><forenames>Fei</forenames></author><author><keyname>Ying</keyname><forenames>Rendong</forenames></author><author><keyname>Liu</keyname><forenames>Yipeng</forenames></author><author><keyname>Liu</keyname><forenames>Peilin</forenames></author><author><keyname>Truong</keyname><forenames>Trieu-Kien</forenames></author></authors><title>A Simple Local Minimal Intensity Prior and An Improved Algorithm for
  Blind Image Deblurring</title><categories>eess.IV cs.GR</categories><comments>13 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind image deblurring is a long standing challenging problem in image
processing and low-level vision. Recently, sophisticated priors such as dark
channel prior, extreme channel prior, and local maximum gradient prior, have
shown promising effectiveness. However, these methods are computationally
expensive. Meanwhile, since these priors involved subproblems cannot be solved
explicitly, approximate solution is commonly used, which limits the best
exploitation of their capability. To address these problems, this work firstly
proposes a simplified sparsity prior of local minimal pixels, namely patch-wise
minimal pixels (PMP). The PMP of clear images is much more sparse than that of
blurred ones, and hence is very effective in discriminating between clear and
blurred images. Then, a novel algorithm is designed to efficiently exploit the
sparsity of PMP in deblurring. The new algorithm flexibly imposes sparsity
inducing on the PMP under the MAP framework rather than directly uses the half
quadratic splitting algorithm. By this, it avoids non-rigorous approximation
solution in existing algorithms, while being much more computationally
efficient. Extensive experiments demonstrate that the proposed algorithm can
achieve better practical stability compared with state-of-the-arts. In terms of
deblurring quality, robustness and computational efficiency, the new algorithm
is superior to state-of-the-arts. Code for reproducing the results of the new
method is available at https://github.com/FWen/deblur-pmp.git.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06649</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06649</id><created>2019-06-16</created><authors><author><keyname>Qiu</keyname><forenames>Min</forenames></author><author><keyname>Wu</keyname><forenames>Xiaowei</forenames></author><author><keyname>Xie</keyname><forenames>Yixuan</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Density Evolution Analysis of Partially Information Coupled Turbo Codes
  on the Erasure Channel</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 3 figures, accepted 2019 IEEE Information Theory Workshop
  (ITW)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the performance of a class of spatially coupled
codes, namely partially information coupled turbo codes (PIC-TCs) over the
binary erasure channel (BEC). This class of codes enjoy flexible code rate
adjustment by varying the coupling ratio. Moreover, the coupling method can be
directly applied to any component codes without changing the encoding and
decoding architectures of the underlying component codes. However, the
theoretical performance of PIC-TCs has not been fully investigated. For this
work, we consider the codes that have coupling memory $m$ and study the
corresponding graph model. We then derive the exact density evolution equations
for these code ensembles with any given coupling ratio and coupling memory $m$
to precisely compute their belief propagation decoding thresholds for the BEC.
Our simulation results verify the correctness of our theoretical analysis and
also show better error performance over uncoupled turbo codes with a variety of
code rates on the BEC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06651</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06651</id><created>2019-06-16</created><authors><author><keyname>Qiu</keyname><forenames>Min</forenames></author></authors><title>Lattice Coding for Downlink Multiuser Transmission</title><categories>cs.IT eess.SP math.IT</categories><comments>353 pages, PhD thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis, we mainly investigate the lattice coding problem of the
downlink communication between a base station and multiple users. The base
station broadcasts a message containing each user's intended message. The
capacity limit of such a system setting is already well-known while the design
of practical coding and modulation schemes to approach the theoretical limit
has not been fully studied and investigated in the literature. This thesis
attempts to address this problem by providing a systematic design on lattice
coding and modulation schemes for downlink multiuser communication systems. The
main idea is to exploit the structure property of lattices to harness
interference from downlink users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06666</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06666</id><created>2019-06-16</created><authors><author><keyname>Alvarez-Estevez</keyname><forenames>Diego</forenames></author><author><keyname>Fern&#xe1;ndez-Varela</keyname><forenames>Isaac</forenames></author></authors><title>Dealing with the database variability problem in learning from medical
  data: an ensemble-based approach using convolutional neural networks and a
  case of study applied to automatic sleep scoring</title><categories>cs.LG eess.SP stat.ML</categories><comments>27 pages, 1 figure, 5 tables, 4 supplementary tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we examine the problematic associated to the development of
machine learning models to achieve robust generalization capabilities on
common-task multiple-database scenarios. Referred as the ''database variability
problem'', we focus on a specific medical domain (sleep staging in Sleep
Medicine) to show the non-triviality of translating the estimated model's local
generalization capabilities to independent external databases. We analyze some
of the scalability problems when multiple-database data are used as input to
train a single learning model. Then, we introduce a novel approach based on an
ensemble of local models, and we show its advantages in terms of inter-database
generalization performance and data scalability. Further on, we analyze
different model configurations and data pre-processing techniques to evaluate
their effects over the overall generalization performance. For this purpose we
carry out experimentation involving several sleep databases evaluating
different machine learning models based on Convolutional Neural Networks
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06695</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06695</id><created>2019-06-16</created><authors><author><keyname>Lou</keyname><forenames>Tai-shan</forenames></author><author><keyname>Chen</keyname><forenames>Nan-hua</forenames></author><author><keyname>Xiong</keyname><forenames>Hua</forenames></author><author><keyname>Li</keyname><forenames>Ya-xi</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>Ensemble Consider Kalman Filtering</title><categories>eess.SY cs.SY</categories><comments>5 pages, 3 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the ensemble consider Kalman filter is proposed to mitigate
the negative effects of uncertain parameters in nonlinear dynamic and
measurement models. The ensemble Kalman filter can avoid using the Jacobian
matrices and reduce the computational complexity, the unknown parameters of the
models still are not considered. By incorporating the statistics of the
uncertain parameters into the state estimation formulations and using an
augmented-state approach, the ensemble integration is reset by resampling the
ensemble members in the new step, and the EnCKF algorithm is derived. Two
numerical simulations show that the presented EnCKF can mitigate the negative
effects of the uncertain parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06697</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06697</id><created>2019-06-16</created><authors><author><keyname>Kawulok</keyname><forenames>Michal</forenames></author><author><keyname>Piechaczek</keyname><forenames>Szymon</forenames></author><author><keyname>Hrynczenko</keyname><forenames>Krzysztof</forenames></author><author><keyname>Benecki</keyname><forenames>Pawel</forenames></author><author><keyname>Kostrzewa</keyname><forenames>Daniel</forenames></author><author><keyname>Nalepa</keyname><forenames>Jakub</forenames></author></authors><title>On training deep networks for satellite image super-resolution</title><categories>cs.CV eess.IV</categories><comments>IGARSS 2019 conference paper</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The capabilities of super-resolution reconstruction (SRR)---techniques for
enhancing image spatial resolution---have been recently improved significantly
by the use of deep convolutional neural networks. Commonly, such networks are
learned using huge training sets composed of original images alongside their
low-resolution counterparts, obtained with bicubic downsampling. In this paper,
we investigate how the SRR performance is influenced by the way such
low-resolution training data are obtained, which has not been explored up to
date. Our extensive experimental study indicates that the training data
characteristics have a large impact on the reconstruction accuracy, and the
widely-adopted approach is not the most effective for dealing with satellite
images. Overall, we argue that developing better training data preparation
routines may be pivotal in making SRR suitable for real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06746</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06746</id><created>2019-06-16</created><authors><author><keyname>Hamidi</keyname><forenames>Nima</forenames></author><author><keyname>Vahidzadeh</keyname><forenames>Mohsen</forenames></author><author><keyname>Baek</keyname><forenames>Stephen</forenames></author></authors><title>Multi-scale Embedded CNN for Music Tagging (MsE-CNN)</title><categories>cs.SD cs.IR cs.LG eess.AS</categories><comments>Proceedings of the 36th International Conference on Machine Learning
  (ICML)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) recently gained notable attraction in a
variety of machine learning tasks: including music classification and style
tagging. In this work, we propose implementing intermediate connections to the
CNN architecture to facilitate the transfer of multi-scale/level knowledge
between different layers. Our novel model for music tagging shows significant
improvement in comparison to the proposed approaches in the literature, due to
its ability to carry low-level timbral features to the last layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06762</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06762</id><created>2019-06-16</created><updated>2019-11-14</updated><authors><author><keyname>Maiti</keyname><forenames>Soumi</forenames></author><author><keyname>Mandel</keyname><forenames>Michael I</forenames></author></authors><title>Parametric Resynthesis with neural vocoders</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise suppression systems generally produce output speech with compromised
quality. We propose to utilize the high quality speech generation capability of
neural vocoders for noise suppression. We use a neural network to predict clean
mel-spectrogram features from noisy speech and then compare two neural
vocoders, WaveNet and WaveGlow, for synthesizing clean speech from the
predicted mel spectrogram. Both WaveNet and WaveGlow achieve better subjective
and objective quality scores than the source separation model Chimera++.
Further, WaveNet and WaveGlow also achieve significantly better subjective
quality ratings than the oracle Wiener mask. Moreover, we observe that between
WaveNet and WaveGlow, WaveNet achieves the best subjective quality scores,
although at the cost of much slower waveform generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06763</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06763</id><created>2019-06-16</created><authors><author><keyname>Henderson</keyname><forenames>Trevor</forenames></author><author><keyname>Solomon</keyname><forenames>Justin</forenames></author></authors><title>Audio Transport: A Generalized Portamento via Optimal Transport</title><categories>eess.AS cs.SD</categories><comments>Accepted to The 22nd International Conference on Digital Audio
  Effects (DAFx-19), Birmingham, UK, September 2-6, 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper proposes a new method to interpolate between two audio signals. As
an interpolation parameter is changed, the pitches in one signal slide to the
pitches in the other, producing a portamento, or musical glide. The assignment
of pitches in one sound to pitches in the other is accomplished by solving a
1-dimensional optimal transport problem. In addition, we introduce several
techniques that preserve the audio fidelity over this highly non-linear
transformation.
  A portamento is a natural way for a musician to transition between notes, but
traditionally it has only been possible for instruments with a continuously
variable pitch like the human voice or the violin. Audio transport extends the
portamento to any instrument, even polyphonic ones. Moreover, the effect can be
used to transition between different instruments, groups of instruments, or
really any transient-less audio signals. The audio transport effect operates in
real-time; we open-source implementation is provided. In experiments with
sinusoidal inputs, the interpolating effect is indistinguishable from ideal
sine sweeps. In general, the effect produces clear, musical results for a wide
variety of inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06764</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06764</id><created>2019-06-16</created><authors><author><keyname>Cuomo</keyname><forenames>Francesca</forenames></author><author><keyname>Campo</keyname><forenames>Manuel</forenames></author><author><keyname>Bassetti</keyname><forenames>Enrico</forenames></author><author><keyname>Cartella</keyname><forenames>Lorenzo</forenames></author><author><keyname>Sole</keyname><forenames>Federica</forenames></author><author><keyname>Bianchi</keyname><forenames>Giuseppe</forenames></author></authors><title>Adaptive mitigation of the Air-Time pressure in LoRa multi-gateway
  architectures</title><categories>eess.SP</categories><doi>10.5281/zenodo.2572479</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LoRa is a promising technology in the current Internet of Things market,
which operates in un-licensed bands achieving long-range communications and
with ultra power devices. In this work we capitalize on the idea introduced in
[1], i.e. balance the Air-Time of the different modulation spreading factors
(SF), and adapt it to operate in a typical metropolitan scenario comprising
multiple gateways (GWs) interconnected to a same network server. Our proposed
approach, named ADaptive Mitigation of the AIr-time pressure in lORa (AD
MAIORA), relies on a suitable measure of the per-spreading-factor load at each
GW - quantified by means of a so-called pressure table -, and on a relevant
heuristic algorithm which attempts to balance such a per-SF-pressure.
Especially in cases of very loaded scenarios, where a high number of nodes
insist on the same GWs, the use of AD MAIORA shows significant performance
gains, up to a factor of 5 improvements with respect to the legacy LoRaWAN's
Adaptive Data Rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06777</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06777</id><created>2019-06-16</created><updated>2019-07-09</updated><authors><author><keyname>Furieri</keyname><forenames>Luca</forenames></author><author><keyname>Zheng</keyname><forenames>Yang</forenames></author><author><keyname>Papachristodoulou</keyname><forenames>Antonis</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author></authors><title>Sparsity Invariance for Convex Design of Distributed Controllers</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of designing optimal distributed controllers for
linear time invariant (LTI) systems, which corresponds to minimizing a norm of
the closed-loop system subject to sparsity constraints on the controller
structure. This problem is NP-hard in general and motivates the development of
tractable approximations. We characterize a class of convex restrictions based
on a new notion of Sparsity Invariance (SI). The underlying idea of SI is to
design sparsity patterns for transfer matrices Y(s) and X(s) such that any
corresponding controller K(s)=Y(s)X(s)^-1 exhibits the desired sparsity
pattern. For sparsity constraints, the approach of SI goes beyond the
well-known notion of Quadratic Invariance (QI) in the sense that 1) the SI
framework returns a convex restriction for any distributed control problem
independently of whether QI holds; 2) the solution via the SI approach is
guaranteed to be globally optimal when QI holds and performs at least as well
as that obtained by considering a nearest QI subset. Moreover, the notion of SI
can be naturally applied to the problem of designing structured static
state-feedback controllers, while QI is not utilizable. Numerical examples show
that even for non-QI cases, SI can recover solutions that are 1) globally
optimal and 2) strictly more performing than previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06819</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06819</id><created>2019-06-16</created><updated>2019-06-29</updated><authors><author><keyname>Li</keyname><forenames>Hanyu</forenames></author><author><keyname>Li</keyname><forenames>Jingjing</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author></authors><title>A Fusion Adversarial Underwater Image Enhancement Network with a Public
  Test Dataset</title><categories>eess.IV cs.CV</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underwater image enhancement algorithms have attracted much attention in
underwater vision task. However, these algorithms are mainly evaluated on
different data sets and different metrics. In this paper, we set up an
effective and pubic underwater test dataset named U45 including the color
casts, low contrast and haze-like effects of underwater degradation and propose
a fusion adversarial network for enhancing underwater images. Meanwhile, the
well-designed the adversarial loss including Lgt loss and Lfe loss is presented
to focus on image features of ground truth, and image features of the image
enhanced by fusion enhance method, respectively. The proposed network corrects
color casts effectively and owns faster testing time with fewer parameters.
Experiment results on U45 dataset demonstrate that the proposed method achieves
better or comparable performance than the other state-of-the-art methods in
terms of qualitative and quantitative evaluations. Moreover, an ablation study
demonstrates the contributions of each component, and the application test
further shows the effectiveness of the enhanced images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06854</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06854</id><created>2019-06-17</created><authors><author><keyname>Han</keyname><forenames>Yoseob</forenames></author><author><keyname>Kim</keyname><forenames>Junyoung</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Differentiated Backprojection Domain Deep Learning for Conebeam Artifact
  Removal</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conebeam CT using a circular trajectory is quite often used for various
applications due to its relative simple geometry. For conebeam geometry,
Feldkamp, Davis and Kress algorithm is regarded as the standard reconstruction
method, but this algorithm suffers from so-called conebeam artifacts as the
cone angle increases. Various model-based iterative reconstruction methods have
been developed to reduce the cone-beam artifacts, but these algorithms usually
require multiple applications of computational expensive forward and
backprojections. In this paper, we develop a novel deep learning approach for
accurate conebeam artifact removal. In particular, our deep network, designed
on the differentiated backprojection domain, performs a data-driven inversion
of an ill-posed deconvolution problem associated with the Hilbert transform.
The reconstruction results along the coronal and sagittal directions are then
combined using a spectral blending technique to minimize the spectral leakage.
Experimental results show that our method outperforms the existing iterative
methods despite significantly reduced runtime complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06858</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06858</id><created>2019-06-17</created><authors><author><keyname>Cao</keyname><forenames>Xiaowen</forenames></author><author><keyname>Zhu</keyname><forenames>Guangxu</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>Optimal Power Control for Over-the-Air Computation in Fading Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the power control problem for Over-the-air
computation (AirComp) over fading channels. Our objective is to minimize the
computation error by jointly optimizing the transmit power at the
power-constrained devices and a signal scaling factor (called denoising factor)
at the fusion center (FC). The problem is generally non-convex due to the
coupling of the transmit power over devices and denoising factor at the FC. To
tackle the challenge, we first consider the special case with static channels,
for which we derive the optimal solution in closed form. The optimal power
control exhibits a threshold-based structure. Specifically, for each device, if
the product of the channel quality and power budget, called quality indicator,
exceeds an optimized threshold, this device applies channel-inversion power
control; otherwise, it performs full power transmission. Building on the
results, we proceed to consider the general case with time-varying channels. To
solve the more challenging non-convex power control problem, we use the
Lagrange-duality method via exploiting its &quot;time-sharing&quot; property. The derived
optimal power control exhibits a regularized channel inversion structure, where
the regularization has the function of balancing the tradeoff between the
signal-magnitude alignment and noise suppression. Moreover, for the special
case with only one device being power limited, we show that the optimal power
control for the power-limited device has an interesting channel-inversion
water-filling structure, while those for other devices (with sufficient power
budgets) reduce to channel-inversion power control over all fading states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06867</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06867</id><created>2019-06-17</created><authors><author><keyname>Mamaghani</keyname><forenames>Milad Tatar</forenames></author><author><keyname>Hong</keyname><forenames>Yi</forenames></author></authors><title>On the Performance of Low-Altitude UAV-Enabled Secure AF Relaying with
  Cooperative Jamming and SWIPT</title><categories>cs.IT eess.SP math.IT</categories><comments>10 pages, 9 figures, Submitted for possible journal publication</comments><doi>10.1109/ACCESS.2019.2948384</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel cooperative secure unmanned aerial vehicle (UAV)
aided transmission protocol, where a source (Alice) sends confidential
information to a destination (Bob) via an energy-constrained UAV-mounted
amplify-and-forward (AF) relay in the presence of a ground eavesdropper (Eve).
We adopt destination-assisted cooperative jamming (CJ) as well as simultaneous
wireless information and power transfer (SWIPT) at the UAV-mounted relay to
enhance physical-layer security (PLS) and transmission reliability. Assuming a
low altitude UAV, we derive connection probability (CP), secrecy outage
probability (SOP), instantaneous secrecy rate, and average secrecy rate (ASR)
of the proposed protocol over Air-Ground (AG) channels, which are modeled as
Rician fading with elevation-angel dependent parameters. By simulations, we
verify our theoretical results and demonstrate significant performance
improvement of our protocol, when compared to conventional transmission
protocol with ground relaying and UAV-based transmission protocol without
destination-assisted jamming. Finally, we evaluate the impacts of different
system parameters and different UAV's locations on the proposed protocol in
terms of ASR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06874</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06874</id><created>2019-06-17</created><updated>2019-06-20</updated><authors><author><keyname>Liu</keyname><forenames>Zhi-Song</forenames></author><author><keyname>Wang</keyname><forenames>Li-Wen</forenames></author><author><keyname>Li</keyname><forenames>Chu-Tak</forenames></author><author><keyname>Siu</keyname><forenames>Wan-Chi</forenames></author></authors><title>Hierarchical Back Projection Network for Image Super-Resolution</title><categories>cs.CV eess.IV</categories><journal-ref>2019 IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning based single image super-resolution methods use a large number
of training datasets and have recently achieved great quality progress both
quantitatively and qualitatively. Most deep networks focus on nonlinear mapping
from low-resolution inputs to high-resolution outputs via residual learning
without exploring the feature abstraction and analysis. We propose a
Hierarchical Back Projection Network (HBPN), that cascades multiple HourGlass
(HG) modules to bottom-up and top-down process features across all scales to
capture various spatial correlations and then consolidates the best
representation for reconstruction. We adopt the back projection blocks in our
proposed network to provide the error correlated up and down-sampling process
to replace simple deconvolution and pooling process for better estimation. A
new Softmax based Weighted Reconstruction (WR) process is used to combine the
outputs of HG modules to further improve super-resolution. Experimental results
on various datasets (including the validation dataset, NTIRE2019, of the Real
Image Super-resolution Challenge) show that our proposed approach can achieve
and improve the performance of the state-of-the-art methods for different
scaling factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06878</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06878</id><created>2019-06-17</created><updated>2019-07-04</updated><authors><author><keyname>Xu</keyname><forenames>Jun</forenames></author><author><keyname>Huang</keyname><forenames>Yuan</forenames></author><author><keyname>Liu</keyname><forenames>Li</forenames></author><author><keyname>Zhu</keyname><forenames>Fan</forenames></author><author><keyname>Hou</keyname><forenames>Xingsong</forenames></author><author><keyname>Shao</keyname><forenames>Ling</forenames></author></authors><title>Noisy-As-Clean: Learning Unsupervised Denoising from the Corrupted Image</title><categories>cs.CV eess.IV</categories><comments>13 pages, 7 figures, 8 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years, supervised networks have achieved promising
performance on image denoising. These methods learn image priors and synthetic
noise statistics from plenty pairs of noisy and clean images. Recently, several
unsupervised denoising networks are proposed only using external noisy images
for training. However, the networks learned from external data inherently
suffer from the domain gap dilemma, i.e., the image priors and noise statistics
are very different between the training data and the corrupted test images.
This dilemma becomes more clear when dealing with the signal dependent
realistic noise in real photographs. In this work, we provide a statistically
useful conclusion: it is possible to learn an unsupervised network only with
the corrupted image, approximating the optimal parameters of a supervised
network learned with pairs of noisy and clean images. This is achieved by
proposing a &quot;Noisy-As-Clean&quot; strategy: taking the corrupted image as &quot;clean&quot;
target and the simulated noisy images (based on the corrupted image) as inputs.
Extensive experiments show that the unsupervised denoising networks learned
with our &quot;Noisy-As-Clean&quot; strategy surprisingly outperforms previous supervised
networks on removing several typical synthetic noise and realistic noise. The
code will be publicly released.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06907</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06907</id><created>2019-06-17</created><updated>2020-01-13</updated><authors><author><keyname>Engels</keyname><forenames>Jonas</forenames></author><author><keyname>Claessens</keyname><forenames>Bert</forenames></author><author><keyname>Deconinck</keyname><forenames>Geert</forenames></author></authors><title>Optimal Combination of Frequency Control and Peak Shaving with Battery
  Storage Systems</title><categories>math.OC cs.SY eess.SY</categories><comments>Published in IEEE Transactions on Smart Grid</comments><journal-ref>IEEE Transactions on Smart Grid, 2019</journal-ref><doi>10.1109/TSG.2019.2963098</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining revenue streams by providing multiple services with battery storage
systems increases profitability and enhances the investment case. In this work,
we present a novel optimisation and control framework that enables a storage
system to optimally combine the provision of primary frequency control services
with peak shaving of a consumption profile. We adopt a dynamic programming
framework to connect the daily bidding in frequency control markets with the
longer term peak shaving objective: reducing the maximum consumption peak over
an entire billing period. The framework also allows to aggregate frequency
control capacity of multiple batteries installed at different sites, creating
synergies when the consumption profile peaks occur on different times. Using a
case study of two batteries at two industrial sites, we show that the presented
approach increases net profit of the batteries significantly compared to using
the batteries for only peak shaving or frequency control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06909</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06909</id><created>2019-06-17</created><updated>2019-06-24</updated><authors><author><keyname>Cances</keyname><forenames>Leo</forenames></author><author><keyname>Guyot</keyname><forenames>Patrice</forenames></author><author><keyname>Pellegrini</keyname><forenames>Thomas</forenames></author></authors><title>Evaluation of post-processing algorithms for polyphonic sound event
  detection</title><categories>eess.AS cs.SD</categories><comments>5 pages, 2 figures, 1 table 2019 IEEE Workshop on Applications of
  Signal Processing to Audio and Acoustics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound event detection (SED) aims at identifying audio events (audio tagging
task) in recordings and then locating them temporally (localization task). This
last task ends with the segmentation of the frame-level class predictions, that
determines the onsets and offsets of the audio events. Yet, this step is often
overlooked in scientific publications. In this paper, we focus on the
post-processing algorithms used to identify the audio event boundaries.
Different post-processing steps are investigated, through smoothing,
thresholding, and optimization. In particular, we evaluate different approaches
for temporal segmentation, namely statistic-based and parametric methods.
Experiments are carried out on the DCASE 2018 challenge task 4 data. We
compared post-processing algorithms on the temporal prediction curves of two
models: one based on the challenge's baseline and a Multiple Instance Learning
(MIL) model. Results show the crucial impact of the post-processing methods on
the final detection score. Statistic-based methods yield a 22.9% event-based
F-score on the evaluation set with our MIL model. Moreover, the best results
were obtained using class-dependent parametric methods with 32.0% F-score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06926</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06926</id><created>2019-06-17</created><authors><author><keyname>Kooijman</keyname><forenames>Dave</forenames></author><author><keyname>Schoellig</keyname><forenames>Angela P.</forenames></author><author><keyname>Antunes</keyname><forenames>Duarte J.</forenames></author></authors><title>Trajectory Tracking for Quadrotors with Attitude Control on
  $\mathcal{S}^2 \times \mathcal{S}^1$</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control of a quadrotor is typically split into two subsequent problems:
finding desired accelerations to control its position, and controlling its
attitude and the total thrust to track these accelerations and to track a yaw
angle reference. While the thrust vector, generating accelerations, and the
angle of rotation about the thrust vector, determining the yaw angle, can be
controlled independently, most attitude control strategies in the literature,
relying on representations in terms of quaternions, rotation matrices or Euler
angles, result in an unnecessary coupling between the control of the thrust
vector and of the angle about this vector. This leads, for instance, to
undesired position tracking errors due to yaw tracking errors. In this paper we
propose to tackle the attitude control problem using an attitude representation
in the Cartesian product of the 2-sphere and the 1-sphere, denoted by
$\mathcal{S}^2\times \mathcal{S}^1$. We propose a non-linear tracking control
law on $\mathcal{S}^2\times \mathcal{S}^1$ that decouples the control of the
thrust vector and of the angle of rotation about the thrust vector, and
guarantees almost global asymptotic stability. Simulation results highlight the
advantages of the proposed approach over previous approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06931</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06931</id><created>2019-06-17</created><updated>2019-12-16</updated><authors><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Jan</forenames></author><author><keyname>Meggendorfer</keyname><forenames>Tobias</forenames></author></authors><title>Of Cores: A Partial-Exploration Framework for Markov Decision Processes</title><categories>eess.SY cs.AI cs.LO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a framework for approximate analysis of Markov decision
processes (MDP) with bounded-, unbounded-, and infinite-horizon properties. The
main idea is to identify a &quot;core&quot; of an MDP, i.e., a subsystem where we
provably remain with high probability, and to avoid computation on the less
relevant rest of the state space. Although we identify the core using
simulations and statistical techniques, it allows for rigorous error bounds in
the analysis. Consequently, we obtain efficient analysis algorithms based on
partial exploration for various settings, including the challenging case of
strongly connected systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06961</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06961</id><created>2019-06-17</created><authors><author><keyname>Tafro</keyname><forenames>Azra</forenames></author><author><keyname>Ser&#x161;i&#x107;</keyname><forenames>Damir</forenames></author><author><keyname>Kr&#x17e;i&#x107;</keyname><forenames>Ana Sovi&#x107;</forenames></author></authors><title>2D PET Image Reconstruction Using Robust L1 Estimation of the Gaussian
  Mixture Model</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An image or volume of interest in positron emission tomography (PET) is
reconstructed from pairs of gamma rays emitted from a radioactive substance.
Many image reconstruction methods are based on estimation of pixels or voxels
on some predefined grid. Such an approach is usually associated with limited
resolution of the reconstruction, high computational complexity due to slow
convergence and noisy results. This paper explores reconstruction of PET images
using the underlying assumption that the originals of interest can be modeled
using Gaussian mixture models. A robust segmentation method based on
statistical properties of the model is presented, with an iterative algorithm
resembling the expectation-maximization algorithm. Use of parametric models for
image description instead of pixels circumvent some of the mentioned
limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06963</identifier>
 <datestamp>2019-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06963</id><created>2019-06-17</created><updated>2019-12-18</updated><authors><author><keyname>Dvorkin</keyname><forenames>Yury</forenames></author></authors><title>A Chance-Constrained Stochastic Electricity Market</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficiently accommodating uncertain renewable resources in wholesale
electricity markets is among the foremost priorities of market regulators in
the US, UK and EU nations. However, existing deterministic market designs fail
to internalize the uncertainty and their scenario-based stochastic extensions
are limited in their ability to simultaneously maximize social welfare and
guarantee non-confiscatory market outcomes in expectation and per each
scenario. This paper proposes a chance-constrained stochastic market design,
which is capable of producing a robust competitive equilibrium and
internalizing uncertainty of the renewable resources in the price formation
process. The equilibrium and resulting prices are obtained for different
uncertainty assumptions, which requires using either linear (restrictive
assumptions) or second-order conic (more general assumptions) duality in the
price formation process. The usefulness of the proposed stochastic market
design is demonstrated via the case study carried out on the 8-zone ISO New
England testbed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06969</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06969</id><created>2019-06-17</created><authors><author><keyname>Usama</keyname><forenames>Muhammad</forenames></author><author><keyname>Chang</keyname><forenames>Dong Eui</forenames></author></authors><title>Robotic Navigation using Entropy-Based Exploration</title><categories>cs.RO cs.SY eess.SY</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robotic navigation concerns the task in which a robot should be able to find
a safe and feasible path and traverse between two points in a complex
environment. We approach the problem of robotic navigation using reinforcement
learning and use deep $Q$-networks to train agents to solve the task of robotic
navigation. We compare the Entropy-Based Exploration (EBE) with the widely used
$\epsilon$-greedy exploration strategy by training agents using both of them in
simulation. The trained agents are then tested on different versions of the
environment to test the generalization ability of the learned policies. We also
implement the learned policies on a real robot in complex real environment
without any fine tuning and compare the effectiveness of the above-mentioned
exploration strategies in the real world setting. Video showing experiments on
TurtleBot3 platform is available at \url{https://youtu.be/NHT-EiN_4n8}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06972</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06972</id><created>2019-06-17</created><authors><author><keyname>Jiang</keyname><forenames>Yifan</forenames></author><author><keyname>Gong</keyname><forenames>Xinyu</forenames></author><author><keyname>Liu</keyname><forenames>Ding</forenames></author><author><keyname>Cheng</keyname><forenames>Yu</forenames></author><author><keyname>Fang</keyname><forenames>Chen</forenames></author><author><keyname>Shen</keyname><forenames>Xiaohui</forenames></author><author><keyname>Yang</keyname><forenames>Jianchao</forenames></author><author><keyname>Zhou</keyname><forenames>Pan</forenames></author><author><keyname>Wang</keyname><forenames>Zhangyang</forenames></author></authors><title>EnlightenGAN: Deep Light Enhancement without Paired Supervision</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning-based methods have achieved remarkable success in image
restoration and enhancement, but are they still competitive when there is a
lack of paired training data? As one such example, this paper explores the
low-light image enhancement problem, where in practice it is extremely
challenging to simultaneously take a low-light and a normal-light photo of the
same visual scene. We propose a highly effective unsupervised generative
adversarial network, dubbed EnlightenGAN, that can be trained without
low/normal-light image pairs, yet proves to generalize very well on various
real-world test images. Instead of supervising the learning using ground truth
data, we propose to regularize the unpaired training using the information
extracted from the input itself, and benchmark a series of innovations for the
low-light image enhancement problem, including a global-local discriminator
structure, a self-regularized perceptual loss fusion, and attention mechanism.
Through extensive experiments, our proposed approach outperforms recent methods
under a variety of metrics in terms of visual quality and subjective user
study. Thanks to the great flexibility brought by unpaired training,
EnlightenGAN is demonstrated to be easily adaptable to enhancing real-world
images from various domains. The code is available at
\url{https://github.com/yueruchen/EnlightenGAN}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06973</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.06973</id><created>2019-06-17</created><authors><author><keyname>Horstmann</keyname><forenames>Stefanie</forenames></author><author><keyname>Ram&#xed;rez</keyname><forenames>David</forenames></author><author><keyname>Schreier</keyname><forenames>Peter J.</forenames></author></authors><title>Two-Channel Passive Detection Exploiting Cyclostationarity</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses a two-channel passive detection problem exploiting
cyclostationarity. Given a reference channel (RC) and a surveillance channel
(SC), the goal is to detect a target echo present at the surveillance array
transmitted by an illuminator of opportunity equipped with multiple antennas.
Since common transmission signals are cyclostationary, we exploit this
information at the detector. Specifically, we derive an asymptotic generalized
likelihood ratio test (GLRT) to detect the presence of a cyclostationary signal
at the SC given observations from RC and SC. This detector tests for different
covariance structures. Simulation results show good performance of the proposed
detector compared to competing techniques that do not exploit
cyclostationarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07000</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07000</id><created>2019-06-17</created><updated>2019-10-19</updated><authors><author><keyname>Dong</keyname><forenames>Fei</forenames></author><author><keyname>You</keyname><forenames>Keyou</forenames></author><author><keyname>Zhang</keyname><forenames>Jiaqi</forenames></author></authors><title>Flight Control for UAV Loitering Over a Ground Target with Unknown
  Maneuver</title><categories>eess.SY cs.SY</categories><comments>12 pages, 14 figures. Accepted by IEEE Transactions on Control
  Systems Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a flight controller for an unmanned aerial vehicle (UAV)
to loiter over a ground moving target (GMT). We are concerned with the scenario
that the stochastically time-varying maneuver of the GMT is unknown to the UAV,
which renders it challenging to estimate the GMT's motion state. Assuming that
the state of the GMT is available, we first design a discrete-time Lyapunov
vector field for the loitering guidance and then design a discrete-time
integral sliding mode control (ISMC) to track the guidance commands. By
modeling the maneuver process as a finite-state Markov chain, we propose a
Rao-Blackwellised particle filter (RBPF), which only requires a few number of
particles, to simultaneously estimate the motion state and the maneuver of the
GMT with a camera or radar sensor. Then, we apply the principle of certainty
equivalence to the ISMC and obtain the flight controller for completing the
loitering task. Finally, the effectiveness and advantages of our controller are
validated via simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07012</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07012</id><created>2019-06-17</created><updated>2019-07-15</updated><authors><author><keyname>Tiwari</keyname><forenames>Krishan Kumar</forenames></author><author><keyname>Grass</keyname><forenames>Eckhard</forenames></author><author><keyname>Thompson</keyname><forenames>John S.</forenames></author><author><keyname>Kraemer</keyname><forenames>Rolf</forenames></author></authors><title>Beam Entropy of 5G Cellular Millimetre-Wave Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>Under peer-review for IEEE VTC Fall 2019</comments><report-no>Published in Proc. of IEEE VTC2019-Fall</report-no><doi>10.1109/VTCFall.2019.8891530</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we obtain and study typical beam entropy values for millimetre
wave (mm-wave) channel models using the NYUSIM simulator for frequencies up to
100 GHz for fifth generation (5G) and beyond 5G cellular communication systems.
The beam entropy is used to quantify sparse MIMO channel randomness in
beamspace. Lower relative beam entropy channels are suitable for
memory-assisted statistically-ranked (MarS) and hybrid radio frequency (RF)
beam training algorithms. High beam entropies can potentially be advantageous
for low overhead secured radio communications by generating cryptographic keys
based on channel randomness in beamspace, especially for sparse multiple input
multiple output (MIMO) channels. Urban micro (UMi), urban macro (UMa) and rural
macro (RMa) cellular scenarios have been investigated in this work for 28, 60,
73 and 100 GHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07023</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07023</id><created>2019-06-17</created><authors><author><keyname>Ugrinovskii</keyname><forenames>Valery</forenames></author></authors><title>Distributed $H_\infty$ Estimation Resilient to Biasing Attacks</title><categories>eess.SY cs.SY</categories><comments>Accepted for publication in IEEE Transactions on Control of Network
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the distributed $H_\infty$ estimation problem with an additional
requirement of resilience to biasing attacks. An attack scenario is considered
where an adversary misappropriates some of the observer nodes and injects
biasing signals into observer dynamics. The paper proposes a procedure for the
derivation of a distributed observer which endows each node with an attack
detector which also functions as an attack compensating feedback controller for
the main observer. Connecting these controlled observers into a network results
in a distributed observer whose nodes produce unbiased robust estimates of the
plant. We show that the gains for each controlled observer in the network can
be computed in a decentralized fashion, thus reducing vulnerability of the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07084</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07084</id><created>2019-06-17</created><updated>2019-08-12</updated><authors><author><keyname>Huo</keyname><forenames>Qiang</forenames></author></authors><title>Particle Swarm Optimization for Great Enhancement in Semi-Supervised
  Retinal Vessel Segmentation with Generative Adversarial Networks</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retinal vessel segmentation based on deep learning requires a lot of manual
labeled data. That is time-consuming, laborious and professional. What is
worse, the acquisition of abundant fundus images is difficult. These problems
are more serious due to the presence of abnormalities, varying size and shape
of the vessels, non-uniform illumination and anatomical changes. In this paper,
we propose a data-efficient semi-supervised learning framework, which
effectively combines the existing deep learning network with GAN and
self-training ideas. In view of the difficulty of tuning hyper-parameters of
semi-supervised learning, we propose a method for hyper-parameters selection
based on particle swarm optimization algorithm. To the best of our knowledge,
this work is the first demonstration that combines intelligent optimization
with semi-supervised learning for achieving the best performance. Under the
collaboration of adversarial learning, self-training and PSO to select optimal
hyper-parameters, we obtain the performance of retinal vessel segmentation
approximate to or even better than representative supervised learning using
only one tenth of the labeled data from DRIVE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07091</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07091</id><created>2019-06-17</created><updated>2019-10-14</updated><authors><author><keyname>Yang</keyname><forenames>Jianlong</forenames></author><author><keyname>Liu</keyname><forenames>Peng</forenames></author><author><keyname>Duan</keyname><forenames>Lixin</forenames></author><author><keyname>Hu</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author></authors><title>Deep learning enables extraction of capillary-level angiograms from
  single OCT volume</title><categories>physics.med-ph eess.IV</categories><comments>Accepted for oral presentation at SPIE BiOS 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical coherence tomography angiography (OCTA) has drawn numerous attentions
in ophthalmology. However, its data acquisition is time-consuming, because it
is based on temporal-decorrelation principle thus requires multiple repeated
volumetric OCT scans. In this paper, we developed a deep learning algorithm by
combining a fovea attention mechanism with a residual neural network, which is
able to extract capillary-level angiograms directly from a single OCT scan. The
segmentation results of the inner limiting membrane and outer plexiform layers
and the central $1\times1$ mm$^2$ field of view of the fovea are employed in
the fovea attention mechanism. So the influences of large retinal vessels and
choroidal vasculature on the extraction of capillaries can be minimized during
the training of the network. The results demonstrate that the proposed
algorithm has the capacity to better-visualizing capillaries around the foveal
avascular zone than the existing work using a U-Net architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07093</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07093</id><created>2019-06-17</created><authors><author><keyname>Hu</keyname><forenames>Ke</forenames></author><author><keyname>Sak</keyname><forenames>Hasim</forenames></author><author><keyname>Liao</keyname><forenames>Hank</forenames></author></authors><title>Adversarial Training for Multilingual Acoustic Modeling</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multilingual training has been shown to improve acoustic modeling performance
by sharing and transferring knowledge in modeling different languages.
Knowledge sharing is usually achieved by using common lower-level layers for
different languages in a deep neural network. Recently, the domain adversarial
network was proposed to reduce domain mismatch of training data and learn
domain-invariant features. It is thus worth exploring whether adversarial
training can further promote knowledge sharing in multilingual models. In this
work, we apply the domain adversarial network to encourage the shared layers of
a multilingual model to learn language-invariant features. Bidirectional Long
Short-Term Memory (LSTM) recurrent neural networks (RNN) are used as building
blocks. We show that shared layers learned this way contain less language
identification information and lead to better performance. In an automatic
speech recognition task for seven languages, the resultant acoustic model
improves the word error rate (WER) of the multilingual model by 4% relative on
average, and the monolingual models by 10%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07109</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07109</id><created>2019-06-17</created><authors><author><keyname>Bodduna</keyname><forenames>Kireeti</forenames></author><author><keyname>Weickert</keyname><forenames>Joachim</forenames></author></authors><title>Enhancing Patch-Based Methods with Inter-frame Connectivity for
  Denoising Multi-frame Images</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3D block matching (BM3D) method is among the state-of-art methods for
denoising images corrupted with additive white Gaussian noise. With the help of
a novel inter-frame connectivity strategy, we propose an extension of the BM3D
method for the scenario where we have multiple images of the same scene. Our
proposed extension outperforms all the existing trivial and non-trivial
extensions of patch-based denoising methods for multi-frame images. We can
achieve a quality difference of as high as 28% over the next best method
without using any additional parameters. Our method can also be easily
generalised to other similar existing patch-based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07126</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07126</id><created>2019-06-17</created><authors><author><keyname>Zheng</keyname><forenames>Xiaodong</forenames></author><author><keyname>Chen</keyname><forenames>Haoyong</forenames></author><author><keyname>Xu</keyname><forenames>Yan</forenames></author><author><keyname>Shen</keyname><forenames>Feifan</forenames></author><author><keyname>Liang</keyname><forenames>Zipeng</forenames></author></authors><title>A Global Solution Method for Decentralized Multi-Area SCUC and Savings
  Allocation Based on MILP Value Functions</title><categories>eess.SY cs.SY</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To address the issue that Lagrangian dual function based algorithms cannot
guarantee convergence and global optimality for decentralized multi-area
security constrained unit commitment (M-SCUC) problems, a novel decomposition
and coordination method using MILP (mixed integer linear programming) value
functions is proposed in this paper. Each regional system operator sets the
tie-line power injections as variational parameters in its regional SCUC model,
and utilizes a finite algorithm to generate a MILP value function, which
returns the optimal generation cost for any given interchange scheduling. With
the value functions available from all system operators, theoretically, a
coordinator is able to derive a globally optimal interchange scheduling. Since
power exchanges may alter the financial position of each area considerably from
what it would have been via scheduling independently, we then propose a fair
savings allocation method using the values functions derived above and the
Shapley value in cooperative game theory. Numerical experiments on a two-area
12-bus system and a three-area 457-bus system are carried out. The validness of
the value functions based method is verified for the decentralized M-SCUC
problems. The outcome of savings allocation is compared with that of the
locational marginal cost based method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07145</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07145</id><created>2019-06-17</created><authors><author><keyname>Elowsson</keyname><forenames>Anders</forenames></author><author><keyname>Friberg</keyname><forenames>Anders</forenames></author></authors><title>Modeling Music Modality with a Key-Class Invariant Pitch Chroma CNN</title><categories>cs.SD cs.IR cs.LG eess.AS</categories><comments>Accepted for publication in ISMIR, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a convolutional neural network (CNN) that uses input from
a polyphonic pitch estimation system to predict perceived minor/major modality
in music audio. The pitch activation input is structured to allow the first CNN
layer to compute two pitch chromas focused on different octaves. The following
layers perform harmony analysis across chroma and time scales. Through max
pooling across pitch, the CNN becomes invariant with regards to the key class
(i.e., key disregarding mode) of the music. A multilayer perceptron combines
the modality activation output with spectral features for the final prediction.
The study uses a dataset of 203 excerpts rated by around 20 listeners each, a
small challenging data size requiring a carefully designed parameter sharing.
With an R2 of about 0.71, the system clearly outperforms previous systems as
well as individual human listeners. A final ablation study highlights the
importance of using pitch activations processed across longer time scales, and
using pooling to facilitate invariance with regards to the key class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07155</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07155</id><created>2019-06-17</created><authors><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Wang</keyname><forenames>Jiaqi</forenames></author><author><keyname>Pang</keyname><forenames>Jiangmiao</forenames></author><author><keyname>Cao</keyname><forenames>Yuhang</forenames></author><author><keyname>Xiong</keyname><forenames>Yu</forenames></author><author><keyname>Li</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Sun</keyname><forenames>Shuyang</forenames></author><author><keyname>Feng</keyname><forenames>Wansen</forenames></author><author><keyname>Liu</keyname><forenames>Ziwei</forenames></author><author><keyname>Xu</keyname><forenames>Jiarui</forenames></author><author><keyname>Zhang</keyname><forenames>Zheng</forenames></author><author><keyname>Cheng</keyname><forenames>Dazhi</forenames></author><author><keyname>Zhu</keyname><forenames>Chenchen</forenames></author><author><keyname>Cheng</keyname><forenames>Tianheng</forenames></author><author><keyname>Zhao</keyname><forenames>Qijie</forenames></author><author><keyname>Li</keyname><forenames>Buyu</forenames></author><author><keyname>Lu</keyname><forenames>Xin</forenames></author><author><keyname>Zhu</keyname><forenames>Rui</forenames></author><author><keyname>Wu</keyname><forenames>Yue</forenames></author><author><keyname>Dai</keyname><forenames>Jifeng</forenames></author><author><keyname>Wang</keyname><forenames>Jingdong</forenames></author><author><keyname>Shi</keyname><forenames>Jianping</forenames></author><author><keyname>Ouyang</keyname><forenames>Wanli</forenames></author><author><keyname>Loy</keyname><forenames>Chen Change</forenames></author><author><keyname>Lin</keyname><forenames>Dahua</forenames></author></authors><title>MMDetection: Open MMLab Detection Toolbox and Benchmark</title><categories>cs.CV cs.LG eess.IV</categories><comments>Technical report of MMDetection. 11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present MMDetection, an object detection toolbox that contains a rich set
of object detection and instance segmentation methods as well as related
components and modules. The toolbox started from a codebase of MMDet team who
won the detection track of COCO Challenge 2018. It gradually evolves into a
unified platform that covers many popular detection methods and contemporary
modules. It not only includes training and inference codes, but also provides
weights for more than 200 network models. We believe this toolbox is by far the
most complete detection toolbox. In this paper, we introduce the various
features of this toolbox. In addition, we also conduct a benchmarking study on
different methods, components, and their hyper-parameters. We wish that the
toolbox and benchmark could serve the growing research community by providing a
flexible toolkit to reimplement existing methods and develop their own new
detectors. Code and models are available at
https://github.com/open-mmlab/mmdetection. The project is under active
development and we will keep this document updated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07185</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07185</id><created>2019-06-17</created><authors><author><keyname>Chen</keyname><forenames>Juntao</forenames></author><author><keyname>Touati</keyname><forenames>Corinne</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>A Dynamic Game Approach to Strategic Design of Secure and Resilient
  Infrastructure Network</title><categories>eess.SY cs.GT cs.SY</categories><comments>13 pages; To appear in IEEE T-IFS. arXiv admin note: substantial text
  overlap with arXiv:1707.07054</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infrastructure networks are vulnerable to both cyber and physical attacks.
Building a secure and resilient networked system is essential for providing
reliable and dependable services. To this end, we establish a two-player
three-stage game framework to capture the dynamics in the infrastructure
protection and recovery phases. Specifically, the goal of the infrastructure
network designer is to keep the network connected before and after the attack,
while the adversary aims to disconnect the network by compromising a set of
links. With costs for creating and removing links, the two players aim to
maximize their utilities while minimizing the costs. In this paper, we use the
concept of subgame perfect equilibrium (SPE) to characterize the optimal
strategies of the network defender and attacker. We derive the SPE explicitly
in terms of system parameters. We further investigate the resilience planning
of the defender and the strategic timing of attack of the adversary. Finally,
we use case studies of UAV-enabled communication networks for disaster recovery
to corroborate the obtained analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07211</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07211</id><created>2019-06-17</created><authors><author><keyname>Wang</keyname><forenames>Junqi</forenames></author><author><keyname>Xiao</keyname><forenames>Li</forenames></author><author><keyname>Wilson</keyname><forenames>Tony W.</forenames></author><author><keyname>Stephen</keyname><forenames>Julia M.</forenames></author><author><keyname>Calhoun</keyname><forenames>Vince D.</forenames></author><author><keyname>Wang</keyname><forenames>Yu-Ping</forenames></author></authors><title>Brain Maturation Study during Adolescence Using Graph Laplacian Learning
  Based Fourier Transform</title><categories>q-bio.NC eess.SP</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Longitudinal neuroimaging studies have demonstrated that
adolescence is the crucial developmental epoch of continued brain growth and
change. A large number of researchers dedicate to uncovering the mechanisms
about brain maturity during adolescence. Motivated by both achievement in graph
signal processing and recent evidence that some brain areas act as hubs
connecting functionally specialized systems, we proposed an approach to detect
these regions from spectral analysis perspective. In particular, as human brain
undergoes substantial development throughout adolescence, we addressed the
challenge by evaluating the functional network difference among age groups from
functional magnetic resonance imaging (fMRI) observations. Methods: We treated
these observations as graph signals defined on the parcellated functional brain
regions and applied graph Laplacian learning based Fourier Transform (GLFT) to
transform the original graph signals into frequency domain. Eigen-analysis was
conducted afterwards to study the behavior of the corresponding brain regions,
which enables the characterization of brain maturation. Result: We first
evaluated our method on the synthetic data and further applied the method to
resting and task state fMRI imaging data from Philadelphia Neurodevelopmental
Cohort (PNC) dataset, comprised of normally developing adolescents from 8 to
22. The model provided a highest accuracy of 95.69% in distinguishing different
adolescence stages. Conclusion: We detected 13 hubs from resting state fMRI and
16 hubs from task state fMRI that are highly related to brain maturation
process. Significance: The proposed GLFT method is powerful in extracting the
brain connectivity patterns and identifying hub regions with a high prediction
power
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07222</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07222</id><created>2019-06-17</created><updated>2019-06-18</updated><authors><author><keyname>Zhang</keyname><forenames>Larry</forenames></author><author><keyname>Chen</keyname><forenames>Xiaotong</forenames></author><author><keyname>Vakil</keyname><forenames>Abbad</forenames></author><author><keyname>Byott</keyname><forenames>Ali</forenames></author><author><keyname>Ghomi</keyname><forenames>Reza Hosseini</forenames></author></authors><title>DigiVoice: Voice Biomarker Featurization and Analysis Pipeline</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, data-driven models have enabled significant advances in
medicine. Simultaneously, voice has shown potential for analysis in precision
medicine as a biomarker for screening illnesses. There has been a growing trend
to pursue voice data to understand neuropsychiatric diseases. In this paper, we
present DigiVoice, a comprehensive feature extraction and analysis pipeline for
voice data. DigiVoice supports raw .WAV files and text transcriptions in order
to analyze the entire content of voice. DigiVoice supports feature extraction
including acoustic, natural language, linguistic complexity, and semantic
coherence features. DigiVoice also supports machine learning capabilities
including data visualization, feature selection, feature transformation, and
modeling. To our knowledge, DigiVoice provides the most comprehensive voice
feature set for data analysis to date. With DigiVoice, we plan to accelerate
research to correlate voice biomarkers with illness to enable data-driven
treatment. We have worked closely with our industry partner, NeuroLex
Laboratories, to make voice computing open source and accessible. DigiVoice
enables researchers to leverage our technology across the domains of voice
computing and precision medicine without domain-specific expertise. Our work
allows any researchers to use voice as a biomarker in their past, current, or
future studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07233</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07233</id><created>2019-06-13</created><authors><author><keyname>Wu</keyname><forenames>Hui</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Jiao</keyname><forenames>Chunxu</forenames></author><author><keyname>Li</keyname><forenames>Chunguang</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author></authors><title>Learn to Sense: a Meta-learning Based Sensing and Fusion Framework for
  Wireless Sensor Networks</title><categories>eess.SP</categories><comments>Paper accepted for publication in IEEE Internet of Things Journal</comments><doi>10.1109/JIOT.2019.2919225</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSN) acts as the backbone of Internet of Things
(IoT) technology. In WSN, field sensing and fusion are the most commonly seen
problems, which involve collecting and processing of a huge volume of spatial
samples in an unknown field to reconstruct the field or extract its features.
One of the major concerns is how to reduce the communication overhead and data
redundancy with prescribed fusion accuracy. In this paper, an integrated
communication and computation framework based on meta-learning is proposed to
enable adaptive field sensing and reconstruction. It consists of a
stochastic-gradient-descent (SGD) based base-learner used for the field model
prediction aiming to minimize the average prediction error, and a reinforcement
meta-learner aiming to optimize the sensing decision by simultaneously
rewarding the error reduction with samples obtained so far and penalizing the
corresponding communication cost. An adaptive sensing algorithm based on the
above two-layer meta-learning framework is presented. It actively determines
the next most informative sensing location, and thus considerably reduces the
spatial samples and yields superior performance and robustness compared with
conventional schemes. The convergence behavior of the proposed algorithm is
also comprehensively analyzed and simulated. The results reveal that the
proposed field sensing algorithm significantly improves the convergence rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07234</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07234</id><created>2019-06-17</created><updated>2019-08-09</updated><authors><author><keyname>Feng</keyname><forenames>Siyuan</forenames></author><author><keyname>Lee</keyname><forenames>Tan</forenames></author><author><keyname>Peng</keyname><forenames>Zhiyuan</forenames></author></authors><title>Combining Adversarial Training and Disentangled Speech Representation
  for Robust Zero-Resource Subword Modeling</title><categories>eess.AS cs.CL cs.SD</categories><comments>5 pages, 3 figures, accepted for publication in INTERSPEECH 2019,
  Graz, Austria</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study addresses the problem of unsupervised subword unit discovery from
untranscribed speech. It forms the basis of the ultimate goal of ZeroSpeech
2019, building text-to-speech systems without text labels. In this work, unit
discovery is formulated as a pipeline of phonetically discriminative feature
learning and unit inference. One major difficulty in robust unsupervised
feature learning is dealing with speaker variation. Here the robustness towards
speaker variation is achieved by applying adversarial training and FHVAE based
disentangled speech representation learning. A comparison of the two approaches
as well as their combination is studied in a DNN-bottleneck feature (DNN-BNF)
architecture. Experiments are conducted on ZeroSpeech 2019 and 2017.
Experimental results on ZeroSpeech 2017 show that both approaches are effective
while the latter is more prominent, and that their combination brings further
marginal improvement in across-speaker condition. Results on ZeroSpeech 2019
show that in the ABX discriminability task, our approaches significantly
outperform the official baseline, and are competitive to or even outperform the
official topline. The proposed unit sequence smoothing algorithm improves
synthesis quality, at a cost of slight decrease in ABX discriminability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07245</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07245</id><created>2019-06-17</created><updated>2019-07-03</updated><authors><author><keyname>Feng</keyname><forenames>Siyuan</forenames></author><author><keyname>Lee</keyname><forenames>Tan</forenames></author></authors><title>Improving Unsupervised Subword Modeling via Disentangled Speech
  Representation Learning and Transformation</title><categories>eess.AS cs.LG cs.SD</categories><comments>5 pages, 3 figures, accepted for publication in INTERSPEECH 2019,
  Graz, Austria</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study tackles unsupervised subword modeling in the zero-resource
scenario, learning frame-level speech representation that is phonetically
discriminative and speaker-invariant, using only untranscribed speech for
target languages. Frame label acquisition is an essential step in solving this
problem. High quality frame labels should be in good consistency with golden
transcriptions and robust to speaker variation. We propose to improve frame
label acquisition in our previously adopted deep neural network-bottleneck
feature (DNN-BNF) architecture by applying the factorized hierarchical
variational autoencoder (FHVAE). FHVAEs learn to disentangle linguistic content
and speaker identity information encoded in speech. By discarding or unifying
speaker information, speaker-invariant features are learned and fed as inputs
to DPGMM frame clustering and DNN-BNF training. Experiments conducted on
ZeroSpeech 2017 show that our proposed approaches achieve $2.4\%$ and $0.6\%$
absolute ABX error rate reductions in across- and within-speaker conditions,
comparing to the baseline DNN-BNF system without applying FHVAEs. Our proposed
approaches significantly outperform vocal tract length normalization in
improving frame labeling and subword modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07258</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07258</id><created>2019-06-17</created><authors><author><keyname>Oghaz</keyname><forenames>Mahdi Maktabdar</forenames></author><author><keyname>Khadka</keyname><forenames>Anish R</forenames></author><author><keyname>Argyriou</keyname><forenames>Vasileios</forenames></author><author><keyname>Remagnino</keyname><forenames>Paolo</forenames></author></authors><title>Content-aware Density Map for Crowd Counting and Density Estimation</title><categories>cs.CV eess.IV</categories><journal-ref>32nd International Conference on Computer Animation and Social
  Agents (CASA 2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precise knowledge about the size of a crowd, its density and flow can provide
valuable information for safety and security applications, event planning,
architectural design and to analyze consumer behavior. Creating a powerful
machine learning model, to employ for such applications requires a large and
highly accurate and reliable dataset. Unfortunately the existing crowd counting
and density estimation benchmark datasets are not only limited in terms of
their size, but also lack annotation, in general too time consuming to
implement. This paper attempts to address this very issue through a content
aware technique, uses combinations of Chan-Vese segmentation algorithm,
two-dimensional Gaussian filter and brute-force nearest neighbor search. The
results shows that by simply replacing the commonly used density map generators
with the proposed method, higher level of accuracy can be achieved using the
existing state of the art models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07265</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07265</id><created>2019-06-12</created><authors><author><keyname>Levin</keyname><forenames>Keith</forenames></author><author><keyname>Lodhia</keyname><forenames>Asad</forenames></author><author><keyname>Levina</keyname><forenames>Elizaveta</forenames></author></authors><title>Recovering low-rank structure from multiple networks with unknown edge
  distributions</title><categories>math.ST cs.LG eess.SP stat.ME stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In increasingly many settings, particularly in neuroimaging, data sets
consist of multiple samples from a population of networks, with vertices
aligned across networks. For example, fMRI studies yield graphs whose vertices
correspond to brain regions, which are the same across subjects. We consider
the setting where we observe a sample of networks whose adjacency matrices have
a shared low-rank expectation, but edge-level noise distributions may vary from
one network to another. We show that so long as edge noise is sub-gamma
distributed in each network, the shared low-rank structure can be recovered
accurately using an eigenvalue truncation of a weighted network average. We
also explore the extent to which edge-level errors influence estimation and
downstream inference tasks. The proposed approach is illustrated on synthetic
networks and on an fMRI study of schizophrenia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07290</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07290</id><created>2019-06-17</created><authors><author><keyname>Chou</keyname><forenames>Tzu-Hsuan</forenames></author><author><keyname>Michelusi</keyname><forenames>Nicolo</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Krogmeier</keyname><forenames>James V.</forenames></author></authors><title>Millimeter Wave Channel Recommendation System Aided by Tensor Completion</title><categories>eess.SP</categories><comments>6 pages, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate and fast beam-alignment is important to cope with the fast-varying
environment in millimeter-wave communications. A data-driven approach is a
promising solution to reduce the training overhead by leveraging side
information and on the field measurements. In this work, a two-stage tensor
completion algorithm is proposed to predict the received power on a set of
possible users' positions, given received power measurements on a small subset
of positions; based on these predictions, a small subset of beams is
recommended to reduce the training overhead of beam-alignment, based on
positional side information. The proposed method is evaluated with the DeepMIMO
dataset, generated from Wireless Insite, which provides parameterized channels
for the experiment. The numerical results demonstrate that, with high
probability, the proposed algorithm recommends a small set of beams which
contain the best beam, thus achieving correct alignment with small training
overhead. Given power measurements on only 8 random positions out of 25, our
algorithm attains a probability of incorrect alignment of only 2%, with only
2.7% of trained beams. To the best of our knowledge, this is the first work to
consider the beam recommendation problem with only the knowledge at neighboring
positions but none at the user's position.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07295</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07295</id><created>2019-06-17</created><updated>2019-10-09</updated><authors><author><keyname>Myronenko</keyname><forenames>Andriy</forenames></author><author><keyname>Yang</keyname><forenames>Dong</forenames></author><author><keyname>Buch</keyname><forenames>Varun</forenames></author><author><keyname>Xu</keyname><forenames>Daguang</forenames></author><author><keyname>Ihsani</keyname><forenames>Alvin</forenames></author><author><keyname>Doyle</keyname><forenames>Sean</forenames></author><author><keyname>Michalski</keyname><forenames>Mark</forenames></author><author><keyname>Tenenholtz</keyname><forenames>Neil</forenames></author><author><keyname>Roth</keyname><forenames>Holger</forenames></author></authors><title>4D CNN for semantic segmentation of cardiac volumetric sequences</title><categories>eess.IV cs.CV</categories><comments>MICCAI, STACOM, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a 4D convolutional neural network (CNN) for the segmentation of
retrospective ECG-gated cardiac CT, a series of single-channel volumetric data
over time. While only a small subset of volumes in the temporal sequence is
annotated, we define a sparse loss function on available labels to allow the
network to leverage unlabeled images during training and generate a fully
segmented sequence. We investigate the accuracy of the proposed 4D network to
predict temporally consistent segmentations and compare with traditional 3D
segmentation approaches. We demonstrate the feasibility of the 4D CNN and
establish its performance on cardiac 4D CCTA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07298</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07298</id><created>2019-06-17</created><authors><author><keyname>Novoa</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Mahu</keyname><forenames>Rodrigo</forenames></author><author><keyname>D&#xed;az</keyname><forenames>Alejandro</forenames></author><author><keyname>Wuth</keyname><forenames>Jorge</forenames></author><author><keyname>Stern</keyname><forenames>Richard</forenames></author><author><keyname>Yoma</keyname><forenames>Nestor Becerra</forenames></author></authors><title>Weighted delay-and-sum beamforming guided by visual tracking for
  human-robot interaction</title><categories>eess.AS cs.SD eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper describes the integration of weighted delay-and-sum beamforming
with speech source localization using image processing and robot head visual
servoing for source tracking. We take into consideration the fact that the
directivity gain provided by the beamforming depends on the angular distance
between its main lobe and the main response axis of the microphone array. A
visual servoing scheme is used to reduce the angular distance between the
center of the video frame of a robot camera and a target object. Additionally,
the beamforming strategy presented combines two information sources: the
direction of the target object obtained with image processing and the audio
signals provided by a microphone array. These sources of information were
integrated by making use of a weighted delay-and-sum beamforming method.
Experiments were carried out with a real mobile robotic testbed built with a
PR2 robot. Static and dynamic robot head as well as the use of one and two
external noise sources were considered. The results presented here show that
the appropriate integration of visual source tracking with visual servoing and
a beamforming method can lead to a reduction in WER as high as 34% compared to
beamforming alone.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="6000" completeListSize="16166">4250076|7001</resumptionToken>
</ListRecords>
</OAI-PMH>
